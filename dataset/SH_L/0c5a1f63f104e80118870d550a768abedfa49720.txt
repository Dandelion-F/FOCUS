parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()/$anonymous1/()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testValueInspector()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testValueInspector()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/updateNull()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testValueInspector()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsNull()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testValueInspector()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testValueInspector()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/reset()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testValueInspector()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/evaluate(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testShortCircuit()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testShortCircuit()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testShortCircuit()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/Or/Or(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testShortCircuit()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testShortCircuit()/$anonymous1/()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testShortCircuit()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/And/And(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testShortCircuit()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/reset()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testShortCircuit()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/evaluate(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testAnd()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testAnd()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doAndTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testOr()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/testOr()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doOrTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doAndTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/And/And(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doAndTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doAndTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/reset()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doAndTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/evaluate(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsNull()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsNull()/$anonymous1/()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doubleMoreThan10()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doubleMoreThan10()/$anonymous1/()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doOrTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doOrTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/Or/Or(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doOrTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/reset()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doOrTest(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector,int,int,boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/evaluate(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/hadoop/example/GroupReadSupportTest/testInitWithPartialSchema()#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/hadoop/example/GroupReadSupportTest/testInitWithPartialSchema()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/example/GroupReadSupportTest/testInitWithPartialSchema()#parquet/hadoop/example/GroupReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)
parquet/hadoop/example/GroupReadSupportTest/testInitWithPartialSchema()#java/util/HashMap/HashMap()
parquet/hadoop/example/GroupReadSupportTest/testInitWithPartialSchema()#parquet/hadoop/example/GroupReadSupport/GroupReadSupport()
parquet/hadoop/example/GroupReadSupportTest/testInitWithoutSpecifyingRequestSchema()#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/hadoop/example/GroupReadSupportTest/testInitWithoutSpecifyingRequestSchema()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/example/GroupReadSupportTest/testInitWithoutSpecifyingRequestSchema()#parquet/hadoop/example/GroupReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)
parquet/hadoop/example/GroupReadSupportTest/testInitWithoutSpecifyingRequestSchema()#java/util/HashMap/HashMap()
parquet/hadoop/example/GroupReadSupportTest/testInitWithoutSpecifyingRequestSchema()#parquet/hadoop/example/GroupReadSupport/GroupReadSupport()
parquet/thrift/projection/PathGlobPatternTest/testRecursiveGlob()#parquet/thrift/projection/PathGlobPattern/matches(java.lang.CharSequence)
parquet/thrift/projection/PathGlobPatternTest/testRecursiveGlob()#parquet/thrift/projection/PathGlobPattern/PathGlobPattern(java.lang.String)
parquet/thrift/projection/PathGlobPatternTest/testStandardGlob()#parquet/thrift/projection/PathGlobPattern/matches(java.lang.CharSequence)
parquet/thrift/projection/PathGlobPatternTest/testStandardGlob()#parquet/thrift/projection/PathGlobPattern/PathGlobPattern(java.lang.String)
parquet/filter/PagedRecordFilter/page(long,long)#parquet/filter/PagedRecordFilter/page(long,long)/$anonymous1/()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveColumnsFrom(java.lang.String)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveColumnsFrom(java.lang.String)#java/lang/String/split(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveColumnsFrom(java.lang.String)#java/lang/String/length()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveColumnsFrom(java.lang.String)#java/util/Arrays/asList(T[])
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testSimpleType()#org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testConversion(java.lang.String,java.lang.String,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testConversion(java.lang.String,java.lang.String,java.lang.String)#org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveTypeInfoFrom(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testConversion(java.lang.String,java.lang.String,java.lang.String)#org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveColumnsFrom(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testConversion(java.lang.String,java.lang.String,java.lang.String)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convert(java.util.List,java.util.List)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testConversion(java.lang.String,java.lang.String,java.lang.String)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testStruct()#org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testConversion(java.lang.String,java.lang.String,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testArray()#org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testConversion(java.lang.String,java.lang.String,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMap()#org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testConversion(java.lang.String,java.lang.String,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#parquet/schema/GroupType/getFields()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveTypeInfoFrom(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveColumnsFrom(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convert(java.util.List,java.util.List)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#java/util/List/get(int)
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#parquet/schema/GroupType/getFieldCount()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#parquet/schema/Type/asGroupType()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#parquet/schema/Type/getRepetition()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#parquet/schema/Type/getName()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/testMapOriginalType()#parquet/schema/Type/getOriginalType()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveTypeInfoFrom(java.lang.String)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter/createHiveTypeInfoFrom(java.lang.String)#java/lang/String/length()
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/TwoBitPackingReader/TwoBitPackingReader(java.io.InputStream)
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/FiveBitPackingReader/FiveBitPackingReader(java.io.InputStream,long)
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/SixBitPackingReader/SixBitPackingReader(java.io.InputStream,long)
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/FourBitPackingReader/FourBitPackingReader(java.io.InputStream)
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/EightBitPackingReader/EightBitPackingReader(java.io.InputStream)
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/SevenBitPackingReader/SevenBitPackingReader(java.io.InputStream,long)
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/ZeroBitPackingReader/ZeroBitPackingReader()
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/OneBitPackingReader/OneBitPackingReader(java.io.InputStream)
parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)#parquet/column/values/bitpacking/ThreeBitPackingReader/ThreeBitPackingReader(java.io.InputStream,long)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/TwoBitPackingWriter/TwoBitPackingWriter(java.io.OutputStream)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/SevenBitPackingWriter/SevenBitPackingWriter(java.io.OutputStream)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/ThreeBitPackingWriter/ThreeBitPackingWriter(java.io.OutputStream)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/ZeroBitPackingWriter/ZeroBitPackingWriter()
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/EightBitPackingWriter/EightBitPackingWriter(java.io.OutputStream)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/SixBitPackingWriter/SixBitPackingWriter(java.io.OutputStream)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/OneBitPackingWriter/OneBitPackingWriter(java.io.OutputStream)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/FiveBitPackingWriter/FiveBitPackingWriter(java.io.OutputStream)
parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)#parquet/column/values/bitpacking/FourBitPackingWriter/FourBitPackingWriter(java.io.OutputStream)
parquet/column/values/boundedint/BitReader/readNBitInteger(int)#parquet/column/values/boundedint/BitReader/getNextByte()
parquet/column/values/boundedint/BitReader/readByte()#parquet/column/values/boundedint/BitReader/getNextByte()
parquet/column/values/boundedint/BitReader/readUnsignedVarint()#parquet/column/values/boundedint/BitReader/readByte()
parquet/column/values/boundedint/BitReader/readUnsignedVarint()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/column/values/boundedint/BitReader/readBit()#parquet/column/values/boundedint/BitReader/getNextByte()
parquet/column/values/boundedint/BitReader/readBit()#parquet/column/values/boundedint/BitReader/extractBit(int,int)
parquet/avro/AvroIndexedRecordConverter/FieldEnumConverter/addBinary(parquet.io.api.Binary)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldEnumConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/avro/AvroIndexedRecordConverter/FieldEnumConverter/addBinary(parquet.io.api.Binary)#java/lang/Enum/valueOf(java.lang.Class,java.lang.String)
parquet/pig/summary/ValueStat/add(double)#java/lang/Math/min(double,double)
parquet/pig/summary/ValueStat/add(double)#java/lang/Math/max(double,double)
parquet/pig/summary/ValueStat/merge(parquet.pig.summary.ValueStat)#java/lang/Math/min(double,double)
parquet/pig/summary/ValueStat/merge(parquet.pig.summary.ValueStat)#java/lang/Math/max(double,double)
parquet/thrift/projection/amend/ReadFieldBeginProtocol/readFieldBegin()#parquet/thrift/struct/ThriftField/getFieldId()
parquet/thrift/projection/amend/ReadFieldBeginProtocol/readFieldBegin()#parquet/thrift/struct/ThriftField/getName()
parquet/column/statistics/DoubleStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/bytes/BytesUtils/bytesToLong(byte[])
parquet/column/statistics/DoubleStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/DoubleStatistics/setMinMaxFromBytes(byte[],byte[])#java/lang/Double/longBitsToDouble(long)
parquet/column/statistics/DoubleStatistics/toString()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/statistics/DoubleStatistics/toString()#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/DoubleStatistics/toString()#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/DoubleStatistics/setMinMax(double,double)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/DoubleStatistics/getMinBytes()#java/lang/Double/doubleToLongBits(double)
parquet/column/statistics/DoubleStatistics/getMinBytes()#parquet/bytes/BytesUtils/longToBytes(long)
parquet/column/statistics/DoubleStatistics/initializeStats(double,double)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/DoubleStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/DoubleStatistics/getMin()
parquet/column/statistics/DoubleStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/DoubleStatistics/initializeStats(double,double)
parquet/column/statistics/DoubleStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/DoubleStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/DoubleStatistics/getMax()
parquet/column/statistics/DoubleStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/DoubleStatistics/updateStats(double,double)
parquet/column/statistics/DoubleStatistics/getMaxBytes()#java/lang/Double/doubleToLongBits(double)
parquet/column/statistics/DoubleStatistics/getMaxBytes()#parquet/bytes/BytesUtils/longToBytes(long)
parquet/column/statistics/DoubleStatistics/updateStats(double)#parquet/column/statistics/DoubleStatistics/updateStats(double,double)
parquet/column/statistics/DoubleStatistics/updateStats(double)#parquet/column/statistics/DoubleStatistics/initializeStats(double,double)
parquet/column/statistics/DoubleStatistics/updateStats(double)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/values/boundedint/TestBoundedColumns/b(int)#parquet/column/values/boundedint/TestBoundedColumns/b(int,int)
parquet/column/values/boundedint/TestBoundedColumns/toBinaryString(byte[],int)#java/lang/Integer/toBinaryString(int)
parquet/column/values/boundedint/TestBoundedColumns/toBinaryString(byte[],int)#java/lang/String/length()
parquet/column/values/boundedint/TestBoundedColumns/testWriterNoRepeat()#parquet/column/values/boundedint/TestBoundedColumns/b(int,int)
parquet/column/values/boundedint/TestBoundedColumns/testWriterNoRepeat()#parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])
parquet/column/values/boundedint/TestBoundedColumns/toBinaryString(byte[])#parquet/column/values/boundedint/TestBoundedColumns/toBinaryString(byte[],int)
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/column/values/boundedint/BoundedIntValuesWriter/BoundedIntValuesWriter(int,int)
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/column/values/boundedint/BoundedIntValuesWriter/writeInteger(int)
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/column/values/boundedint/TestBoundedColumns/concat(java.lang.String[])
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#java/util/Arrays/toString(int[])
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/column/values/boundedint/BoundedIntValuesReader/readInteger()
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/column/values/boundedint/BoundedIntValuesReader/BoundedIntValuesReader(int)
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/column/values/boundedint/BoundedIntValuesReader/initFromPage(int,byte[],int)
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#java/util/Arrays/toString(java.lang.Object[])
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#java/io/PrintStream/println(java.lang.String)
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/column/values/boundedint/TestBoundedColumns/toBinaryString(byte[],int)
parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])#parquet/column/values/boundedint/BoundedIntValuesWriter/getBytes()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/column/values/boundedint/BoundedIntValuesWriter/BoundedIntValuesWriter(int,int)
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/column/values/boundedint/BoundedIntValuesWriter/writeInteger(int)
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#java/io/PrintStream/println(java.lang.String)
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/column/values/boundedint/BoundedIntValuesWriter/getBytes()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/column/values/boundedint/BoundedIntValuesReader/getNextOffset()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/column/values/boundedint/BoundedIntValuesWriter/reset()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#java/io/ByteArrayOutputStream/toByteArray()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/column/values/boundedint/BoundedIntValuesReader/readInteger()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#java/io/ByteArrayOutputStream/close()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/column/values/boundedint/BoundedIntValuesReader/BoundedIntValuesReader(int)
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/column/values/boundedint/BoundedIntValuesReader/initFromPage(int,byte[],int)
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#java/util/Random/nextBoolean()
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#java/util/Random/nextInt(int)
parquet/column/values/boundedint/TestBoundedColumns/testSerDe()#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/column/values/boundedint/TestBoundedColumns/b(int,int)#java/lang/Integer/toBinaryString(int)
parquet/column/values/boundedint/TestBoundedColumns/b(int,int)#java/lang/String/length()
parquet/column/values/boundedint/TestBoundedColumns/testWriterRepeatNoRepeatAndRepeatUnderThreshold()#parquet/column/values/boundedint/TestBoundedColumns/b(int,int)
parquet/column/values/boundedint/TestBoundedColumns/testWriterRepeatNoRepeatAndRepeatUnderThreshold()#parquet/column/values/boundedint/TestBoundedColumns/b(int)
parquet/column/values/boundedint/TestBoundedColumns/testWriterRepeatNoRepeatAndRepeatUnderThreshold()#parquet/column/values/boundedint/TestBoundedColumns/compareOutput(int,int[],java.lang.String[])
parquet/avro/TestSpecificInputOutputFormat/MyMapper/run(parquet.proto.utils.Context)#parquet/avro/TestSpecificInputOutputFormat/nextRecord(int)
parquet/Preconditions/checkNotNull(T,java.lang.String)#java/lang/NullPointerException/NullPointerException(java.lang.String)
parquet/Preconditions/checkState(boolean,java.lang.String)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/Preconditions/checkArgument(boolean,java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/hadoop/codec/CodecConfigTest/testReadingCodecs()#parquet/hadoop/codec/CodecConfigTest/shouldUseParquetFlagToSetCodec(java.lang.String,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/codec/CodecConfigTest/testReadingCodecs()#parquet/hadoop/codec/CodecConfigTest/shouldUseHadoopFlagToSetCodec(java.lang.String,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/codec/CodecConfigTest/testReadingCodecs()#parquet/hadoop/metadata/CompressionCodecName/getHadoopCompressionCodecClassName()
parquet/hadoop/codec/CodecConfigTest/shouldUseParquetFlagToSetCodec(java.lang.String,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/hadoop/codec/CodecConfigTest/shouldUseParquetFlagToSetCodec(java.lang.String,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/codec/CodecConfig/from(parquet.cascading.JobConf)
parquet/hadoop/codec/CodecConfigTest/shouldUseParquetFlagToSetCodec(java.lang.String,parquet.hadoop.metadata.CompressionCodecName)#java/lang/Object/Object()
parquet/hadoop/codec/CodecConfigTest/shouldUseHadoopFlagToSetCodec(java.lang.String,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/hadoop/codec/CodecConfigTest/shouldUseHadoopFlagToSetCodec(java.lang.String,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/codec/CodecConfig/from(parquet.cascading.JobConf)
parquet/hadoop/codec/CodecConfigTest/shouldUseHadoopFlagToSetCodec(java.lang.String,parquet.hadoop.metadata.CompressionCodecName)#java/lang/Object/Object()
parquet/hadoop/TestParquetFileWriter/testMergeMetadata()#parquet/hadoop/metadata/FileMetaData/FileMetaData(parquet.schema.MessageType,java.util.Map,java.lang.String)
parquet/hadoop/TestParquetFileWriter/testMergeMetadata()#parquet/hadoop/metadata/GlobalMetaData/getSchema()
parquet/hadoop/TestParquetFileWriter/testMergeMetadata()#java/util/HashMap/HashMap()
parquet/hadoop/TestParquetFileWriter/testMergeMetadata()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/hadoop/TestParquetFileWriter/testMergeMetadata()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/hadoop/TestParquetFileWriter/testMergeMetadata()#parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData)
parquet/hadoop/TestParquetFileWriter/testConvertToThriftStatistics()#parquet/format/converter/ParquetMetadataConverter/toParquetStatistics(parquet.column.statistics.Statistics)
parquet/hadoop/TestParquetFileWriter/testConvertToThriftStatistics()#parquet/column/statistics/LongStatistics/LongStatistics()
parquet/hadoop/TestParquetFileWriter/testConvertToThriftStatistics()#parquet/column/statistics/LongStatistics/getMax()
parquet/hadoop/TestParquetFileWriter/testConvertToThriftStatistics()#parquet/column/statistics/LongStatistics/updateStats(long)
parquet/hadoop/TestParquetFileWriter/testConvertToThriftStatistics()#parquet/column/statistics/Statistics/getNumNulls()
parquet/hadoop/TestParquetFileWriter/testConvertToThriftStatistics()#parquet/format/converter/ParquetMetadataConverter/fromParquetStatistics(parquet.format.converter.Statistics,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/hadoop/TestParquetFileWriter/testConvertToThriftStatistics()#parquet/column/statistics/LongStatistics/getMin()
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#parquet/hadoop/ParquetFileReader/readFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,boolean)
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#java/io/File/getAbsoluteFile()
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#java/io/File/toURI()
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#parquet/hadoop/ParquetFileWriter/writeMetadataFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List)
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#java/lang/Object/Object()
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#java/util/List/size()
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#parquet/hadoop/ParquetFileReader/readSummaryFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#java/util/Arrays/asList(T[])
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)
parquet/hadoop/TestParquetFileWriter/testMetaDataFile()#java/io/File/File(java.lang.String)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/start()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalSize()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/endBlock()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/io/File/getAbsoluteFile()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/bytes/BytesInput/from(byte[])
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/util/List/size()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/io/File/File(java.lang.String)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/column/page/PageReadStore/getRowCount()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/util/List/get(int)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/util/HashSet/HashSet()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/util/HashSet/add(E)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/PrintFooter/main(java.lang.String[])
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileReader/ParquetFileReader(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List,java.util.List)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/ParquetFileWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.hadoop.Path)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/startBlock(long)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/util/Arrays/asList(T[])
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/TestParquetFileWriter/validateContains(parquet.schema.MessageType,parquet.column.page.PageReadStore,java.lang.String[],int,parquet.bytes.BytesInput)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/util/HashMap/HashMap()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/end(java.util.Map)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/endColumn()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/io/File/toURI()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileReader/readNextRowGroup()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/metadata/BlockMetaData/getTotalByteSize()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/ParquetFileWriter/getPos()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#parquet/hadoop/metadata/ColumnChunkMetaData/getEncodings()
parquet/hadoop/TestParquetFileWriter/testWriteRead()#java/io/File/delete()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#java/io/File/getName()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#java/lang/String/valueOf(java.lang.Object)
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#parquet/hadoop/Footer/getFile()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#java/util/List/size()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#java/io/File/exists()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#java/io/File/File(java.lang.String)
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#java/lang/String/startsWith(java.lang.String)
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#parquet/hadoop/Footer/getParquetMetadata()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#java/util/Map/get(java.lang.Object)
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#parquet/hadoop/metadata/FileMetaData/getKeyValueMetaData()
parquet/hadoop/TestParquetFileWriter/validateFooters(java.util.List)#java/io/File/getPath()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileWriter/start()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/bytes/BytesInput/from(byte[])
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/column/statistics/LongStatistics/setMinMax(long,long)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#java/io/File/File(java.lang.String)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#java/util/List/get(int)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#java/io/File/delete()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/column/statistics/LongStatistics/LongStatistics()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileWriter/ParquetFileWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.hadoop.Path)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileWriter/startBlock(long)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileWriter/endBlock()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/column/statistics/Statistics/equals(parquet.column.statistics.Statistics)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#java/io/File/getAbsoluteFile()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/column/statistics/BinaryStatistics/getMinBytes()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#java/util/HashMap/HashMap()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileWriter/end(java.util.Map)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileWriter/endColumn()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#java/lang/String/String(byte[])
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#java/io/File/toURI()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/column/statistics/BinaryStatistics/getMaxBytes()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/column/statistics/BinaryStatistics/setMinMax(parquet.io.api.Binary,parquet.io.api.Binary)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/TestParquetFileWriter/testWriteReadStatistics()#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/start()
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/ParquetFileWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.hadoop.Path)
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#java/util/HashMap/put(K,V)
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/endBlock()
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/bytes/BytesInput/from(byte[])
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/startBlock(long)
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#java/util/HashMap/HashMap()
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/end(java.util.Map)
parquet/hadoop/TestParquetFileWriter/createFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/endColumn()
parquet/hadoop/TestParquetFileWriter/validateContains(parquet.schema.MessageType,parquet.column.page.PageReadStore,java.lang.String[],int,parquet.bytes.BytesInput)#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/hadoop/TestParquetFileWriter/validateContains(parquet.schema.MessageType,parquet.column.page.PageReadStore,java.lang.String[],int,parquet.bytes.BytesInput)#parquet/column/page/Page/getBytes()
parquet/hadoop/TestParquetFileWriter/validateContains(parquet.schema.MessageType,parquet.column.page.PageReadStore,java.lang.String[],int,parquet.bytes.BytesInput)#parquet/column/page/Page/getValueCount()
parquet/hadoop/TestParquetFileWriter/validateContains(parquet.schema.MessageType,parquet.column.page.PageReadStore,java.lang.String[],int,parquet.bytes.BytesInput)#parquet/column/page/PageReadStore/getPageReader(parquet.column.ColumnDescriptor)
parquet/hadoop/TestParquetFileWriter/validateContains(parquet.schema.MessageType,parquet.column.page.PageReadStore,java.lang.String[],int,parquet.bytes.BytesInput)#parquet/column/page/PageReader/readPage()
parquet/hadoop/TestParquetFileWriter/validateContains(parquet.schema.MessageType,parquet.column.page.PageReadStore,java.lang.String[],int,parquet.bytes.BytesInput)#parquet/bytes/BytesInput/toByteArray()
parquet/hadoop/metadata/EncodingList/hashCode()#java/lang/Enum/hashCode()
parquet/hadoop/metadata/EncodingList/size()#java/util/List/size()
parquet/hadoop/metadata/EncodingList/getEncodingList(java.util.List)#parquet/hadoop/metadata/EncodingList/EncodingList(java.util.List)
parquet/hadoop/metadata/EncodingList/getEncodingList(java.util.List)#parquet/common/internal/Canonicalizer/canonicalize(T)
parquet/hadoop/metadata/EncodingList/iterator()#java/util/List/iterator()
parquet/hadoop/metadata/EncodingList/equals(java.lang.Object)#java/lang/Enum/equals(java.lang.Object)
parquet/hadoop/metadata/EncodingList/equals(java.lang.Object)#java/util/List/size()
parquet/hadoop/metadata/EncodingList/equals(java.lang.Object)#java/util/List/get(int)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/column/ColumnDescriptor/getType()
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#java/io/IOException/IOException(java.lang.String)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/hadoop/ParquetFileReader/Chunk/readAsBytesInput(int)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#java/util/List/size()
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/hadoop/metadata/ColumnChunkMetaData/getCodec()
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#java/util/List/add(E)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/hadoop/CodecFactory/getDecompressor(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/hadoop/ParquetFileReader/Chunk/pos()
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,int,parquet.column.Encoding)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.format.converter.Encoding)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/hadoop/metadata/ColumnChunkMetaData/getValueCount()
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/format/converter/ParquetMetadataConverter/fromParquetStatistics(parquet.format.converter.Statistics,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#java/io/ByteArrayInputStream/skip(long)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/hadoop/ParquetFileReader/Chunk/readPageHeader()
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/column/page/Page/Page(parquet.bytes.BytesInput,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/hadoop/ParquetFileReader/Chunk/readAllPages()#parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/ColumnChunkPageReader(parquet.hadoop.CodecFactory.BytesDecompressor,java.util.List,parquet.column.page.DictionaryPage)
parquet/hadoop/ParquetFileReader/Chunk/readAsBytesInput(int)#parquet/bytes/BytesInput/from(byte[],int,int)
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#java/nio/Buffer/limit(int)
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#java/nio/Buffer/position()
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#java/nio/ByteBuffer/put(java.nio.ByteBuffer)
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#parquet/hadoop/codec/SnappyUtil/validateBuffer(byte[],int,int)
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#java/nio/ByteBuffer/allocateDirect(int)
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#java/nio/Buffer/capacity()
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#java/nio/Buffer/hasRemaining()
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#java/nio/ByteBuffer/put(byte[],int,int)
parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)#java/nio/Buffer/rewind()
parquet/hadoop/codec/SnappyCompressor/reinit(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/codec/SnappyCompressor/reset()
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/Buffer/clear()
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/ByteBuffer/get(byte[],int,int)
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/Buffer/limit(int)
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/Buffer/position()
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/Buffer/remaining()
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/Buffer/position(int)
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#parquet/hadoop/codec/SnappyUtil/validateBuffer(byte[],int,int)
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#parquet/hadoop/codec/SnappyCompressor/needsInput()
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/ByteBuffer/allocateDirect(int)
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/Buffer/rewind()
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/Buffer/hasRemaining()
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/nio/Buffer/capacity()
parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)#java/lang/Math/min(int,int)
parquet/hadoop/codec/SnappyCompressor/finished()#java/nio/Buffer/position()
parquet/hadoop/codec/SnappyCompressor/finished()#java/nio/Buffer/hasRemaining()
parquet/hadoop/codec/SnappyCompressor/reset()#java/nio/Buffer/limit(int)
parquet/hadoop/codec/SnappyCompressor/reset()#java/nio/Buffer/rewind()
parquet/hadoop/TestSnappyCodec/TestSnappyStream()#parquet/hadoop/codec/SnappyCodec/createInputStream(java.io.InputStream)
parquet/hadoop/TestSnappyCodec/TestSnappyStream()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/hadoop/TestSnappyCodec/TestSnappyStream()#java/io/ByteArrayOutputStream/toByteArray()
parquet/hadoop/TestSnappyCodec/TestSnappyStream()#java/lang/Math/min(int,int)
parquet/hadoop/TestSnappyCodec/TestSnappyStream()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/hadoop/TestSnappyCodec/TestSnappyStream()#parquet/hadoop/codec/SnappyCodec/createOutputStream(java.io.OutputStream)
parquet/hadoop/TestSnappyCodec/TestSnappyStream()#parquet/hadoop/codec/SnappyCodec/SnappyCodec()
parquet/hadoop/TestSnappyCodec/TestSnappyStream()#parquet/hadoop/codec/SnappyCodec/setConf(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyCompressor/setInput(byte[],int,int)
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#java/lang/String/length()
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyDecompressor/needsInput()
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyCompressor/needsInput()
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyDecompressor/finished()
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyDecompressor/reset()
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyCompressor/compress(byte[],int,int)
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyCompressor/finished()
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#java/lang/String/getBytes()
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#java/lang/System/arraycopy(java.lang.Object,int,java.lang.Object,int,int)
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyCompressor/finish()
parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])#parquet/hadoop/codec/SnappyCompressor/reset()
parquet/hadoop/TestSnappyCodec/TestSnappy()#parquet/hadoop/TestSnappyCodec/TestSnappy(parquet.hadoop.codec.SnappyCompressor,parquet.hadoop.codec.SnappyDecompressor,java.lang.String[])
parquet/hadoop/TestSnappyCodec/TestSnappy()#parquet/hadoop/codec/SnappyDecompressor/SnappyDecompressor()
parquet/hadoop/TestSnappyCodec/TestSnappy()#parquet/hadoop/codec/SnappyCompressor/SnappyCompressor()
parquet/thrift/pig/ParquetThriftStorer/getOutputFormat()#parquet/hadoop/ParquetOutputFormat/ParquetOutputFormat(S)
parquet/thrift/pig/ParquetThriftStorer/getOutputFormat()#parquet/thrift/pig/TupleToThriftWriteSupport/TupleToThriftWriteSupport(java.lang.String)
parquet/thrift/pig/ParquetThriftStorer/putNext(parquet.pig.convert.Tuple)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/avro/AvroIndexedRecordConverter/MapConverter/MapKeyValueConverter/end()#java/util/Map/put(K,V)
parquet/avro/AvroIndexedRecordConverter/MapConverter/MapKeyValueConverter/getConverter(int)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/BoolType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.BoolType)
parquet/hadoop/metadata/GlobalMetaData/merge()#parquet/hadoop/metadata/FileMetaData/FileMetaData(parquet.schema.MessageType,java.util.Map,java.lang.String)
parquet/hadoop/metadata/GlobalMetaData/merge()#java/lang/Object/toString()
parquet/hadoop/metadata/GlobalMetaData/merge()#java/util/Map/Entry/getValue()
parquet/hadoop/metadata/GlobalMetaData/merge()#java/util/Set/size()
parquet/hadoop/metadata/GlobalMetaData/merge()#java/util/Map/Entry/getKey()
parquet/hadoop/metadata/GlobalMetaData/merge()#java/util/Set/iterator()
parquet/hadoop/metadata/GlobalMetaData/merge()#java/util/Map/entrySet()
parquet/hadoop/metadata/GlobalMetaData/merge()#java/util/Iterator/next()
parquet/hadoop/metadata/GlobalMetaData/merge()#java/util/HashMap/HashMap()
parquet/hadoop/metadata/GlobalMetaData/merge()#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/metadata/GlobalMetaData/merge()#java/util/Map/put(K,V)
parquet/filter2/predicate/Operators/ColumnFilterPredicate/hashCode()#parquet/filter2/predicate/Operators/Column/hashCode()
parquet/filter2/predicate/Operators/ColumnFilterPredicate/hashCode()#java/lang/Object/hashCode()
parquet/filter2/predicate/Operators/ColumnFilterPredicate/hashCode()#java/lang/Object/getClass()
parquet/filter2/predicate/Operators/ColumnFilterPredicate/equals(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
parquet/filter2/predicate/Operators/ColumnFilterPredicate/equals(java.lang.Object)#parquet/filter2/predicate/Operators/Column/equals(java.lang.Object)
parquet/filter2/predicate/Operators/ColumnFilterPredicate/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/pig/PigMetaData/getPigSchemas(java.util.Map)#java/util/Map/get(java.lang.Object)
parquet/pig/PigMetaData/fromMetaData(java.util.Map)#java/util/Map/get(java.lang.Object)
parquet/pig/PigMetaData/fromMetaData(java.util.Map)#parquet/pig/PigMetaData/PigMetaData(java.lang.String)
parquet/pig/PigMetaData/fromMetaData(java.util.Map)#java/util/Map/containsKey(java.lang.Object)
parquet/pig/PigMetaData/addToMetaData(java.util.Map)#java/util/Map/put(K,V)
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#java/io/PrintStream/println(java.lang.String)
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#parquet/thrift/struct/CompatibilityChecker/checkCompatibility(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#parquet/thrift/struct/CompatibilityReport/getMessages()
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#java/io/PrintStream/println(java.lang.Object)
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#parquet/thrift/struct/CompatibilityRunner/checkExist(java.io.File)
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#java/lang/System/exit(int)
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#java/io/File/File(java.lang.String)
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#parquet/thrift/struct/CompatibilityChecker/CompatibilityChecker()
parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)#java/util/LinkedList/pollFirst()
parquet/thrift/struct/CompatibilityRunner/generateJson(java.util.LinkedList)#java/lang/Class/forName(java.lang.String)
parquet/thrift/struct/CompatibilityRunner/generateJson(java.util.LinkedList)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/struct/CompatibilityRunner/generateJson(java.util.LinkedList)#java/io/File/File(java.io.File,java.lang.String)
parquet/thrift/struct/CompatibilityRunner/generateJson(java.util.LinkedList)#java/io/File/File(java.lang.String)
parquet/thrift/struct/CompatibilityRunner/generateJson(java.util.LinkedList)#java/util/LinkedList/pollFirst()
parquet/thrift/struct/CompatibilityRunner/generateJson(java.util.LinkedList)#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/struct/CompatibilityRunner/main(java.lang.String[])#parquet/thrift/struct/CompatibilityRunner/compareJson(java.util.LinkedList)
parquet/thrift/struct/CompatibilityRunner/main(java.lang.String[])#parquet/thrift/struct/CompatibilityRunner/generateJson(java.util.LinkedList)
parquet/thrift/struct/CompatibilityRunner/main(java.lang.String[])#java/util/Arrays/asList(T[])
parquet/thrift/struct/CompatibilityRunner/main(java.lang.String[])#java/lang/String/equals(java.lang.Object)
parquet/thrift/struct/CompatibilityRunner/main(java.lang.String[])#java/util/LinkedList/pollFirst()
parquet/thrift/struct/CompatibilityRunner/main(java.lang.String[])#java/util/LinkedList/LinkedList(java.util.Collection)
parquet/thrift/struct/CompatibilityRunner/checkExist(java.io.File)#java/io/File/exists()
parquet/thrift/struct/CompatibilityRunner/checkExist(java.io.File)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/avro/AvroIndexedRecordConverter/FieldFloatConverter/addInt(int)#java/lang/Float/valueOf(float)
parquet/avro/AvroIndexedRecordConverter/FieldFloatConverter/addInt(int)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldFloatConverter/addFloat(float)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldFloatConverter/addLong(long)#java/lang/Float/valueOf(float)
parquet/avro/AvroIndexedRecordConverter/FieldFloatConverter/addLong(long)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/hadoop/codec/SnappyDecompressor/needsInput()#java/nio/Buffer/hasRemaining()
parquet/hadoop/codec/SnappyDecompressor/finished()#java/nio/Buffer/hasRemaining()
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/Buffer/clear()
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/ByteBuffer/get(byte[],int,int)
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/Buffer/limit(int)
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/Buffer/position()
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/Buffer/remaining()
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#parquet/hadoop/codec/SnappyUtil/validateBuffer(byte[],int,int)
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/ByteBuffer/allocateDirect(int)
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/Buffer/rewind()
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/Buffer/hasRemaining()
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/nio/Buffer/capacity()
parquet/hadoop/codec/SnappyDecompressor/decompress(byte[],int,int)#java/lang/Math/min(int,int)
parquet/hadoop/codec/SnappyDecompressor/reset()#java/nio/Buffer/limit(int)
parquet/hadoop/codec/SnappyDecompressor/reset()#java/nio/Buffer/rewind()
parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)#java/nio/Buffer/limit(int)
parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)#java/nio/Buffer/position()
parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)#java/nio/ByteBuffer/put(java.nio.ByteBuffer)
parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)#parquet/hadoop/codec/SnappyUtil/validateBuffer(byte[],int,int)
parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)#java/nio/ByteBuffer/allocateDirect(int)
parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)#java/nio/Buffer/capacity()
parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)#java/nio/ByteBuffer/put(byte[],int,int)
parquet/hadoop/codec/SnappyDecompressor/setInput(byte[],int,int)#java/nio/Buffer/rewind()
parquet/thrift/struct/ThriftType/ComplexTypeVisitor/visit(parquet.thrift.struct.ThriftType.BoolType)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/ComplexTypeVisitor/visit(parquet.thrift.struct.ThriftType.I32Type)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/ComplexTypeVisitor/visit(parquet.thrift.struct.ThriftType.StringType)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/ComplexTypeVisitor/visit(parquet.thrift.struct.ThriftType.DoubleType)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/ComplexTypeVisitor/visit(parquet.thrift.struct.ThriftType.I16Type)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/ComplexTypeVisitor/visit(parquet.thrift.struct.ThriftType.ByteType)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/ComplexTypeVisitor/visit(parquet.thrift.struct.ThriftType.I64Type)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/ComplexTypeVisitor/visit(parquet.thrift.struct.ThriftType.EnumType)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter/end()#org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/add(int,org.apache.hadoop.hive.ql.io.parquet.Writable)
org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter/end()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter/add(int,org.apache.hadoop.hive.ql.io.parquet.Writable)#org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter/set(int,org.apache.hadoop.hive.ql.io.parquet.Writable)
org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter/set(int,org.apache.hadoop.hive.ql.io.parquet.Writable)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/thrift/ThriftParquetReader/build(parquet.hadoop.Path)#parquet/thrift/ThriftParquetReader/Builder/Builder(parquet.hadoop.Path)
parquet/column/values/dictionary/IntList/add(int)#parquet/column/values/dictionary/IntList/initSlab()
parquet/column/values/dictionary/IntList/add(int)#java/util/List/add(E)
parquet/column/values/dictionary/IntList/size()#java/util/List/size()
parquet/column/values/dictionary/IntList/iterator()#java/util/List/toArray(T[])
parquet/column/values/dictionary/IntList/iterator()#java/util/List/size()
parquet/column/values/dictionary/IntList/iterator()#parquet/column/values/dictionary/IntList/IntIterator/IntIterator(int[][],int)
parquet/column/values/deltastrings/TestDeltaByteArray/testLengths()#parquet/column/values/deltastrings/DeltaByteArrayWriter/DeltaByteArrayWriter(int)
parquet/column/values/deltastrings/TestDeltaByteArray/testLengths()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/DeltaBinaryPackingValuesReader()
parquet/column/values/deltastrings/TestDeltaByteArray/testLengths()#parquet/column/values/ValuesReader/getNextOffset()
parquet/column/values/deltastrings/TestDeltaByteArray/testLengths()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltastrings/TestDeltaByteArray/testLengths()#parquet/column/values/deltastrings/DeltaByteArrayWriter/getBytes()
parquet/column/values/deltastrings/TestDeltaByteArray/testLengths()#parquet/column/values/Utils/readInts(parquet.column.values.ValuesReader,byte[],int,int)
parquet/column/values/deltastrings/TestDeltaByteArray/testLengths()#parquet/column/values/Utils/readInts(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltastrings/TestDeltaByteArray/testLengths()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/deltastrings/TestDeltaByteArray/testSerialization()#parquet/column/values/deltastrings/DeltaByteArrayWriter/DeltaByteArrayWriter(int)
parquet/column/values/deltastrings/TestDeltaByteArray/testSerialization()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltastrings/TestDeltaByteArray/testSerialization()#parquet/column/values/deltastrings/DeltaByteArrayReader/DeltaByteArrayReader()
parquet/column/values/deltastrings/TestDeltaByteArray/testSerialization()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/deltastrings/TestDeltaByteArray/testSerialization()#parquet/column/values/deltastrings/DeltaByteArrayWriter/getBytes()
parquet/column/values/deltastrings/TestDeltaByteArray/testSerialization()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltastrings/TestDeltaByteArray/testSerialization()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/deltastrings/TestDeltaByteArray/testRandomStrings()#parquet/column/values/deltastrings/DeltaByteArrayWriter/DeltaByteArrayWriter(int)
parquet/column/values/deltastrings/TestDeltaByteArray/testRandomStrings()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltastrings/TestDeltaByteArray/testRandomStrings()#parquet/column/values/deltastrings/DeltaByteArrayReader/DeltaByteArrayReader()
parquet/column/values/deltastrings/TestDeltaByteArray/testRandomStrings()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/deltastrings/TestDeltaByteArray/testRandomStrings()#parquet/column/values/deltastrings/DeltaByteArrayWriter/getBytes()
parquet/column/values/deltastrings/TestDeltaByteArray/testRandomStrings()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltastrings/TestDeltaByteArray/testRandomStrings()#parquet/bytes/BytesInput/toByteArray()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addInt(int)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/startField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addInt(int)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/endField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addInt(int)#parquet/io/api/PrimitiveConverter/addInt(int)
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addFloat(float)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/startField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addFloat(float)#parquet/io/api/PrimitiveConverter/addFloat(float)
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addFloat(float)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/endField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addDouble(double)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/startField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addDouble(double)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/endField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addDouble(double)#parquet/io/api/PrimitiveConverter/addDouble(double)
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addBoolean(boolean)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/startField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addBoolean(boolean)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/endField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addBoolean(boolean)#parquet/io/api/PrimitiveConverter/addBoolean(boolean)
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addLong(long)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/startField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addLong(long)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/endField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addLong(long)#parquet/io/api/PrimitiveConverter/addLong(long)
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addBinary(parquet.io.api.Binary)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/startField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addBinary(parquet.io.api.Binary)#parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/endField()
parquet/thrift/ThriftRecordConverter/PrimitiveFieldHandler/addBinary(parquet.io.api.Binary)#parquet/io/api/PrimitiveConverter/addBinary(parquet.io.api.Binary)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/align(int,int)#java/lang/StringBuilder/append(java.lang.String)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/align(int,int)#java/lang/String/length()
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/align(int,int)#java/lang/StringBuilder/StringBuilder()
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/align(int,int)#java/lang/StringBuilder/toString()
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/align(int,int)#java/lang/String/valueOf(int)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/getUnpackShiftString(int,int,boolean)#parquet/encoding/bitpacking/IntBasedBitPackingGenerator/align(int,int)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/getPackShiftString(int,int,int,int,boolean)#parquet/encoding/bitpacking/IntBasedBitPackingGenerator/align(int,int)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)#parquet/encoding/bitpacking/IntBasedBitPackingGenerator/align(int,int)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)#parquet/encoding/bitpacking/IntBasedBitPackingGenerator/getUnpackShiftString(int,int,boolean)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)#parquet/encoding/bitpacking/IntBasedBitPackingGenerator/getPackShiftString(int,int,int,int,boolean)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)#java/io/Writer/append(java.lang.CharSequence)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/Writer/append(java.lang.CharSequence)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/getAbsoluteFile()
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/exists()
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/File(java.lang.String)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/OutputStreamWriter/close()
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/mkdirs()
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/FileWriter/FileWriter(java.io.File)
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/getParentFile()
parquet/encoding/bitpacking/IntBasedBitPackingGenerator/main(java.lang.String[])#parquet/encoding/bitpacking/IntBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)
parquet/avro/AvroParquetInputFormat/setRequestedProjection(parquet.proto.utils.Job,parquet.pig.convert.Schema)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/avro/AvroParquetInputFormat/setRequestedProjection(parquet.proto.utils.Job,parquet.pig.convert.Schema)#parquet/avro/AvroReadSupport/setRequestedProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.pig.convert.Schema)
parquet/avro/AvroParquetInputFormat/setAvroReadSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)#parquet/avro/AvroReadSupport/setAvroReadSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.pig.convert.Schema)
parquet/avro/AvroParquetInputFormat/setAvroReadSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/column/values/dictionary/PlainValuesDictionary/PlainIntegerDictionary/toString()#java/lang/StringBuilder/append(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainIntegerDictionary/toString()#java/lang/StringBuilder/append(int)
parquet/column/values/dictionary/PlainValuesDictionary/PlainIntegerDictionary/toString()#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainIntegerDictionary/toString()#java/lang/StringBuilder/toString()
parquet/avro/TestSpecificReadWrite/testAvroReadSchema()#parquet/avro/AvroReadSupport/setAvroReadSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.pig.convert.Schema)
parquet/avro/TestSpecificReadWrite/testAvroReadSchema()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path,parquet.filter.UnboundRecordFilter)
parquet/avro/TestSpecificReadWrite/testAvroReadSchema()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean)
parquet/avro/TestSpecificReadWrite/testFilterWithDictionary()#parquet/filter/ColumnPredicates/equalTo(java.lang.String)
parquet/avro/TestSpecificReadWrite/testFilterWithDictionary()#parquet/avro/TestSpecificReadWrite/getVwPolo()
parquet/avro/TestSpecificReadWrite/testFilterWithDictionary()#parquet/avro/TestSpecificReadWrite/getVwPassat()
parquet/avro/TestSpecificReadWrite/testFilterWithDictionary()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path,parquet.filter.UnboundRecordFilter)
parquet/avro/TestSpecificReadWrite/testFilterWithDictionary()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/avro/TestSpecificReadWrite/testFilterWithDictionary()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean)
parquet/avro/TestSpecificReadWrite/testReadWriteSpecificWithDictionary()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestSpecificReadWrite/testReadWriteSpecificWithDictionary()#parquet/avro/TestSpecificReadWrite/getVwPolo()
parquet/avro/TestSpecificReadWrite/testReadWriteSpecificWithDictionary()#parquet/avro/TestSpecificReadWrite/getVwPassat()
parquet/avro/TestSpecificReadWrite/testReadWriteSpecificWithDictionary()#parquet/avro/TestSpecificReadWrite/getBmwMini()
parquet/avro/TestSpecificReadWrite/testReadWriteSpecificWithDictionary()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean)
parquet/avro/TestSpecificReadWrite/testReadWriteSpecific()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestSpecificReadWrite/testReadWriteSpecific()#parquet/avro/TestSpecificReadWrite/getVwPolo()
parquet/avro/TestSpecificReadWrite/testReadWriteSpecific()#parquet/avro/TestSpecificReadWrite/getVwPassat()
parquet/avro/TestSpecificReadWrite/testReadWriteSpecific()#parquet/avro/TestSpecificReadWrite/getBmwMini()
parquet/avro/TestSpecificReadWrite/testReadWriteSpecific()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean)
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#java/lang/Class/getSimpleName()
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#parquet/filter/ColumnPredicates/equalTo(java.lang.String)
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#parquet/avro/TestSpecificReadWrite/getVwPolo()
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#parquet/avro/TestSpecificReadWrite/getVwPassat()
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#parquet/avro/AvroParquetWriter/AvroParquetWriter(parquet.hadoop.Path,parquet.pig.convert.Schema,parquet.hadoop.metadata.CompressionCodecName,int,int,boolean)
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path,parquet.filter.UnboundRecordFilter)
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#parquet/avro/TestSpecificReadWrite/getBmwMini()
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#java/lang/Object/getClass()
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#java/io/File/deleteOnExit()
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#java/io/File/delete()
parquet/avro/TestSpecificReadWrite/testFilterMatchesFinalBlockOnly()#java/io/File/getPath()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean)#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)
parquet/avro/TestSpecificReadWrite/testFilterMatchesNoBlocks()#parquet/filter/ColumnPredicates/equalTo(java.lang.String)
parquet/avro/TestSpecificReadWrite/testFilterMatchesNoBlocks()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path,parquet.filter.UnboundRecordFilter)
parquet/avro/TestSpecificReadWrite/testFilterMatchesNoBlocks()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/avro/TestSpecificReadWrite/testFilterMatchesNoBlocks()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)
parquet/avro/TestSpecificReadWrite/getVwPolo()#java/lang/String/getBytes()
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultiple()#parquet/filter/ColumnPredicates/equalTo(java.lang.String)
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultiple()#parquet/avro/TestSpecificReadWrite/getVwPolo()
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultiple()#parquet/avro/TestSpecificReadWrite/getVwPassat()
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultiple()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path,parquet.filter.UnboundRecordFilter)
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultiple()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultiple()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean)
parquet/avro/TestSpecificReadWrite/testProjection()#java/util/ArrayList/ArrayList()
parquet/avro/TestSpecificReadWrite/testProjection()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path,parquet.filter.UnboundRecordFilter)
parquet/avro/TestSpecificReadWrite/testProjection()#java/lang/String/equals(java.lang.Object)
parquet/avro/TestSpecificReadWrite/testProjection()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean)
parquet/avro/TestSpecificReadWrite/testProjection()#java/lang/Object/Object()
parquet/avro/TestSpecificReadWrite/testProjection()#parquet/avro/AvroReadSupport/setRequestedProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.pig.convert.Schema)
parquet/avro/TestSpecificReadWrite/getVwPassat()#java/lang/String/getBytes()
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/filter/ColumnPredicates/equalTo(float)
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/filter/ColumnPredicates/equalTo(java.lang.String)
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/avro/TestSpecificReadWrite/getVwPolo()
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/avro/TestSpecificReadWrite/getVwPassat()
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path,parquet.filter.UnboundRecordFilter)
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/avro/TestSpecificReadWrite/getBmwMini()
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean)
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/avro/TestSpecificReadWrite/testFilterOnSubAttribute()#parquet/filter/ColumnPredicates/equalTo(boolean)
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultipleBlocks()#parquet/filter/ColumnPredicates/equalTo(java.lang.String)
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultipleBlocks()#parquet/avro/TestSpecificReadWrite/getVwPolo()
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultipleBlocks()#parquet/avro/TestSpecificReadWrite/getVwPassat()
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultipleBlocks()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path,parquet.filter.UnboundRecordFilter)
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultipleBlocks()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/avro/TestSpecificReadWrite/testFilterMatchesMultipleBlocks()#parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)
parquet/avro/TestSpecificReadWrite/getBmwMini()#java/lang/String/getBytes()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#java/lang/Class/getSimpleName()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#parquet/avro/TestSpecificReadWrite/getVwPolo()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#parquet/avro/TestSpecificReadWrite/getVwPassat()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#parquet/avro/AvroParquetWriter/AvroParquetWriter(parquet.hadoop.Path,parquet.pig.convert.Schema,parquet.hadoop.metadata.CompressionCodecName,int,int,boolean)
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#parquet/avro/TestSpecificReadWrite/getBmwMini()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#java/lang/Object/getClass()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#java/io/File/deleteOnExit()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#java/io/File/delete()
parquet/avro/TestSpecificReadWrite/writeCarsToParquetFile(int,parquet.hadoop.metadata.CompressionCodecName,boolean,int,int)#java/io/File/getPath()
parquet/pig/summary/Summary/setUDFContextSignature(java.lang.String)#parquet/pig/summary/Summary/saveSchemaToUDFContext()
parquet/pig/summary/Summary/merge(parquet.pig.convert.Tuple)#parquet/pig/summary/Summary/getData(parquet.pig.convert.Tuple)
parquet/pig/summary/Summary/merge(parquet.pig.convert.Tuple)#parquet/pig/summary/TupleSummaryData/merge(parquet.pig.summary.SummaryData)
parquet/pig/summary/Summary/merge(parquet.pig.convert.Tuple)#parquet/pig/summary/TupleSummaryData/TupleSummaryData()
parquet/pig/summary/Summary/getIntermed()#java/lang/Class/getName()
parquet/pig/summary/Summary/sumUp(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)
parquet/pig/summary/Summary/sumUp(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/TupleSummaryData/TupleSummaryData()
parquet/pig/summary/Summary/getInputSchema(java.lang.String)#java/util/Properties/getProperty(java.lang.String)
parquet/pig/summary/Summary/getInputSchema(java.lang.String)#parquet/pig/summary/Summary/getProperties(java.lang.String)
parquet/pig/summary/Summary/getInputSchema(java.lang.String)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/summary/Summary/saveSchemaToUDFContext()#java/lang/String/length()
parquet/pig/summary/Summary/saveSchemaToUDFContext()#parquet/pig/summary/Summary/getProperties(java.lang.String)
parquet/pig/summary/Summary/saveSchemaToUDFContext()#java/lang/String/substring(int,int)
parquet/pig/summary/Summary/saveSchemaToUDFContext()#java/util/Hashtable/put(K,V)
parquet/pig/summary/Summary/exec(parquet.pig.convert.Tuple)#parquet/pig/summary/SummaryData/toPrettyJSON(parquet.pig.summary.SummaryData)
parquet/pig/summary/Summary/exec(parquet.pig.convert.Tuple)#parquet/pig/summary/Summary/sumUp(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)
parquet/pig/summary/Summary/setInputSchema(parquet.pig.convert.Schema)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/summary/Summary/setInputSchema(parquet.pig.convert.Schema)#parquet/pig/summary/Summary/saveSchemaToUDFContext()
parquet/pig/summary/Summary/getData(parquet.pig.convert.Tuple)#parquet/pig/summary/SummaryData/fromJSON(java.lang.String,java.lang.Class)
parquet/pig/summary/Summary/getFinal()#java/lang/Class/getName()
parquet/pig/summary/Summary/getInitial()#java/lang/Class/getName()
parquet/thrift/projection/FieldsPath/push(parquet.thrift.struct.ThriftField)#java/util/ArrayList/add(E)
parquet/thrift/projection/FieldsPath/isValueFieldOfMap(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/MapType/getValue()
parquet/thrift/projection/FieldsPath/isValueFieldOfMap(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/projection/FieldsPath/toString()#parquet/thrift/struct/ThriftField/getName()
parquet/thrift/projection/FieldsPath/toString()#java/lang/StringBuffer/append(java.lang.String)
parquet/thrift/projection/FieldsPath/toString()#java/util/ArrayList/get(int)
parquet/thrift/projection/FieldsPath/toString()#parquet/thrift/projection/FieldsPath/isValueFieldOfMap(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/FieldsPath/toString()#java/lang/StringBuffer/length()
parquet/thrift/projection/FieldsPath/toString()#java/util/ArrayList/size()
parquet/thrift/projection/FieldsPath/toString()#java/lang/StringBuffer/substring(int,int)
parquet/thrift/projection/FieldsPath/toString()#parquet/thrift/projection/FieldsPath/isKeyFieldOfMap(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/FieldsPath/toString()#java/lang/StringBuffer/StringBuffer()
parquet/thrift/projection/FieldsPath/isKeyFieldOfMap(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/MapType/getKey()
parquet/thrift/projection/FieldsPath/isKeyFieldOfMap(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/projection/FieldsPath/pop()#java/util/ArrayList/remove(int)
parquet/thrift/projection/FieldsPath/pop()#java/util/ArrayList/size()
parquet/scrooge/ScroogeReadSupport/getProjectedSchema(parquet.thrift.projection.FieldProjectionFilter)#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeReadSupport/getProjectedSchema(parquet.thrift.projection.FieldProjectionFilter)#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeReadSupport/getProjectedSchema(parquet.thrift.projection.FieldProjectionFilter)#parquet/thrift/ThriftSchemaConverter/convert(parquet.thrift.struct.ThriftType.StructType)
parquet/scrooge/ScroogeReadSupport/getProjectedSchema(parquet.thrift.projection.FieldProjectionFilter)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter(parquet.thrift.projection.FieldProjectionFilter)
parquet/column/values/boundedint/DevNullValuesWriter/getBytes()#parquet/bytes/BytesInput/empty()
parquet/pig/TestTupleRecordConsumer/testArtSchema()#parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)
parquet/pig/TestTupleRecordConsumer/testArtSchema()#parquet/example/data/Group/addGroup(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testArtSchema()#parquet/example/data/Group/add(int,long)
parquet/pig/TestTupleRecordConsumer/testArtSchema()#parquet/pig/TestTupleRecordConsumer/getMessageType(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testArtSchema()#parquet/example/data/simple/SimpleGroup/SimpleGroup(parquet.schema.GroupType)
parquet/pig/TestTupleRecordConsumer/testArtSchema()#parquet/example/data/Group/add(java.lang.String,java.lang.String)
parquet/pig/TestTupleRecordConsumer/testArtSchema()#parquet/example/data/Group/add(java.lang.String,long)
parquet/pig/TestTupleRecordConsumer/testArtSchema()#parquet/example/data/Group/append(java.lang.String,java.lang.String)
parquet/pig/TestTupleRecordConsumer/testArtSchema()#java/util/Arrays/asList(T[])
parquet/pig/TestTupleRecordConsumer/testBags()#parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)
parquet/pig/TestTupleRecordConsumer/testBags()#parquet/example/data/Group/addGroup(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testBags()#parquet/pig/TestTupleRecordConsumer/getMessageType(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testBags()#parquet/example/data/simple/SimpleGroup/SimpleGroup(parquet.schema.GroupType)
parquet/pig/TestTupleRecordConsumer/testBags()#parquet/example/data/Group/append(java.lang.String,java.lang.String)
parquet/pig/TestTupleRecordConsumer/testBags()#java/util/Arrays/asList(T[])
parquet/pig/TestTupleRecordConsumer/pigMetaData(java.lang.String)#parquet/pig/PigMetaData/PigMetaData(java.lang.String)
parquet/pig/TestTupleRecordConsumer/pigMetaData(java.lang.String)#java/util/HashMap/HashMap()
parquet/pig/TestTupleRecordConsumer/pigMetaData(java.lang.String)#parquet/pig/PigMetaData/addToMetaData(java.util.Map)
parquet/pig/TestTupleRecordConsumer/testFromTuple(java.lang.String,java.util.List)#java/util/ArrayList/ArrayList()
parquet/pig/TestTupleRecordConsumer/testFromTuple(java.lang.String,java.util.List)#parquet/pig/TupleWriteSupport/write(parquet.pig.convert.Tuple)
parquet/pig/TestTupleRecordConsumer/testFromTuple(java.lang.String,java.util.List)#parquet/pig/TestTupleRecordConsumer/newTupleWriter(java.lang.String,parquet.io.api.RecordMaterializer)
parquet/pig/TestTupleRecordConsumer/testFromTuple(java.lang.String,java.util.List)#parquet/Log/debug(java.lang.Object)
parquet/pig/TestTupleRecordConsumer/testFromTuple(java.lang.String,java.util.List)#parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#java/util/ArrayList/ArrayList()
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#java/lang/Object/toString()
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/io/RecordConsumerLoggingWrapper/RecordConsumerLoggingWrapper(parquet.io.api.RecordConsumer)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/pig/TupleWriteSupport/write(parquet.pig.convert.Tuple)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/pig/TestTupleRecordConsumer/newTupleWriter(java.lang.String,parquet.io.api.RecordMaterializer)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/Log/debug(java.lang.Object)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#java/util/List/add(E)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/io/ConverterConsumer/ConverterConsumer(parquet.io.api.GroupConverter,parquet.schema.MessageType)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/example/data/simple/convert/GroupRecordConverter/getCurrentRecord()
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#java/util/List/size()
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/pig/TestTupleRecordConsumer/getMessageType(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)#java/util/List/get(int)
parquet/pig/TestTupleRecordConsumer/testComplexSchema()#parquet/pig/TestTupleRecordConsumer/testFromTuple(java.lang.String,java.util.List)
parquet/pig/TestTupleRecordConsumer/testComplexSchema()#java/util/Arrays/asList(T[])
parquet/pig/TestTupleRecordConsumer/getMessageType(java.lang.String)#parquet/pig/PigSchemaConverter/PigSchemaConverter()
parquet/pig/TestTupleRecordConsumer/getMessageType(java.lang.String)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TestTupleRecordConsumer/testMaps()#parquet/pig/TestTupleRecordConsumer/testFromGroups(java.lang.String,java.util.List)
parquet/pig/TestTupleRecordConsumer/testMaps()#parquet/example/data/Group/addGroup(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testMaps()#parquet/pig/TestTupleRecordConsumer/getMessageType(java.lang.String)
parquet/pig/TestTupleRecordConsumer/testMaps()#parquet/example/data/simple/SimpleGroup/SimpleGroup(parquet.schema.GroupType)
parquet/pig/TestTupleRecordConsumer/testMaps()#parquet/example/data/Group/append(java.lang.String,java.lang.String)
parquet/pig/TestTupleRecordConsumer/testMaps()#java/util/Arrays/asList(T[])
parquet/pig/TestTupleRecordConsumer/newTupleWriter(java.lang.String,parquet.io.api.RecordMaterializer)#parquet/pig/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/pig/TestTupleRecordConsumer/newTupleWriter(java.lang.String,parquet.io.api.RecordMaterializer)#parquet/pig/TupleWriteSupport/fromPigSchema(java.lang.String)
parquet/pig/TestTupleRecordConsumer/newTupleWriter(java.lang.String,parquet.io.api.RecordMaterializer)#parquet/pig/TupleWriteSupport/getParquetSchema()
parquet/pig/TestTupleRecordConsumer/newTupleWriter(java.lang.String,parquet.io.api.RecordMaterializer)#parquet/pig/TupleWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)
parquet/pig/TestTupleRecordConsumer/newTupleWriter(java.lang.String,parquet.io.api.RecordMaterializer)#parquet/io/api/RecordMaterializer/getRootConverter()
parquet/pig/TestTupleRecordConsumer/newTupleWriter(java.lang.String,parquet.io.api.RecordMaterializer)#parquet/io/ConverterConsumer/ConverterConsumer(parquet.io.api.GroupConverter,parquet.schema.MessageType)
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#java/util/Map/Entry/getValue()
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#parquet/pig/TestTupleRecordConsumer/pigMetaData(java.lang.String)
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#parquet/pig/TestTupleRecordConsumer/getMessageType(java.lang.String)
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#java/util/Arrays/asList(T[])
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#java/util/HashMap/HashMap()
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#parquet/pig/TupleReadSupport/init(parquet.hadoop.api.InitContext)
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#java/util/Map/Entry/getKey()
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#parquet/pig/TupleReadSupport/TupleReadSupport()
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#parquet/pig/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#java/util/Map/put(K,V)
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#parquet/hadoop/api/InitContext/InitContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#java/util/Map/entrySet()
parquet/pig/TestTupleRecordConsumer/newPigRecordConsumer(java.lang.String)#java/util/HashSet/HashSet(java.util.Collection)
parquet/pig/TestTupleRecordConsumer/testMapSchema()#parquet/pig/TestTupleRecordConsumer/testFromTuple(java.lang.String,java.util.List)
parquet/pig/TestTupleRecordConsumer/testMapSchema()#java/util/Arrays/asList(T[])
parquet/pig/TestTupleRecordConsumer/testMapSchema()#parquet/pig/TestTupleRecordConsumer/testMapSchema()/$anonymous3/()
parquet/pig/TestTupleRecordConsumer/testMapSchema()#parquet/pig/TestTupleRecordConsumer/testMapSchema()/$anonymous2/()
parquet/pig/TestTupleRecordConsumer/testMapSchema()#parquet/pig/TestTupleRecordConsumer/testMapSchema()/$anonymous1/()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/memUsageString(java.lang.String)#parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/column/page/DictionaryPage/getUncompressedSize()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/writeDataPages(parquet.bytes.BytesInput,long,long,parquet.column.statistics.Statistics,java.util.List)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#java/util/Set/clear()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/column/page/DictionaryPage/getDictionarySize()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/hadoop/CodecFactory/BytesCompressor/getCodecName()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/endColumn()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#java/util/Set/add(E)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/Log/info(java.lang.Object)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/column/page/DictionaryPage/getEncoding()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/getMemSize()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/bytes/BytesInput/copy(parquet.bytes.BytesInput)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,int,parquet.column.Encoding)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/hadoop/CodecFactory/BytesCompressor/compress(parquet.bytes.BytesInput)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/bytes/BytesInput/size()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getBytes()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getEncoding()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getDictionarySize()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/hadoop/CodecFactory/BytesCompressor/compress(parquet.bytes.BytesInput)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/size()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#java/util/Set/add(E)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/format/converter/ParquetMetadataConverter/writeDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding,java.io.OutputStream)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/hadoop/CodecFactory/BytesCompressor/compress(parquet.bytes.BytesInput)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/size()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#java/util/Set/add(E)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/format/converter/ParquetMetadataConverter/writeDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding,java.io.OutputStream)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/column/statistics/BooleanStatistics/BooleanStatistics()
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/allocatedSize()#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/tools/command/DumpCommand/DumpConverter/asGroupConverter()#parquet/tools/command/DumpCommand/DumpGroupConverter/DumpGroupConverter()
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/memUsageString(java.lang.String)#parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/length()
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/writeTo(java.io.OutputStream)
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/writeBytes(parquet.io.api.Binary)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/getAllocatedSize()#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/getBufferedSize()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/reset()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/getBytes()#parquet/bytes/LittleEndianDataOutputStream/flush()
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/getBytes()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/getBytes()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/getBytes()#parquet/Log/debug(java.lang.Object)
parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/getBytes()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/statistics/TestStatistics/testNumNulls()#parquet/column/statistics/Statistics/setNumNulls(long)
parquet/column/statistics/TestStatistics/testNumNulls()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/column/statistics/TestStatistics/testNumNulls()#parquet/column/statistics/Statistics/incrementNumNulls()
parquet/column/statistics/TestStatistics/testNumNulls()#parquet/column/statistics/Statistics/incrementNumNulls(long)
parquet/column/statistics/TestStatistics/testNumNulls()#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/TestStatistics/testMergingIntStats()#parquet/column/statistics/IntStatistics/getMin()
parquet/column/statistics/TestStatistics/testMergingIntStats()#parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)
parquet/column/statistics/TestStatistics/testMergingIntStats()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/column/statistics/TestStatistics/testMergingIntStats()#parquet/column/statistics/IntStatistics/updateStats(int)
parquet/column/statistics/TestStatistics/testMergingIntStats()#parquet/column/statistics/IntStatistics/getMax()
parquet/column/statistics/TestStatistics/testFloatMinMax()#parquet/column/statistics/FloatStatistics/getMax()
parquet/column/statistics/TestStatistics/testFloatMinMax()#java/nio/ByteBuffer/order(java.nio.ByteOrder)
parquet/column/statistics/TestStatistics/testFloatMinMax()#parquet/column/statistics/FloatStatistics/getMinBytes()
parquet/column/statistics/TestStatistics/testFloatMinMax()#parquet/column/statistics/FloatStatistics/getMin()
parquet/column/statistics/TestStatistics/testFloatMinMax()#parquet/column/statistics/FloatStatistics/setMinMaxFromBytes(byte[],byte[])
parquet/column/statistics/TestStatistics/testFloatMinMax()#parquet/column/statistics/FloatStatistics/updateStats(float)
parquet/column/statistics/TestStatistics/testFloatMinMax()#java/nio/ByteBuffer/wrap(byte[])
parquet/column/statistics/TestStatistics/testFloatMinMax()#parquet/column/statistics/FloatStatistics/getMaxBytes()
parquet/column/statistics/TestStatistics/testFloatMinMax()#java/nio/ByteBuffer/getFloat()
parquet/column/statistics/TestStatistics/testFloatMinMax()#parquet/column/statistics/FloatStatistics/FloatStatistics()
parquet/column/statistics/TestStatistics/testFloatMinMax()#parquet/column/statistics/FloatStatistics/toString()
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/column/statistics/BinaryStatistics/toString()
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/column/statistics/BinaryStatistics/getMax()
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/column/statistics/BinaryStatistics/getMinBytes()
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/column/statistics/BinaryStatistics/updateStats(parquet.io.api.Binary)
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/column/statistics/BinaryStatistics/getMin()
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/column/statistics/BinaryStatistics/getMaxBytes()
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/statistics/TestStatistics/testBinaryMinMax()#java/lang/String/String(byte[])
parquet/column/statistics/TestStatistics/testBinaryMinMax()#parquet/column/statistics/BinaryStatistics/setMinMaxFromBytes(byte[],byte[])
parquet/column/statistics/TestStatistics/testBooleanMinMax()#parquet/column/statistics/BooleanStatistics/setMinMaxFromBytes(byte[],byte[])
parquet/column/statistics/TestStatistics/testBooleanMinMax()#parquet/column/statistics/BooleanStatistics/getMaxBytes()
parquet/column/statistics/TestStatistics/testBooleanMinMax()#parquet/column/statistics/BooleanStatistics/getMin()
parquet/column/statistics/TestStatistics/testBooleanMinMax()#parquet/column/statistics/BooleanStatistics/toString()
parquet/column/statistics/TestStatistics/testBooleanMinMax()#parquet/column/statistics/BooleanStatistics/getMinBytes()
parquet/column/statistics/TestStatistics/testBooleanMinMax()#parquet/column/statistics/BooleanStatistics/getMax()
parquet/column/statistics/TestStatistics/testBooleanMinMax()#parquet/column/statistics/BooleanStatistics/BooleanStatistics()
parquet/column/statistics/TestStatistics/testBooleanMinMax()#parquet/column/statistics/BooleanStatistics/updateStats(boolean)
parquet/column/statistics/TestStatistics/testMergingBooleanStats()#parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)
parquet/column/statistics/TestStatistics/testMergingBooleanStats()#parquet/column/statistics/BooleanStatistics/getMin()
parquet/column/statistics/TestStatistics/testMergingBooleanStats()#parquet/column/statistics/BooleanStatistics/getMax()
parquet/column/statistics/TestStatistics/testMergingBooleanStats()#parquet/column/statistics/BooleanStatistics/BooleanStatistics()
parquet/column/statistics/TestStatistics/testMergingBooleanStats()#parquet/column/statistics/BooleanStatistics/updateStats(boolean)
parquet/column/statistics/TestStatistics/testLongMinMax()#parquet/column/statistics/LongStatistics/LongStatistics()
parquet/column/statistics/TestStatistics/testLongMinMax()#parquet/column/statistics/LongStatistics/getMinBytes()
parquet/column/statistics/TestStatistics/testLongMinMax()#parquet/column/statistics/LongStatistics/toString()
parquet/column/statistics/TestStatistics/testLongMinMax()#java/nio/ByteBuffer/order(java.nio.ByteOrder)
parquet/column/statistics/TestStatistics/testLongMinMax()#parquet/column/statistics/LongStatistics/getMax()
parquet/column/statistics/TestStatistics/testLongMinMax()#parquet/column/statistics/LongStatistics/updateStats(long)
parquet/column/statistics/TestStatistics/testLongMinMax()#parquet/column/statistics/LongStatistics/getMaxBytes()
parquet/column/statistics/TestStatistics/testLongMinMax()#java/nio/ByteBuffer/wrap(byte[])
parquet/column/statistics/TestStatistics/testLongMinMax()#parquet/column/statistics/LongStatistics/getMin()
parquet/column/statistics/TestStatistics/testLongMinMax()#java/nio/ByteBuffer/getLong()
parquet/column/statistics/TestStatistics/testLongMinMax()#parquet/column/statistics/LongStatistics/setMinMaxFromBytes(byte[],byte[])
parquet/column/statistics/TestStatistics/testMergingLongStats()#parquet/column/statistics/LongStatistics/LongStatistics()
parquet/column/statistics/TestStatistics/testMergingLongStats()#parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)
parquet/column/statistics/TestStatistics/testMergingLongStats()#parquet/column/statistics/LongStatistics/getMax()
parquet/column/statistics/TestStatistics/testMergingLongStats()#parquet/column/statistics/LongStatistics/updateStats(long)
parquet/column/statistics/TestStatistics/testMergingLongStats()#parquet/column/statistics/LongStatistics/getMin()
parquet/column/statistics/TestStatistics/testMergingStringStats()#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/column/statistics/TestStatistics/testMergingStringStats()#parquet/column/statistics/BinaryStatistics/updateStats(parquet.io.api.Binary)
parquet/column/statistics/TestStatistics/testMergingStringStats()#parquet/column/statistics/BinaryStatistics/getMin()
parquet/column/statistics/TestStatistics/testMergingStringStats()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/statistics/TestStatistics/testMergingStringStats()#parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)
parquet/column/statistics/TestStatistics/testMergingStringStats()#parquet/column/statistics/BinaryStatistics/getMax()
parquet/column/statistics/TestStatistics/testMergingDoubleStats()#parquet/column/statistics/DoubleStatistics/DoubleStatistics()
parquet/column/statistics/TestStatistics/testMergingDoubleStats()#parquet/column/statistics/DoubleStatistics/getMin()
parquet/column/statistics/TestStatistics/testMergingDoubleStats()#parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)
parquet/column/statistics/TestStatistics/testMergingDoubleStats()#parquet/column/statistics/DoubleStatistics/updateStats(double)
parquet/column/statistics/TestStatistics/testMergingDoubleStats()#parquet/column/statistics/DoubleStatistics/getMax()
parquet/column/statistics/TestStatistics/testMergingFloatStats()#parquet/column/statistics/FloatStatistics/FloatStatistics()
parquet/column/statistics/TestStatistics/testMergingFloatStats()#parquet/column/statistics/FloatStatistics/getMax()
parquet/column/statistics/TestStatistics/testMergingFloatStats()#parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)
parquet/column/statistics/TestStatistics/testMergingFloatStats()#parquet/column/statistics/FloatStatistics/getMin()
parquet/column/statistics/TestStatistics/testMergingFloatStats()#parquet/column/statistics/FloatStatistics/updateStats(float)
parquet/column/statistics/TestStatistics/testMergingStatistics()#parquet/column/statistics/TestStatistics/testMergingIntStats()
parquet/column/statistics/TestStatistics/testMergingStatistics()#parquet/column/statistics/TestStatistics/testMergingFloatStats()
parquet/column/statistics/TestStatistics/testMergingStatistics()#parquet/column/statistics/TestStatistics/testMergingBooleanStats()
parquet/column/statistics/TestStatistics/testMergingStatistics()#parquet/column/statistics/TestStatistics/testMergingLongStats()
parquet/column/statistics/TestStatistics/testMergingStatistics()#parquet/column/statistics/TestStatistics/testMergingStringStats()
parquet/column/statistics/TestStatistics/testMergingStatistics()#parquet/column/statistics/TestStatistics/testMergingDoubleStats()
parquet/column/statistics/TestStatistics/testDoubleMinMax()#parquet/column/statistics/DoubleStatistics/getMin()
parquet/column/statistics/TestStatistics/testDoubleMinMax()#parquet/column/statistics/DoubleStatistics/getMaxBytes()
parquet/column/statistics/TestStatistics/testDoubleMinMax()#java/nio/ByteBuffer/order(java.nio.ByteOrder)
parquet/column/statistics/TestStatistics/testDoubleMinMax()#parquet/column/statistics/DoubleStatistics/updateStats(double)
parquet/column/statistics/TestStatistics/testDoubleMinMax()#parquet/column/statistics/DoubleStatistics/toString()
parquet/column/statistics/TestStatistics/testDoubleMinMax()#parquet/column/statistics/DoubleStatistics/getMax()
parquet/column/statistics/TestStatistics/testDoubleMinMax()#java/nio/ByteBuffer/wrap(byte[])
parquet/column/statistics/TestStatistics/testDoubleMinMax()#parquet/column/statistics/DoubleStatistics/getMinBytes()
parquet/column/statistics/TestStatistics/testDoubleMinMax()#parquet/column/statistics/DoubleStatistics/setMinMaxFromBytes(byte[],byte[])
parquet/column/statistics/TestStatistics/testDoubleMinMax()#parquet/column/statistics/DoubleStatistics/DoubleStatistics()
parquet/column/statistics/TestStatistics/testDoubleMinMax()#java/nio/ByteBuffer/getDouble()
parquet/column/statistics/TestStatistics/testIntMinMax()#parquet/column/statistics/IntStatistics/getMinBytes()
parquet/column/statistics/TestStatistics/testIntMinMax()#parquet/column/statistics/IntStatistics/getMin()
parquet/column/statistics/TestStatistics/testIntMinMax()#parquet/column/statistics/IntStatistics/setMinMaxFromBytes(byte[],byte[])
parquet/column/statistics/TestStatistics/testIntMinMax()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/column/statistics/TestStatistics/testIntMinMax()#java/nio/ByteBuffer/order(java.nio.ByteOrder)
parquet/column/statistics/TestStatistics/testIntMinMax()#parquet/column/statistics/IntStatistics/getMaxBytes()
parquet/column/statistics/TestStatistics/testIntMinMax()#parquet/column/statistics/IntStatistics/updateStats(int)
parquet/column/statistics/TestStatistics/testIntMinMax()#parquet/column/statistics/IntStatistics/toString()
parquet/column/statistics/TestStatistics/testIntMinMax()#java/nio/ByteBuffer/getInt()
parquet/column/statistics/TestStatistics/testIntMinMax()#parquet/column/statistics/IntStatistics/getMax()
parquet/column/statistics/TestStatistics/testIntMinMax()#java/nio/ByteBuffer/wrap(byte[])
parquet/avro/AvroParquetReader/builder(parquet.hadoop.Path)#parquet/hadoop/ParquetReader/builder(parquet.hadoop.api.ReadSupport,parquet.hadoop.Path)
parquet/avro/AvroParquetReader/builder(parquet.hadoop.Path)#parquet/avro/AvroReadSupport/AvroReadSupport()
parquet/proto/ProtoWriteSupport/MessageWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/endGroup()
parquet/proto/ProtoWriteSupport/MessageWriter/writeRawValue(java.lang.Object)#parquet/proto/ProtoWriteSupport/MessageWriter/writeAllFields(parquet.proto.utils.MessageOrBuilder)
parquet/proto/ProtoWriteSupport/MessageWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/startGroup()
parquet/proto/ProtoWriteSupport/MessageWriter/writeTopLevelMessage(java.lang.Object)#parquet/proto/ProtoWriteSupport/MessageWriter/writeAllFields(parquet.proto.utils.MessageOrBuilder)
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/unknownType(Descriptors.FieldDescriptor)
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/schema/Type/asGroupType()
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/MessageWriter/MessageWriter(Descriptors.Descriptor,parquet.schema.GroupType)
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/BooleanWriter/BooleanWriter()
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/IntWriter/IntWriter()
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/FloatWriter/FloatWriter()
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/EnumWriter/EnumWriter()
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/LongWriter/LongWriter()
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/BinaryWriter/BinaryWriter()
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/StringWriter/StringWriter()
parquet/proto/ProtoWriteSupport/MessageWriter/createWriter(Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoWriteSupport/DoubleWriter/DoubleWriter()
parquet/proto/ProtoWriteSupport/MessageWriter/writeField(java.lang.Object)#parquet/io/api/RecordConsumer/endGroup()
parquet/proto/ProtoWriteSupport/MessageWriter/writeField(java.lang.Object)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/proto/ProtoWriteSupport/MessageWriter/writeField(java.lang.Object)#parquet/proto/ProtoWriteSupport/MessageWriter/writeAllFields(parquet.proto.utils.MessageOrBuilder)
parquet/proto/ProtoWriteSupport/MessageWriter/writeField(java.lang.Object)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/proto/ProtoWriteSupport/MessageWriter/writeField(java.lang.Object)#parquet/io/api/RecordConsumer/startGroup()
parquet/proto/ProtoWriteSupport/MessageWriter/writeAllFields(parquet.proto.utils.MessageOrBuilder)#parquet/proto/ProtoWriteSupport/FieldWriter/writeField(java.lang.Object)
parquet/thrift/TestThriftParquetReaderWriter/testWriteRead()#parquet/thrift/ThriftParquetWriter/ThriftParquetWriter(parquet.hadoop.Path,java.lang.Class,parquet.hadoop.metadata.CompressionCodecName)
parquet/thrift/TestThriftParquetReaderWriter/testWriteRead()#parquet/thrift/ThriftParquetReader/ThriftParquetReader(parquet.hadoop.Path)
parquet/thrift/TestThriftParquetReaderWriter/testWriteRead()#java/util/Arrays/asList(T[])
parquet/thrift/TestThriftParquetReaderWriter/testWriteRead()#parquet/thrift/ThriftParquetReader/ThriftParquetReader(parquet.hadoop.Path,java.lang.Class)
parquet/thrift/TestThriftParquetReaderWriter/testWriteRead()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/clear(java.lang.Object)#java/util/Map/clear()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/put(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/Map/put(K,V)
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/remove(java.lang.Object,java.lang.Object)#java/util/Map/remove(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)#java/util/HashMap/HashMap()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)#java/util/Map/size()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/create()#java/util/HashMap/HashMap()
org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/filter/AndRecordFilter/isMatch()#parquet/filter/RecordFilter/isMatch()
parquet/filter/AndRecordFilter/and(parquet.filter.UnboundRecordFilter,parquet.filter.UnboundRecordFilter)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter/AndRecordFilter/and(parquet.filter.UnboundRecordFilter,parquet.filter.UnboundRecordFilter)#parquet/filter/AndRecordFilter/and(parquet/filter/UnboundRecordFilter,parquet/filter/UnboundRecordFilter)/$anonymous1/()
parquet/cascading/TestParquetTupleScheme/testFieldProjection()#parquet/cascading/TestParquetTupleScheme/ProjectedTupleFunction/ProjectedTupleFunction()
parquet/cascading/TestParquetTupleScheme/testFieldProjection()#parquet/cascading/ParquetTupleScheme/ParquetTupleScheme(parquet.cascading.Fields)
parquet/cascading/TestParquetTupleScheme/testFieldProjection()#java/io/File/File(java.lang.String)
parquet/cascading/TestParquetTupleScheme/testFieldProjection()#parquet/cascading/TestParquetTupleScheme/createFileForRead()
parquet/cascading/TestParquetTupleScheme/testFieldProjection()#java/lang/Object/Object()
parquet/cascading/TestParquetTupleScheme/createFileForRead()#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/cascading/TestParquetTupleScheme/createFileForRead()#java/io/ByteArrayOutputStream/reset()
parquet/cascading/TestParquetTupleScheme/createFileForRead()#java/io/ByteArrayOutputStream/toByteArray()
parquet/cascading/TestParquetTupleScheme/createFileForRead()#parquet/hadoop/thrift/ThriftToParquetFileWriter/ThriftToParquetFileWriter(parquet.hadoop.Path,parquet.pig.TaskAttemptContext,parquet.hadoop.thrift.TProtocolFactory,java.lang.Class)
parquet/cascading/TestParquetTupleScheme/createFileForRead()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/cascading/TestParquetTupleScheme/createFileForRead()#parquet/hadoop/thrift/ThriftToParquetFileWriter/write(parquet.hadoop.thrift.BytesWritable)
parquet/cascading/TestParquetTupleScheme/createFileForRead()#parquet/hadoop/thrift/ThriftToParquetFileWriter/close()
parquet/cascading/TestParquetTupleScheme/testReadPattern()#parquet/cascading/TestParquetTupleScheme/testReadWrite(java.lang.String)
parquet/cascading/TestParquetTupleScheme/testReadWrite(java.lang.String)#parquet/cascading/TestParquetTupleScheme/UnpackTupleFunction/UnpackTupleFunction()
parquet/cascading/TestParquetTupleScheme/testReadWrite(java.lang.String)#parquet/cascading/ParquetTupleScheme/ParquetTupleScheme(parquet.cascading.Fields)
parquet/cascading/TestParquetTupleScheme/testReadWrite(java.lang.String)#java/io/File/File(java.lang.String)
parquet/cascading/TestParquetTupleScheme/testReadWrite(java.lang.String)#parquet/cascading/TestParquetTupleScheme/createFileForRead()
parquet/cascading/TestParquetTupleScheme/testReadWrite(java.lang.String)#java/lang/Object/Object()
parquet/hadoop/LruCache/size()#java/util/HashMap/size()
parquet/hadoop/LruCache/remove(K)#java/util/HashMap/remove(java.lang.Object)
parquet/hadoop/LruCache/remove(K)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/LruCache/put(K,V)#java/util/LinkedHashMap/get(java.lang.Object)
parquet/hadoop/LruCache/put(K,V)#java/util/HashMap/put(K,V)
parquet/hadoop/LruCache/put(K,V)#parquet/Log/warn(java.lang.Object)
parquet/hadoop/LruCache/put(K,V)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/LruCache/put(K,V)#parquet/hadoop/LruCache/Value/isCurrent(K)
parquet/hadoop/LruCache/put(K,V)#parquet/hadoop/LruCache/Value/isNewerThan(V)
parquet/hadoop/LruCache/clear()#java/util/LinkedHashMap/clear()
parquet/hadoop/LruCache/getCurrentValue(K)#java/util/LinkedHashMap/get(java.lang.Object)
parquet/hadoop/LruCache/getCurrentValue(K)#parquet/hadoop/LruCache/remove(K)
parquet/hadoop/LruCache/getCurrentValue(K)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/LruCache/getCurrentValue(K)#parquet/hadoop/LruCache/Value/isCurrent(K)
parquet/hadoop/ParquetFileReader/WorkaroundChunk/readAsBytesInput(int)#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/hadoop/ParquetFileReader/WorkaroundChunk/readAsBytesInput(int)#parquet/bytes/BytesInput/copy(parquet.bytes.BytesInput)
parquet/hadoop/ParquetFileReader/WorkaroundChunk/readAsBytesInput(int)#parquet/hadoop/ParquetFileReader/Chunk/readAsBytesInput(int)
parquet/hadoop/ParquetFileReader/WorkaroundChunk/readAsBytesInput(int)#parquet/Log/info(java.lang.Object)
parquet/hadoop/ParquetFileReader/WorkaroundChunk/readAsBytesInput(int)#parquet/bytes/BytesInput/from(java.io.InputStream,int)
parquet/hadoop/ParquetFileReader/WorkaroundChunk/readPageHeader()#java/io/SequenceInputStream/SequenceInputStream(java.io.InputStream,java.io.InputStream)
parquet/hadoop/ParquetFileReader/WorkaroundChunk/readPageHeader()#parquet/Log/info(java.lang.Object)
parquet/proto/ProtoWriteSupport/BooleanWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/addBoolean(boolean)
parquet/avro/TestInputOutputFormat/MyMapper2/map(java.lang.Void,parquet.avro.GenericRecord,parquet.proto.utils.Context)#java/lang/Object/Object()
parquet/column/values/deltastrings/DeltaByteArrayWriter/getBufferedSize()#parquet/column/values/ValuesWriter/getBufferedSize()
parquet/column/values/deltastrings/DeltaByteArrayWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/fromByteArray(byte[],int,int)
parquet/column/values/deltastrings/DeltaByteArrayWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/deltastrings/DeltaByteArrayWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/deltastrings/DeltaByteArrayWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/column/values/deltastrings/DeltaByteArrayWriter/getAllocatedSize()#parquet/column/values/ValuesWriter/getAllocatedSize()
parquet/column/values/deltastrings/DeltaByteArrayWriter/getBytes()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/values/deltastrings/DeltaByteArrayWriter/getBytes()#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/deltastrings/DeltaByteArrayWriter/reset()#parquet/column/values/ValuesWriter/reset()
parquet/column/values/deltastrings/DeltaByteArrayWriter/memUsageString(java.lang.String)#parquet/column/values/ValuesWriter/memUsageString(java.lang.String)
parquet/filter2/recordlevel/TestValueInspector/testReusable()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()
parquet/filter2/recordlevel/TestValueInspector/testReusable()#java/util/Arrays/asList(T[])
parquet/filter2/recordlevel/TestValueInspector/testReusable()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/reset()
parquet/filter2/recordlevel/TestValueInspector/testReusable()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/getResult()
parquet/filter2/recordlevel/TestValueInspector/testReusable()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)
parquet/filter2/recordlevel/TestValueInspector/testLifeCycle()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()
parquet/filter2/recordlevel/TestValueInspector/testLifeCycle()#java/lang/Throwable/getMessage()
parquet/filter2/recordlevel/TestValueInspector/testLifeCycle()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/reset()
parquet/filter2/recordlevel/TestValueInspector/testLifeCycle()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/getResult()
parquet/filter2/recordlevel/TestValueInspector/testLifeCycle()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)
parquet/filter2/recordlevel/TestValueInspector/testLifeCycle()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/isKnown()
parquet/example/data/simple/convert/GroupRecordConverter/getCurrentRecord()#parquet/example/data/simple/convert/SimpleGroupConverter/getCurrentRecord()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData,java.lang.Long)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.Type)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.Type,int,parquet.schema.MessageType,java.util.List)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData,java.lang.Long)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/Type/getRepetition()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#java/util/List/toArray(T[])
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#java/util/List/size()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/column/ColumnDescriptor/getMaxRepetitionLevel()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#java/util/List/add(E)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#java/util/List/remove(int)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/column/ColumnDescriptor/getMaxDefinitionLevel()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/Type/getName()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/Type/getOriginalType()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.column.ColumnDescriptor)#parquet/column/ColumnDescriptor/getType()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.column.ColumnDescriptor)#parquet/column/ColumnDescriptor/getPath()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.column.ColumnDescriptor)#parquet/column/ColumnDescriptor/getMaxDefinitionLevel()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.column.ColumnDescriptor)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.column.ColumnDescriptor)#parquet/column/ColumnDescriptor/getMaxRepetitionLevel()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)#parquet/common/schema/ColumnPath/toArray()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)#java/util/Map/get(java.lang.Object)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)#parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)#java/util/Map/containsKey(java.lang.Object)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)#java/util/Map/put(K,V)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)#java/util/LinkedHashMap/LinkedHashMap()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.Type,int,parquet.schema.MessageType,java.util.List)#parquet/schema/Type/asGroupType()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.Type,int,parquet.schema.MessageType,java.util.List)#parquet/schema/Type/asPrimitiveType()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.Type,int,parquet.schema.MessageType,java.util.List)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.Type,int,parquet.schema.MessageType,java.util.List)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.MessageType)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#java/util/Map/Entry/getKey()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/tools/util/PrettyPrintWriter/incrementTabLevel()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/hadoop/metadata/FileMetaData/getCreatedBy()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/tools/util/PrettyPrintWriter/decrementTabLevel()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/schema/Type/getName()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#java/util/Map/entrySet()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/tools/util/PrettyPrintWriter/rule(char)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#java/util/Map/Entry/getValue()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/hadoop/metadata/FileMetaData/getKeyValueMetaData()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.FileMetaData)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/GroupType/getFields()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/Type/getRepetition()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#java/util/List/remove(int)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#java/util/List/size()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.Type,int,parquet.schema.MessageType,java.util.List)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#java/util/List/add(E)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/Type/getName()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.GroupType,int,parquet.schema.MessageType,java.util.List)#parquet/schema/GroupType/getFieldCount()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData,java.lang.Long)#parquet/hadoop/metadata/BlockMetaData/getRowCount()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData,java.lang.Long)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData,java.lang.Long)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData,java.lang.Long)#parquet/hadoop/metadata/BlockMetaData/getTotalByteSize()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData,java.lang.Long)#parquet/tools/util/PrettyPrintWriter/rule(char)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.BlockMetaData,java.lang.Long)#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalSize()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getDictionaryPageOffset()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getType()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#java/lang/String/isEmpty()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getValueCount()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getEncodings()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getCodec()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalUncompressedSize()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.PrimitiveType,int,parquet.schema.MessageType,java.util.List)
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.MessageType)#parquet/schema/GroupType/getFields()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.MessageType)#java/util/ArrayList/ArrayList()
parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.MessageType)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.schema.Type,int,parquet.schema.MessageType,java.util.List)
parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)#parquet/tools/util/PrettyPrintWriter/println(java.lang.String)
parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ColumnChunkMetaData,boolean)
parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)#java/util/Map/Entry/getValue()
parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)#parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)
parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)#java/util/Map/Entry/getKey()
parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)#java/util/Map/entrySet()
parquet/tools/util/MetadataUtils/showColumnChunkDetails(parquet.tools.util.PrettyPrintWriter,java.util.Map,int)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/getCurrentArray()#java/util/List/toArray(T[])
org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/getCurrentArray()#java/util/List/size()
org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/getCurrentArray()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/end()#org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/getCurrentArray()
org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/end()#org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/set(int,org.apache.hadoop.hive.ql.io.parquet.Writable)
org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/add(int,org.apache.hadoop.hive.ql.io.parquet.Writable)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/add(int,org.apache.hadoop.hive.ql.io.parquet.Writable)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/pig/summary/NumberSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(parquet.pig.summary.SummaryData)
parquet/pig/summary/NumberSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/ValueStat/merge(parquet.pig.summary.ValueStat)
parquet/pig/summary/NumberSummaryData/add(java.lang.Number)#parquet/pig/summary/SummaryData/add(java.lang.Object)
parquet/pig/summary/NumberSummaryData/add(java.lang.Number)#java/lang/Number/doubleValue()
parquet/pig/summary/NumberSummaryData/add(java.lang.Number)#parquet/pig/summary/ValueStat/add(double)
parquet/thrift/struct/ThriftField/hashCode()#java/lang/String/hashCode()
parquet/thrift/struct/ThriftField/hashCode()#java/lang/Enum/hashCode()
parquet/thrift/struct/ThriftField/hashCode()#parquet/thrift/struct/ThriftType/hashCode()
parquet/thrift/struct/ThriftField/equals(java.lang.Object)#parquet/thrift/struct/ThriftType/equals(java.lang.Object)
parquet/thrift/struct/ThriftField/equals(java.lang.Object)#java/lang/String/equals(java.lang.Object)
parquet/thrift/struct/ThriftField/toString()#parquet/thrift/struct/JSON/toJSON(java.lang.Object)
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveWritableObject(java.lang.Object)#org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/getBytes()
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveWritableObject(java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveWritableObject(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveWritableObject(java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveJavaObject(java.lang.Object)#java/lang/Object/toString()
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveJavaObject(java.lang.Object)#org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/getString()
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveJavaObject(java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveJavaObject(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/getPrimitiveJavaObject(java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/set(java.lang.Object,parquet.hadoop.example.Text)#parquet/io/api/Binary/fromByteArray(byte[])
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/set(java.lang.Object,parquet.hadoop.example.Text)#org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/BinaryWritable(parquet.io.api.Binary)
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/set(java.lang.Object,java.lang.String)#org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/BinaryWritable(parquet.io.api.Binary)
org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector/set(java.lang.Object,java.lang.String)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/thrift/struct/ThriftType/I64Type/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.I64Type)
parquet/column/values/ValuesWriter/writeByte(int)#java/lang/Class/getName()
parquet/column/values/ValuesWriter/writeByte(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/ValuesWriter/writeByte(int)#java/lang/Object/getClass()
parquet/column/values/ValuesWriter/writeFloat(float)#java/lang/Class/getName()
parquet/column/values/ValuesWriter/writeFloat(float)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/ValuesWriter/writeFloat(float)#java/lang/Object/getClass()
parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)#java/lang/Class/getName()
parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)#java/lang/Object/getClass()
parquet/column/values/ValuesWriter/writeInteger(int)#java/lang/Class/getName()
parquet/column/values/ValuesWriter/writeInteger(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/ValuesWriter/writeInteger(int)#java/lang/Object/getClass()
parquet/column/values/ValuesWriter/writeLong(long)#java/lang/Class/getName()
parquet/column/values/ValuesWriter/writeLong(long)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/ValuesWriter/writeLong(long)#java/lang/Object/getClass()
parquet/column/values/ValuesWriter/writeBoolean(boolean)#java/lang/Class/getName()
parquet/column/values/ValuesWriter/writeBoolean(boolean)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/ValuesWriter/writeBoolean(boolean)#java/lang/Object/getClass()
parquet/column/values/ValuesWriter/writeDouble(double)#java/lang/Class/getName()
parquet/column/values/ValuesWriter/writeDouble(double)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/values/ValuesWriter/writeDouble(double)#java/lang/Object/getClass()
parquet/column/values/Utils/writeInts(parquet.column.values.ValuesWriter,int[])#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/Utils/getRandomStringSamples(int,int)#java/util/Random/nextInt(int)
parquet/column/values/Utils/getRandomStringSamples(int,int)#parquet/column/values/RandomStr/get(int)
parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int,int)#parquet/column/values/ValuesReader/readBytes()
parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int,int)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int,int)
parquet/column/values/Utils/readInts(parquet.column.values.ValuesReader,byte[],int,int)#parquet/column/values/ValuesReader/readInteger()
parquet/column/values/Utils/readInts(parquet.column.values.ValuesReader,byte[],int,int)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/Utils/readInts(parquet.column.values.ValuesReader,byte[],int)#parquet/column/values/Utils/readInts(parquet.column.values.ValuesReader,byte[],int,int)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/TestableAbstractParquetMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/thrift/struct/CompatibilityChecker/checkCompatibility(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/CompatibleCheckerVisitor/getReport()
parquet/thrift/struct/CompatibilityChecker/checkCompatibility(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/struct/CompatibilityChecker/checkCompatibility(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/CompatibleCheckerVisitor/CompatibleCheckerVisitor(parquet.thrift.struct.ThriftType.StructType)
parquet/hadoop/util/TestSerializationUtil/readObjectFromConfAsBase64UnsetKey()#parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/util/TestSerializationUtil/testReadWriteObjectToConfAsBase64()#parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/util/TestSerializationUtil/testReadWriteObjectToConfAsBase64()#java/util/HashMap/HashMap()
parquet/hadoop/util/TestSerializationUtil/testReadWriteObjectToConfAsBase64()#parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/util/TestSerializationUtil/testReadWriteObjectToConfAsBase64()#java/util/Map/put(K,V)
parquet/hadoop/ParquetFileReader/close()#parquet/hadoop/CodecFactory/release()
parquet/hadoop/ParquetFileReader/readFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,boolean)#parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)
parquet/hadoop/ParquetFileReader/readFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,boolean)#parquet/hadoop/ParquetFileReader/listFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#java/io/IOException/IOException(java.lang.String,java.lang.Throwable)
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#java/util/List/addAll(java.util.Collection)
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#java/util/HashMap/HashMap()
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#java/util/List/add(E)
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#parquet/Log/info(java.lang.Object)
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org/apache/hadoop/hive/ql/io/parquet/Configuration,java/util/Collection,boolean)/$anonymous1/()
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#java/util/HashSet/HashSet()
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)#parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)#java/io/IOException/IOException(java.lang.String,java.lang.Throwable)
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)#java/lang/Throwable/getCause()
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)#java/lang/Throwable/getMessage()
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)#parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)#java/util/List/add(E)
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)#parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org/apache/hadoop/hive/ql/io/parquet/Configuration,java/util/List,boolean)/$anonymous1/()
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#java/util/Arrays/equals(byte[],byte[])
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#java/util/Arrays/toString(byte[])
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java.io.InputStream,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/bytes/BytesUtils/readIntLittleEndian(java.io.InputStream)
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#java/util/HashMap/HashMap()
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/BlockMetaData/getPath()
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#java/util/List/add(E)
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/Footer/Footer(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/ParquetMetadata(parquet.hadoop.metadata.FileMetaData,java.util.List)
parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)#java/lang/Object/Object()
parquet/hadoop/ParquetFileReader/readFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#parquet/hadoop/ParquetFileReader/readFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus,boolean)
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)
parquet/hadoop/ParquetFileReader/readFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#parquet/hadoop/ParquetFileReader/readFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/hadoop/ParquetFileReader/readFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#parquet/hadoop/ParquetFileReader/status(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/hadoop/ParquetFileReader/readSummaryFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#parquet/hadoop/ParquetFileReader/footersFromSummaryFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)
parquet/hadoop/ParquetFileReader/readSummaryFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
parquet/hadoop/ParquetFileReader/readSummaryFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#parquet/hadoop/ParquetFileReader/filter(boolean)
parquet/hadoop/ParquetFileReader/readSummaryMetadata(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,boolean)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
parquet/hadoop/ParquetFileReader/readSummaryMetadata(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,boolean)#parquet/Log/info(java.lang.Object)
parquet/hadoop/ParquetFileReader/readSummaryMetadata(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,boolean)#java/lang/Object/Object()
parquet/hadoop/ParquetFileReader/readSummaryMetadata(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,boolean)#parquet/hadoop/ParquetFileReader/filter(boolean)
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/util/ArrayList/ArrayList(int)
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/util/List/size()
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/util/concurrent/ExecutorService/shutdownNow()
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/util/List/add(E)
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/util/concurrent/Executors/newFixedThreadPool(int)
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#parquet/Log/info(java.lang.Object)
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/util/concurrent/Future/get()
parquet/hadoop/ParquetFileReader/runAllInParallel(int,java.util.List)#java/util/concurrent/ExecutorService/submit(java.util.concurrent.Callable)
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#parquet/hadoop/ParquetFileReader/listFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)
parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,boolean)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/ParquetFileReader/ChunkDescriptor/ChunkDescriptor(parquet.column.ColumnDescriptor,parquet.hadoop.metadata.ColumnChunkMetaData,long,int)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/ColumnChunkPageReadStore/addColumn(parquet.column.ColumnDescriptor,parquet.hadoop.ColumnChunkPageReadStore.ColumnChunkPageReader)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/ConsecutiveChunkList(long)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#java/util/Map/get(java.lang.Object)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#java/util/List/size()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/metadata/ColumnChunkMetaData/getStartingPos()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/endPos()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#java/util/List/get(int)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/readAll(parquet.hadoop.FSDataInputStream)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/util/counters/BenchmarkCounter/incrementTotalBytes(long)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/ParquetFileReader/Chunk/readAllPages()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/metadata/BlockMetaData/getRowCount()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalSize()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReadStore(long)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/hadoop/ParquetFileReader/readNextRowGroup()#java/util/List/add(E)
parquet/hadoop/ParquetFileReader/readNextRowGroup()#parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/addChunk(parquet.hadoop.ParquetFileReader.ChunkDescriptor)
parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
parquet/hadoop/ParquetFileReader/listFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetFileReader/listFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#java/util/Arrays/asList(T[])
parquet/hadoop/ParquetFileReader/listFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)#parquet/hadoop/ParquetFileReader/listFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)
parquet/schema/Types/MessageTypeBuilder/named(java.lang.String)#parquet/schema/MessageType/MessageType(java.lang.String,java.util.List)
parquet/schema/Types/MessageTypeBuilder/named(java.lang.String)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/column/values/plain/PlainValuesReader/IntegerPlainValuesReader/skip()#parquet/bytes/LittleEndianDataInputStream/skipBytes(int)
parquet/column/values/plain/PlainValuesReader/IntegerPlainValuesReader/skip()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesReader/IntegerPlainValuesReader/readInteger()#parquet/bytes/LittleEndianDataInputStream/readInt()
parquet/column/values/plain/PlainValuesReader/IntegerPlainValuesReader/readInteger()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/dictionary/PlainValuesDictionary/PlainLongDictionary/toString()#java/lang/StringBuilder/append(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainLongDictionary/toString()#java/lang/StringBuilder/append(int)
parquet/column/values/dictionary/PlainValuesDictionary/PlainLongDictionary/toString()#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainLongDictionary/toString()#java/lang/StringBuilder/append(long)
parquet/column/values/dictionary/PlainValuesDictionary/PlainLongDictionary/toString()#java/lang/StringBuilder/toString()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/hashCode()#org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/getBigDecimal()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/hashCode()#java/math/BigDecimal/hashCode()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(java.math.BigDecimal)#java/math/BigDecimal/scale()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(java.math.BigDecimal)#org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(byte[],int)
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(java.math.BigDecimal)#java/math/BigDecimal/compareTo(java.math.BigDecimal)
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(java.math.BigDecimal)#java/math/BigDecimal/unscaledValue()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(java.math.BigDecimal)#java/math/BigDecimal/stripTrailingZeros()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(java.math.BigDecimal)#java/math/BigInteger/toByteArray()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/write(java.io.DataOutput)#java/io/DataOutput/write(byte[])
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/compareTo(org.apache.hadoop.hive.ql.io.parquet.writable.BigDecimalWritable)#java/math/BigDecimal/compareTo(java.math.BigDecimal)
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/compareTo(org.apache.hadoop.hive.ql.io.parquet.writable.BigDecimalWritable)#org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/getBigDecimal()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/setFromBytes(byte[],int,int)#java/lang/System/arraycopy(java.lang.Object,int,java.lang.Object,int,int)
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/getBigDecimal()#java/math/BigInteger/BigInteger(byte[])
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/getBigDecimal()#java/math/BigDecimal/BigDecimal(java.math.BigInteger,int)
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/readFields(java.io.DataInput)#java/io/DataInput/readFully(byte[])
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(org.apache.hadoop.hive.ql.io.parquet.writable.BigDecimalWritable)#org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(java.math.BigDecimal)
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/set(org.apache.hadoop.hive.ql.io.parquet.writable.BigDecimalWritable)#org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/getBigDecimal()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/toString()#java/math/BigDecimal/toString()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/toString()#org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/getBigDecimal()
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/equals(java.lang.Object)#java/math/BigDecimal/compareTo(java.math.BigDecimal)
org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/equals(java.lang.Object)#org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable/getBigDecimal()
parquet/bytes/BytesUtils/writeIntLittleEndian(java.io.OutputStream,int)#java/io/OutputStream/write(int)
parquet/bytes/BytesUtils/writeIntLittleEndian(java.io.OutputStream,int)#parquet/Log/debug(java.lang.Object)
parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)#java/io/InputStream/read()
parquet/bytes/BytesUtils/readIntLittleEndianOnTwoBytes(java.io.InputStream)#java/io/InputStream/read()
parquet/bytes/BytesUtils/readIntLittleEndianOnTwoBytes(java.io.InputStream)#java/io/EOFException/EOFException()
parquet/bytes/BytesUtils/writeIntLittleEndianOnTwoBytes(java.io.OutputStream,int)#java/io/OutputStream/write(int)
parquet/bytes/BytesUtils/writeZigZagVarInt(int,java.io.OutputStream)#parquet/bytes/BytesUtils/writeUnsignedVarInt(int,java.io.OutputStream)
parquet/bytes/BytesUtils/getWidthFromMaxInt(int)#java/lang/Integer/numberOfLeadingZeros(int)
parquet/bytes/BytesUtils/writeIntLittleEndianPaddedOnBitWidth(java.io.OutputStream,int,int)#parquet/bytes/BytesUtils/paddedByteCountFromBits(int)
parquet/bytes/BytesUtils/writeIntLittleEndianPaddedOnBitWidth(java.io.OutputStream,int,int)#parquet/bytes/BytesUtils/writeIntLittleEndian(java.io.OutputStream,int)
parquet/bytes/BytesUtils/writeIntLittleEndianPaddedOnBitWidth(java.io.OutputStream,int,int)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/bytes/BytesUtils/writeIntLittleEndianPaddedOnBitWidth(java.io.OutputStream,int,int)#parquet/bytes/BytesUtils/writeIntLittleEndianOnThreeBytes(java.io.OutputStream,int)
parquet/bytes/BytesUtils/writeIntLittleEndianPaddedOnBitWidth(java.io.OutputStream,int,int)#parquet/bytes/BytesUtils/writeIntLittleEndianOnOneByte(java.io.OutputStream,int)
parquet/bytes/BytesUtils/writeIntLittleEndianPaddedOnBitWidth(java.io.OutputStream,int,int)#parquet/bytes/BytesUtils/writeIntLittleEndianOnTwoBytes(java.io.OutputStream,int)
parquet/bytes/BytesUtils/writeIntLittleEndianPaddedOnBitWidth(java.io.OutputStream,int,int)#java/io/IOException/IOException(java.lang.String)
parquet/bytes/BytesUtils/readZigZagVarInt(java.io.InputStream)#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/bytes/BytesUtils/readIntLittleEndianOnOneByte(java.io.InputStream)#java/io/InputStream/read()
parquet/bytes/BytesUtils/readIntLittleEndianOnOneByte(java.io.InputStream)#java/io/EOFException/EOFException()
parquet/bytes/BytesUtils/readIntLittleEndianOnThreeBytes(java.io.InputStream)#java/io/InputStream/read()
parquet/bytes/BytesUtils/readIntLittleEndianOnThreeBytes(java.io.InputStream)#java/io/EOFException/EOFException()
parquet/bytes/BytesUtils/writeUnsignedVarInt(int,java.io.OutputStream)#java/io/OutputStream/write(int)
parquet/bytes/BytesUtils/writeIntLittleEndianOnThreeBytes(java.io.OutputStream,int)#java/io/OutputStream/write(int)
parquet/bytes/BytesUtils/readIntLittleEndianPaddedOnBitWidth(java.io.InputStream,int)#java/io/IOException/IOException(java.lang.String)
parquet/bytes/BytesUtils/readIntLittleEndianPaddedOnBitWidth(java.io.InputStream,int)#parquet/bytes/BytesUtils/readIntLittleEndianOnThreeBytes(java.io.InputStream)
parquet/bytes/BytesUtils/readIntLittleEndianPaddedOnBitWidth(java.io.InputStream,int)#parquet/bytes/BytesUtils/readIntLittleEndian(java.io.InputStream)
parquet/bytes/BytesUtils/readIntLittleEndianPaddedOnBitWidth(java.io.InputStream,int)#parquet/bytes/BytesUtils/readIntLittleEndianOnTwoBytes(java.io.InputStream)
parquet/bytes/BytesUtils/readIntLittleEndianPaddedOnBitWidth(java.io.InputStream,int)#parquet/bytes/BytesUtils/paddedByteCountFromBits(int)
parquet/bytes/BytesUtils/readIntLittleEndianPaddedOnBitWidth(java.io.InputStream,int)#parquet/bytes/BytesUtils/readIntLittleEndianOnOneByte(java.io.InputStream)
parquet/bytes/BytesUtils/readIntLittleEndianPaddedOnBitWidth(java.io.InputStream,int)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/bytes/BytesUtils/writeIntLittleEndianOnOneByte(java.io.OutputStream,int)#java/io/OutputStream/write(int)
parquet/bytes/BytesUtils/readIntLittleEndian(java.io.InputStream)#java/io/InputStream/read()
parquet/bytes/BytesUtils/readIntLittleEndian(java.io.InputStream)#java/io/EOFException/EOFException()
parquet/avro/AvroReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/AvroReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType,java.util.Map)
parquet/avro/AvroReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)
parquet/avro/AvroReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/util/Map/put(K,V)
parquet/avro/AvroReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/util/LinkedHashMap/LinkedHashMap()
parquet/avro/AvroReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/avro/AvroReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/AvroReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/Map/get(java.lang.Object)
parquet/avro/AvroReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/avro/AvroRecordMaterializer/AvroRecordMaterializer(parquet.schema.MessageType,parquet.pig.convert.Schema)
parquet/avro/AvroReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/avro/AvroSchemaConverter/convert(parquet.schema.MessageType)
parquet/avro/AvroReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getReadSupportMetadata()
parquet/thrift/ThriftMetaData/fromExtraMetaData(java.util.Map)#java/util/Map/get(java.lang.Object)
parquet/thrift/ThriftMetaData/fromExtraMetaData(java.util.Map)#parquet/thrift/ThriftMetaData/parseDescriptor(java.lang.String)
parquet/thrift/ThriftMetaData/fromExtraMetaData(java.util.Map)#parquet/thrift/ThriftMetaData/ThriftMetaData(java.lang.String,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/ThriftMetaData/getThriftClass(java.lang.String)#java/lang/Class/forName(java.lang.String)
parquet/thrift/ThriftMetaData/getThriftClass(java.lang.String)#java/lang/Class/isAssignableFrom(java.lang.Class)
parquet/thrift/ThriftMetaData/getThriftClass(java.lang.String)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String)
parquet/thrift/ThriftMetaData/getThriftClass(java.lang.String)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/thrift/ThriftMetaData/parseDescriptor(java.lang.String)#parquet/thrift/struct/ThriftType/fromJSON(java.lang.String)
parquet/thrift/ThriftMetaData/parseDescriptor(java.lang.String)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/thrift/ThriftMetaData/getThriftClass()#parquet/thrift/ThriftMetaData/getThriftClass(java.lang.String)
parquet/thrift/ThriftMetaData/toString()#parquet/thrift/ThriftMetaData/toExtraMetaData()
parquet/thrift/ThriftMetaData/toExtraMetaData()#parquet/thrift/ThriftMetaData/getThriftClass()
parquet/thrift/ThriftMetaData/toExtraMetaData()#java/util/HashMap/HashMap()
parquet/thrift/ThriftMetaData/toExtraMetaData()#java/lang/Class/getName()
parquet/thrift/ThriftMetaData/toExtraMetaData()#java/util/Map/put(K,V)
parquet/thrift/ThriftMetaData/toExtraMetaData()#parquet/thrift/struct/ThriftType/toJSON()
parquet/thrift/ThriftMetaData/getThriftClassNames(java.util.Map)#java/util/Map/get(java.lang.Object)
parquet/hadoop/metadata/TestColumnChunkMetaData/testConversionBig()#parquet/hadoop/metadata/TestColumnChunkMetaData/newMD(long)
parquet/hadoop/metadata/TestColumnChunkMetaData/testConversionBig()#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/hadoop/metadata/TestColumnChunkMetaData/newMD(long)#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/hadoop/metadata/TestColumnChunkMetaData/newMD(long)#parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/hadoop/metadata/TestColumnChunkMetaData/newMD(long)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/hadoop/metadata/TestColumnChunkMetaData/newMD(long)#java/util/HashSet/HashSet()
parquet/hadoop/metadata/TestColumnChunkMetaData/testConversionSmall()#parquet/hadoop/metadata/TestColumnChunkMetaData/newMD(long)
parquet/hadoop/metadata/TestColumnChunkMetaData/testConversionSmall()#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/hadoop/metadata/TestColumnChunkMetaData/testConversionVeryBig()#parquet/hadoop/metadata/TestColumnChunkMetaData/newMD(long)
parquet/hadoop/metadata/TestColumnChunkMetaData/testConversionVeryBig()#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/hadoop/metadata/TestColumnChunkMetaData/testConversionNeg()#parquet/hadoop/metadata/TestColumnChunkMetaData/newMD(long)
parquet/hadoop/metadata/TestColumnChunkMetaData/testConversionNeg()#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/hadoop/CodecFactory/getDecompressor(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/CodecFactory/BytesDecompressor/BytesDecompressor(parquet.hadoop.metadata.CompressionCodec)
parquet/hadoop/CodecFactory/getDecompressor(parquet.hadoop.metadata.CompressionCodecName)#java/util/Map/get(java.lang.Object)
parquet/hadoop/CodecFactory/getDecompressor(parquet.hadoop.metadata.CompressionCodecName)#java/util/Map/put(K,V)
parquet/hadoop/CodecFactory/getDecompressor(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/CodecFactory/getCodec(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/CodecFactory/release()#java/util/Map/values()
parquet/hadoop/CodecFactory/release()#java/util/Map/clear()
parquet/hadoop/CodecFactory/release()#parquet/hadoop/CodecFactory/BytesCompressor/release()
parquet/hadoop/CodecFactory/release()#parquet/hadoop/CodecFactory/BytesDecompressor/release()
parquet/hadoop/CodecFactory/getCodec(parquet.hadoop.metadata.CompressionCodecName)#java/lang/Class/forName(java.lang.String)
parquet/hadoop/CodecFactory/getCodec(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/metadata/CompressionCodecName/getHadoopCompressionCodecClassName()
parquet/hadoop/CodecFactory/getCodec(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/hadoop/CodecFactory/getCompressor(parquet.hadoop.metadata.CompressionCodecName,int)#parquet/hadoop/CodecFactory/BytesCompressor/BytesCompressor(parquet.hadoop.metadata.CompressionCodecName,parquet.hadoop.metadata.CompressionCodec,int)
parquet/hadoop/CodecFactory/getCompressor(parquet.hadoop.metadata.CompressionCodecName,int)#java/util/Map/get(java.lang.Object)
parquet/hadoop/CodecFactory/getCompressor(parquet.hadoop.metadata.CompressionCodecName,int)#java/util/Map/put(K,V)
parquet/hadoop/CodecFactory/getCompressor(parquet.hadoop.metadata.CompressionCodecName,int)#parquet/hadoop/CodecFactory/getCodec(parquet.hadoop.metadata.CompressionCodecName)
parquet/thrift/struct/ThriftType/I32Type/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.I32Type)
parquet/column/ColumnDescriptor/hashCode()#java/util/Arrays/hashCode(java.lang.Object[])
parquet/column/ColumnDescriptor/toString()#java/util/Arrays/toString(java.lang.Object[])
parquet/column/ColumnDescriptor/equals(java.lang.Object)#java/util/Arrays/equals(java.lang.Object[],java.lang.Object[])
parquet/column/ColumnDescriptor/compareTo(parquet.column.ColumnDescriptor)#java/lang/String/compareTo(java.lang.String)
parquet/filter2/Generator/main(java.lang.String[])#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])
parquet/thrift/TestThriftToPigCompatibility/testStructInMap()#parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)
parquet/thrift/TestThriftToPigCompatibility/testStructInMap()#java/util/Collections/singletonMap(K,V)
parquet/thrift/TestThriftToPigCompatibility/testStructInMap()#java/util/HashMap/HashMap()
parquet/thrift/TestThriftToPigCompatibility/testStructInMap()#java/lang/Object/Object()
parquet/thrift/TestThriftToPigCompatibility/testProtocolAddressBook()#java/util/ArrayList/ArrayList()
parquet/thrift/TestThriftToPigCompatibility/testProtocolAddressBook()#parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)
parquet/thrift/TestThriftToPigCompatibility/testProtocolAddressBook()#java/util/Arrays/asList(T[])
parquet/thrift/TestThriftToPigCompatibility/testProtocolAddressBook()#java/lang/Object/Object()
parquet/thrift/TestThriftToPigCompatibility/testProtocolEmptyAdressBook()#java/util/ArrayList/ArrayList()
parquet/thrift/TestThriftToPigCompatibility/testProtocolEmptyAdressBook()#parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)
parquet/thrift/TestThriftToPigCompatibility/testMapInSet()#parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)
parquet/thrift/TestThriftToPigCompatibility/testMapInSet()#java/util/HashMap/HashMap()
parquet/thrift/TestThriftToPigCompatibility/testMapInSet()#java/util/Set/add(E)
parquet/thrift/TestThriftToPigCompatibility/testMapInSet()#java/util/Map/put(K,V)
parquet/thrift/TestThriftToPigCompatibility/testMapInSet()#java/util/HashSet/HashSet()
parquet/thrift/TestThriftToPigCompatibility/testMap()#parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)
parquet/thrift/TestThriftToPigCompatibility/testMap()#java/util/TreeMap/TreeMap()
parquet/thrift/TestThriftToPigCompatibility/testMap()#java/util/Map/put(K,V)
parquet/thrift/TestThriftToPigCompatibility/testOneOfEach()#java/util/ArrayList/ArrayList()
parquet/thrift/TestThriftToPigCompatibility/testOneOfEach()#parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)
parquet/thrift/TestThriftToPigCompatibility/testOneOfEach()#java/nio/ByteBuffer/wrap(byte[])
parquet/thrift/TestThriftToPigCompatibility/testOneOfEach()#java/lang/String/getBytes()
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/pig/convert/TupleRecordMaterializer/TupleRecordMaterializer(parquet.schema.GroupType,parquet.pig.convert.Schema,boolean)
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/schema/Type/toString()
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/io/RecordConsumerLoggingWrapper/RecordConsumerLoggingWrapper(parquet.io.api.RecordConsumer)
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/pig/convert/TupleRecordMaterializer/getRootConverter()
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/pig/PigSchemaConverter/PigSchemaConverter()
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/pig/convert/TupleRecordMaterializer/getCurrentRecord()
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#java/lang/Object/getClass()
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema)
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/thrift/ParquetWriteProtocol/ParquetWriteProtocol(parquet.io.api.RecordConsumer,parquet.io.MessageColumnIO,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/io/ConverterConsumer/ConverterConsumer(parquet.io.api.GroupConverter,parquet.schema.MessageType)
parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/thrift/TestThriftToPigCompatibility/testStringList()#java/util/ArrayList/ArrayList()
parquet/thrift/TestThriftToPigCompatibility/testStringList()#parquet/thrift/TestThriftToPigCompatibility/validateSameTupleAsEB(T)
parquet/thrift/TestThriftToPigCompatibility/testStringList()#java/util/List/add(E)
parquet/column/statistics/IntStatistics/getMinBytes()#parquet/bytes/BytesUtils/intToBytes(int)
parquet/column/statistics/IntStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/bytes/BytesUtils/bytesToInt(byte[])
parquet/column/statistics/IntStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/IntStatistics/setMinMax(int,int)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/IntStatistics/updateStats(int)#parquet/column/statistics/IntStatistics/updateStats(int,int)
parquet/column/statistics/IntStatistics/updateStats(int)#parquet/column/statistics/IntStatistics/initializeStats(int,int)
parquet/column/statistics/IntStatistics/updateStats(int)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/IntStatistics/toString()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/statistics/IntStatistics/toString()#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/IntStatistics/toString()#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/IntStatistics/initializeStats(int,int)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/IntStatistics/getMaxBytes()#parquet/bytes/BytesUtils/intToBytes(int)
parquet/column/statistics/IntStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/IntStatistics/getMin()
parquet/column/statistics/IntStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/IntStatistics/updateStats(int,int)
parquet/column/statistics/IntStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/IntStatistics/getMax()
parquet/column/statistics/IntStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/IntStatistics/initializeStats(int,int)
parquet/column/statistics/IntStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/isEmpty()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/addRowGroup(parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/BlockMetaData/getCompressedSize()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/addRowGroup(parquet.hadoop.metadata.BlockMetaData)#java/util/List/add(E)
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalSize()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/common/schema/ColumnPath/toArray()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/hadoop/ParquetInputSplit/ParquetInputSplit(parquet.hadoop.Path,long,long,long,java.lang.String[],long[],java.lang.String,java.util.Map)
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/hadoop/metadata/BlockMetaData/getTotalByteSize()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#java/util/List/get(int)
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getRowGroupCount()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/schema/MessageType/containsPath(java.lang.String[])
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/hadoop/metadata/BlockMetaData/getStartingPos()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)#parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getRowGroups()
parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getRowGroupCount()#java/util/List/size()
parquet/proto/ProtoParquetOutputFormat/setProtobufClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/proto/ProtoParquetOutputFormat/setProtobufClass(parquet.proto.utils.Job,java.lang.Class)#parquet/proto/ProtoWriteSupport/setSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)
parquet/filter2/recordlevel/PhoneBookWriter/Location/hashCode()#java/lang/Double/hashCode()
parquet/filter2/recordlevel/PhoneBookWriter/Location/equals(java.lang.Object)#java/lang/Double/equals(java.lang.Object)
parquet/filter2/recordlevel/PhoneBookWriter/Location/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/io/api/Binary/fromString(java.lang.String)#java/lang/String/getBytes(java.lang.String)
parquet/io/api/Binary/fromString(java.lang.String)#parquet/io/api/Binary/FromStringBinary/FromStringBinary(byte[])
parquet/io/api/Binary/fromString(java.lang.String)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/io/api/Binary/fromByteBuffer(java.nio.ByteBuffer)#parquet/io/api/Binary/ByteBufferBackedBinary/ByteBufferBackedBinary(java.nio.ByteBuffer)
parquet/io/api/Binary/fromByteArray(byte[],int,int)#parquet/io/api/Binary/ByteArraySliceBackedBinary/ByteArraySliceBackedBinary(byte[],int,int)
parquet/io/api/Binary/fromByteArray(byte[])#parquet/io/api/Binary/ByteArrayBackedBinary/ByteArrayBackedBinary(byte[])
parquet/io/api/Binary/equals(java.lang.Object)#parquet/io/api/Binary/equals(parquet.io.api.Binary)
parquet/io/api/Binary/toString()#parquet/io/api/Binary/length()
parquet/io/api/Binary/toString()#java/util/Arrays/toString(byte[])
parquet/io/api/Binary/toString()#parquet/io/api/Binary/getBytes()
parquet/column/impl/ColumnReadStoreImpl/newMemColumnReader(parquet.column.ColumnDescriptor,parquet.column.page.PageReader)#parquet/column/impl/ColumnReadStoreImpl/getPrimitiveConverter(parquet.column.ColumnDescriptor)
parquet/column/impl/ColumnReadStoreImpl/newMemColumnReader(parquet.column.ColumnDescriptor,parquet.column.page.PageReader)#parquet/column/impl/ColumnReaderImpl/ColumnReaderImpl(parquet.column.ColumnDescriptor,parquet.column.page.PageReader,parquet.io.api.PrimitiveConverter)
parquet/column/impl/ColumnReadStoreImpl/getColumnReader(parquet.column.ColumnDescriptor)#parquet/column/page/PageReadStore/getPageReader(parquet.column.ColumnDescriptor)
parquet/column/impl/ColumnReadStoreImpl/getColumnReader(parquet.column.ColumnDescriptor)#parquet/column/impl/ColumnReadStoreImpl/newMemColumnReader(parquet.column.ColumnDescriptor,parquet.column.page.PageReader)
parquet/column/impl/ColumnReadStoreImpl/getPrimitiveConverter(parquet.column.ColumnDescriptor)#parquet/io/api/GroupConverter/getConverter(int)
parquet/column/impl/ColumnReadStoreImpl/getPrimitiveConverter(parquet.column.ColumnDescriptor)#parquet/column/ColumnDescriptor/getPath()
parquet/column/impl/ColumnReadStoreImpl/getPrimitiveConverter(parquet.column.ColumnDescriptor)#parquet/io/api/Converter/asPrimitiveConverter()
parquet/column/impl/ColumnReadStoreImpl/getPrimitiveConverter(parquet.column.ColumnDescriptor)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/column/impl/ColumnReadStoreImpl/getPrimitiveConverter(parquet.column.ColumnDescriptor)#parquet/schema/GroupType/getType(java.lang.String)
parquet/column/impl/ColumnReadStoreImpl/getPrimitiveConverter(parquet.column.ColumnDescriptor)#parquet/schema/Type/asGroupType()
parquet/column/impl/ColumnReadStoreImpl/getPrimitiveConverter(parquet.column.ColumnDescriptor)#parquet/io/api/Converter/asGroupConverter()
parquet/schema/GroupType/convertChildren(java.util.List,parquet.schema.TypeConverter)#java/util/ArrayList/ArrayList(int)
parquet/schema/GroupType/convertChildren(java.util.List,parquet.schema.TypeConverter)#java/util/List/size()
parquet/schema/GroupType/convertChildren(java.util.List,parquet.schema.TypeConverter)#java/util/List/add(E)
parquet/schema/GroupType/convertChildren(java.util.List,parquet.schema.TypeConverter)#parquet/schema/Type/convert(java.util.List,parquet.schema.TypeConverter)
parquet/schema/GroupType/getFieldName(int)#java/util/List/get(int)
parquet/schema/GroupType/getFieldName(int)#parquet/schema/Type/getName()
parquet/schema/GroupType/containsField(java.lang.String)#java/util/Map/containsKey(java.lang.Object)
parquet/schema/GroupType/getMaxDefinitionLevel(java.lang.String[],int)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/schema/GroupType/getMaxDefinitionLevel(java.lang.String[],int)#parquet/schema/Type/getMaxDefinitionLevel(java.lang.String[],int)
parquet/schema/GroupType/getMaxDefinitionLevel(java.lang.String[],int)#parquet/schema/GroupType/getType(java.lang.String)
parquet/schema/GroupType/withId(int)#parquet/schema/Type/getRepetition()
parquet/schema/GroupType/withId(int)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,java.util.List,parquet.schema.Type.ID)
parquet/schema/GroupType/withId(int)#parquet/schema/Type/ID/ID(int)
parquet/schema/GroupType/withId(int)#parquet/schema/Type/getName()
parquet/schema/GroupType/withId(int)#parquet/schema/Type/getOriginalType()
parquet/schema/GroupType/withNewFields(parquet.schema.Type[])#parquet/schema/GroupType/withNewFields(java.util.List)
parquet/schema/GroupType/withNewFields(parquet.schema.Type[])#java/util/Arrays/asList(T[])
parquet/schema/GroupType/equals(parquet.schema.Type)#parquet/schema/GroupType/getFields()
parquet/schema/GroupType/equals(parquet.schema.Type)#parquet/schema/Type/asGroupType()
parquet/schema/GroupType/equals(parquet.schema.Type)#parquet/schema/Type/isPrimitive()
parquet/schema/GroupType/equals(parquet.schema.Type)#java/util/List/equals(java.lang.Object)
parquet/schema/GroupType/equals(parquet.schema.Type)#parquet/schema/Type/equals(parquet.schema.Type)
parquet/schema/GroupType/getType(int)#java/util/List/get(int)
parquet/schema/GroupType/getType(java.lang.String[],int)#parquet/schema/Type/getType(java.lang.String[],int)
parquet/schema/GroupType/getType(java.lang.String[],int)#parquet/schema/GroupType/getType(java.lang.String)
parquet/schema/GroupType/union(parquet.schema.Type)#parquet/schema/GroupType/union(parquet.schema.Type,boolean)
parquet/schema/GroupType/typeEquals(parquet.schema.Type)#parquet/schema/GroupType/equals(parquet.schema.Type)
parquet/schema/GroupType/union(parquet.schema.Type,boolean)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,java.util.List)
parquet/schema/GroupType/union(parquet.schema.Type,boolean)#parquet/schema/IncompatibleSchemaModificationException/IncompatibleSchemaModificationException(java.lang.String)
parquet/schema/GroupType/union(parquet.schema.Type,boolean)#parquet/schema/Type/isPrimitive()
parquet/schema/GroupType/union(parquet.schema.Type,boolean)#parquet/schema/Type/getName()
parquet/schema/GroupType/union(parquet.schema.Type,boolean)#parquet/schema/GroupType/mergeFields(parquet.schema.GroupType)
parquet/schema/GroupType/union(parquet.schema.Type,boolean)#parquet/schema/Type/asGroupType()
parquet/schema/GroupType/union(parquet.schema.Type,boolean)#parquet/schema/Type/getRepetition()
parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)#parquet/schema/GroupType/getFields()
parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)#parquet/schema/Type/asGroupType()
parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)#parquet/schema/Type/isPrimitive()
parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)#parquet/schema/Type/checkContains(parquet.schema.Type)
parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)#parquet/schema/Type/getName()
parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)#parquet/schema/GroupType/getType(java.lang.String)
parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/schema/GroupType/containsPath(java.lang.String[],int)#parquet/schema/GroupType/containsField(java.lang.String)
parquet/schema/GroupType/containsPath(java.lang.String[],int)#parquet/schema/Type/containsPath(java.lang.String[],int)
parquet/schema/GroupType/containsPath(java.lang.String[],int)#parquet/schema/GroupType/getType(java.lang.String)
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#parquet/schema/GroupType/getFields()
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#parquet/schema/Type/getRepetition()
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#java/util/ArrayList/ArrayList()
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#parquet/schema/GroupType/containsField(java.lang.String)
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#parquet/schema/Type/Repetition/isMoreRestrictiveThan(parquet.schema.Type.Repetition)
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#parquet/schema/IncompatibleSchemaModificationException/IncompatibleSchemaModificationException(java.lang.String)
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#parquet/schema/Type/union(parquet.schema.Type,boolean)
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#java/util/List/add(E)
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#parquet/schema/Type/getName()
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)#parquet/schema/GroupType/getType(java.lang.String)
parquet/schema/GroupType/hashCode()#parquet/schema/GroupType/getFields()
parquet/schema/GroupType/hashCode()#java/util/List/hashCode()
parquet/schema/GroupType/hashCode()#parquet/schema/Type/hashCode()
parquet/schema/GroupType/convert(java.util.List,parquet.schema.TypeConverter)#parquet/schema/GroupType/convertChildren(java.util.List,parquet.schema.TypeConverter)
parquet/schema/GroupType/convert(java.util.List,parquet.schema.TypeConverter)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/schema/GroupType/convert(java.util.List,parquet.schema.TypeConverter)#parquet/schema/TypeConverter/convertGroupType(java.util.List,parquet.schema.GroupType,java.util.List)
parquet/schema/GroupType/convert(java.util.List,parquet.schema.TypeConverter)#java/util/List/add(E)
parquet/schema/GroupType/checkContains(parquet.schema.Type)#parquet/schema/Type/checkContains(parquet.schema.Type)
parquet/schema/GroupType/checkContains(parquet.schema.Type)#parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)
parquet/schema/GroupType/membersDisplayString(java.lang.StringBuilder,java.lang.String)#java/lang/StringBuilder/append(java.lang.String)
parquet/schema/GroupType/membersDisplayString(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)
parquet/schema/GroupType/membersDisplayString(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/isPrimitive()
parquet/schema/GroupType/withNewFields(java.util.List)#parquet/schema/Type/getRepetition()
parquet/schema/GroupType/withNewFields(java.util.List)#parquet/schema/Type/getId()
parquet/schema/GroupType/withNewFields(java.util.List)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,java.util.List,parquet.schema.Type.ID)
parquet/schema/GroupType/withNewFields(java.util.List)#parquet/schema/Type/getName()
parquet/schema/GroupType/withNewFields(java.util.List)#parquet/schema/Type/getOriginalType()
parquet/schema/GroupType/getMaxRepetitionLevel(java.lang.String[],int)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/schema/GroupType/getMaxRepetitionLevel(java.lang.String[],int)#parquet/schema/Type/getMaxRepetitionLevel(java.lang.String[],int)
parquet/schema/GroupType/getMaxRepetitionLevel(java.lang.String[],int)#parquet/schema/GroupType/getType(java.lang.String)
parquet/schema/GroupType/accept(parquet.schema.TypeVisitor)#parquet/schema/TypeVisitor/visit(parquet.schema.GroupType)
parquet/schema/GroupType/typeHashCode()#parquet/schema/GroupType/hashCode()
parquet/schema/GroupType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/GroupType/membersDisplayString(java.lang.StringBuilder,java.lang.String)
parquet/schema/GroupType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/String/toLowerCase()
parquet/schema/GroupType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/StringBuilder/append(java.lang.String)
parquet/schema/GroupType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getId()
parquet/schema/GroupType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/Enum/name()
parquet/schema/GroupType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getRepetition()
parquet/schema/GroupType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getName()
parquet/schema/GroupType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getOriginalType()
parquet/schema/GroupType/getPaths(int)#java/util/ArrayList/ArrayList()
parquet/schema/GroupType/getPaths(int)#parquet/schema/Type/getPaths(int)
parquet/schema/GroupType/getPaths(int)#java/util/List/add(E)
parquet/schema/GroupType/getPaths(int)#parquet/schema/Type/getName()
parquet/schema/GroupType/getFieldIndex(java.lang.String)#java/util/Map/get(java.lang.Object)
parquet/schema/GroupType/getFieldIndex(java.lang.String)#java/util/Map/containsKey(java.lang.Object)
parquet/schema/GroupType/getFieldIndex(java.lang.String)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/schema/GroupType/getFieldCount()#java/util/List/size()
parquet/schema/GroupType/getType(java.lang.String)#parquet/schema/GroupType/getType(int)
parquet/schema/GroupType/getType(java.lang.String)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/schema/GroupType/mergeFields(parquet.schema.GroupType)#parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)
parquet/schema/Types/buildGroup(parquet.schema.Type.Repetition)#parquet/schema/Types/GroupBuilder/GroupBuilder(java.lang.Class)
parquet/schema/Types/buildGroup(parquet.schema.Type.Repetition)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/requiredGroup()#parquet/schema/Types/GroupBuilder/GroupBuilder(java.lang.Class)
parquet/schema/Types/requiredGroup()#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/repeated(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/PrimitiveBuilder/PrimitiveBuilder(java.lang.Class,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/Types/repeated(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/repeatedGroup()#parquet/schema/Types/GroupBuilder/GroupBuilder(java.lang.Class)
parquet/schema/Types/repeatedGroup()#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/PrimitiveBuilder/PrimitiveBuilder(java.lang.Class,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/PrimitiveBuilder/PrimitiveBuilder(java.lang.Class,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/Types/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)#parquet/schema/Types/PrimitiveBuilder/PrimitiveBuilder(java.lang.Class,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/Types/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/buildMessage()#parquet/schema/Types/MessageTypeBuilder/MessageTypeBuilder()
parquet/schema/Types/optionalGroup()#parquet/schema/Types/GroupBuilder/GroupBuilder(java.lang.Class)
parquet/schema/Types/optionalGroup()#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/reset()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/reset(boolean)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeRleRun()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeOrAppendBitPackedRun()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/getBufferedSize()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/endPreviousBitPackedRun()#parquet/bytes/CapacityByteArrayOutputStream/setByte(long,byte)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeRleRun()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/endPreviousBitPackedRun()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeRleRun()#parquet/bytes/BytesUtils/writeIntLittleEndianPaddedOnBitWidth(java.io.OutputStream,int,int)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeRleRun()#parquet/bytes/BytesUtils/writeUnsignedVarInt(int,java.io.OutputStream)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeOrAppendBitPackedRun()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/endPreviousBitPackedRun()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeOrAppendBitPackedRun()#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeOrAppendBitPackedRun()#parquet/bytes/CapacityByteArrayOutputStream/getCurrentIndex()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeOrAppendBitPackedRun()#parquet/column/values/bitpacking/BytePacker/pack8Values(int[],int,byte[],int)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeOrAppendBitPackedRun()#java/io/OutputStream/write(byte[])
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/getAllocatedSize()#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeRleRun()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeOrAppendBitPackedRun()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/endPreviousBitPackedRun()
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/column/values/rle/RunLengthBitPackingHybridEncoder/reset(boolean)#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#java/lang/Object/toString()
parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#java/util/Iterator/hasNext()
parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#java/util/List/size()
parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#java/util/Iterator/next()
parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#parquet/filter2/recordlevel/TestRecordLevelFilters/getExpected(parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)
parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#java/util/List/iterator()
parquet/filter2/recordlevel/TestRecordLevelFilters/makeUsers()#java/util/ArrayList/ArrayList()
parquet/filter2/recordlevel/TestRecordLevelFilters/makeUsers()#parquet/filter2/recordlevel/PhoneBookWriter/Location/Location(java.lang.Double,java.lang.Double)
parquet/filter2/recordlevel/TestRecordLevelFilters/makeUsers()#parquet/filter2/recordlevel/PhoneBookWriter/PhoneNumber/PhoneNumber(long,java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/makeUsers()#java/util/Arrays/asList(T[])
parquet/filter2/recordlevel/TestRecordLevelFilters/makeUsers()#java/util/List/add(E)
parquet/filter2/recordlevel/TestRecordLevelFilters/makeUsers()#parquet/filter2/recordlevel/PhoneBookWriter/User/User(long,java.lang.String,java.util.List,parquet.filter2.recordlevel.PhoneBookWriter.Location)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNoFilter()#parquet/filter2/recordlevel/TestRecordLevelFilters/testNoFilter()/$anonymous1/()
parquet/filter2/recordlevel/TestRecordLevelFilters/testNoFilter()#parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNoFilter()#parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testAllFilter()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/recordlevel/TestRecordLevelFilters/testAllFilter()#parquet/filter2/predicate/FilterApi/binaryColumn(java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/testAllFilter()#java/util/ArrayList/ArrayList()
parquet/filter2/recordlevel/TestRecordLevelFilters/testAllFilter()#parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testAllFilter()#parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/recordlevel/TestRecordLevelFilters/testAllFilter()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/getExpected(parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#java/util/ArrayList/ArrayList()
parquet/filter2/recordlevel/TestRecordLevelFilters/getExpected(parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)
parquet/filter2/recordlevel/TestRecordLevelFilters/getExpected(parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#parquet/filter2/recordlevel/TestRecordLevelFilters/UserFilter/keep(parquet.filter2.recordlevel.PhoneBookWriter.User)
parquet/filter2/recordlevel/TestRecordLevelFilters/getExpected(parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)#java/util/List/add(E)
parquet/filter2/recordlevel/TestRecordLevelFilters/setup()#parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.util.List)
parquet/filter2/recordlevel/TestRecordLevelFilters/setup()#parquet/filter2/recordlevel/TestRecordLevelFilters/makeUsers()
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotNull()#parquet/filter2/predicate/FilterApi/binaryColumn(java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotNull()#parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotNull()#parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotNull()/$anonymous1/()
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotNull()#parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotNull()#parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotNull()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotStartWithP()#parquet/filter2/predicate/FilterApi/binaryColumn(java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotStartWithP()#parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotStartWithP()#parquet/filter2/predicate/FilterApi/userDefined(parquet.filter2.predicate.Operators.Column,java.lang.Class)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotStartWithP()#parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotStartWithP()#parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotStartWithP()/$anonymous1/()
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotStartWithP()#parquet/filter2/predicate/FilterApi/not(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/recordlevel/TestRecordLevelFilters/testNameNotStartWithP()#parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/predicate/FilterApi/binaryColumn(java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/predicate/FilterApi/doubleColumn(java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/predicate/FilterApi/gt(C,T)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/recordlevel/TestRecordLevelFilters/assertFilter(java.util.List,parquet.filter2.recordlevel.TestRecordLevelFilters.UserFilter)
parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()#parquet/filter2/recordlevel/TestRecordLevelFilters/testComplex()/$anonymous1/()
parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/createProtocolEventsForField(parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ReadFieldBeginProtocol/ReadFieldBeginProtocol(parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/createProtocolEventsForField(parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/createProtocolEventsForField(parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/DefaultEventsVisitor/DefaultEventsVisitor()
parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/createProtocolEventsForField(parquet.thrift.struct.ThriftField)#java/util/List/addAll(java.util.Collection)
parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/createProtocolEventsForField(parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/DefaultEventsVisitor/getEvents()
parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/createProtocolEventsForField(parquet.thrift.struct.ThriftField)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/createProtocolEventsForField(parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/impl/ColumnReadStoreImpl/getColumnReader(parquet.column.ColumnDescriptor)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getDouble()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/tools/command/DumpCommand/binaryToString(parquet.io.api.Binary)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getCurrentDefinitionLevel()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnDescriptor/getMaxDefinitionLevel()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getLong()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getFloat()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getInteger()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getBinary()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getTotalValueCount()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnDescriptor/getType()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/consume()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getBoolean()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/tools/command/DumpCommand/binaryToBigInteger(parquet.io.api.Binary)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/column/ColumnReader/getCurrentRepetitionLevel()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/command/DumpCommand/binaryToBigInteger(parquet.io.api.Binary)#java/math/BigInteger/BigInteger(byte[])
parquet/tools/command/DumpCommand/binaryToBigInteger(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/PageReader/getTotalValueCount()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/tools/util/PrettyPrintWriter/rule(char)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/Page/getValueEncoding()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/ColumnDescriptor/getPath()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/Page/getValueCount()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/PageReader/readDictionaryPage()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/ColumnDescriptor/getMaxDefinitionLevel()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/ColumnDescriptor/getMaxRepetitionLevel()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/DictionaryPage/getEncoding()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/PageReader/readPage()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/Page/getUncompressedSize()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/Page/getDlEncoding()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/PageReadStore/getPageReader(parquet.column.ColumnDescriptor)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/DictionaryPage/getDictionarySize()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)#parquet/column/page/Page/getRlEncoding()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#java/util/ArrayList/ArrayList()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/schema/MessageType/getColumns()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.page.PageReadStore,parquet.column.ColumnDescriptor)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/common/schema/ColumnPath/toArray()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/column/ColumnDescriptor/getPath()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#java/util/List/size()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/column/page/PageReadStore/getRowCount()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#java/util/List/add(E)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/util/PrettyPrintWriter/flushColumns()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/util/PrettyPrintWriter/decrementTabLevel()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/column/ColumnDescriptor/getType()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.column.impl.ColumnReadStoreImpl,parquet.column.ColumnDescriptor,long,long,long)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/hadoop/ParquetFileReader/ParquetFileReader(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List,java.util.List)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/util/PrettyPrintWriter/rule(char)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/column/impl/ColumnReadStoreImpl/ColumnReadStoreImpl(parquet.column.page.PageReadStore,parquet.io.api.GroupConverter,parquet.schema.MessageType)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/command/DumpCommand/DumpGroupConverter/DumpGroupConverter()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#java/util/Collections/singletonList(T)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/hadoop/ParquetFileReader/close()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,java.util.List)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#java/util/Set/contains(java.lang.Object)
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/hadoop/ParquetFileReader/readNextRowGroup()
parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)#parquet/tools/util/PrettyPrintWriter/incrementTabLevel()
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/command/ArgsOnlyCommand/execute(parquet.tools.command.CommandLine)
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withFlushOnTab()
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/stdoutPrettyPrinter()
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/build()
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop()
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withMaxBufferedLines(long)
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withColumnPadding(int)
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withWhitespaceHandler(parquet.tools.util.PrettyPrintWriter.WhiteSpaceHandler)
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#java/util/Arrays/asList(T[])
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/command/DumpCommand/dump(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata,parquet.schema.MessageType,parquet.hadoop.Path,boolean,boolean,java.util.Set)
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#java/util/HashSet/HashSet(java.util.Collection)
parquet/tools/command/DumpCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withAutoColumn()
parquet/tools/command/DumpCommand/binaryToString(parquet.io.api.Binary)#java/nio/charset/CharsetDecoder/decode(java.nio.ByteBuffer)
parquet/tools/command/DumpCommand/binaryToString(parquet.io.api.Binary)#parquet/io/api/Binary/toByteBuffer()
parquet/tools/command/DumpCommand/binaryToString(parquet.io.api.Binary)#java/nio/CharBuffer/toString()
parquet/tools/command/DumpCommand/binaryToString(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)#parquet/io/api/RecordConsumer/endGroup()
parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)#parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)
parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)#java/util/Iterator/hasNext()
parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)#java/lang/Iterable/iterator()
parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)#parquet/io/api/RecordConsumer/startGroup()
parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)#parquet/schema/GroupType/getType(int)
parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/schema/GroupType/getFields()
parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#java/util/List/get(int)
parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/schema/Type/getName()
parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)
parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/avro/AvroWriteSupport/write(parquet.avro.IndexedRecord)#parquet/io/api/RecordConsumer/startMessage()
parquet/avro/AvroWriteSupport/write(parquet.avro.IndexedRecord)#parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)
parquet/avro/AvroWriteSupport/write(parquet.avro.IndexedRecord)#parquet/io/api/RecordConsumer/endMessage()
parquet/avro/AvroWriteSupport/writeRecord(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/io/api/RecordConsumer/endGroup()
parquet/avro/AvroWriteSupport/writeRecord(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/avro/AvroWriteSupport/writeRecordFields(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)
parquet/avro/AvroWriteSupport/writeRecord(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)#parquet/io/api/RecordConsumer/startGroup()
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#parquet/schema/Type/asGroupType()
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#parquet/io/api/RecordConsumer/endGroup()
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#java/util/Map/size()
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#java/util/Map/keySet()
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#parquet/io/api/RecordConsumer/startGroup()
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#java/util/Map/values()
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)#parquet/schema/GroupType/getType(int)
parquet/avro/AvroWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/AvroWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/HashMap/HashMap()
parquet/avro/AvroWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)
parquet/avro/AvroWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/Map/put(K,V)
parquet/avro/AvroWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/WriteSupport/WriteContext/WriteContext(parquet.schema.MessageType,java.util.Map)
parquet/avro/AvroWriteSupport/fromAvroString(java.lang.Object)#java/lang/Object/toString()
parquet/avro/AvroWriteSupport/fromAvroString(java.lang.Object)#parquet/io/api/Binary/fromByteArray(byte[],int,int)
parquet/avro/AvroWriteSupport/fromAvroString(java.lang.Object)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/Binary/fromByteBuffer(java.nio.ByteBuffer)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#java/lang/Number/floatValue()
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#java/lang/Object/toString()
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/avro/AvroWriteSupport/writeArray(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Iterable)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/Binary/fromByteArray(byte[])
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/avro/AvroWriteSupport/writeRecord(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.avro.IndexedRecord)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/avro/AvroWriteSupport/writeUnion(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Object)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#java/lang/Number/longValue()
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/avro/AvroWriteSupport/fromAvroString(java.lang.Object)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/avro/AvroSchemaConverter/getNonNull(parquet.pig.convert.Schema)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#java/lang/Number/doubleValue()
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#java/lang/Number/intValue()
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/addFloat(float)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/addLong(long)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/addBoolean(boolean)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/avro/AvroWriteSupport/writeMap(parquet.schema.GroupType,parquet.pig.convert.Schema,java.util.Map)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/avro/AvroWriteSupport/writeUnion(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Object)#parquet/schema/Type/asGroupType()
parquet/avro/AvroWriteSupport/writeUnion(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/endGroup()
parquet/avro/AvroWriteSupport/writeUnion(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Object)#parquet/avro/AvroWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.Schema,java.lang.Object)
parquet/avro/AvroWriteSupport/writeUnion(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/avro/AvroWriteSupport/writeUnion(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/startGroup()
parquet/avro/AvroWriteSupport/writeUnion(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Object)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/avro/AvroWriteSupport/writeUnion(parquet.schema.GroupType,parquet.pig.convert.Schema,java.lang.Object)#parquet/schema/GroupType/getType(int)
parquet/hadoop/ParquetOutputCommitter/commitJob(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputCommitter/commitJob(parquet.hadoop.util.JobContext)#parquet/Log/warn(java.lang.Object,java.lang.Throwable)
parquet/hadoop/ParquetOutputCommitter/commitJob(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetFileWriter/writeMetadataFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List)
parquet/hadoop/ParquetOutputCommitter/commitJob(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetFileReader/readAllFootersInParallel(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)
parquet/hadoop/ParquetOutputCommitter/commitJob(parquet.hadoop.util.JobContext)#java/lang/Object/Object()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/predicate/Operators/LtEq/LtEq(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/predicate/Operators/NotEq/NotEq(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/predicate/Operators/Eq/Eq(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/predicate/LogicalInverter/invert(parquet.filter2.predicate.FilterPredicate)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/LogicalInverter/invert(parquet.filter2.predicate.FilterPredicate)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/And/And(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/Or/Or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.LogicalNotUserDefined)#parquet/filter2/predicate/Operators/LogicalNotUserDefined/getUserDefined()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Not)#parquet/filter2/predicate/Operators/Not/getPredicate()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/predicate/Operators/Lt/Lt(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/predicate/Operators/Gt/Gt(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/predicate/Operators/GtEq/GtEq(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/predicate/LogicalInverter/visit(parquet.filter2.predicate.Operators.UserDefined)#parquet/filter2/predicate/Operators/LogicalNotUserDefined/LogicalNotUserDefined(parquet.filter2.predicate.Operators.UserDefined)
parquet/column/values/bitpacking/BaseBitPackingWriter/finish(int,int,java.io.OutputStream)#java/io/OutputStream/write(int)
parquet/column/values/bitpacking/BaseBitPackingWriter/finish(int,long,java.io.OutputStream)#java/io/OutputStream/write(int)
parquet/hadoop/CodecFactory/BytesCompressor/compress(parquet.bytes.BytesInput)#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/hadoop/CodecFactory/BytesCompressor/compress(parquet.bytes.BytesInput)#java/io/ByteArrayOutputStream/reset()
parquet/hadoop/CodecFactory/BytesCompressor/compress(parquet.bytes.BytesInput)#parquet/bytes/BytesInput/from(java.io.ByteArrayOutputStream)
parquet/scrooge/ScroogeStructConverterTest/testMapComplex()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testMapComplex()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testMapComplex()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testMapComplex()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveMapKey()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveMapKey()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveMapKey()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveMapKey()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveSet()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveSet()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveSet()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveSet()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertEnum()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertEnum()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertEnum()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertEnum()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testDefaultFields()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testDefaultFields()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testDefaultFields()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testDefaultFields()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveMapValue()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveMapValue()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveMapValue()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveMapValue()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertOptionalPrimitiveMap()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertOptionalPrimitiveMap()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertOptionalPrimitiveMap()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertOptionalPrimitiveMap()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveList()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveList()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveList()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertPrimitiveList()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertStruct()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertStruct()#parquet/scrooge/ScroogeStructConverter/ScroogeStructConverter()
parquet/scrooge/ScroogeStructConverterTest/testConvertStruct()#parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)
parquet/scrooge/ScroogeStructConverterTest/testConvertStruct()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/column/values/dictionary/DictionaryValuesReader/readBytes()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/dictionary/DictionaryValuesReader/readBytes()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/dictionary/DictionaryValuesReader/readBytes()#parquet/column/Dictionary/decodeToBinary(int)
parquet/column/values/dictionary/DictionaryValuesReader/readDouble()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/dictionary/DictionaryValuesReader/readDouble()#parquet/column/Dictionary/decodeToDouble(int)
parquet/column/values/dictionary/DictionaryValuesReader/readDouble()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/dictionary/DictionaryValuesReader/readLong()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/dictionary/DictionaryValuesReader/readLong()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/dictionary/DictionaryValuesReader/readLong()#parquet/column/Dictionary/decodeToLong(int)
parquet/column/values/dictionary/DictionaryValuesReader/readFloat()#parquet/column/Dictionary/decodeToFloat(int)
parquet/column/values/dictionary/DictionaryValuesReader/readFloat()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/dictionary/DictionaryValuesReader/readFloat()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/dictionary/DictionaryValuesReader/readValueDictionaryId()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/dictionary/DictionaryValuesReader/readValueDictionaryId()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[],int,int)
parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)#parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)/$anonymous1/(int,java.io.ByteArrayInputStream)
parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/RunLengthBitPackingHybridDecoder(int,java.io.ByteArrayInputStream)
parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)#parquet/bytes/BytesUtils/readIntLittleEndianOnOneByte(java.io.InputStream)
parquet/column/values/dictionary/DictionaryValuesReader/skip()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/dictionary/DictionaryValuesReader/skip()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/dictionary/DictionaryValuesReader/readInteger()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/dictionary/DictionaryValuesReader/readInteger()#parquet/column/Dictionary/decodeToInt(int)
parquet/column/values/dictionary/DictionaryValuesReader/readInteger()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/bitpacking/BitPackingValuesReader/readInteger()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/bitpacking/BitPackingValuesReader/readInteger()#parquet/column/values/bitpacking/BitPacking/BitPackingReader/read()
parquet/column/values/bitpacking/BitPackingValuesReader/initFromPage(int,byte[],int)#parquet/bytes/BytesUtils/paddedByteCountFromBits(int)
parquet/column/values/bitpacking/BitPackingValuesReader/initFromPage(int,byte[],int)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[],int,int)
parquet/column/values/bitpacking/BitPackingValuesReader/initFromPage(int,byte[],int)#parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)
parquet/column/values/bitpacking/BitPackingValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/BitPackingValuesReader/skip()#parquet/column/values/bitpacking/BitPackingValuesReader/readInteger()
parquet/column/values/bitpacking/TwoBitPackingReader/read()#java/io/InputStream/read()
parquet/pig/convert/MapConverter/MapKeyValueConverter/getConverter(int)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/pig/convert/MapConverter/MapKeyValueConverter/end()#java/lang/Object/toString()
parquet/pig/convert/MapConverter/MapKeyValueConverter/end()#java/util/Map/put(K,V)
parquet/column/values/bitpacking/FiveBitPackingWriter/finish()#parquet/column/values/bitpacking/BaseBitPackingWriter/finish(int,long,java.io.OutputStream)
parquet/column/values/bitpacking/FiveBitPackingWriter/write(int)#java/io/OutputStream/write(int)
parquet/pig/convert/MapConverter/StringKeyConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testEmptyContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListElement(java.lang.Object,int)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testEmptyContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getList(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testEmptyContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListLength(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testEmptyContainer()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testNullArray()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListElement(java.lang.Object,int)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testNullArray()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getList(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testNullArray()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListLength(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/setUp()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/ParquetHiveArrayInspector(org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testNullContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListElement(java.lang.Object,int)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testNullContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getList(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testNullContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListLength(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testRegularList()#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testRegularList()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListElement(java.lang.Object,int)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testRegularList()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getList(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testRegularList()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListLength(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector/testRegularList()#java/lang/Object/Object()
parquet/scrooge/ParquetScroogeSchemeTest/ObjectToStringFunction/operate(parquet.cascading.FlowProcess,parquet.cascading.FunctionCall)#java/lang/Object/toString()
parquet/column/values/boundedint/BoundedIntValuesReader/readInteger()#parquet/column/values/boundedint/BitReader/readNBitInteger(int)
parquet/column/values/boundedint/BoundedIntValuesReader/readInteger()#parquet/column/values/boundedint/BitReader/readBit()
parquet/column/values/boundedint/BoundedIntValuesReader/readInteger()#parquet/column/values/boundedint/BitReader/readUnsignedVarint()
parquet/column/values/boundedint/BoundedIntValuesReader/readInteger()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/boundedint/BoundedIntValuesReader/skip()#parquet/column/values/boundedint/BoundedIntValuesReader/readInteger()
parquet/column/values/boundedint/BoundedIntValuesReader/initFromPage(int,byte[],int)#parquet/column/values/boundedint/BitReader/prepare(byte[],int,int)
parquet/column/values/boundedint/BoundedIntValuesReader/initFromPage(int,byte[],int)#parquet/bytes/BytesUtils/readIntLittleEndian(byte[],int)
parquet/column/values/boundedint/BoundedIntValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/proto/ProtoMessageConverter/ProtoBinaryConverter/addBinary(parquet.io.api.Binary)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/proto/ProtoMessageConverter/ProtoBinaryConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toByteBuffer()
parquet/thrift/struct/CompatibilityReport/fail(java.lang.String)#java/util/List/add(E)
parquet/filter2/predicate/TestLogicalInverseRewriter/assertNoOp(parquet.filter2.predicate.FilterPredicate)#parquet/filter2/predicate/LogicalInverseRewriter/rewrite(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverseRewriter/testComplex()#parquet/filter2/predicate/LogicalInverseRewriter/rewrite(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/lt(C,T)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/Operators/LogicalNotUserDefined/LogicalNotUserDefined(parquet.filter2.predicate.Operators.UserDefined)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/not(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/ltEq(C,T)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/gt(C,T)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/LogicalInverseRewriter/rewrite(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/TestLogicalInverseRewriter/assertNoOp(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/gtEq(C,T)
parquet/filter2/predicate/TestLogicalInverseRewriter/testBaseCases()#parquet/filter2/predicate/FilterApi/userDefined(parquet.filter2.predicate.Operators.Column,java.lang.Class)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/readBytes()#parquet/column/values/ValuesReader/readInteger()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/readBytes()#parquet/io/api/Binary/fromByteArray(byte[],int,int)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/skip()#parquet/column/values/ValuesReader/readInteger()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/initFromPage(int,byte[],int)#parquet/column/values/ValuesReader/getNextOffset()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/initFromPage(int,byte[],int)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/plain/PlainValuesReader/FloatPlainValuesReader/skip()#parquet/bytes/LittleEndianDataInputStream/skipBytes(int)
parquet/column/values/plain/PlainValuesReader/FloatPlainValuesReader/skip()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesReader/FloatPlainValuesReader/readFloat()#parquet/bytes/LittleEndianDataInputStream/readFloat()
parquet/column/values/plain/PlainValuesReader/FloatPlainValuesReader/readFloat()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/example/data/simple/convert/SimpleGroupConverter/start()#parquet/example/data/Group/addGroup(int)
parquet/example/data/simple/convert/SimpleGroupConverter/start()#parquet/example/data/simple/convert/SimpleGroupConverter/getCurrentRecord()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/getSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/DataWritableWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/write(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/write(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/setSchema(parquet.schema.MessageType,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/Type/toString()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/getSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/HashMap/HashMap()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/WriteSupport/WriteContext/WriteContext(parquet.schema.MessageType,java.util.Map)
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/testEmptyContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/testEmptyContainer()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/testHashMap()#java/util/HashMap/HashMap()
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/testHashMap()#org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/testNullMap()#org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/testRegularMap()#org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/testRegularMap()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/testNullContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector/setUp()#org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/StandardParquetHiveMapInspector(org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
parquet/column/page/DictionaryPage/toString()#parquet/bytes/BytesInput/size()
parquet/column/page/DictionaryPage/copy()#parquet/bytes/BytesInput/copy(parquet.bytes.BytesInput)
parquet/column/page/DictionaryPage/copy()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,int,parquet.column.Encoding)
parquet/thrift/ParquetReadProtocol/readSetBegin()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readSetBegin()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readFieldBegin()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readFieldBegin()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readI16()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readI16()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readMessageEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readMessageEnd()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readStructBegin()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readStructBegin()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readSetEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readSetEnd()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readByte()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readByte()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readStructEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readStructEnd()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readI64()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readI64()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readBool()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readBool()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readI32()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readI32()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readListBegin()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readListBegin()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readMapBegin()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readMapBegin()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readString()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readString()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readDouble()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readDouble()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readListEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readListEnd()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readMapEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readMapEnd()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readFieldEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readFieldEnd()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readBinary()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readBinary()#parquet/thrift/ParquetReadProtocol/next()
parquet/thrift/ParquetReadProtocol/readMessageBegin()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetReadProtocol/readMessageBegin()#parquet/thrift/ParquetReadProtocol/next()
parquet/hadoop/CodecFactory/BytesDecompressor/decompress(parquet.bytes.BytesInput,int)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/hadoop/CodecFactory/BytesDecompressor/decompress(parquet.bytes.BytesInput,int)#parquet/bytes/BytesInput/from(java.io.InputStream,int)
parquet/hadoop/CodecFactory/BytesDecompressor/decompress(parquet.bytes.BytesInput,int)#parquet/bytes/BytesInput/toByteArray()
parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/writeI32(int)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/writeI32(int)#parquet/io/ColumnIO/toString()
parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/writeI32(int)#parquet/thrift/struct/ThriftType/EnumType/getEnumValueById(int)
parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/writeI32(int)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/writeI32(int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/writeI32(int)#parquet/thrift/struct/ThriftType/EnumValue/getName()
parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/writeI32(int)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/writeI32(int)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/avro/AvroIndexedRecordConverter/FieldLongConverter/addInt(int)#java/lang/Long/valueOf(long)
parquet/avro/AvroIndexedRecordConverter/FieldLongConverter/addInt(int)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldLongConverter/addLong(long)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/pig/summary/Summary/Intermediate/exec(parquet.pig.convert.Tuple)#parquet/pig/summary/Summary/merge(parquet.pig.convert.Tuple)
parquet/pig/summary/Summary/Intermediate/exec(parquet.pig.convert.Tuple)#parquet/pig/summary/Summary/JSONTuple/JSONTuple(parquet.pig.summary.TupleSummaryData)
parquet/io/api/Binary/FromStringBinary/toString()#parquet/io/api/Binary/ByteArrayBackedBinary/toStringUsingUTF8()
parquet/hive/internal/AbstractHiveBinding/getColumns(java.lang.String)#java/util/List/removeAll(java.util.Collection)
parquet/hive/TestHiveBindingFactory/NoopClassLoader/loadClass(java.lang.String)#java/lang/ClassNotFoundException/ClassNotFoundException(java.lang.String)
parquet/schema/Types/GroupBuilder/addFields(parquet.schema.Type[])#java/util/List/add(E)
parquet/schema/Types/GroupBuilder/optionalGroup()#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/GroupBuilder/optionalGroup()#parquet/schema/Types/GroupBuilder/GroupBuilder(P)
parquet/schema/Types/GroupBuilder/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/GroupBuilder/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/PrimitiveBuilder/PrimitiveBuilder(P,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/Types/GroupBuilder/addField(parquet.schema.Type)#java/util/List/add(E)
parquet/schema/Types/GroupBuilder/group(parquet.schema.Type.Repetition)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/GroupBuilder/group(parquet.schema.Type.Repetition)#parquet/schema/Types/GroupBuilder/GroupBuilder(P)
parquet/schema/Types/GroupBuilder/repeated(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/GroupBuilder/repeated(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/PrimitiveBuilder/PrimitiveBuilder(P,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/Types/GroupBuilder/requiredGroup()#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/GroupBuilder/requiredGroup()#parquet/schema/Types/GroupBuilder/GroupBuilder(P)
parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Types/PrimitiveBuilder/PrimitiveBuilder(P,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/Types/GroupBuilder/repeatedGroup()#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/GroupBuilder/repeatedGroup()#parquet/schema/Types/GroupBuilder/GroupBuilder(P)
parquet/schema/Types/GroupBuilder/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)#parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)
parquet/schema/Types/GroupBuilder/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)#parquet/schema/Types/PrimitiveBuilder/PrimitiveBuilder(P,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/Types/GroupBuilder/build(java.lang.String)#parquet/Preconditions/checkState(boolean,java.lang.String)
parquet/schema/Types/GroupBuilder/build(java.lang.String)#java/util/List/isEmpty()
parquet/schema/Types/GroupBuilder/build(java.lang.String)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,java.util.List,parquet.schema.Type.ID)
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/makeLookupStructure(Descriptors.FieldDescriptor)#java/util/HashMap/HashMap()
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/makeLookupStructure(Descriptors.FieldDescriptor)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/addBinary(parquet.io.api.Binary)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/addBinary(parquet.io.api.Binary)#parquet/proto/ProtoMessageConverter/ProtoEnumConverter/translateEnumValue(parquet.io.api.Binary)
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/translateEnumValue(parquet.io.api.Binary)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/addValueFromDictionary(int)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/setDictionary(parquet.column.Dictionary)#parquet/column/Dictionary/decodeToBinary(int)
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/setDictionary(parquet.column.Dictionary)#parquet/proto/ProtoMessageConverter/ProtoEnumConverter/translateEnumValue(parquet.io.api.Binary)
parquet/proto/ProtoMessageConverter/ProtoEnumConverter/setDictionary(parquet.column.Dictionary)#parquet/column/Dictionary/getMaxId()
parquet/thrift/struct/JSON/toJSON(java.lang.Object)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/thrift/struct/JSON/toJSON(java.lang.Object)#java/io/StringWriter/StringWriter()
parquet/thrift/struct/JSON/toJSON(java.lang.Object)#java/io/StringWriter/toString()
parquet/thrift/struct/JSON/fromJSON(java.lang.String,java.lang.Class)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper/close(org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#java/io/IOException/IOException(java.lang.Throwable)
org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper/write(java.lang.Void,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#java/io/IOException/IOException(java.lang.Throwable)
org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper/close(boolean)#org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper/close(org.apache.hadoop.hive.ql.io.parquet.read.Reporter)
org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper/write(org.apache.hadoop.hive.ql.io.parquet.Writable)#org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper/write(java.lang.Void,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)
parquet/filter2/recordlevel/PhoneBookWriter/PhoneNumber/equals(java.lang.Object)#java/lang/String/equals(java.lang.Object)
parquet/filter2/recordlevel/PhoneBookWriter/PhoneNumber/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/filter2/recordlevel/PhoneBookWriter/PhoneNumber/hashCode()#java/lang/String/hashCode()
parquet/io/ConverterConsumer/startGroup()#parquet/io/api/GroupConverter/start()
parquet/io/ConverterConsumer/endGroup()#parquet/io/api/GroupConverter/end()
parquet/io/ConverterConsumer/endMessage()#parquet/io/api/GroupConverter/end()
parquet/io/ConverterConsumer/startField(java.lang.String,int)#parquet/io/api/GroupConverter/getConverter(int)
parquet/io/ConverterConsumer/startField(java.lang.String,int)#parquet/schema/GroupType/getType(int)
parquet/io/ConverterConsumer/startField(java.lang.String,int)#parquet/schema/Type/isPrimitive()
parquet/io/ConverterConsumer/startField(java.lang.String,int)#parquet/io/api/Converter/asPrimitiveConverter()
parquet/io/ConverterConsumer/startField(java.lang.String,int)#java/util/Deque/push(E)
parquet/io/ConverterConsumer/startField(java.lang.String,int)#parquet/schema/Type/asGroupType()
parquet/io/ConverterConsumer/startField(java.lang.String,int)#parquet/io/api/Converter/asGroupConverter()
parquet/io/ConverterConsumer/endField(java.lang.String,int)#java/util/Deque/pop()
parquet/io/ConverterConsumer/startMessage()#parquet/io/api/GroupConverter/start()
parquet/io/ConverterConsumer/addFloat(float)#parquet/io/api/PrimitiveConverter/addFloat(float)
parquet/io/ConverterConsumer/addBinary(parquet.io.api.Binary)#parquet/io/api/PrimitiveConverter/addBinary(parquet.io.api.Binary)
parquet/io/ConverterConsumer/addBoolean(boolean)#parquet/io/api/PrimitiveConverter/addBoolean(boolean)
parquet/io/ConverterConsumer/addLong(long)#parquet/io/api/PrimitiveConverter/addLong(long)
parquet/io/ConverterConsumer/addDouble(double)#parquet/io/api/PrimitiveConverter/addDouble(double)
parquet/io/ConverterConsumer/addInteger(int)#parquet/io/api/PrimitiveConverter/addInt(int)
parquet/proto/ProtoWriteSupport/LongWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/addLong(long)
parquet/column/values/boundedint/BoundedIntValuesFactory/getBoundedReader(int)#parquet/column/values/boundedint/BoundedIntValuesReader/BoundedIntValuesReader(int)
parquet/column/values/boundedint/BoundedIntValuesFactory/getBoundedReader(int)#parquet/column/values/boundedint/ZeroIntegerValuesReader/ZeroIntegerValuesReader()
parquet/column/values/boundedint/BoundedIntValuesFactory/getBoundedWriter(int,int)#parquet/column/values/boundedint/BoundedIntValuesWriter/BoundedIntValuesWriter(int,int)
parquet/column/values/boundedint/BoundedIntValuesFactory/getBoundedWriter(int,int)#parquet/column/values/boundedint/DevNullValuesWriter/DevNullValuesWriter()
parquet/thrift/ThriftRecordConverter/MapKeyValueConverter/getConverter(int)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/endGroup()#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/addFloat(float)#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/io/ExpectationValidatingRecordConsumer/endMessage()#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/startField(java.lang.String,int)#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/addInteger(int)#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/endField(java.lang.String,int)#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/startGroup()#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/startMessage()#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)#java/util/Deque/pop()
parquet/io/ExpectationValidatingRecordConsumer/addBoolean(boolean)#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/addLong(long)#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/io/ExpectationValidatingRecordConsumer/addDouble(double)#parquet/io/ExpectationValidatingRecordConsumer/validate(java.lang.String)
parquet/tools/Main/showUsage(java.lang.String,parquet.tools.command.Command)#parquet/tools/Main/showUsage(parquet.tools.HelpFormatter,java.io.PrintWriter,java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/showUsage(java.lang.String,parquet.tools.command.Command)#parquet/tools/command/Command/getOptions()
parquet/tools/Main/showUsage(java.lang.String,parquet.tools.command.Command)#java/io/PrintWriter/PrintWriter(java.io.OutputStream,boolean)
parquet/tools/Main/mergeOptions(parquet.tools.command.Options,parquet.tools.Options[])#parquet/tools/Main/mergeOptionsInto(parquet.tools.command.Options,parquet.tools.command.Options)
parquet/tools/Main/die(java.lang.String,boolean)#parquet/tools/Main/die(java.lang.String,boolean,java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/die(java.lang.String,boolean,java.lang.String,parquet.tools.command.Command)#parquet/tools/Main/showUsage(java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/die(java.lang.String,boolean,java.lang.String,parquet.tools.command.Command)#java/io/PrintStream/println(java.lang.String)
parquet/tools/Main/die(java.lang.String,boolean,java.lang.String,parquet.tools.command.Command)#java/io/PrintStream/println()
parquet/tools/Main/die(java.lang.String,boolean,java.lang.String,parquet.tools.command.Command)#java/lang/System/exit(int)
parquet/tools/Main/die(java.lang.Throwable,boolean,java.lang.String,parquet.tools.command.Command)#java/lang/Throwable/getMessage()
parquet/tools/Main/die(java.lang.Throwable,boolean,java.lang.String,parquet.tools.command.Command)#parquet/tools/Main/die(java.lang.String,boolean,java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/die(java.lang.Throwable,boolean)#parquet/tools/Main/die(java.lang.Throwable,boolean,java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/showUsage(parquet.tools.HelpFormatter,java.io.PrintWriter,java.lang.String,parquet.tools.command.Command)#parquet/tools/Main/mergeOptions(parquet.tools.command.Options,parquet.tools.Options[])
parquet/tools/Main/showUsage(parquet.tools.HelpFormatter,java.io.PrintWriter,java.lang.String,parquet.tools.command.Command)#parquet/tools/command/Command/getUsageDescription()
parquet/tools/Main/showUsage(parquet.tools.HelpFormatter,java.io.PrintWriter,java.lang.String,parquet.tools.command.Command)#parquet/tools/command/Command/getOptions()
parquet/tools/Main/main(java.lang.String[])#java/lang/System/setOut(java.io.PrintStream)
parquet/tools/Main/main(java.lang.String[])#parquet/tools/Main/showUsage(java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/main(java.lang.String[])#parquet/tools/Main/mergeOptions(parquet.tools.command.Options,parquet.tools.Options[])
parquet/tools/Main/main(java.lang.String[])#java/lang/System/setErr(java.io.PrintStream)
parquet/tools/Main/main(java.lang.String[])#parquet/tools/command/Registry/getCommandByName(java.lang.String)
parquet/tools/Main/main(java.lang.String[])#parquet/tools/command/Command/supportsExtraArgs()
parquet/tools/Main/main(java.lang.String[])#java/lang/System/exit(int)
parquet/tools/Main/main(java.lang.String[])#parquet/tools/Main/showUsage()
parquet/tools/Main/main(java.lang.String[])#parquet/tools/command/Command/getOptions()
parquet/tools/Main/main(java.lang.String[])#parquet/tools/Main/die(java.lang.Throwable,boolean,java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/main(java.lang.String[])#parquet/tools/Main/main(java/lang/String[])/$anonymous2/()
parquet/tools/Main/main(java.lang.String[])#java/lang/String/equals(java.lang.Object)
parquet/tools/Main/main(java.lang.String[])#java/lang/Throwable/printStackTrace(java.io.PrintStream)
parquet/tools/Main/main(java.lang.String[])#java/util/Arrays/copyOfRange(T[],int,int)
parquet/tools/Main/main(java.lang.String[])#parquet/tools/Main/die(java.lang.String,boolean,java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/main(java.lang.String[])#java/io/PrintStream/PrintStream(java.io.OutputStream)
parquet/tools/Main/main(java.lang.String[])#java/lang/System/setProperty(java.lang.String,java.lang.String)
parquet/tools/Main/main(java.lang.String[])#parquet/tools/Main/main(java/lang/String[])/$anonymous1/()
parquet/tools/Main/main(java.lang.String[])#parquet/tools/command/Command/execute(parquet.tools.command.CommandLine)
parquet/tools/Main/showUsage()#java/io/PrintWriter/println()
parquet/tools/Main/showUsage()#parquet/tools/command/Registry/allCommands()
parquet/tools/Main/showUsage()#java/util/Map/Entry/getValue()
parquet/tools/Main/showUsage()#parquet/tools/Main/showUsage(parquet.tools.HelpFormatter,java.io.PrintWriter,java.lang.String,parquet.tools.command.Command)
parquet/tools/Main/showUsage()#java/util/Map/Entry/getKey()
parquet/tools/Main/showUsage()#java/util/Map/entrySet()
parquet/tools/Main/showUsage()#java/io/PrintWriter/PrintWriter(java.io.OutputStream,boolean)
parquet/hadoop/metadata/IntColumnChunkMetaData/getFirstDataPageOffset()#parquet/hadoop/metadata/IntColumnChunkMetaData/intToPositiveLong(int)
parquet/hadoop/metadata/IntColumnChunkMetaData/getTotalSize()#parquet/hadoop/metadata/IntColumnChunkMetaData/intToPositiveLong(int)
parquet/hadoop/metadata/IntColumnChunkMetaData/positiveLongToInt(long)#parquet/hadoop/metadata/ColumnChunkMetaData/positiveLongFitsInAnInt(long)
parquet/hadoop/metadata/IntColumnChunkMetaData/positiveLongToInt(long)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/hadoop/metadata/IntColumnChunkMetaData/getDictionaryPageOffset()#parquet/hadoop/metadata/IntColumnChunkMetaData/intToPositiveLong(int)
parquet/hadoop/metadata/IntColumnChunkMetaData/getValueCount()#parquet/hadoop/metadata/IntColumnChunkMetaData/intToPositiveLong(int)
parquet/hadoop/metadata/IntColumnChunkMetaData/getTotalUncompressedSize()#parquet/hadoop/metadata/IntColumnChunkMetaData/intToPositiveLong(int)
parquet/hadoop/ParquetReader/close()#parquet/hadoop/InternalParquetRecordReader/close()
parquet/hadoop/ParquetReader/builder(parquet.hadoop.api.ReadSupport,parquet.hadoop.Path)#parquet/hadoop/ParquetReader/Builder/Builder(parquet.hadoop.api.ReadSupport,parquet.hadoop.Path)
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/ParquetReader/initReader()#java/util/Iterator/hasNext()
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/Footer/getFile()
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/Footer/getParquetMetadata()
parquet/hadoop/ParquetReader/initReader()#java/util/Iterator/next()
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/InternalParquetRecordReader/InternalParquetRecordReader(parquet.hadoop.api.ReadSupport,parquet.filter2.compat.FilterCompat.Filter)
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/metadata/GlobalMetaData/getSchema()
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/metadata/FileMetaData/getKeyValueMetaData()
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/api/ReadSupport/ReadContext/getReadSupportMetadata()
parquet/hadoop/ParquetReader/initReader()#parquet/filter2/compat/RowGroupFilter/filterRowGroups(parquet.filter2.compat.FilterCompat.Filter,java.util.List,parquet.schema.MessageType)
parquet/hadoop/ParquetReader/initReader()#parquet/hadoop/InternalParquetRecordReader/close()
parquet/hadoop/ParquetReader/read()#parquet/hadoop/InternalParquetRecordReader/nextKeyValue()
parquet/hadoop/ParquetReader/read()#parquet/hadoop/InternalParquetRecordReader/getCurrentValue()
parquet/hadoop/ParquetReader/read()#parquet/hadoop/ParquetReader/initReader()
parquet/hadoop/ParquetReader/read()#parquet/hadoop/ParquetReader/read()
parquet/hadoop/ParquetReader/read()#java/io/IOException/IOException(java.lang.Throwable)
parquet/tools/command/CatCommand/execute(parquet.tools.command.CommandLine)#java/io/PrintWriter/println()
parquet/tools/command/CatCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetReader/ParquetReader(parquet.hadoop.Path,parquet.hadoop.api.ReadSupport)
parquet/tools/command/CatCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/command/ArgsOnlyCommand/execute(parquet.tools.command.CommandLine)
parquet/tools/command/CatCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetReader/close()
parquet/tools/command/CatCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter)
parquet/tools/command/CatCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/read/SimpleReadSupport/SimpleReadSupport()
parquet/tools/command/CatCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetReader/read()
parquet/tools/command/CatCommand/execute(parquet.tools.command.CommandLine)#java/io/PrintWriter/PrintWriter(java.io.OutputStream,boolean)
parquet/column/values/bitpacking/SevenBitPackingReader/read()#java/io/InputStream/read()
parquet/column/values/bitpacking/SevenBitPackingReader/read()#parquet/column/values/bitpacking/BaseBitPackingReader/alignToBytes(int)
parquet/pig/convert/TupleRecordMaterializer/getCurrentRecord()#parquet/pig/convert/TupleConverter/getCurrentTuple()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/createProtocolEventsForField(parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/ProtocolEventsAmender/isStopField(parquet.thrift.TField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftField/getFieldId()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/DefaultProtocolEventsGenerator/DefaultProtocolEventsGenerator()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/getChildren()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#java/util/Set/add(E)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/ProtocolEventsAmender/acceptProtocol(parquet.thrift.TProtocol)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#java/util/Set/contains(java.lang.Object)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/getChildById(short)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/ProtocolEventsAmender/isRequired(parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)#java/util/HashSet/HashSet()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkList(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkList(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/acceptProtocol(parquet.thrift.TProtocol)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkList(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/ListType/getValues()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkList(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/projection/amend/ProtocolEventsAmender/isRequired(parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getRequirement()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkSet(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/SetType/getValues()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkSet(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkSet(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/acceptProtocol(parquet.thrift.TProtocol)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkSet(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkPrimitiveField(byte,java.util.Iterator)#parquet/thrift/projection/amend/ProtocolEventsAmender/acceptProtocol(parquet.thrift.TProtocol)
parquet/thrift/projection/amend/ProtocolEventsAmender/amendMissingRequiredFields(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkStruct(java.util.Iterator,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkPrimitiveField(byte,java.util.Iterator)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkMap(java.util.Iterator,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkList(java.util.Iterator,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkSet(java.util.Iterator,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkMap(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/checkField(byte,java.util.Iterator,parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkMap(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/MapType/getValue()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkMap(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/projection/amend/ProtocolEventsAmender/acceptProtocol(parquet.thrift.TProtocol)
parquet/thrift/projection/amend/ProtocolEventsAmender/checkMap(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/MapType/getKey()
parquet/thrift/projection/amend/ProtocolEventsAmender/checkMap(java.util.Iterator,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createArray(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ListObjectInspector)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createArray(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ListObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createObject(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createArray(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ListObjectInspector)#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createObject(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createMap(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.MapObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createObject(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createArray(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ListObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createObject(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createStruct(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.StructObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createObject(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createObject(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createPrimitive(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.PrimitiveObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createPrimitive(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.PrimitiveObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/BinaryWritable(parquet.io.api.Binary)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createPrimitive(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.PrimitiveObjectInspector)#parquet/io/api/Binary/fromString(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createPrimitive(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.PrimitiveObjectInspector)#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/serialize(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createStruct(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.StructObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/serialize(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createMap(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.MapObjectInspector)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createMap(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.MapObjectInspector)#java/util/Map/Entry/getValue()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createMap(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.MapObjectInspector)#java/util/Map/Entry/getKey()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createMap(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.MapObjectInspector)#java/util/Map/entrySet()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createMap(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.MapObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createObject(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createMap(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.MapObjectInspector)#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createStruct(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.StructObjectInspector)#java/util/List/size()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createStruct(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.StructObjectInspector)#java/util/List/get(int)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createStruct(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.StructObjectInspector)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createObject(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/createStruct(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.StructObjectInspector)#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)#java/util/Properties/getProperty(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)#java/lang/String/split(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)#org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/ArrayWritableObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.StructTypeInfo)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)#java/lang/String/length()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)#java/util/List/size()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)#java/util/Arrays/asList(T[])
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/pig/PigSchemaConverter/ColumnNameAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#java/util/ArrayList/ArrayList()
parquet/pig/PigSchemaConverter/ColumnNameAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/schema/GroupType/containsField(java.lang.String)
parquet/pig/PigSchemaConverter/ColumnNameAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/ColumnNameAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/pig/PigSchemaConverter/name(java.lang.String,java.lang.String)
parquet/pig/PigSchemaConverter/ColumnNameAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#java/util/List/add(E)
parquet/pig/PigSchemaConverter/ColumnNameAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/schema/GroupType/getType(java.lang.String)
parquet/column/mem/TestMemPageStore/test()#parquet/column/page/PageReader/getTotalValueCount()
parquet/column/mem/TestMemPageStore/test()#parquet/column/statistics/LongStatistics/LongStatistics()
parquet/column/mem/TestMemPageStore/test()#parquet/column/page/mem/MemPageStore/getPageWriter(parquet.column.ColumnDescriptor)
parquet/column/mem/TestMemPageStore/test()#parquet/column/ColumnDescriptor/ColumnDescriptor(java.lang.String[],parquet.schema.PrimitiveType.PrimitiveTypeName,int,int)
parquet/column/mem/TestMemPageStore/test()#parquet/bytes/BytesInput/from(byte[])
parquet/column/mem/TestMemPageStore/test()#parquet/column/page/Page/getValueCount()
parquet/column/mem/TestMemPageStore/test()#java/io/PrintStream/println(long)
parquet/column/mem/TestMemPageStore/test()#parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)
parquet/column/mem/TestMemPageStore/test()#parquet/column/page/PageReader/readPage()
parquet/column/mem/TestMemPageStore/test()#parquet/column/page/PageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/column/mem/TestMemPageStore/test()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/column/mem/TestMemPageStore/test()#java/io/PrintStream/println(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getPos()#org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getProgress()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/schema/Type/toString()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/hive/HiveBinding/pushProjectionsAndFilters(parquet.cascading.JobConf,parquet.hadoop.Path)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#java/util/Map/get(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/hadoop/ParquetInputSplit/ParquetInputSplit(parquet.hadoop.Path,long,long,long,java.lang.String[],long[],java.lang.String,java.util.Map)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/DataWritableReadSupport()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/schema/GroupType/getFieldCount()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/hadoop/metadata/FileMetaData/getKeyValueMetaData()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/hadoop/metadata/FileMetaData/getSchema()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getSplit(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf)#parquet/hadoop/api/ReadSupport/ReadContext/getReadSupportMetadata()
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/next(java.lang.Void,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#java/io/IOException/IOException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/next(java.lang.Void,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#java/lang/System/arraycopy(java.lang.Object,int,java.lang.Object,int,int)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/next(java.lang.Void,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#java/io/IOException/IOException(java.lang.Throwable)
org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper/getProgress()#java/io/IOException/IOException(java.lang.Throwable)
parquet/column/impl/ColumnWriteStoreImpl/memSize()#parquet/column/impl/ColumnWriterImpl/getBufferedSizeInMemory()
parquet/column/impl/ColumnWriteStoreImpl/memSize()#java/util/Map/values()
parquet/column/impl/ColumnWriteStoreImpl/getColumnWriter(parquet.column.ColumnDescriptor)#java/util/Map/get(java.lang.Object)
parquet/column/impl/ColumnWriteStoreImpl/getColumnWriter(parquet.column.ColumnDescriptor)#parquet/column/impl/ColumnWriteStoreImpl/newMemColumn(parquet.column.ColumnDescriptor)
parquet/column/impl/ColumnWriteStoreImpl/getColumnWriter(parquet.column.ColumnDescriptor)#java/util/Map/put(K,V)
parquet/column/impl/ColumnWriteStoreImpl/newMemColumn(parquet.column.ColumnDescriptor)#parquet/column/page/PageWriteStore/getPageWriter(parquet.column.ColumnDescriptor)
parquet/column/impl/ColumnWriteStoreImpl/newMemColumn(parquet.column.ColumnDescriptor)#parquet/column/impl/ColumnWriterImpl/ColumnWriterImpl(parquet.column.ColumnDescriptor,parquet.column.page.PageWriter,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/column/impl/ColumnWriteStoreImpl/flush()#parquet/column/impl/ColumnWriterImpl/flush()
parquet/column/impl/ColumnWriteStoreImpl/flush()#java/util/Map/values()
parquet/column/impl/ColumnWriteStoreImpl/getColumnDescriptors()#java/util/Map/keySet()
parquet/column/impl/ColumnWriteStoreImpl/allocatedSize()#parquet/column/impl/ColumnWriterImpl/allocatedSize()
parquet/column/impl/ColumnWriteStoreImpl/allocatedSize()#java/util/Map/values()
parquet/column/impl/ColumnWriteStoreImpl/maxColMemSize()#parquet/column/impl/ColumnWriterImpl/getBufferedSizeInMemory()
parquet/column/impl/ColumnWriteStoreImpl/maxColMemSize()#java/lang/Math/max(long,long)
parquet/column/impl/ColumnWriteStoreImpl/maxColMemSize()#java/util/Map/values()
parquet/column/impl/ColumnWriteStoreImpl/toString()#parquet/column/impl/ColumnWriterImpl/getBufferedSizeInMemory()
parquet/column/impl/ColumnWriteStoreImpl/toString()#java/util/Map/Entry/getValue()
parquet/column/impl/ColumnWriteStoreImpl/toString()#parquet/column/ColumnDescriptor/getPath()
parquet/column/impl/ColumnWriteStoreImpl/toString()#java/lang/StringBuilder/append(long)
parquet/column/impl/ColumnWriteStoreImpl/toString()#java/util/Map/Entry/getKey()
parquet/column/impl/ColumnWriteStoreImpl/toString()#java/lang/StringBuilder/StringBuilder()
parquet/column/impl/ColumnWriteStoreImpl/toString()#java/util/Map/entrySet()
parquet/column/impl/ColumnWriteStoreImpl/toString()#java/lang/StringBuilder/toString()
parquet/column/impl/ColumnWriteStoreImpl/toString()#java/util/Arrays/toString(java.lang.Object[])
parquet/column/impl/ColumnWriteStoreImpl/toString()#java/lang/StringBuilder/append(java.lang.String)
parquet/column/impl/ColumnWriteStoreImpl/memUsageString()#java/lang/StringBuilder/append(java.lang.String)
parquet/column/impl/ColumnWriteStoreImpl/memUsageString()#parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)
parquet/column/impl/ColumnWriteStoreImpl/memUsageString()#java/lang/StringBuilder/toString()
parquet/column/impl/ColumnWriteStoreImpl/memUsageString()#java/util/Map/values()
parquet/column/impl/ColumnWriteStoreImpl/memUsageString()#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/column/ParquetProperties/getColumnDescriptorValuesWriter(int,int)#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/RunLengthBitPackingHybridValuesWriter(int,int)
parquet/column/ParquetProperties/getColumnDescriptorValuesWriter(int,int)#parquet/column/values/boundedint/DevNullValuesWriter/DevNullValuesWriter()
parquet/column/ParquetProperties/getColumnDescriptorValuesWriter(int,int)#parquet/bytes/BytesUtils/getWidthFromMaxInt(int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/ColumnDescriptor/getType()
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/FixedLenByteArrayPlainValuesWriter(int,int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/RunLengthBitPackingHybridValuesWriter(int,int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/deltastrings/DeltaByteArrayWriter/DeltaByteArrayWriter(int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/DeltaBinaryPackingValuesWriter(int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/plain/BooleanPlainValuesWriter/BooleanPlainValuesWriter()
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/PlainLongDictionaryValuesWriter(int,int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/ColumnDescriptor/getTypeLength()
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter(int,int,int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/PlainIntegerDictionaryValuesWriter(int,int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/PlainFloatDictionaryValuesWriter(int,int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/PlainBinaryDictionaryValuesWriter(int,int)
parquet/column/ParquetProperties/getValuesWriter(parquet.column.ColumnDescriptor,int)#parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/PlainDoubleDictionaryValuesWriter(int,int)
parquet/column/values/bitpacking/ThreeBitPackingWriter/write(int)#java/io/OutputStream/write(int)
parquet/column/values/bitpacking/ThreeBitPackingWriter/finish()#parquet/column/values/bitpacking/BaseBitPackingWriter/finish(int,int,java.io.OutputStream)
parquet/pig/convert/MapConverter/BufferMap/clear()#java/util/List/clear()
parquet/pig/convert/MapConverter/BufferMap/put(java.lang.String,java.lang.Object)#java/util/AbstractMap/SimpleImmutableEntry/SimpleImmutableEntry(K,V)
parquet/pig/convert/MapConverter/BufferMap/put(java.lang.String,java.lang.Object)#java/util/List/add(E)
parquet/pig/PerfTestReadAllCols/main(java.lang.String[])#java/lang/StringBuilder/append(java.lang.String)
parquet/pig/PerfTestReadAllCols/main(java.lang.String[])#java/io/File/exists()
parquet/pig/PerfTestReadAllCols/main(java.lang.String[])#java/io/File/File(java.lang.String)
parquet/pig/PerfTestReadAllCols/main(java.lang.String[])#java/lang/StringBuilder/StringBuilder()
parquet/pig/PerfTestReadAllCols/main(java.lang.String[])#parquet/pig/PerfTest2/clean(java.io.File)
parquet/pig/PerfTestReadAllCols/main(java.lang.String[])#java/io/PrintStream/println(java.lang.Object)
parquet/pig/PerfTestReadAllCols/main(java.lang.String[])#parquet/pig/PerfTest2/write(java.lang.String)
parquet/pig/PerfTestReadAllCols/main(java.lang.String[])#parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addInt(int)#parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addFloat(float)#parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addBinary(parquet.io.api.Binary)#java/nio/charset/CharsetDecoder/decode(java.nio.ByteBuffer)
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toByteBuffer()
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addBinary(parquet.io.api.Binary)#java/nio/CharBuffer/toString()
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addBoolean(boolean)#parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addDouble(double)#parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)
parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/addLong(long)#parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)
parquet/hadoop/ParquetRecordWriter/write(java.lang.Void,T)#parquet/hadoop/InternalParquetRecordWriter/write(T)
parquet/hadoop/ParquetRecordWriter/close(parquet.pig.TaskAttemptContext)#parquet/hadoop/InternalParquetRecordWriter/close()
parquet/proto/ProtoRecordConverter/start()#parquet/proto/ProtoMessageConverter/start()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/And/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/Visitor/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.And)
parquet/thrift/TestProtocolReadToWrite/testOneOfEach()#java/util/ArrayList/ArrayList()
parquet/thrift/TestProtocolReadToWrite/testOneOfEach()#parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)
parquet/thrift/TestProtocolReadToWrite/testOneOfEach()#java/nio/ByteBuffer/wrap(byte[])
parquet/thrift/TestProtocolReadToWrite/testOneOfEach()#java/lang/String/getBytes()
parquet/thrift/TestProtocolReadToWrite/testEmptyStruct()#parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()/$anonymous1/()
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#java/lang/Class/newInstance()
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#parquet/thrift/BufferedProtocolReadToWrite/BufferedProtocolReadToWrite(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.FieldIgnoredHandler)
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#java/io/ByteArrayOutputStream/toByteArray()
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.OutputStream)
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.InputStream)
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestProtocolReadToWrite/testMissingFieldHandling()#parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/TestProtocolReadToWrite/testWriteRead()#java/util/ArrayList/ArrayList()
parquet/thrift/TestProtocolReadToWrite/testWriteRead()#parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)
parquet/thrift/TestProtocolReadToWrite/testWriteRead()#java/util/Arrays/asList(T[])
parquet/thrift/TestProtocolReadToWrite/testWriteRead()#java/lang/Object/Object()
parquet/thrift/TestProtocolReadToWrite/testMapSet()#parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)
parquet/thrift/TestProtocolReadToWrite/testMapSet()#java/util/HashMap/HashMap()
parquet/thrift/TestProtocolReadToWrite/testMapSet()#java/util/Set/add(E)
parquet/thrift/TestProtocolReadToWrite/testMapSet()#java/util/Map/put(K,V)
parquet/thrift/TestProtocolReadToWrite/testMapSet()#java/util/HashSet/HashSet()
parquet/thrift/TestProtocolReadToWrite/protocol(java.io.OutputStream)#java/lang/Object/Object()
parquet/thrift/TestProtocolReadToWrite/protocol(java.io.InputStream)#java/lang/Object/Object()
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/util/ArrayList/ArrayList()
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#parquet/thrift/TestProtocolReadToWrite/CountingErrorHandler/CountingErrorHandler()
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/lang/Throwable/getCause()
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/lang/String/contains(java.lang.CharSequence)
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/lang/String/getBytes()
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.OutputStream)
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.InputStream)
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/lang/Throwable/getMessage()
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#parquet/thrift/BufferedProtocolReadToWrite/BufferedProtocolReadToWrite(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.FieldIgnoredHandler)
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/nio/ByteBuffer/wrap(byte[])
parquet/thrift/TestProtocolReadToWrite/testIncompatibleSchemaRecord()#java/io/ByteArrayOutputStream/toByteArray()
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#java/lang/Class/getSimpleName()
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#java/io/ByteArrayOutputStream/toByteArray()
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#java/lang/Object/getClass()
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.OutputStream)
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.InputStream)
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#parquet/thrift/ProtocolReadToWrite/ProtocolReadToWrite()
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#parquet/thrift/BufferedProtocolReadToWrite/BufferedProtocolReadToWrite(parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#parquet/thrift/ProtocolPipe/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/TestProtocolReadToWrite/writeReadCompare(parquet.thrift.TBase)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#parquet/thrift/TestProtocolReadToWrite/CountingErrorHandler/CountingErrorHandler()
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#java/lang/Throwable/getCause()
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#java/io/ByteArrayOutputStream/toByteArray()
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#java/lang/String/contains(java.lang.CharSequence)
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.OutputStream)
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#java/lang/Throwable/getMessage()
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#parquet/thrift/BufferedProtocolReadToWrite/BufferedProtocolReadToWrite(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.FieldIgnoredHandler)
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.InputStream)
parquet/thrift/TestProtocolReadToWrite/testEnumMissingSchema()#java/lang/Object/Object()
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#parquet/thrift/BufferedProtocolReadToWrite/BufferedProtocolReadToWrite(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.FieldIgnoredHandler)
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()/$anonymous1/()
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#java/io/ByteArrayOutputStream/toByteArray()
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.OutputStream)
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#parquet/thrift/TestProtocolReadToWrite/protocol(java.io.InputStream)
parquet/thrift/TestProtocolReadToWrite/TestExtraFieldWhenFieldIndexIsNotStartFromZero()#java/lang/Object/Object()
parquet/hadoop/PrintFooter/Stats/toString(int)#parquet/hadoop/PrintFooter/humanReadable(long)
parquet/hadoop/PrintFooter/Stats/add(long)#java/lang/Math/min(long,long)
parquet/hadoop/PrintFooter/Stats/add(long)#java/lang/Math/max(long,long)
parquet/bytes/TestCapacityByteArrayOutputStream/testWrite()#parquet/bytes/CapacityByteArrayOutputStream/CapacityByteArrayOutputStream(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWrite()#parquet/bytes/TestCapacityByteArrayOutputStream/validate(parquet.bytes.CapacityByteArrayOutputStream,int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWrite()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/bytes/TestCapacityByteArrayOutputStream/testWrite()#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#parquet/bytes/CapacityByteArrayOutputStream/CapacityByteArrayOutputStream(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#parquet/bytes/TestCapacityByteArrayOutputStream/writeArraysOf3(parquet.bytes.CapacityByteArrayOutputStream,int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#parquet/bytes/CapacityByteArrayOutputStream/getSlabCount()
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#parquet/bytes/TestCapacityByteArrayOutputStream/validate(parquet.bytes.CapacityByteArrayOutputStream,int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#java/io/OutputStream/write(byte[])
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayManySlabs()#parquet/bytes/BytesInput/toByteArray()
parquet/bytes/TestCapacityByteArrayOutputStream/writeArraysOf3(parquet.bytes.CapacityByteArrayOutputStream,int)#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/bytes/TestCapacityByteArrayOutputStream/writeArraysOf3(parquet.bytes.CapacityByteArrayOutputStream,int)#java/io/OutputStream/write(byte[])
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayAndInt()#parquet/bytes/CapacityByteArrayOutputStream/CapacityByteArrayOutputStream(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayAndInt()#parquet/bytes/TestCapacityByteArrayOutputStream/validate(parquet.bytes.CapacityByteArrayOutputStream,int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayAndInt()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayAndInt()#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayAndInt()#java/io/OutputStream/write(byte[])
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArray()#parquet/bytes/CapacityByteArrayOutputStream/CapacityByteArrayOutputStream(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArray()#parquet/bytes/TestCapacityByteArrayOutputStream/writeArraysOf3(parquet.bytes.CapacityByteArrayOutputStream,int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArray()#parquet/bytes/TestCapacityByteArrayOutputStream/validate(parquet.bytes.CapacityByteArrayOutputStream,int)
parquet/bytes/TestCapacityByteArrayOutputStream/validate(parquet.bytes.CapacityByteArrayOutputStream,int)#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/bytes/TestCapacityByteArrayOutputStream/validate(parquet.bytes.CapacityByteArrayOutputStream,int)#parquet/bytes/BytesInput/toByteArray()
parquet/bytes/TestCapacityByteArrayOutputStream/testReset()#parquet/bytes/CapacityByteArrayOutputStream/CapacityByteArrayOutputStream(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testReset()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/bytes/TestCapacityByteArrayOutputStream/testReset()#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testReset()#java/util/Arrays/toString(byte[])
parquet/bytes/TestCapacityByteArrayOutputStream/testReset()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/bytes/TestCapacityByteArrayOutputStream/testReset()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/bytes/TestCapacityByteArrayOutputStream/testReset()#parquet/bytes/BytesInput/toByteArray()
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayBiggerThanSlab()#parquet/bytes/CapacityByteArrayOutputStream/CapacityByteArrayOutputStream(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayBiggerThanSlab()#parquet/bytes/TestCapacityByteArrayOutputStream/writeArraysOf3(parquet.bytes.CapacityByteArrayOutputStream,int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayBiggerThanSlab()#parquet/bytes/TestCapacityByteArrayOutputStream/validate(parquet.bytes.CapacityByteArrayOutputStream,int)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayBiggerThanSlab()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayBiggerThanSlab()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayBiggerThanSlab()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayBiggerThanSlab()#java/io/OutputStream/write(byte[])
parquet/bytes/TestCapacityByteArrayOutputStream/testWriteArrayBiggerThanSlab()#parquet/bytes/BytesInput/toByteArray()
parquet/bytes/TestCapacityByteArrayOutputStream/testReplaceByte()#parquet/bytes/CapacityByteArrayOutputStream/CapacityByteArrayOutputStream(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testReplaceByte()#parquet/bytes/CapacityByteArrayOutputStream/writeTo(java.io.OutputStream)
parquet/bytes/TestCapacityByteArrayOutputStream/testReplaceByte()#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/bytes/TestCapacityByteArrayOutputStream/testReplaceByte()#parquet/bytes/CapacityByteArrayOutputStream/getCurrentIndex()
parquet/bytes/TestCapacityByteArrayOutputStream/testReplaceByte()#java/io/ByteArrayOutputStream/toByteArray()
parquet/bytes/TestCapacityByteArrayOutputStream/testReplaceByte()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/bytes/TestCapacityByteArrayOutputStream/testReplaceByte()#parquet/bytes/CapacityByteArrayOutputStream/setByte(long,byte)
parquet/column/values/dictionary/PlainValuesDictionary/PlainBinaryDictionary/toString()#java/lang/StringBuilder/append(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainBinaryDictionary/toString()#java/lang/StringBuilder/append(int)
parquet/column/values/dictionary/PlainValuesDictionary/PlainBinaryDictionary/toString()#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainBinaryDictionary/toString()#java/lang/StringBuilder/append(java.lang.Object)
parquet/column/values/dictionary/PlainValuesDictionary/PlainBinaryDictionary/toString()#java/lang/StringBuilder/toString()
org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/getConverterFromDescription(parquet.schema.Type,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)#parquet/schema/Type/asPrimitiveType()
org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/getConverterFromDescription(parquet.schema.Type,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)#org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter/getNewConverter(java.lang.Class,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/getConverterFromDescription(parquet.schema.Type,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)#org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter/ArrayWritableGroupConverter(parquet.schema.GroupType,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter,int)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/getConverterFromDescription(parquet.schema.Type,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/getConverterFromDescription(parquet.schema.Type,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)#org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/DataWritableGroupConverter(parquet.schema.GroupType,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter,int)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/getConverterFromDescription(parquet.schema.Type,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)#parquet/schema/Type/isPrimitive()
org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/getConverterFromDescription(parquet.schema.Type,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)#parquet/schema/Type/asGroupType()
org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter/getConverterFromDescription(parquet.schema.Type,int,org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter)#parquet/schema/Type/getRepetition()
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testGetHiveRecordWriter()#java/util/Properties/setProperty(java.lang.String,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testGetHiveRecordWriter()#java/lang/Throwable/getMessage()
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testGetHiveRecordWriter()#org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testGetHiveRecordWriter()#java/util/Properties/Properties()
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testGetHiveRecordWriter()#org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/MapredParquetOutputFormat(parquet.hive.OutputFormat)
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testConstructorWithFormat()#org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/MapredParquetOutputFormat()
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testGetRecordWriterThrowsException()#org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/MapredParquetOutputFormat()
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testGetRecordWriterThrowsException()#java/lang/Throwable/getMessage()
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testGetRecordWriterThrowsException()#org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getRecordWriter(parquet.hadoop.example.FileSystem,parquet.cascading.JobConf,java.lang.String,parquet.hadoop.mapred.Progressable)
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat/testConstructor()#org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/MapredParquetOutputFormat()
parquet/example/data/simple/DoubleValue/writeValue(parquet.io.api.RecordConsumer)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/example/data/simple/DoubleValue/toString()#java/lang/String/valueOf(double)
parquet/hadoop/thrift/ThriftToParquetFileWriter/close()#java/io/IOException/IOException(java.lang.String,java.lang.Throwable)
parquet/hadoop/thrift/ThriftToParquetFileWriter/close()#java/lang/Thread/interrupted()
parquet/thrift/struct/ThriftType/DoubleType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.DoubleType)
parquet/column/values/bitpacking/EightBitPackingReader/read()#java/io/InputStream/read()
parquet/cascading/TupleReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/cascading/SchemaIntersection/getRequestedSchema()
parquet/cascading/TupleReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/cascading/SchemaIntersection/SchemaIntersection(parquet.schema.MessageType,parquet.cascading.Fields)
parquet/cascading/TupleReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/cascading/TupleReadSupport/getRequestedFields(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/cascading/TupleReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType)
parquet/cascading/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/cascading/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/cascading/convert/TupleRecordMaterializer/TupleRecordMaterializer(parquet.schema.GroupType)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#parquet/io/api/RecordConsumer/addFloat(float)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/getBinary()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#parquet/io/api/RecordConsumer/addInteger(int)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#parquet/io/api/RecordConsumer/addLong(long)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#parquet/io/api/RecordConsumer/addBoolean(boolean)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)#parquet/io/api/RecordConsumer/addDouble(double)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/Type/asGroupType()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/Type/isPrimitive()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/Type/getName()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/endGroup()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/GroupType/getType(int)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/GroupType/getFieldCount()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/startGroup()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#java/lang/Enum/equals(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/Type/isPrimitive()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeArray(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/Type/getName()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/Type/asGroupType()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/Type/getRepetition()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/endGroup()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writePrimitive(org.apache.hadoop.hive.ql.io.parquet.Writable)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/GroupType/getType(int)
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/schema/GroupType/getFieldCount()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/startGroup()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/write(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#parquet/io/api/RecordConsumer/startMessage()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/write(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#parquet/io/api/RecordConsumer/endMessage()
org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/write(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter/writeData(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,parquet.schema.GroupType)
parquet/pig/summary/Summary/Final/exec(parquet.pig.convert.Tuple)#parquet/pig/summary/SummaryData/toPrettyJSON(parquet.pig.summary.SummaryData)
parquet/pig/summary/Summary/Final/exec(parquet.pig.convert.Tuple)#parquet/pig/summary/Summary/merge(parquet.pig.convert.Tuple)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/ColumnDescriptor/getType()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/impl/ColumnReaderImpl/bindToDictionary(parquet.column.Dictionary)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/page/Page/getValueEncoding()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/Encoding/getDictionaryBasedValuesReader(parquet.column.ColumnDescriptor,parquet.column.ValuesType,parquet.column.Dictionary)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/io/api/PrimitiveConverter/hasDictionarySupport()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/page/Page/getDlEncoding()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/page/Page/getBytes()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/page/Page/getValueCount()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/impl/ColumnReaderImpl/bind(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/Encoding/usesDictionary()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/values/ValuesReader/getNextOffset()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/Log/debug(java.lang.Object)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/page/PageReader/readPage()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/Encoding/getValuesReader(parquet.column.ColumnDescriptor,parquet.column.ValuesType)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/column/page/Page/getRlEncoding()
parquet/column/impl/ColumnReaderImpl/readPage()#parquet/bytes/BytesInput/toByteArray()
parquet/column/impl/ColumnReaderImpl/getInteger()#parquet/column/impl/ColumnReaderImpl/readValue()
parquet/column/impl/ColumnReaderImpl/getInteger()#parquet/column/impl/ColumnReaderImpl/Binding/getInteger()
parquet/column/impl/ColumnReaderImpl/writeCurrentValueToConverter()#parquet/column/impl/ColumnReaderImpl/readValue()
parquet/column/impl/ColumnReaderImpl/writeCurrentValueToConverter()#parquet/column/impl/ColumnReaderImpl/Binding/writeValue()
parquet/column/impl/ColumnReaderImpl/readValue()#parquet/column/impl/ColumnReaderImpl/Binding/read()
parquet/column/impl/ColumnReaderImpl/readValue()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/impl/ColumnReaderImpl/readValue()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/impl/ColumnReaderImpl/consume()#parquet/column/impl/ColumnReaderImpl/checkRead()
parquet/column/impl/ColumnReaderImpl/bind(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/PrimitiveType/PrimitiveTypeName/convert(parquet.schema.PrimitiveType.PrimitiveTypeNameConverter)
parquet/column/impl/ColumnReaderImpl/bind(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/impl/ColumnReaderImpl/bind(parquet/schema/PrimitiveType/PrimitiveTypeName)/$anonymous1/()
parquet/column/impl/ColumnReaderImpl/getDouble()#parquet/column/impl/ColumnReaderImpl/readValue()
parquet/column/impl/ColumnReaderImpl/getDouble()#parquet/column/impl/ColumnReaderImpl/Binding/getDouble()
parquet/column/impl/ColumnReaderImpl/skip()#parquet/column/impl/ColumnReaderImpl/Binding/skip()
parquet/column/impl/ColumnReaderImpl/bindToDictionary(parquet.column.Dictionary)#parquet/column/impl/ColumnReaderImpl/bindToDictionary(parquet/column/Dictionary)/$anonymous1/()
parquet/column/impl/ColumnReaderImpl/getFloat()#parquet/column/impl/ColumnReaderImpl/readValue()
parquet/column/impl/ColumnReaderImpl/getFloat()#parquet/column/impl/ColumnReaderImpl/Binding/getFloat()
parquet/column/impl/ColumnReaderImpl/readRepetitionAndDefinitionLevels()#parquet/column/values/ValuesReader/readInteger()
parquet/column/impl/ColumnReaderImpl/getLong()#parquet/column/impl/ColumnReaderImpl/readValue()
parquet/column/impl/ColumnReaderImpl/getLong()#parquet/column/impl/ColumnReaderImpl/Binding/getLong()
parquet/column/impl/ColumnReaderImpl/getBinary()#parquet/column/impl/ColumnReaderImpl/Binding/getBinary()
parquet/column/impl/ColumnReaderImpl/getBinary()#parquet/column/impl/ColumnReaderImpl/readValue()
parquet/column/impl/ColumnReaderImpl/getBoolean()#parquet/column/impl/ColumnReaderImpl/readValue()
parquet/column/impl/ColumnReaderImpl/getBoolean()#parquet/column/impl/ColumnReaderImpl/Binding/getBoolean()
parquet/column/impl/ColumnReaderImpl/checkRead()#parquet/column/impl/ColumnReaderImpl/readPage()
parquet/column/impl/ColumnReaderImpl/checkRead()#parquet/column/impl/ColumnReaderImpl/readRepetitionAndDefinitionLevels()
parquet/column/impl/ColumnReaderImpl/checkRead()#parquet/column/impl/ColumnReaderImpl/isPageFullyConsumed()
parquet/column/impl/ColumnReaderImpl/checkRead()#parquet/Log/debug(java.lang.Object)
parquet/column/impl/ColumnReaderImpl/checkRead()#parquet/column/impl/ColumnReaderImpl/isFullyConsumed()
parquet/column/impl/ColumnReaderImpl/getCurrentValueDictionaryID()#parquet/column/impl/ColumnReaderImpl/readValue()
parquet/column/impl/ColumnReaderImpl/getCurrentValueDictionaryID()#parquet/column/impl/ColumnReaderImpl/Binding/getDictionaryId()
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/setStructFieldData(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.StructField,java.lang.Object)#org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/StructFieldImpl/getIndex()
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/setStructFieldData(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.StructField,java.lang.Object)#java/util/ArrayList/set(int,E)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/equals(java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/create()#java/util/ArrayList/ArrayList(java.util.Collection)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/create()#java/util/ArrayList/add(E)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldsDataAsList(java.lang.Object)#java/util/ArrayList/ArrayList(java.util.Collection)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldsDataAsList(java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldsDataAsList(java.lang.Object)#java/util/Arrays/asList(T[])
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldsDataAsList(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldsDataAsList(java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)#org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/ArrayWritableObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.StructTypeInfo)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)#org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)#org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/StandardParquetHiveMapInspector(org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/ParquetHiveArrayInspector(org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getObjectInspector(org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)#org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/DeepParquetHiveMapInspector(org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldRef(java.lang.String)#java/util/HashMap/get(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldData(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.StructField)#org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/StructFieldImpl/getIndex()
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldData(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.StructField)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldData(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.StructField)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldData(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.StructField)#java/util/List/get(int)
org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector/getStructFieldData(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.StructField)#java/lang/Object/getClass()
parquet/filter2/predicate/TestFilterApiMethods/testFilterPredicateCreation()#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/predicate/TestFilterApiMethods/testFilterPredicateCreation()#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/predicate/TestFilterApiMethods/testFilterPredicateCreation()#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/predicate/TestFilterApiMethods/testFilterPredicateCreation()#parquet/filter2/predicate/Operators/Not/getPredicate()
parquet/filter2/predicate/TestFilterApiMethods/testFilterPredicateCreation()#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/filter2/predicate/TestFilterApiMethods/testFilterPredicateCreation()#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/predicate/TestFilterApiMethods/testFilterPredicateCreation()#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/predicate/TestFilterApiMethods/testUdp()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/predicate/TestFilterApiMethods/testUdp()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestFilterApiMethods/testUdp()#parquet/filter2/predicate/FilterApi/userDefined(parquet.filter2.predicate.Operators.Column,java.lang.Class)
parquet/filter2/predicate/TestFilterApiMethods/testUdp()#parquet/filter2/predicate/Operators/UserDefined/getUserDefinedPredicateClass()
parquet/filter2/predicate/TestFilterApiMethods/testUdp()#parquet/filter2/predicate/Operators/UserDefined/getUserDefinedPredicate()
parquet/filter2/predicate/TestFilterApiMethods/testUdp()#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/predicate/TestFilterApiMethods/testToString()#java/lang/Object/toString()
parquet/filter2/predicate/TestFilterApiMethods/testToString()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestFilterApiMethods/testToString()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/filter2/predicate/TestFilterApiMethods/testToString()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#parquet/filter2/predicate/FilterApi/binaryColumn(java.lang.String)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#java/io/ObjectInputStream/readObject()
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#java/io/ObjectOutputStream/writeObject(java.lang.Object)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#parquet/filter2/predicate/FilterApi/userDefined(parquet.filter2.predicate.Operators.Column,java.lang.Class)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#java/io/ObjectInputStream/ObjectInputStream(java.io.InputStream)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#java/io/ObjectOutputStream/close()
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#java/io/ObjectOutputStream/ObjectOutputStream(java.io.OutputStream)
parquet/filter2/predicate/TestFilterApiMethods/testSerializable()#java/io/ByteArrayOutputStream/toByteArray()
parquet/io/ValidatingRecordConsumer/endGroup()#parquet/schema/Type/asGroupType()
parquet/io/ValidatingRecordConsumer/endGroup()#parquet/io/api/RecordConsumer/endGroup()
parquet/io/ValidatingRecordConsumer/endGroup()#java/util/Deque/peek()
parquet/io/ValidatingRecordConsumer/endGroup()#parquet/io/ValidatingRecordConsumer/validateMissingFields(int)
parquet/io/ValidatingRecordConsumer/endGroup()#parquet/schema/GroupType/getFieldCount()
parquet/io/ValidatingRecordConsumer/endGroup()#java/util/Deque/pop()
parquet/io/ValidatingRecordConsumer/startMessage()#parquet/io/api/RecordConsumer/startMessage()
parquet/io/ValidatingRecordConsumer/startMessage()#java/util/Deque/push(E)
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#java/util/Deque/peek()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#java/util/Arrays/toString(java.lang.Object[])
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/schema/Type/asPrimitiveType()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/schema/Type/isPrimitive()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/schema/Type/getName()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/schema/Type/asGroupType()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/schema/Type/getRepetition()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/schema/GroupType/getType(int)
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#parquet/Log/debug(java.lang.Object)
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#java/util/Deque/pop()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])#java/util/Deque/push(E)
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#java/util/Deque/peek()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Type/asPrimitiveType()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Type/isPrimitive()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Type/getName()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Type/asGroupType()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/Type/getRepetition()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/GroupType/getType(int)
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/Log/debug(java.lang.Object)
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#java/util/Deque/pop()
parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)#java/util/Deque/push(E)
parquet/io/ValidatingRecordConsumer/endMessage()#parquet/schema/Type/asGroupType()
parquet/io/ValidatingRecordConsumer/endMessage()#java/util/Deque/peek()
parquet/io/ValidatingRecordConsumer/endMessage()#parquet/io/api/RecordConsumer/endMessage()
parquet/io/ValidatingRecordConsumer/endMessage()#parquet/io/ValidatingRecordConsumer/validateMissingFields(int)
parquet/io/ValidatingRecordConsumer/endMessage()#parquet/schema/GroupType/getFieldCount()
parquet/io/ValidatingRecordConsumer/endMessage()#java/util/Deque/pop()
parquet/io/ValidatingRecordConsumer/endField(java.lang.String,int)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/io/ValidatingRecordConsumer/endField(java.lang.String,int)#java/util/Deque/pop()
parquet/io/ValidatingRecordConsumer/endField(java.lang.String,int)#java/util/Deque/push(E)
parquet/io/ValidatingRecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName[])
parquet/io/ValidatingRecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/io/ValidatingRecordConsumer/addFloat(float)#parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/io/ValidatingRecordConsumer/addFloat(float)#parquet/io/api/RecordConsumer/addFloat(float)
parquet/io/ValidatingRecordConsumer/startField(java.lang.String,int)#java/util/Deque/peek()
parquet/io/ValidatingRecordConsumer/startField(java.lang.String,int)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/io/ValidatingRecordConsumer/startField(java.lang.String,int)#parquet/io/ValidatingRecordConsumer/validateMissingFields(int)
parquet/io/ValidatingRecordConsumer/startField(java.lang.String,int)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/io/ValidatingRecordConsumer/startField(java.lang.String,int)#java/util/Deque/push(E)
parquet/io/ValidatingRecordConsumer/addBoolean(boolean)#parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/io/ValidatingRecordConsumer/addBoolean(boolean)#parquet/io/api/RecordConsumer/addBoolean(boolean)
parquet/io/ValidatingRecordConsumer/addDouble(double)#parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/io/ValidatingRecordConsumer/addDouble(double)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/io/ValidatingRecordConsumer/addLong(long)#parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/io/ValidatingRecordConsumer/addLong(long)#parquet/io/api/RecordConsumer/addLong(long)
parquet/io/ValidatingRecordConsumer/addInteger(int)#parquet/io/ValidatingRecordConsumer/validate(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/io/ValidatingRecordConsumer/addInteger(int)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/io/ValidatingRecordConsumer/validateMissingFields(int)#parquet/schema/Type/asGroupType()
parquet/io/ValidatingRecordConsumer/validateMissingFields(int)#java/util/Deque/peek()
parquet/io/ValidatingRecordConsumer/validateMissingFields(int)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/io/ValidatingRecordConsumer/validateMissingFields(int)#parquet/schema/GroupType/getType(int)
parquet/io/ValidatingRecordConsumer/validateMissingFields(int)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/io/ValidatingRecordConsumer/startGroup()#parquet/schema/Type/asGroupType()
parquet/io/ValidatingRecordConsumer/startGroup()#java/util/Deque/peek()
parquet/io/ValidatingRecordConsumer/startGroup()#parquet/schema/GroupType/getType(int)
parquet/io/ValidatingRecordConsumer/startGroup()#parquet/io/api/RecordConsumer/startGroup()
parquet/io/ValidatingRecordConsumer/startGroup()#java/util/Deque/push(E)
parquet/proto/ProtoWriteSupportTest/testRepeatedInnerMessageMessage_scalar()#parquet/proto/ProtoWriteSupportTest/createReadConsumerInstance(java.lang.Class,parquet.io.api.RecordConsumer)
parquet/proto/ProtoWriteSupportTest/testRepeatedInnerMessageMessage_scalar()#parquet/io/api/Binary/fromByteArray(byte[])
parquet/proto/ProtoWriteSupportTest/testRepeatedInnerMessageMessage_scalar()#parquet/proto/ProtoWriteSupport/write(T)
parquet/proto/ProtoWriteSupportTest/testRepeatedInnerMessageMessage_scalar()#java/lang/String/getBytes()
parquet/proto/ProtoWriteSupportTest/testOptionalInnerMessage()#parquet/proto/ProtoWriteSupportTest/createReadConsumerInstance(java.lang.Class,parquet.io.api.RecordConsumer)
parquet/proto/ProtoWriteSupportTest/testOptionalInnerMessage()#parquet/io/api/Binary/fromByteArray(byte[])
parquet/proto/ProtoWriteSupportTest/testOptionalInnerMessage()#parquet/proto/ProtoWriteSupport/write(T)
parquet/proto/ProtoWriteSupportTest/testOptionalInnerMessage()#java/lang/String/getBytes()
parquet/proto/ProtoWriteSupportTest/testRepeatedIntMessage()#parquet/proto/ProtoWriteSupportTest/createReadConsumerInstance(java.lang.Class,parquet.io.api.RecordConsumer)
parquet/proto/ProtoWriteSupportTest/testRepeatedIntMessage()#parquet/proto/ProtoWriteSupport/write(T)
parquet/proto/ProtoWriteSupportTest/testSimplestMessage()#parquet/proto/ProtoWriteSupportTest/createReadConsumerInstance(java.lang.Class,parquet.io.api.RecordConsumer)
parquet/proto/ProtoWriteSupportTest/testSimplestMessage()#parquet/io/api/Binary/fromByteArray(byte[])
parquet/proto/ProtoWriteSupportTest/testSimplestMessage()#parquet/proto/ProtoWriteSupport/write(T)
parquet/proto/ProtoWriteSupportTest/testSimplestMessage()#java/lang/String/getBytes()
parquet/proto/ProtoWriteSupportTest/createReadConsumerInstance(java.lang.Class,parquet.io.api.RecordConsumer)#parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/proto/ProtoWriteSupportTest/createReadConsumerInstance(java.lang.Class,parquet.io.api.RecordConsumer)#parquet/proto/ProtoWriteSupport/ProtoWriteSupport(java.lang.Class)
parquet/proto/ProtoWriteSupportTest/createReadConsumerInstance(java.lang.Class,parquet.io.api.RecordConsumer)#parquet/proto/ProtoWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)
parquet/proto/ProtoWriteSupportTest/testRepeatedInnerMessageMessage_message()#parquet/proto/ProtoWriteSupportTest/createReadConsumerInstance(java.lang.Class,parquet.io.api.RecordConsumer)
parquet/proto/ProtoWriteSupportTest/testRepeatedInnerMessageMessage_message()#parquet/io/api/Binary/fromByteArray(byte[])
parquet/proto/ProtoWriteSupportTest/testRepeatedInnerMessageMessage_message()#parquet/proto/ProtoWriteSupport/write(T)
parquet/proto/ProtoWriteSupportTest/testRepeatedInnerMessageMessage_message()#java/lang/String/getBytes()
parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])#parquet/proto/TestUtils/someTemporaryFilePath()
parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])#java/util/Arrays/asList(T[])
parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])#java/util/Collections/unmodifiableList(java.util.List)
parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])#parquet/proto/TestUtils/inferRecordsClass(parquet.proto.MessageOrBuilder[])
parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])#parquet/proto/utils/WriteUsingMR/waitForJob(parquet.proto.utils.Job)
parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])#java/lang/Object/Object()
parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])#parquet/proto/ProtoParquetOutputFormat/setProtobufClass(parquet.proto.utils.Job,java.lang.Class)
parquet/proto/utils/WriteUsingMR/waitForJob(parquet.proto.utils.Job)#java/lang/Thread/sleep(long)
parquet/proto/utils/WriteUsingMR/waitForJob(parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/proto/utils/WriteUsingMR/waitForJob(parquet.proto.utils.Job)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/convert/TupleConverter/FieldByteArrayConverter/addBinary(parquet.io.api.Binary)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldByteArrayConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/filter/OrRecordFilter/isMatch()#parquet/filter/RecordFilter/isMatch()
parquet/filter/OrRecordFilter/or(parquet.filter.UnboundRecordFilter,parquet.filter.UnboundRecordFilter)#parquet/filter/OrRecordFilter/or(parquet/filter/UnboundRecordFilter,parquet/filter/UnboundRecordFilter)/$anonymous1/()
parquet/filter/OrRecordFilter/or(parquet.filter.UnboundRecordFilter,parquet.filter.UnboundRecordFilter)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/thrift/struct/ThriftType/StringType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.StringType)
parquet/column/values/bitpacking/TestBitPackingColumn/testThree()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne_0_0()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne_1_1()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testTwo()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne_9_1s()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne_9_0s()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne_0()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#java/lang/Enum/toString()
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/ValuesReader/readInteger()
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/TestBitPackingColumn/PACKING_TYPE/getWriter(int)
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/TestBitPacking/toString(byte[])
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#java/lang/Math/pow(double,double)
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/TestBitPackingColumn/PACKING_TYPE/values()
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/TestBitPackingColumn/PACKING_TYPE/getReader(int)
parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/bitpacking/TestBitPackingColumn/testFive()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testSix()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testSeven()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne_9_0s_1_1()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testFour()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne_7_0s_1_1()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testZero()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPackingColumn/testOne_1()#parquet/column/values/bitpacking/TestBitPackingColumn/validateEncodeDecode(int,int[],java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/util/Map/Entry/getValue()
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/util/Map/get(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/util/Map/Entry/getKey()
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/util/Map/containsKey(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/util/Map/entrySet()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/writeSetBegin(parquet.thrift.TSet)#parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/startListWrapper()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/writeSetEnd()#parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/endListWrapper()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/startListWrapper()#parquet/io/ColumnIO/getType()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/startListWrapper()#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/startListWrapper()#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/startListWrapper()#parquet/schema/Type/getName()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/startListWrapper()#parquet/io/api/RecordConsumer/startGroup()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/endListWrapper()#parquet/io/ColumnIO/getType()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/endListWrapper()#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/endListWrapper()#parquet/schema/Type/getName()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/endListWrapper()#parquet/io/api/RecordConsumer/endGroup()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/endListWrapper()#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/writeListEnd()#parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/endListWrapper()
parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/writeListBegin(parquet.thrift.TList)#parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/startListWrapper()
parquet/proto/ProtoWriteSupport/IntWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/filter2/statisticslevel/TestStatisticsFilter/testMissingColumn()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/filter2/statisticslevel/TestStatisticsFilter/testMissingColumn()#java/lang/Throwable/getMessage()
parquet/filter2/statisticslevel/TestStatisticsFilter/testMissingColumn()#java/util/Arrays/asList(T[])
parquet/filter2/statisticslevel/TestStatisticsFilter/testMissingColumn()#parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testMissingColumn()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testMissingColumn()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testMissingColumn()#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/statisticslevel/TestStatisticsFilter/testLtEq()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testLtEq()#parquet/filter2/predicate/FilterApi/ltEq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNonNull()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNonNull()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)#java/util/Arrays/asList(T[])
parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)#parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)#java/util/HashSet/HashSet(java.util.Collection)
parquet/filter2/statisticslevel/TestStatisticsFilter/testOr()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testOr()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/statisticslevel/TestStatisticsFilter/testOr()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testLt()#parquet/filter2/predicate/FilterApi/lt(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testLt()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testAnd()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testAnd()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testAnd()#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/statisticslevel/TestStatisticsFilter/testGt()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testGt()#parquet/filter2/predicate/FilterApi/gt(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#parquet/filter2/predicate/LogicalInverseRewriter/rewrite(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#parquet/filter2/predicate/FilterApi/not(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#parquet/column/statistics/IntStatistics/setMinMax(int,int)
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#java/util/Arrays/asList(T[])
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#parquet/filter2/predicate/FilterApi/userDefined(parquet.filter2.predicate.Operators.Column,java.lang.Class)
parquet/filter2/statisticslevel/TestStatisticsFilter/testUdp()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNull()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNull()#parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNull()#parquet/column/statistics/Statistics/setNumNulls(long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNull()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNull()#parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNull()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNull()#parquet/column/statistics/IntStatistics/setMinMax(int,int)
parquet/filter2/statisticslevel/TestStatisticsFilter/testEqNull()#java/util/Arrays/asList(T[])
parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)#java/util/Arrays/asList(T[])
parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)#parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)#java/util/HashSet/HashSet(java.util.Collection)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNonNull()#parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNonNull()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNonNull()#parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNonNull()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNonNull()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNonNull()#parquet/column/statistics/IntStatistics/setMinMax(int,int)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNonNull()#java/util/Arrays/asList(T[])
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNull()#parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNull()#parquet/column/statistics/Statistics/setNumNulls(long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNull()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNull()#parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNull()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNull()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNull()#parquet/column/statistics/IntStatistics/setMinMax(int,int)
parquet/filter2/statisticslevel/TestStatisticsFilter/testNotEqNull()#java/util/Arrays/asList(T[])
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#parquet/column/statistics/DoubleStatistics/DoubleStatistics()
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#parquet/filter2/statisticslevel/TestStatisticsFilter/getDoubleColumnMeta(parquet.column.statistics.DoubleStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#java/lang/Throwable/getMessage()
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#java/util/Arrays/asList(T[])
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#parquet/filter2/statisticslevel/TestStatisticsFilter/getIntColumnMeta(parquet.column.statistics.IntStatistics,long)
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#parquet/filter2/predicate/FilterApi/not(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testClearExceptionForNots()#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/statisticslevel/TestStatisticsFilter/testGtEq()#parquet/filter2/predicate/FilterApi/gtEq(C,T)
parquet/filter2/statisticslevel/TestStatisticsFilter/testGtEq()#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumnFilterPredicate(parquet.filter2.predicate.Operators.ColumnFilterPredicate)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumnFilterPredicate(parquet.filter2.predicate.Operators.ColumnFilterPredicate)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.UserDefined)#parquet/filter2/predicate/Operators/UserDefined/getColumn()
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.UserDefined)#parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumnFilterPredicate(parquet.filter2.predicate.Operators.ColumnFilterPredicate)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumnFilterPredicate(parquet.filter2.predicate.Operators.ColumnFilterPredicate)
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumnFilterPredicate(parquet.filter2.predicate.Operators.ColumnFilterPredicate)#parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumnFilterPredicate(parquet.filter2.predicate.Operators.ColumnFilterPredicate)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumnFilterPredicate(parquet.filter2.predicate.Operators.ColumnFilterPredicate)
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#parquet/column/ColumnDescriptor/getType()
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#java/lang/Object/equals(java.lang.Object)
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#parquet/common/schema/ColumnPath/toDotString()
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#java/util/Map/get(java.lang.Object)
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#parquet/filter2/predicate/Operators/Column/getColumnType()
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#parquet/filter2/predicate/SchemaCompatibilityValidator/getColumnDescriptor(parquet.common.schema.ColumnPath)
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#parquet/column/ColumnDescriptor/getMaxRepetitionLevel()
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumn(parquet.filter2.predicate.Operators.Column)#java/util/Map/put(K,V)
parquet/filter2/predicate/SchemaCompatibilityValidator/getColumnDescriptor(parquet.common.schema.ColumnPath)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/filter2/predicate/SchemaCompatibilityValidator/getColumnDescriptor(parquet.common.schema.ColumnPath)#java/util/Map/get(java.lang.Object)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.LogicalNotUserDefined)#parquet/filter2/predicate/Operators/LogicalNotUserDefined/getUserDefined()
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.LogicalNotUserDefined)#parquet/filter2/predicate/Operators/UserDefined/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/predicate/SchemaCompatibilityValidator/validateColumnFilterPredicate(parquet.filter2.predicate.Operators.ColumnFilterPredicate)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.Not)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/SchemaCompatibilityValidator/visit(parquet.filter2.predicate.Operators.Not)#parquet/filter2/predicate/Operators/Not/getPredicate()
parquet/filter2/predicate/SchemaCompatibilityValidator/validate(parquet.filter2.predicate.FilterPredicate,parquet.schema.MessageType)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/SchemaCompatibilityValidator/validate(parquet.filter2.predicate.FilterPredicate,parquet.schema.MessageType)#parquet/filter2/predicate/SchemaCompatibilityValidator/SchemaCompatibilityValidator(parquet.schema.MessageType)
parquet/filter2/predicate/SchemaCompatibilityValidator/validate(parquet.filter2.predicate.FilterPredicate,parquet.schema.MessageType)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/example/data/simple/IntegerValue/toString()#java/lang/String/valueOf(int)
parquet/example/data/simple/IntegerValue/writeValue(parquet.io.api.RecordConsumer)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/cascading/convert/TupleRecordMaterializer/getCurrentRecord()#parquet/cascading/convert/TupleConverter/getCurrentTuple()
parquet/io/PerfTest/read(parquet.io.RecordReader,int,parquet.schema.MessageType)#java/io/PrintStream/print(java.lang.String)
parquet/io/PerfTest/read(parquet.io.RecordReader,int,parquet.schema.MessageType)#java/lang/System/currentTimeMillis()
parquet/io/PerfTest/read(parquet.io.RecordReader,int,parquet.schema.MessageType)#parquet/io/RecordReader/read()
parquet/io/PerfTest/read(parquet.io.RecordReader,int,parquet.schema.MessageType)#java/lang/Object/equals(java.lang.Object)
parquet/io/PerfTest/read(parquet.io.RecordReader,int,parquet.schema.MessageType)#java/lang/System/gc()
parquet/io/PerfTest/read(parquet.io.RecordReader,int,parquet.schema.MessageType)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/io/PerfTest/read(parquet.io.RecordReader,int,parquet.schema.MessageType)#java/io/PrintStream/printf(java.lang.String,java.lang.Object[])
parquet/io/PerfTest/newColumnFactory(parquet.schema.MessageType)#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/io/PerfTest/newColumnFactory(parquet.schema.MessageType)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,java.lang.String)#parquet/io/PerfTest/read(parquet.io.RecordReader,int,parquet.schema.MessageType)
parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,java.lang.String)#parquet/example/DummyRecordConverter/DummyRecordConverter(parquet.schema.MessageType)
parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,java.lang.String)#parquet/io/PerfTest/newColumnFactory(parquet.schema.MessageType)
parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,java.lang.String)#java/io/PrintStream/println(java.lang.String)
parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,java.lang.String)#java/io/PrintStream/println()
parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,java.lang.String)#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore,parquet.example.data.GroupWriter,int)#java/io/PrintStream/printf(java.lang.String,java.lang.Object[])
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore,parquet.example.data.GroupWriter,int)#java/lang/System/currentTimeMillis()
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore,parquet.example.data.GroupWriter,int)#parquet/column/page/mem/MemPageStore/addRowCount(long)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore,parquet.example.data.GroupWriter,int)#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/PerfTest/main(java.lang.String[])#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/PerfTest/main(java.lang.String[])#parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)
parquet/io/PerfTest/main(java.lang.String[])#parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/io/PerfTest/newColumnFactory(parquet.schema.MessageType)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/column/impl/ColumnWriteStoreImpl/memSize()
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/column/impl/ColumnWriteStoreImpl/maxColMemSize()
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#java/io/PrintStream/println(java.lang.String)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore,parquet.example.data.GroupWriter,int)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#java/io/PrintStream/println()
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/io/PerfTest/write(parquet.column.page.mem.MemPageStore)#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore)#parquet/io/PerfTest/read(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,java.lang.String)
parquet/proto/ProtoSchemaConverterTest/testConvertAllDatatypes()#parquet/proto/ProtoSchemaConverterTest/testConversion(java.lang.Class,java.lang.String)
parquet/proto/ProtoSchemaConverterTest/testConvertRepetition()#parquet/proto/ProtoSchemaConverterTest/testConversion(java.lang.Class,java.lang.String)
parquet/proto/ProtoSchemaConverterTest/testConversion(java.lang.Class,java.lang.String)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/proto/ProtoSchemaConverterTest/testConversion(java.lang.Class,java.lang.String)#parquet/schema/Type/toString()
parquet/proto/ProtoSchemaConverterTest/testConversion(java.lang.Class,java.lang.String)#parquet/proto/ProtoSchemaConverter/convert(java.lang.Class)
parquet/proto/ProtoSchemaConverterTest/testConversion(java.lang.Class,java.lang.String)#parquet/proto/ProtoSchemaConverter/ProtoSchemaConverter()
parquet/proto/ProtoMessageConverter/ProtoIntConverter/addInt(int)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldFixedConverter/addBinary(parquet.io.api.Binary)#java/lang/reflect/Constructor/newInstance(java.lang.Object[])
parquet/avro/AvroIndexedRecordConverter/FieldFixedConverter/addBinary(parquet.io.api.Binary)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/avro/AvroIndexedRecordConverter/FieldFixedConverter/addBinary(parquet.io.api.Binary)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldFixedConverter/addBinary(parquet.io.api.Binary)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/avro/AvroIndexedRecordConverter/FieldFixedConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/avro/AvroIndexedRecordConverter/FieldFixedConverter/addBinary(parquet.io.api.Binary)#java/lang/Object/Object()
parquet/filter2/compat/FilterCompat/FilterPredicateCompat/accept(parquet.filter2.compat.FilterCompat.Visitor)#parquet/filter2/compat/FilterCompat/Visitor/visit(parquet.filter2.compat.FilterCompat.FilterPredicateCompat)
parquet/pig/ParquetStorer/getOutputFormat()#parquet/hadoop/ParquetOutputFormat/ParquetOutputFormat(S)
parquet/pig/ParquetStorer/getOutputFormat()#parquet/pig/ParquetStorer/getSchema()
parquet/pig/ParquetStorer/getOutputFormat()#parquet/pig/TupleWriteSupport/TupleWriteSupport(parquet.pig.convert.Schema)
parquet/pig/ParquetStorer/getSchema()#java/util/Properties/getProperty(java.lang.String)
parquet/pig/ParquetStorer/getSchema()#parquet/pig/ParquetStorer/getProperties()
parquet/pig/ParquetStorer/getSchema()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/pig/ParquetStorer/getSchema()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/pig/ParquetStorer/checkSchema(parquet.pig.ResourceSchema)#java/util/Properties/setProperty(java.lang.String,java.lang.String)
parquet/pig/ParquetStorer/checkSchema(parquet.pig.ResourceSchema)#parquet/pig/ParquetStorer/getProperties()
parquet/pig/ParquetStorer/getProperties()#java/lang/Object/getClass()
parquet/pig/ParquetStorer/putNext(parquet.pig.convert.Tuple)#java/lang/Thread/interrupted()
parquet/pig/ParquetStorer/putNext(parquet.pig.convert.Tuple)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/bitpacking/FourBitPackingReader/read()#java/io/InputStream/read()
parquet/common/internal/Canonicalizer/canonicalize(T)#java/util/concurrent/ConcurrentHashMap/putIfAbsent(K,V)
parquet/common/internal/Canonicalizer/canonicalize(T)#parquet/common/internal/Canonicalizer/toCanonical(T)
parquet/common/internal/Canonicalizer/canonicalize(T)#java/util/concurrent/ConcurrentHashMap/get(java.lang.Object)
parquet/filter2/predicate/Operators/Or/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.Or)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/getRecordReader(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/RecordReaderWrapper(parquet.hadoop.ParquetInputFormat,org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.cascading.JobConf,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/getSplits(parquet.cascading.JobConf,int)#parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/getSplits(parquet.cascading.JobConf,int)#java/util/List/size()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/getSplits(parquet.cascading.JobConf,int)#java/util/Arrays/asList(T[])
parquet/hadoop/mapred/DeprecatedParquetInputFormat/getSplits(parquet.cascading.JobConf,int)#parquet/hadoop/mapred/DeprecatedParquetInputFormat/ParquetInputSplitWrapper/ParquetInputSplitWrapper(parquet.hadoop.ParquetInputSplit)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/getFooters(parquet.cascading.JobConf)#parquet/hadoop/ParquetInputFormat/getFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/getFooters(parquet.cascading.JobConf)#java/util/Arrays/asList(T[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getBufferedSize()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getAllocatedSize()#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/calculateBitWidthsForDeltaBlockBuffer(int)#java/lang/Integer/numberOfLeadingZeros(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/calculateBitWidthsForDeltaBlockBuffer(int)#java/lang/Math/min(int,int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/writeBitWidthForMiniBlock(int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/writeBitWidthForMiniBlock(int)#parquet/bytes/BytesUtils/writeIntLittleEndianOnOneByte(java.io.OutputStream,int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/reset()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getMiniBlockCountToFlush(double)#java/lang/Math/ceil(double)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getMiniBlockCountToFlush(double)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()#parquet/column/values/bitpacking/Packer/newBytePacker(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()#parquet/bytes/CapacityByteArrayOutputStream/write(byte[],int,int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/calculateBitWidthsForDeltaBlockBuffer(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/writeBitWidthForMiniBlock(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/writeMinDelta()
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()#parquet/column/values/bitpacking/BytePacker/pack8Values(int[],int,byte[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getBytes()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getBytes()#parquet/column/values/delta/DeltaBinaryPackingConfig/toBytesInput()
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getBytes()#parquet/bytes/BytesInput/fromZigZagVarInt(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getBytes()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getBytes()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getBytes()#parquet/bytes/BytesInput/fromUnsignedVarInt(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/memUsageString(java.lang.String)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/memUsageString(java.lang.String)#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getAllocatedSize()
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/writeInteger(int)#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/flushBlockBuffer()
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/writeMinDelta()#parquet/bytes/BytesUtils/writeZigZagVarInt(int,java.io.OutputStream)
parquet/column/values/delta/DeltaBinaryPackingValuesWriter/writeMinDelta()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/FileMetaData/FileMetaData(parquet.schema.MessageType,java.util.Map,java.lang.String)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/format/converter/ParquetMetadataConverter/fromParquetSchema(java.util.List)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/BlockMetaData/setTotalByteSize(long)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#java/util/HashMap/HashMap()
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#java/lang/String/equals(java.lang.Object)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/BlockMetaData/setPath(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/BlockMetaData/BlockMetaData()
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/ParquetMetadata/ParquetMetadata(parquet.hadoop.metadata.FileMetaData,java.util.List)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/CompressionCodecName/fromParquet(parquet.hadoop.metadata.CompressionCodec)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/BlockMetaData/addColumn(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/schema/MessageType/getType(java.lang.String[])
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#java/util/ArrayList/ArrayList()
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/schema/Type/asPrimitiveType()
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/common/schema/ColumnPath/toArray()
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/hadoop/metadata/BlockMetaData/setRowCount(long)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/format/converter/ParquetMetadataConverter/getPath(parquet.format.ColumnMetaData)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/format/converter/ParquetMetadataConverter/fromFormatEncodings(java.util.List)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#java/util/List/add(E)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#parquet/format/converter/ParquetMetadataConverter/fromParquetStatistics(parquet.format.converter.Statistics,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)#java/util/Map/put(K,V)
parquet/format/converter/ParquetMetadataConverter/fromParquetSchema(java.util.List)#parquet/schema/Types/MessageTypeBuilder/named(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/fromParquetSchema(java.util.List)#parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)
parquet/format/converter/ParquetMetadataConverter/fromParquetSchema(java.util.List)#parquet/schema/Types/buildMessage()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/format/converter/ParquetMetadataConverter/toFormatEncodings(java.util.Set)
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/common/schema/ColumnPath/toArray()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/CompressionCodecName/getParquetCompressionCodec()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#java/util/Arrays/asList(T[])
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getDictionaryPageOffset()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getType()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/BlockMetaData/getPath()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getCodec()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/BlockMetaData/getTotalByteSize()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getValueCount()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/column/statistics/Statistics/isEmpty()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/format/converter/ParquetMetadataConverter/toParquetStatistics(parquet.column.statistics.Statistics)
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#java/util/ArrayList/ArrayList()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/BlockMetaData/getRowCount()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalSize()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/format/converter/ParquetMetadataConverter/getType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalUncompressedSize()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getEncodings()
parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)#java/lang/Object/Object()
parquet/format/converter/ParquetMetadataConverter/newDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/format/converter/ParquetMetadataConverter/toParquetStatistics(parquet.column.statistics.Statistics)
parquet/format/converter/ParquetMetadataConverter/newDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.column.Encoding)
parquet/format/converter/ParquetMetadataConverter/newDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#java/lang/Object/Object()
parquet/format/converter/ParquetMetadataConverter/newDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/column/statistics/Statistics/isEmpty()
parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.format.converter.Encoding)#parquet/column/Encoding/valueOf(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/toParquetRepetition(parquet.schema.Type.Repetition)#java/lang/Enum/name()
parquet/format/converter/ParquetMetadataConverter/getPrimitive(parquet.format.converter.Type)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/addToList(java.util.List,parquet.schema.Type)#parquet/format/converter/ParquetMetadataConverter/addToList(java/util/List,parquet/schema/Type)/$anonymous1/()
parquet/format/converter/ParquetMetadataConverter/addToList(java.util.List,parquet.schema.Type)#parquet/schema/Type/accept(parquet.schema.TypeVisitor)
parquet/format/converter/ParquetMetadataConverter/fromParquetStatistics(parquet.format.converter.Statistics,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/Statistics/setNumNulls(long)
parquet/format/converter/ParquetMetadataConverter/fromParquetStatistics(parquet.format.converter.Statistics,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/Statistics/setMinMaxFromBytes(byte[],byte[])
parquet/format/converter/ParquetMetadataConverter/fromParquetStatistics(parquet.format.converter.Statistics,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/format/converter/ParquetMetadataConverter/getType(parquet.schema.PrimitiveType.PrimitiveTypeName)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/filterFileMetaData(parquet.format.converter.FileMetaData,parquet.format.converter.ParquetMetadataConverter.RangeMetadataFilter)#java/util/ArrayList/ArrayList()
parquet/format/converter/ParquetMetadataConverter/filterFileMetaData(parquet.format.converter.FileMetaData,parquet.format.converter.ParquetMetadataConverter.RangeMetadataFilter)#parquet/format/converter/ParquetMetadataConverter/RangeMetadataFilter/contains(long)
parquet/format/converter/ParquetMetadataConverter/filterFileMetaData(parquet.format.converter.FileMetaData,parquet.format.converter.ParquetMetadataConverter.RangeMetadataFilter)#parquet/format/converter/ParquetMetadataConverter/getOffset(parquet.format.converter.RowGroup)
parquet/format/converter/ParquetMetadataConverter/toFormatEncodings(java.util.Set)#java/util/ArrayList/ArrayList(int)
parquet/format/converter/ParquetMetadataConverter/toFormatEncodings(java.util.Set)#java/util/Set/size()
parquet/format/converter/ParquetMetadataConverter/toFormatEncodings(java.util.Set)#parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.column.Encoding)
parquet/format/converter/ParquetMetadataConverter/toParquetSchema(parquet.schema.MessageType)#java/util/ArrayList/ArrayList()
parquet/format/converter/ParquetMetadataConverter/toParquetSchema(parquet.schema.MessageType)#parquet/format/converter/ParquetMetadataConverter/addToList(java.util.List,parquet.schema.Type)
parquet/format/converter/ParquetMetadataConverter/toParquetStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/getMinBytes()
parquet/format/converter/ParquetMetadataConverter/toParquetStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/getNumNulls()
parquet/format/converter/ParquetMetadataConverter/toParquetStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/getMaxBytes()
parquet/format/converter/ParquetMetadataConverter/toParquetStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/isEmpty()
parquet/format/converter/ParquetMetadataConverter/range(long,long)#parquet/format/converter/ParquetMetadataConverter/RangeMetadataFilter/RangeMetadataFilter(long,long)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/schema/Types/PrimitiveBuilder/precision(int)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/format/converter/ParquetMetadataConverter/getPrimitive(parquet.format.converter.Type)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/schema/Types/Builder/named(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/format/converter/ParquetMetadataConverter/getOriginalType(parquet.format.converter.ConvertedType)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/format/converter/ParquetMetadataConverter/fromParquetRepetition(parquet.format.converter.FieldRepetitionType)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/schema/Types/GroupBuilder/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/schema/Types/GroupBuilder/group(parquet.schema.Type.Repetition)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/schema/Types/PrimitiveBuilder/scale(int)
parquet/format/converter/ParquetMetadataConverter/buildChildren(parquet.schema.Types.GroupBuilder,java.util.Iterator,int)#parquet/schema/Types/Builder/id(int)
parquet/format/converter/ParquetMetadataConverter/getConvertedType(parquet.schema.OriginalType)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/BlockMetaData/getRowCount()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/format/converter/ParquetMetadataConverter/addKeyValue(parquet.format.converter.FileMetaData,java.lang.String,java.lang.String)
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#java/util/Map/Entry/getKey()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/FileMetaData/getCreatedBy()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#java/util/Map/entrySet()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/format/converter/ParquetMetadataConverter/toParquetSchema(parquet.schema.MessageType)
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#java/util/ArrayList/ArrayList()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/format/converter/ParquetMetadataConverter/addRowGroup(parquet.hadoop.metadata.ParquetMetadata,java.util.List,parquet.hadoop.metadata.BlockMetaData)
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#java/util/Map/Entry/getValue()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/FileMetaData/getKeyValueMetaData()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)#java/lang/Object/Object()
parquet/format/converter/ParquetMetadataConverter/getPath(parquet.format.ColumnMetaData)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java.io.InputStream)#parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java.io.InputStream,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
parquet/format/converter/ParquetMetadataConverter/getOriginalType(parquet.format.converter.ConvertedType)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.column.Encoding)#java/lang/Enum/name()
parquet/format/converter/ParquetMetadataConverter/writeDataPageHeader(int,int,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding,java.io.OutputStream)#parquet/format/converter/ParquetMetadataConverter/newDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/format/converter/ParquetMetadataConverter/writeDataPageHeader(int,int,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding,java.io.OutputStream)#parquet/column/statistics/BooleanStatistics/BooleanStatistics()
parquet/format/converter/ParquetMetadataConverter/fromFormatEncodings(java.util.List)#parquet/format/converter/ParquetMetadataConverter/EncodingList/EncodingList(java.util.Set)
parquet/format/converter/ParquetMetadataConverter/fromFormatEncodings(java.util.List)#parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.format.converter.Encoding)
parquet/format/converter/ParquetMetadataConverter/fromFormatEncodings(java.util.List)#java/util/Map/get(java.lang.Object)
parquet/format/converter/ParquetMetadataConverter/fromFormatEncodings(java.util.List)#java/util/Set/add(E)
parquet/format/converter/ParquetMetadataConverter/fromFormatEncodings(java.util.List)#java/util/Map/put(K,V)
parquet/format/converter/ParquetMetadataConverter/fromFormatEncodings(java.util.List)#java/util/HashSet/HashSet()
parquet/format/converter/ParquetMetadataConverter/fromFormatEncodings(java.util.List)#java/util/Collections/unmodifiableSet(java.util.Set)
parquet/format/converter/ParquetMetadataConverter/fromParquetRepetition(parquet.format.converter.FieldRepetitionType)#parquet/schema/Type/Repetition/valueOf(java.lang.String)
parquet/format/converter/ParquetMetadataConverter/getOffset(parquet.format.converter.RowGroup)#parquet/format/converter/ParquetMetadataConverter/getOffset(parquet.format.converter.RowGroup)
parquet/format/converter/ParquetMetadataConverter/writeDictionaryPageHeader(int,int,int,parquet.column.Encoding,java.io.OutputStream)#parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.column.Encoding)
parquet/format/converter/ParquetMetadataConverter/writeDictionaryPageHeader(int,int,int,parquet.column.Encoding,java.io.OutputStream)#java/lang/Object/Object()
parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java.io.InputStream,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/format/converter/ParquetMetadataConverter/fromParquetMetadata(parquet.format.converter.FileMetaData)
parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java.io.InputStream,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/hadoop/metadata/ParquetMetadata/toPrettyJSON(parquet.hadoop.metadata.ParquetMetadata)
parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java.io.InputStream,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/Log/debug(java.lang.Object)
parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java.io.InputStream,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java/io/InputStream,parquet/format/converter/ParquetMetadataConverter/MetadataFilter)/$anonymous1/()
parquet/format/converter/ParquetMetadataConverter/readParquetMetadata(java.io.InputStream,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)#parquet/format/converter/ParquetMetadataConverter/MetadataFilter/accept(parquet.format.converter.ParquetMetadataConverter.MetadataFilterVisitor)
parquet/format/converter/ParquetMetadataConverter/writeDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding,java.io.OutputStream)#parquet/format/converter/ParquetMetadataConverter/newDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/thrift/struct/ThriftType/I16Type/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.I16Type)
parquet/io/RecordConsumerLoggingWrapper/endGroup()#parquet/io/api/RecordConsumer/endGroup()
parquet/io/RecordConsumerLoggingWrapper/endGroup()#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/startMessage()#parquet/io/api/RecordConsumer/startMessage()
parquet/io/RecordConsumerLoggingWrapper/startMessage()#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)#parquet/io/RecordConsumerLoggingWrapper/indent()
parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)#parquet/Log/debug(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/startField(java.lang.String,int)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/io/RecordConsumerLoggingWrapper/startField(java.lang.String,int)#parquet/io/RecordConsumerLoggingWrapper/logOpen(java.lang.String)
parquet/io/RecordConsumerLoggingWrapper/addInteger(int)#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/addInteger(int)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/io/RecordConsumerLoggingWrapper/startGroup()#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/startGroup()#parquet/io/api/RecordConsumer/startGroup()
parquet/io/RecordConsumerLoggingWrapper/logOpen(java.lang.String)#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/addBinary(parquet.io.api.Binary)#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/addBinary(parquet.io.api.Binary)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/io/RecordConsumerLoggingWrapper/addBinary(parquet.io.api.Binary)#java/util/Arrays/toString(byte[])
parquet/io/RecordConsumerLoggingWrapper/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/io/RecordConsumerLoggingWrapper/endMessage()#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/endMessage()#parquet/io/api/RecordConsumer/endMessage()
parquet/io/RecordConsumerLoggingWrapper/indent()#java/lang/StringBuilder/append(java.lang.String)
parquet/io/RecordConsumerLoggingWrapper/indent()#java/lang/StringBuilder/StringBuilder()
parquet/io/RecordConsumerLoggingWrapper/indent()#java/lang/StringBuilder/toString()
parquet/io/RecordConsumerLoggingWrapper/addFloat(float)#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/addFloat(float)#parquet/io/api/RecordConsumer/addFloat(float)
parquet/io/RecordConsumerLoggingWrapper/logClose(java.lang.String)#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/addBoolean(boolean)#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/addBoolean(boolean)#parquet/io/api/RecordConsumer/addBoolean(boolean)
parquet/io/RecordConsumerLoggingWrapper/addDouble(double)#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/addDouble(double)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/io/RecordConsumerLoggingWrapper/endField(java.lang.String,int)#parquet/io/RecordConsumerLoggingWrapper/logClose(java.lang.String)
parquet/io/RecordConsumerLoggingWrapper/endField(java.lang.String,int)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/io/RecordConsumerLoggingWrapper/addLong(long)#parquet/io/RecordConsumerLoggingWrapper/log(java.lang.Object)
parquet/io/RecordConsumerLoggingWrapper/addLong(long)#parquet/io/api/RecordConsumer/addLong(long)
parquet/avro/AvroSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.OriginalType)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String,parquet.schema.OriginalType)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema)#parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)
parquet/avro/AvroSchemaConverter/convertFields(java.util.List)#java/util/ArrayList/ArrayList()
parquet/avro/AvroSchemaConverter/convertFields(java.util.List)#java/util/List/add(E)
parquet/avro/AvroSchemaConverter/convertFields(java.util.List)#parquet/avro/AvroSchemaConverter/convertField(Schema.Field)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/avro/AvroSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.OriginalType)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/schema/ConversionPatterns/stringKeyMapType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/avro/AvroSchemaConverter/convertFields(java.util.List)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/schema/ConversionPatterns/listType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/avro/AvroSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/avro/AvroSchemaConverter/convertUnion(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/avro/AvroSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,int,parquet.schema.OriginalType)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)
parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,java.util.List)
parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)#parquet/avro/AvroSchemaConverter/convertFields(java.util.List)
parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/avro/AvroSchemaConverter/convertField(Schema.Field)#parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema)
parquet/avro/AvroSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,int,parquet.schema.OriginalType)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,int,java.lang.String,parquet.schema.OriginalType)
parquet/avro/AvroSchemaConverter/convertFields(java.lang.String,java.util.List)#java/util/ArrayList/ArrayList()
parquet/avro/AvroSchemaConverter/convertFields(java.lang.String,java.util.List)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/avro/AvroSchemaConverter/convertFields(java.lang.String,java.util.List)#parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)
parquet/avro/AvroSchemaConverter/convertFields(java.lang.String,java.util.List)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/avro/AvroSchemaConverter/convertFields(java.lang.String,java.util.List)#parquet/schema/Type/getName()
parquet/avro/AvroSchemaConverter/convertFields(java.lang.String,java.util.List)#java/lang/Object/Object()
parquet/avro/AvroSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String,parquet.schema.OriginalType)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/Type/asGroupType()
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#java/lang/Enum/equals(java.lang.Object)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/GroupType/getType(int)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/Type/isPrimitive()
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/GroupType/getFieldCount()
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/avro/AvroSchemaConverter/convertFields(java.lang.String,java.util.List)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/avro/AvroSchemaConverter/convertField(parquet/schema/Type)/$anonymous1/()
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/GroupType/getFields()
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/PrimitiveType/PrimitiveTypeName/convert(parquet.schema.PrimitiveType.PrimitiveTypeNameConverter)
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/Type/asPrimitiveType()
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/Type/getName()
parquet/avro/AvroSchemaConverter/convertField(parquet.schema.Type)#parquet/schema/Type/getOriginalType()
parquet/avro/AvroSchemaConverter/convert(parquet.schema.MessageType)#parquet/schema/GroupType/getFields()
parquet/avro/AvroSchemaConverter/convert(parquet.schema.MessageType)#parquet/schema/Type/getName()
parquet/avro/AvroSchemaConverter/convert(parquet.schema.MessageType)#parquet/avro/AvroSchemaConverter/convertFields(java.lang.String,java.util.List)
parquet/avro/AvroSchemaConverter/convertUnion(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/avro/AvroSchemaConverter/convertUnion(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/avro/AvroSchemaConverter/convertUnion(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#java/util/List/add(E)
parquet/avro/AvroSchemaConverter/convertUnion(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/avro/AvroSchemaConverter/convertField(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)
parquet/avro/AvroSchemaConverter/convertUnion(java.lang.String,parquet.pig.convert.Schema,parquet.schema.Type.Repetition)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,java.util.List)
parquet/io/RecordReaderImplementation/Case/toString()#parquet/io/RecordReaderImplementation/Case/getNextState()
parquet/io/RecordReaderImplementation/Case/equals(java.lang.Object)#parquet/io/RecordReaderImplementation/Case/equals(parquet.io.RecordReaderImplementation.Case)
parquet/thrift/ThriftSchemaConverter/convert(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/ThriftSchemaConverter/convert(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/ThriftSchemaConvertVisitor/ThriftSchemaConvertVisitor(parquet.thrift.projection.FieldProjectionFilter)
parquet/thrift/ThriftSchemaConverter/convert(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/ThriftSchemaConvertVisitor/getConvertedMessageType()
parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/ThriftStructConverter()
parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(java.lang.Class)
parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/ThriftStructConverter()
parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(java.lang.Class)
parquet/thrift/ThriftRecordConverter/FieldStringConverter/addBinary(parquet.io.api.Binary)#parquet/thrift/ThriftRecordConverter/FieldStringConverter/addBinary(parquet/io/api/Binary)/$anonymous1/(java.lang.String)
parquet/Log/error(java.lang.Object)#java/util/logging/Logger/warning(java.lang.String)
parquet/Log/error(java.lang.Object)#java/lang/String/valueOf(java.lang.Object)
parquet/Log/error(java.lang.Object)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Throwable)
parquet/Log/error(java.lang.Object,java.lang.Throwable)#java/lang/String/valueOf(java.lang.Object)
parquet/Log/error(java.lang.Object,java.lang.Throwable)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Throwable)
parquet/Log/warn(java.lang.Object,java.lang.Throwable)#java/lang/String/valueOf(java.lang.Object)
parquet/Log/warn(java.lang.Object,java.lang.Throwable)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Throwable)
parquet/Log/warn(java.lang.Object)#java/util/logging/Logger/warning(java.lang.String)
parquet/Log/warn(java.lang.Object)#java/lang/String/valueOf(java.lang.Object)
parquet/Log/warn(java.lang.Object)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Throwable)
parquet/Log/getLog(java.lang.Class)#parquet/Log/Log(java.lang.Class)
parquet/Log/debug(java.lang.Object,java.lang.Throwable)#java/lang/String/valueOf(java.lang.Object)
parquet/Log/debug(java.lang.Object,java.lang.Throwable)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Throwable)
parquet/Log/debug(java.lang.Object)#java/util/logging/Logger/fine(java.lang.String)
parquet/Log/debug(java.lang.Object)#java/lang/String/valueOf(java.lang.Object)
parquet/Log/debug(java.lang.Object)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Throwable)
parquet/Log/info(java.lang.Object)#java/lang/String/valueOf(java.lang.Object)
parquet/Log/info(java.lang.Object)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Throwable)
parquet/Log/info(java.lang.Object)#java/util/logging/Logger/info(java.lang.String)
parquet/Log/info(java.lang.Object,java.lang.Throwable)#java/lang/String/valueOf(java.lang.Object)
parquet/Log/info(java.lang.Object,java.lang.Throwable)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Throwable)
parquet/column/values/plain/BooleanPlainValuesWriter/reset()#parquet/column/values/bitpacking/ByteBitPackingValuesWriter/reset()
parquet/column/values/plain/BooleanPlainValuesWriter/getBufferedSize()#parquet/column/values/bitpacking/ByteBitPackingValuesWriter/getBufferedSize()
parquet/column/values/plain/BooleanPlainValuesWriter/getAllocatedSize()#parquet/column/values/bitpacking/ByteBitPackingValuesWriter/getAllocatedSize()
parquet/column/values/plain/BooleanPlainValuesWriter/memUsageString(java.lang.String)#parquet/column/values/bitpacking/ByteBitPackingValuesWriter/memUsageString(java.lang.String)
parquet/column/values/plain/BooleanPlainValuesWriter/getBytes()#parquet/column/values/bitpacking/ByteBitPackingValuesWriter/getBytes()
parquet/column/values/plain/BooleanPlainValuesWriter/writeBoolean(boolean)#parquet/column/values/bitpacking/ByteBitPackingValuesWriter/writeInteger(int)
parquet/pig/convert/TupleConverter/FieldLongConverter/addInt(int)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldLongConverter/addBinary(parquet.io.api.Binary)#java/lang/Long/parseLong(java.lang.String)
parquet/pig/convert/TupleConverter/FieldLongConverter/addBinary(parquet.io.api.Binary)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldLongConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/pig/convert/TupleConverter/FieldLongConverter/addFloat(float)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldLongConverter/addLong(long)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldLongConverter/addBoolean(boolean)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldLongConverter/addDouble(double)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#java/io/BufferedReader/close()
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#parquet/hadoop/thrift/ParquetThriftOutputFormat/setThriftClass(parquet.proto.utils.Job,java.lang.Class)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#java/io/File/File(java.lang.String,java.lang.String)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#java/lang/String/indexOf(java.lang.String)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#java/lang/String/substring(int)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#parquet/hadoop/ParquetOutputFormat/setCompression(parquet.proto.utils.Job,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#parquet/hadoop/thrift/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#java/io/BufferedReader/BufferedReader(java.io.Reader)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#parquet/hadoop/thrift/TestInputOutputFormat/nextAddressbook(int)
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#java/io/BufferedReader/readLine()
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#java/lang/Object/Object()
parquet/hadoop/thrift/TestInputOutputFormat/testReadWrite()#java/io/FileReader/FileReader(java.io.File)
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/io/BufferedReader/close()
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/io/PrintStream/println(java.lang.String)
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/io/File/File(java.lang.String)
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/lang/String/toString()
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/lang/String/indexOf(java.lang.String)
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/lang/String/substring(int)
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/io/FileReader/FileReader(java.io.File)
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/io/BufferedReader/BufferedReader(java.io.Reader)
parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)#java/io/BufferedReader/readLine()
parquet/hadoop/thrift/TestInputOutputFormat/nextAddressbook(int)#java/util/ArrayList/ArrayList()
parquet/hadoop/thrift/TestInputOutputFormat/nextAddressbook(int)#java/lang/Object/Object()
parquet/hadoop/thrift/TestInputOutputFormat/write(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.Path,java.lang.Class,java.lang.Class)#parquet/hadoop/thrift/ParquetThriftOutputFormat/setThriftClass(parquet.proto.utils.Job,java.lang.Class)
parquet/hadoop/thrift/TestInputOutputFormat/write(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.Path,java.lang.Class,java.lang.Class)#parquet/hadoop/ParquetOutputFormat/setCompression(parquet.proto.utils.Job,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/thrift/TestInputOutputFormat/write(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.Path,java.lang.Class,java.lang.Class)#parquet/hadoop/thrift/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)
parquet/hadoop/thrift/TestInputOutputFormat/write(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.Path,java.lang.Class,java.lang.Class)#java/lang/Object/Object()
parquet/hadoop/thrift/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#java/lang/Thread/sleep(long)
parquet/hadoop/thrift/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/thrift/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/thrift/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#parquet/Log/info(java.lang.Object)
parquet/hadoop/thrift/TestInputOutputFormat/testSchemaEvolution()#parquet/hadoop/thrift/TestInputOutputFormat/read(java.lang.String,int)
parquet/hadoop/thrift/TestInputOutputFormat/testSchemaEvolution()#parquet/hadoop/thrift/ParquetThriftInputFormat/setThriftClass(parquet.cascading.JobConf,java.lang.Class)
parquet/hadoop/thrift/TestInputOutputFormat/testSchemaEvolution()#parquet/hadoop/thrift/TestInputOutputFormat/write(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.Path,java.lang.Class,java.lang.Class)
parquet/hadoop/thrift/TestInputOutputFormat/testSchemaEvolution()#parquet/hadoop/thrift/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)
parquet/hadoop/thrift/TestInputOutputFormat/testSchemaEvolution()#java/lang/Object/Object()
parquet/thrift/ThriftRecordConverter/PrimitiveCounter/addInt(int)#parquet/io/api/PrimitiveConverter/addInt(int)
parquet/thrift/ThriftRecordConverter/PrimitiveCounter/addFloat(float)#parquet/io/api/PrimitiveConverter/addFloat(float)
parquet/thrift/ThriftRecordConverter/PrimitiveCounter/addBinary(parquet.io.api.Binary)#parquet/io/api/PrimitiveConverter/addBinary(parquet.io.api.Binary)
parquet/thrift/ThriftRecordConverter/PrimitiveCounter/addLong(long)#parquet/io/api/PrimitiveConverter/addLong(long)
parquet/thrift/ThriftRecordConverter/PrimitiveCounter/addBoolean(boolean)#parquet/io/api/PrimitiveConverter/addBoolean(boolean)
parquet/thrift/ThriftRecordConverter/PrimitiveCounter/addDouble(double)#parquet/io/api/PrimitiveConverter/addDouble(double)
parquet/format/converter/ParquetMetadataConverter/SkipMetadataFilter/accept(parquet.format.converter.ParquetMetadataConverter.MetadataFilterVisitor)#parquet/format/converter/ParquetMetadataConverter/MetadataFilterVisitor/visit(parquet.format.converter.ParquetMetadataConverter.SkipMetadataFilter)
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/Types/PrimitiveBuilder/scale(int)
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/Types/PrimitiveBuilder/precision(int)
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testDecimalFixedAnnotation()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testEachPrimitiveType()#parquet/schema/Types/MessageTypeBuilder/named(java.lang.String)
parquet/parser/TestParquetParser/testEachPrimitiveType()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/parser/TestParquetParser/testEachPrimitiveType()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testEachPrimitiveType()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testEachPrimitiveType()#java/lang/StringBuilder/StringBuilder()
parquet/parser/TestParquetParser/testEachPrimitiveType()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testEachPrimitiveType()#java/lang/StringBuilder/append(java.lang.Object)
parquet/parser/TestParquetParser/testEachPrimitiveType()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testEachPrimitiveType()#java/lang/StringBuilder/toString()
parquet/parser/TestParquetParser/testEachPrimitiveType()#java/lang/Enum/toString()
parquet/parser/TestParquetParser/testEachPrimitiveType()#parquet/schema/PrimitiveType/PrimitiveTypeName/values()
parquet/parser/TestParquetParser/testEachPrimitiveType()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testEachPrimitiveType()#java/lang/StringBuilder/append(java.lang.String)
parquet/parser/TestParquetParser/testPaperExample()#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type[])
parquet/parser/TestParquetParser/testPaperExample()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testPaperExample()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testPaperExample()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/parser/TestParquetParser/testPaperExample()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/parser/TestParquetParser/testUTF8Annotation()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testUTF8Annotation()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testUTF8Annotation()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testUTF8Annotation()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testUTF8Annotation()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testUTF8Annotation()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testMAPAnnotations()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testMAPAnnotations()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testMAPAnnotations()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testMAPAnnotations()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testMAPAnnotations()#parquet/schema/Types/GroupBuilder/optionalGroup()
parquet/parser/TestParquetParser/testMAPAnnotations()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testMAPAnnotations()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testMAPAnnotations()#parquet/schema/Types/GroupBuilder/repeatedGroup()
parquet/parser/TestParquetParser/testTimeAnnotations()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/parser/TestParquetParser/testTimeAnnotations()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testTimeAnnotations()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testTimeAnnotations()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testTimeAnnotations()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testTimeAnnotations()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testTimeAnnotations()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testIDs()#parquet/schema/Types/Builder/id(int)
parquet/parser/TestParquetParser/testIDs()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testIDs()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testIDs()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testIDs()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testIDs()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testIDs()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testLISTAnnotation()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testLISTAnnotation()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testLISTAnnotation()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testLISTAnnotation()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testLISTAnnotation()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testLISTAnnotation()#parquet/schema/Types/GroupBuilder/repeated(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testLISTAnnotation()#parquet/schema/Types/GroupBuilder/requiredGroup()
parquet/parser/TestParquetParser/testEmbeddedAnnotations()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testEmbeddedAnnotations()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testEmbeddedAnnotations()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testEmbeddedAnnotations()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testEmbeddedAnnotations()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testEmbeddedAnnotations()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testIntAnnotations()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testIntAnnotations()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testIntAnnotations()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testIntAnnotations()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testIntAnnotations()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testIntAnnotations()#parquet/schema/Types/buildMessage()
parquet/parser/TestParquetParser/testDecimalBinaryAnnotation()#parquet/schema/Types/PrimitiveBuilder/scale(int)
parquet/parser/TestParquetParser/testDecimalBinaryAnnotation()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/parser/TestParquetParser/testDecimalBinaryAnnotation()#parquet/schema/Type/toString()
parquet/parser/TestParquetParser/testDecimalBinaryAnnotation()#parquet/schema/Types/PrimitiveBuilder/precision(int)
parquet/parser/TestParquetParser/testDecimalBinaryAnnotation()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/parser/TestParquetParser/testDecimalBinaryAnnotation()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/parser/TestParquetParser/testDecimalBinaryAnnotation()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/parser/TestParquetParser/testDecimalBinaryAnnotation()#parquet/schema/Types/buildMessage()
parquet/io/ColumnIO/getParent(int)#parquet/io/ColumnIO/getParent(int)
parquet/io/ColumnIO/getParent(int)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/io/ColumnIO/getParent(int)#parquet/io/ColumnIO/getType()
parquet/io/ColumnIO/getParent(int)#parquet/io/ColumnIO/getParent()
parquet/io/ColumnIO/getParent(int)#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/ColumnIO/getParent(int)#parquet/io/ColumnIO/getRepetitionLevel()
parquet/io/ColumnIO/getParent(int)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/io/ColumnIO/getParent(int)#java/util/Arrays/toString(java.lang.Object[])
parquet/io/ColumnIO/getParent(int)#parquet/io/ColumnIO/getFieldPath()
parquet/io/ColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/setRepetitionLevel(int)
parquet/io/ColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/setDefinitionLevel(int)
parquet/io/ColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/setFieldPath(java.lang.String[],int[])
parquet/io/ColumnIO/toString()#java/lang/Class/getSimpleName()
parquet/io/ColumnIO/toString()#java/util/Arrays/toString(java.lang.Object[])
parquet/io/ColumnIO/toString()#java/lang/Object/getClass()
parquet/io/ColumnIO/toString()#parquet/schema/Type/getName()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftType/MapType/getValue()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftType/MapType/getKey()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/struct/ThriftType/ListType/getValues()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#java/lang/Enum/equals(java.lang.Object)
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/CompatibleCheckerVisitor/firstIsMoreRestirctive(parquet.thrift.struct.ThriftField.Requirement,parquet.thrift.struct.ThriftField.Requirement)
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/getType()
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getName()
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#java/lang/String/equals(java.lang.Object)
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getRequirement()
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/CompatibleCheckerVisitor/fail(java.lang.String)
parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/struct/ThriftType/SetType/getValues()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)
parquet/thrift/struct/CompatibleCheckerVisitor/fail(java.lang.String)#parquet/thrift/struct/CompatibilityReport/fail(java.lang.String)
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftField/getFieldId()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/getChildren()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftField/getName()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftField/getRequirement()
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/getChildById(short)
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/CompatibleCheckerVisitor/fail(java.lang.String)
parquet/thrift/struct/CompatibleCheckerVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/CompatibleCheckerVisitor/checkField(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)
parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()#java/lang/Math/min(long,long)
parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()#parquet/hadoop/InternalParquetRecordWriter/initStore()
parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()#parquet/column/impl/ColumnWriteStoreImpl/memSize()
parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()#java/lang/Math/max(long,long)
parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()#parquet/Log/debug(java.lang.Object)
parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()#parquet/Log/info(java.lang.Object)
parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()#parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()
parquet/hadoop/InternalParquetRecordWriter/initStore()#parquet/schema/MessageType/getColumns()
parquet/hadoop/InternalParquetRecordWriter/initStore()#java/lang/Math/max(int,int)
parquet/hadoop/InternalParquetRecordWriter/initStore()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/hadoop/InternalParquetRecordWriter/initStore()#java/util/List/size()
parquet/hadoop/InternalParquetRecordWriter/initStore()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/hadoop/InternalParquetRecordWriter/initStore()#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/hadoop/InternalParquetRecordWriter/initStore()#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/hadoop/InternalParquetRecordWriter/initStore()#parquet/hadoop/api/WriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)
parquet/hadoop/InternalParquetRecordWriter/initStore()#java/lang/Math/min(int,int)
parquet/hadoop/InternalParquetRecordWriter/initStore()#parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriteStore(parquet.hadoop.CodecFactory.BytesCompressor,parquet.schema.MessageType,int)
parquet/hadoop/InternalParquetRecordWriter/close()#parquet/hadoop/api/WriteSupport/finalizeWrite()
parquet/hadoop/InternalParquetRecordWriter/close()#java/util/HashMap/HashMap(java.util.Map)
parquet/hadoop/InternalParquetRecordWriter/close()#java/util/Map/putAll(java.util.Map)
parquet/hadoop/InternalParquetRecordWriter/close()#parquet/hadoop/ParquetFileWriter/end(java.util.Map)
parquet/hadoop/InternalParquetRecordWriter/close()#parquet/hadoop/api/WriteSupport/FinalizedWriteContext/getExtraMetaData()
parquet/hadoop/InternalParquetRecordWriter/close()#parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()
parquet/hadoop/InternalParquetRecordWriter/write(T)#parquet/hadoop/InternalParquetRecordWriter/checkBlockSizeReached()
parquet/hadoop/InternalParquetRecordWriter/write(T)#parquet/hadoop/api/WriteSupport/write(T)
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#parquet/hadoop/ParquetFileWriter/startBlock(long)
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#parquet/hadoop/ParquetFileWriter/endBlock()
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#parquet/Log/warn(java.lang.Object)
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#parquet/Log/info(java.lang.Object)
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#parquet/column/impl/ColumnWriteStoreImpl/allocatedSize()
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#parquet/hadoop/ColumnChunkPageWriteStore/flushToFileWriter(parquet.hadoop.ParquetFileWriter)
parquet/hadoop/InternalParquetRecordWriter/flushRowGroupToStore()#parquet/column/impl/ColumnWriteStoreImpl/memUsageString()
parquet/tools/util/PrettyPrintWriter/setTabLevel(int)#parquet/tools/util/PrettyPrintWriter/flushColumns()
parquet/tools/util/PrettyPrintWriter/print(java.lang.String)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/println(java.lang.String)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(java.lang.String)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String)
parquet/tools/util/PrettyPrintWriter/determineNumColumns()#parquet/tools/util/PrettyPrintWriter/Line/countCharacter(char)
parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String)#parquet/tools/util/PrettyPrintWriter/Span/Span(java.lang.String)
parquet/tools/util/PrettyPrintWriter/append(char)#parquet/tools/util/PrettyPrintWriter/print(char)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#java/lang/String/split(java.lang.String,int)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#java/lang/String/replaceAll(java.lang.String,java.lang.String)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/span(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/flushIfNeeded(boolean)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#java/lang/String/equals(java.lang.Object)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/appendToCurrent(java.lang.String)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#java/util/ArrayList/add(E)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/tabs()
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#java/lang/String/endsWith(java.lang.String)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/flushIfNeeded()
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/Line/Line()
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/resetColor()
parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)#java/lang/String/isEmpty()
parquet/tools/util/PrettyPrintWriter/println(float)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(float)#parquet/tools/util/PrettyPrintWriter/print(float)
parquet/tools/util/PrettyPrintWriter/span(java.lang.String)#parquet/tools/util/PrettyPrintWriter/span(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/rule(char)#parquet/tools/util/PrettyPrintWriter/println(java.lang.String)
parquet/tools/util/PrettyPrintWriter/rule(char)#java/lang/String/valueOf(char)
parquet/tools/util/PrettyPrintWriter/rule(char)#java/lang/String/length()
parquet/tools/util/PrettyPrintWriter/println()#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/println()#parquet/tools/util/PrettyPrintWriter/flushIfNeeded()
parquet/tools/util/PrettyPrintWriter/newPrettyPrinter(java.io.OutputStream)#parquet/tools/util/PrettyPrintWriter/Builder/Builder(java.io.OutputStream)
parquet/tools/util/PrettyPrintWriter/print(float)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/print(float)#java/lang/String/valueOf(float)
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/io/Writer/append(java.lang.CharSequence)
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/lang/AbstractStringBuilder/setLength(int)
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#parquet/tools/util/PrettyPrintWriter/Line/toString(java.lang.StringBuilder)
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/util/ArrayList/size()
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/util/ArrayList/add(E)
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/util/ArrayList/get(int)
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/io/Writer/flush()
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/lang/StringBuilder/toString()
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#parquet/tools/util/PrettyPrintWriter/determineColumnWidths()
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#parquet/tools/util/PrettyPrintWriter/Line/Line()
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/util/ArrayList/clear()
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#parquet/tools/util/PrettyPrintWriter/toColumns(int[],parquet.tools.util.PrettyPrintWriter.Line)
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#java/lang/StringBuilder/StringBuilder()
parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)#parquet/tools/util/PrettyPrintWriter/fixupLine(parquet.tools.util.PrettyPrintWriter.Line)
parquet/tools/util/PrettyPrintWriter/append(java.lang.CharSequence,int,int)#java/lang/CharSequence/toString()
parquet/tools/util/PrettyPrintWriter/append(java.lang.CharSequence,int,int)#java/lang/CharSequence/subSequence(int,int)
parquet/tools/util/PrettyPrintWriter/append(java.lang.CharSequence,int,int)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String)
parquet/tools/util/PrettyPrintWriter/span(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String)
parquet/tools/util/PrettyPrintWriter/span(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String,java.lang.String,java.lang.String,java.lang.String)
parquet/tools/util/PrettyPrintWriter/span(java.lang.String,boolean)#parquet/tools/util/PrettyPrintWriter/resetColor()
parquet/tools/util/PrettyPrintWriter/print(long)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/print(long)#java/lang/String/valueOf(long)
parquet/tools/util/PrettyPrintWriter/println(long)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(long)#parquet/tools/util/PrettyPrintWriter/print(long)
parquet/tools/util/PrettyPrintWriter/format(java.util.Locale,java.lang.String,java.lang.Object[])#parquet/tools/util/PrettyPrintWriter/printf(java.util.Locale,java.lang.String,java.lang.Object[])
parquet/tools/util/PrettyPrintWriter/print(char[])#java/lang/String/valueOf(char[])
parquet/tools/util/PrettyPrintWriter/print(char[])#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/determineColumnWidths()#parquet/tools/util/PrettyPrintWriter/determineNumColumns()
parquet/tools/util/PrettyPrintWriter/determineColumnWidths()#parquet/tools/util/PrettyPrintWriter/Line/firstNonWhiteSpace(int)
parquet/tools/util/PrettyPrintWriter/determineColumnWidths()#parquet/tools/util/PrettyPrintWriter/Line/indexOf(char,int)
parquet/tools/util/PrettyPrintWriter/determineColumnWidths()#parquet/tools/util/PrettyPrintWriter/Line/length()
parquet/tools/util/PrettyPrintWriter/flushIfNeeded()#parquet/tools/util/PrettyPrintWriter/flushIfNeeded(boolean)
parquet/tools/util/PrettyPrintWriter/printf(java.util.Locale,java.lang.String,java.lang.Object[])#java/util/Formatter/format(java.util.Locale,java.lang.String,java.lang.Object[])
parquet/tools/util/PrettyPrintWriter/printf(java.util.Locale,java.lang.String,java.lang.Object[])#parquet/tools/util/PrettyPrintWriter/flushIfNeeded()
parquet/tools/util/PrettyPrintWriter/printf(java.util.Locale,java.lang.String,java.lang.Object[])#java/lang/AbstractStringBuilder/setLength(int)
parquet/tools/util/PrettyPrintWriter/printf(java.util.Locale,java.lang.String,java.lang.Object[])#java/lang/StringBuilder/toString()
parquet/tools/util/PrettyPrintWriter/printf(java.util.Locale,java.lang.String,java.lang.Object[])#parquet/tools/util/PrettyPrintWriter/print(java.lang.String)
parquet/tools/util/PrettyPrintWriter/println(char[])#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(char[])#parquet/tools/util/PrettyPrintWriter/print(char[])
parquet/tools/util/PrettyPrintWriter/print(char)#java/lang/String/valueOf(char)
parquet/tools/util/PrettyPrintWriter/print(char)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/append(java.lang.CharSequence)#java/lang/CharSequence/length()
parquet/tools/util/PrettyPrintWriter/append(java.lang.CharSequence)#parquet/tools/util/PrettyPrintWriter/append(java.lang.CharSequence,int,int)
parquet/tools/util/PrettyPrintWriter/append(java.lang.CharSequence)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String)
parquet/tools/util/PrettyPrintWriter/stdoutPrettyPrinter()#parquet/tools/util/PrettyPrintWriter/Builder/Builder(java.io.OutputStream)
parquet/tools/util/PrettyPrintWriter/stdoutPrettyPrinter()#parquet/tools/util/PrettyPrintWriter/Builder/withAutoFlush()
parquet/tools/util/PrettyPrintWriter/println(char)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(char)#parquet/tools/util/PrettyPrintWriter/print(char)
parquet/tools/util/PrettyPrintWriter/println(int)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(int)#parquet/tools/util/PrettyPrintWriter/print(int)
parquet/tools/util/PrettyPrintWriter/print(java.lang.Object)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/print(java.lang.Object)#java/lang/String/valueOf(java.lang.Object)
parquet/tools/util/PrettyPrintWriter/toColumns(int[],parquet.tools.util.PrettyPrintWriter.Line)#parquet/tools/util/PrettyPrintWriter/Line/firstNonWhiteSpace(int)
parquet/tools/util/PrettyPrintWriter/toColumns(int[],parquet.tools.util.PrettyPrintWriter.Line)#parquet/tools/util/PrettyPrintWriter/Line/indexOf(char,int)
parquet/tools/util/PrettyPrintWriter/toColumns(int[],parquet.tools.util.PrettyPrintWriter.Line)#parquet/tools/util/PrettyPrintWriter/Line/spaceOut(int,int)
parquet/tools/util/PrettyPrintWriter/flushIfNeeded(boolean)#parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)
parquet/tools/util/PrettyPrintWriter/flushIfNeeded(boolean)#java/util/ArrayList/size()
parquet/tools/util/PrettyPrintWriter/printf(java.lang.String,java.lang.Object[])#parquet/tools/util/PrettyPrintWriter/printf(java.util.Locale,java.lang.String,java.lang.Object[])
parquet/tools/util/PrettyPrintWriter/printf(java.lang.String,java.lang.Object[])#java/util/Formatter/locale()
parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String,java.lang.String,java.lang.String,java.lang.String)#parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String)
parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String,java.lang.String,java.lang.String,java.lang.String)#parquet/tools/util/PrettyPrintWriter/Span/Span(java.lang.String,java.lang.String)
parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String,java.lang.String)#parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String,java.lang.String,java.lang.String,java.lang.String)
parquet/tools/util/PrettyPrintWriter/print(int)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/print(int)#java/lang/String/valueOf(int)
parquet/tools/util/PrettyPrintWriter/print(double)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/print(double)#java/lang/String/valueOf(double)
parquet/tools/util/PrettyPrintWriter/println(java.lang.Object)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(java.lang.Object)#parquet/tools/util/PrettyPrintWriter/print(java.lang.Object)
parquet/tools/util/PrettyPrintWriter/fixupLine(parquet.tools.util.PrettyPrintWriter.Line)#parquet/tools/util/PrettyPrintWriter/Line/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)
parquet/tools/util/PrettyPrintWriter/format(java.lang.String,java.lang.Object[])#parquet/tools/util/PrettyPrintWriter/printf(java.lang.String,java.lang.Object[])
parquet/tools/util/PrettyPrintWriter/println(double)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(double)#parquet/tools/util/PrettyPrintWriter/print(double)
parquet/tools/util/PrettyPrintWriter/incrementTabLevel()#parquet/tools/util/PrettyPrintWriter/setTabLevel(int)
parquet/tools/util/PrettyPrintWriter/appendToCurrent(java.lang.String)#parquet/tools/util/PrettyPrintWriter/span(java.lang.String)
parquet/tools/util/PrettyPrintWriter/appendToCurrent(java.lang.String)#parquet/tools/util/PrettyPrintWriter/Line/isEmpty()
parquet/tools/util/PrettyPrintWriter/appendToCurrent(java.lang.String)#parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)
parquet/tools/util/PrettyPrintWriter/appendToCurrent(java.lang.String)#java/util/ArrayList/size()
parquet/tools/util/PrettyPrintWriter/appendToCurrent(java.lang.String)#parquet/tools/util/PrettyPrintWriter/tabs()
parquet/tools/util/PrettyPrintWriter/appendToCurrent(java.lang.String)#java/util/ArrayList/get(int)
parquet/tools/util/PrettyPrintWriter/println(boolean)#parquet/tools/util/PrettyPrintWriter/println()
parquet/tools/util/PrettyPrintWriter/println(boolean)#parquet/tools/util/PrettyPrintWriter/print(boolean)
parquet/tools/util/PrettyPrintWriter/flushColumns()#parquet/tools/util/PrettyPrintWriter/flushColumns(boolean)
parquet/tools/util/PrettyPrintWriter/stderrPrettyPrinter()#parquet/tools/util/PrettyPrintWriter/Builder/Builder(java.io.OutputStream)
parquet/tools/util/PrettyPrintWriter/stderrPrettyPrinter()#parquet/tools/util/PrettyPrintWriter/Builder/withAutoFlush()
parquet/tools/util/PrettyPrintWriter/decrementTabLevel()#parquet/tools/util/PrettyPrintWriter/setTabLevel(int)
parquet/tools/util/PrettyPrintWriter/print(boolean)#parquet/tools/util/PrettyPrintWriter/print(java.lang.String,boolean)
parquet/tools/util/PrettyPrintWriter/print(boolean)#java/lang/String/valueOf(boolean)
parquet/tools/util/PrettyPrintWriter/tabs()#parquet/tools/util/PrettyPrintWriter/Span/Span(java.lang.String)
parquet/tools/util/PrettyPrintWriter/iff(boolean)#parquet/tools/util/PrettyPrintWriter/resetColor()
parquet/proto/ProtoMessageConverter/ProtoLongConverter/addLong(long)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroRecordMaterializer/getCurrentRecord()#parquet/avro/AvroIndexedRecordConverter/getCurrentRecord()
parquet/column/values/plain/PlainValuesReader/DoublePlainValuesReader/readDouble()#parquet/bytes/LittleEndianDataInputStream/readDouble()
parquet/column/values/plain/PlainValuesReader/DoublePlainValuesReader/readDouble()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesReader/DoublePlainValuesReader/skip()#parquet/bytes/LittleEndianDataInputStream/skipBytes(int)
parquet/column/values/plain/PlainValuesReader/DoublePlainValuesReader/skip()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapBegin(parquet.thrift.TMap)#parquet/io/ColumnIO/getType()
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapBegin(parquet.thrift.TMap)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapBegin(parquet.thrift.TMap)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapBegin(parquet.thrift.TMap)#parquet/schema/Type/getName()
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapBegin(parquet.thrift.TMap)#parquet/io/api/RecordConsumer/startGroup()
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapEnd()#parquet/io/ColumnIO/getType()
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapEnd()#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapEnd()#parquet/schema/Type/getName()
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapEnd()#parquet/io/api/RecordConsumer/endGroup()
parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/writeMapEnd()#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/pig/ParquetLoader/getInputFormat()#parquet/Log/debug(java.lang.Object)
parquet/pig/ParquetLoader/getInputFormat()#parquet/pig/ParquetLoader/getParquetInputFormat()
parquet/pig/ParquetLoader/getStatistics(java.lang.String,parquet.proto.utils.Job)#parquet/Log/warn(java.lang.Object,java.lang.Throwable)
parquet/pig/ParquetLoader/getStatistics(java.lang.String,parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/pig/ParquetLoader/getStatistics(java.lang.String,parquet.proto.utils.Job)#parquet/pig/ParquetLoader/getParquetInputFormat()
parquet/pig/ParquetLoader/getParquetInputFormat()#parquet/pig/ParquetLoader/checkSetLocationHasBeenCalled()
parquet/pig/ParquetLoader/getParquetInputFormat()#parquet/pig/ParquetLoader/UnregisteringParquetInputFormat/UnregisteringParquetInputFormat(java.lang.String)
parquet/pig/ParquetLoader/getParquetInputFormat()#java/lang/ref/SoftReference/SoftReference(T)
parquet/pig/ParquetLoader/getSchemaFromRequiredFieldList(parquet.pig.convert.Schema,java.util.List)#parquet/pig/ParquetLoader/getSchemaFromRequiredFieldList(parquet.pig.convert.Schema,java.util.List)
parquet/pig/ParquetLoader/pushProjection(parquet.pig.RequiredFieldList)#parquet/pig/PigSchemaConverter/serializeRequiredFieldList(parquet.pig.RequiredFieldList)
parquet/pig/ParquetLoader/pushProjection(parquet.pig.RequiredFieldList)#parquet/pig/ParquetLoader/storeInUDFContext(java.lang.String,java.lang.Object)
parquet/pig/ParquetLoader/pushProjection(parquet.pig.RequiredFieldList)#parquet/pig/ParquetLoader/getSchemaFromRequiredFieldList(parquet.pig.convert.Schema,java.util.List)
parquet/pig/ParquetLoader/pushProjection(parquet.pig.RequiredFieldList)#parquet/pig/PigSchemaConverter/pigSchemaToString(parquet.pig.convert.Schema)
parquet/pig/ParquetLoader/getPropertyFromUDFContext(java.lang.String)#java/lang/Object/getClass()
parquet/pig/ParquetLoader/isElephantBirdCompatible(parquet.proto.utils.Job)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/pig/ParquetLoader/getNext()#java/lang/Thread/interrupted()
parquet/pig/ParquetLoader/getNext()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/pig/ParquetLoader/getFeatures()#java/util/Arrays/asList(T[])
parquet/pig/ParquetLoader/getFromUDFContext(java.lang.String)#java/lang/Object/getClass()
parquet/pig/ParquetLoader/setPartitionFilter(parquet.pig.Expression)#parquet/Log/debug(java.lang.Object)
parquet/pig/ParquetLoader/checkSetLocationHasBeenCalled()#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#parquet/pig/ParquetLoader/getPropertyFromUDFContext(java.lang.String)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#java/lang/Boolean/parseBoolean(java.lang.String)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#parquet/pig/PigSchemaConverter/serializeRequiredFieldList(parquet.pig.RequiredFieldList)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#parquet/pig/PigSchemaConverter/deserializeRequiredFieldList(java.lang.String)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#parquet/pig/PigSchemaConverter/parsePigSchema(java.lang.String)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#parquet/pig/ParquetLoader/storeInUDFContext(java.lang.String,java.lang.Object)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#parquet/pig/ParquetLoader/initSchema(parquet.proto.utils.Job)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#parquet/pig/PigSchemaConverter/pigSchemaToString(parquet.pig.convert.Schema)
parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)#java/lang/Boolean/toString(boolean)
parquet/pig/ParquetLoader/getPartitionKeys(java.lang.String,parquet.proto.utils.Job)#parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)
parquet/pig/ParquetLoader/getPartitionKeys(java.lang.String,parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/pig/ParquetLoader/prepareToRead(parquet.cascading.RecordReader,parquet.pig.PigSplit)#parquet/Log/debug(java.lang.Object)
parquet/pig/ParquetLoader/convertToElephantBirdCompatibleSchema(parquet.pig.convert.Schema)#parquet/pig/ParquetLoader/convertToElephantBirdCompatibleSchema(parquet.pig.convert.Schema)
parquet/pig/ParquetLoader/setLocation(java.lang.String,parquet.proto.utils.Job)#parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)
parquet/pig/ParquetLoader/setLocation(java.lang.String,parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/pig/ParquetLoader/storeInUDFContext(java.lang.String,java.lang.Object)#java/util/Hashtable/put(K,V)
parquet/pig/ParquetLoader/storeInUDFContext(java.lang.String,java.lang.Object)#java/lang/Object/getClass()
parquet/pig/ParquetLoader/getSchema(java.lang.String,parquet.proto.utils.Job)#parquet/pig/ParquetLoader/setInput(java.lang.String,parquet.proto.utils.Job)
parquet/pig/ParquetLoader/getSchema(java.lang.String,parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/pig/ParquetLoader/getSchema(java.lang.String,parquet.proto.utils.Job)#java/lang/Object/Object()
parquet/pig/ParquetLoader/initSchema(parquet.proto.utils.Job)#parquet/pig/ParquetLoader/isElephantBirdCompatible(parquet.proto.utils.Job)
parquet/pig/ParquetLoader/initSchema(parquet.proto.utils.Job)#parquet/pig/ParquetLoader/convertToElephantBirdCompatibleSchema(parquet.pig.convert.Schema)
parquet/pig/ParquetLoader/initSchema(parquet.proto.utils.Job)#parquet/pig/ParquetLoader/getParquetInputFormat()
parquet/pig/ParquetLoader/initSchema(parquet.proto.utils.Job)#parquet/pig/TupleReadSupport/getPigSchemaFromMultipleFiles(parquet.schema.MessageType,java.util.Map)
parquet/pig/ParquetLoader/initSchema(parquet.proto.utils.Job)#parquet/hadoop/metadata/GlobalMetaData/getKeyValueMetaData()
parquet/pig/ParquetLoader/initSchema(parquet.proto.utils.Job)#parquet/hadoop/metadata/GlobalMetaData/getSchema()
parquet/column/statistics/LongStatistics/getMinBytes()#parquet/bytes/BytesUtils/longToBytes(long)
parquet/column/statistics/LongStatistics/toString()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/statistics/LongStatistics/toString()#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/LongStatistics/toString()#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/LongStatistics/setMinMax(long,long)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/LongStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/bytes/BytesUtils/bytesToLong(byte[])
parquet/column/statistics/LongStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/LongStatistics/updateStats(long)#parquet/column/statistics/LongStatistics/updateStats(long,long)
parquet/column/statistics/LongStatistics/updateStats(long)#parquet/column/statistics/LongStatistics/initializeStats(long,long)
parquet/column/statistics/LongStatistics/updateStats(long)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/LongStatistics/initializeStats(long,long)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/LongStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/LongStatistics/initializeStats(long,long)
parquet/column/statistics/LongStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/LongStatistics/getMin()
parquet/column/statistics/LongStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/LongStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/LongStatistics/getMax()
parquet/column/statistics/LongStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/LongStatistics/updateStats(long,long)
parquet/column/statistics/LongStatistics/getMaxBytes()#parquet/bytes/BytesUtils/longToBytes(long)
parquet/pig/TupleReadSupport/getRequiredFields(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/TupleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)
parquet/pig/TupleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/pig/TupleReadSupport/getRequiredFields(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/pig/TupleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getConfiguration()
parquet/pig/TupleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/pig/PigSchemaConverter/PigSchemaConverter(boolean)
parquet/pig/TupleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getFileSchema()
parquet/pig/TupleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/pig/TupleReadSupport/getPigSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/pig/TupleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType)
parquet/pig/TupleReadSupport/union(parquet.pig.convert.Schema,parquet.pig.convert.Schema)#java/util/ArrayList/ArrayList()
parquet/pig/TupleReadSupport/union(parquet.pig.convert.Schema,parquet.pig.convert.Schema)#parquet/pig/TupleReadSupport/union(parquet.pig.convert.Schema,parquet.pig.convert.Schema)
parquet/pig/TupleReadSupport/union(parquet.pig.convert.Schema,parquet.pig.convert.Schema)#java/lang/Object/Object()
parquet/pig/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/pig/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/pig/convert/TupleRecordMaterializer/TupleRecordMaterializer(parquet.schema.GroupType,parquet.pig.convert.Schema,boolean,boolean)
parquet/pig/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/pig/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/Log/info(java.lang.Object)
parquet/pig/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/pig/TupleReadSupport/getPigSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/pig/TupleReadSupport/getPigSchemaFromMultipleFiles(parquet.schema.MessageType,java.util.Map)#parquet/pig/PigMetaData/getPigSchemas(java.util.Map)
parquet/pig/TupleReadSupport/getPigSchemaFromMultipleFiles(parquet.schema.MessageType,java.util.Map)#parquet/pig/TupleReadSupport/union(parquet.pig.convert.Schema,parquet.pig.convert.Schema)
parquet/pig/TupleReadSupport/getPigSchemaFromMultipleFiles(parquet.schema.MessageType,java.util.Map)#parquet/pig/PigSchemaConverter/parsePigSchema(java.lang.String)
parquet/pig/TupleReadSupport/getPigSchemaFromMultipleFiles(parquet.schema.MessageType,java.util.Map)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/pig/TupleReadSupport/getPigSchemaFromMultipleFiles(parquet.schema.MessageType,java.util.Map)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TupleReadSupport/getPigSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/pig/PigSchemaConverter/parsePigSchema(java.lang.String)
parquet/pig/TupleReadSupport/getPigSchemaFromFile(parquet.schema.MessageType,java.util.Map)#parquet/pig/PigMetaData/getPigSchema()
parquet/pig/TupleReadSupport/getPigSchemaFromFile(parquet.schema.MessageType,java.util.Map)#parquet/pig/PigMetaData/fromMetaData(java.util.Map)
parquet/pig/TupleReadSupport/getPigSchemaFromFile(parquet.schema.MessageType,java.util.Map)#parquet/pig/PigSchemaConverter/parsePigSchema(java.lang.String)
parquet/pig/TupleReadSupport/getPigSchemaFromFile(parquet.schema.MessageType,java.util.Map)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TupleReadSupport/union(parquet.pig.convert.FieldSchema,parquet.pig.convert.FieldSchema)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String)
parquet/pig/TupleReadSupport/union(parquet.pig.convert.FieldSchema,parquet.pig.convert.FieldSchema)#parquet/schema/IncompatibleSchemaModificationException/IncompatibleSchemaModificationException(java.lang.String)
parquet/pig/TupleReadSupport/union(parquet.pig.convert.FieldSchema,parquet.pig.convert.FieldSchema)#parquet/pig/TupleReadSupport/union(parquet.pig.convert.Schema,parquet.pig.convert.Schema)
parquet/pig/TupleReadSupport/union(parquet.pig.convert.FieldSchema,parquet.pig.convert.FieldSchema)#java/lang/Object/Object()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/addValueInspector(parquet.common.schema.ColumnPath,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)#java/util/ArrayList/ArrayList()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/addValueInspector(parquet.common.schema.ColumnPath,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)#java/util/Map/get(java.lang.Object)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/addValueInspector(parquet.common.schema.ColumnPath,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)#java/util/List/add(E)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/addValueInspector(parquet.common.schema.ColumnPath,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)#java/util/Map/put(K,V)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/And/And(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.Not)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/build(parquet.filter2.predicate.FilterPredicate)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/build(parquet.filter2.predicate.FilterPredicate)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/Or/Or(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/pig/summary/SummaryData/toPrettyJSON(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData,parquet.thrift.struct.ObjectMapper)
parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData,parquet.thrift.struct.ObjectMapper)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData,parquet.thrift.struct.ObjectMapper)#java/io/StringWriter/StringWriter()
parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData,parquet.thrift.struct.ObjectMapper)#java/io/StringWriter/toString()
parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData,parquet.thrift.struct.ObjectMapper)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/summary/SummaryData/getField(parquet.pig.convert.Schema,int)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/summary/SummaryData/toString()#parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData)
parquet/pig/summary/SummaryData/fromJSON(java.lang.String,java.lang.Class)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/pig/summary/SummaryData/fromJSON(java.lang.String,java.lang.Class)#java/io/StringReader/StringReader(java.lang.String)
parquet/pig/summary/SummaryData/fromJSON(java.lang.String,java.lang.Class)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData,parquet.thrift.struct.ObjectMapper)
parquet/pig/summary/SummaryData/merge(T,T)#parquet/pig/summary/SummaryData/merge(parquet.pig.summary.SummaryData)
parquet/proto/ProtoWriteSupport/EnumWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/proto/ProtoWriteSupport/EnumWriter/writeRawValue(java.lang.Object)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder/testSlabBoundary()#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/writeInt(int)
parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder/testSlabBoundary()#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder/testSlabBoundary()#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/ByteBasedBitPackingEncoder(int,parquet.column.values.bitpacking.Packer)
parquet/scrooge/ParquetScroogeSchemeTest/thriftRecords(parquet.scrooge.TBase[])#java/util/ArrayList/ArrayList()
parquet/scrooge/ParquetScroogeSchemeTest/testNestedReadingInScrooge()#parquet/scrooge/ParquetScroogeSchemeTest/thriftRecords(parquet.scrooge.TBase[])
parquet/scrooge/ParquetScroogeSchemeTest/testNestedReadingInScrooge()#java/util/HashMap/HashMap()
parquet/scrooge/ParquetScroogeSchemeTest/testNestedReadingInScrooge()#java/lang/Object/Object()
parquet/scrooge/ParquetScroogeSchemeTest/testNestedReadingInScrooge()#parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#parquet/scrooge/ParquetScroogeSchemeTest/deleteIfExist(java.lang.String)
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#parquet/scrooge/ParquetScroogeSchemeTest/writeParquetFile(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#parquet/scrooge/ParquetScroogeSchemeTest/ObjectToStringFunction/ObjectToStringFunction()
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#java/io/File/File(java.lang.String)
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#parquet/cascading/ParquetValueScheme/Config/withProjectionString(java.lang.String)
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#parquet/scrooge/ParquetScroogeScheme/ParquetScroogeScheme(parquet.cascading.ParquetValueScheme.Config)
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#parquet/cascading/ParquetValueScheme/Config/Config()
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#java/lang/Object/Object()
parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)#parquet/cascading/ParquetValueScheme/Config/withRecordClass(java.lang.Class)
parquet/scrooge/ParquetScroogeSchemeTest/testWritePrimitveThriftReadScrooge()#parquet/scrooge/ParquetScroogeSchemeTest/thriftRecords(parquet.scrooge.TBase[])
parquet/scrooge/ParquetScroogeSchemeTest/testWritePrimitveThriftReadScrooge()#parquet/scrooge/ParquetScroogeSchemeTest/verifyScroogeRead(java.util.List,java.lang.Class,java.lang.String,java.lang.String)
parquet/scrooge/ParquetScroogeSchemeTest/writeParquetFile(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/scrooge/ParquetScroogeSchemeTest/writeParquetFile(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#java/io/ByteArrayOutputStream/toByteArray()
parquet/scrooge/ParquetScroogeSchemeTest/writeParquetFile(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#parquet/hadoop/thrift/ThriftToParquetFileWriter/ThriftToParquetFileWriter(parquet.hadoop.Path,parquet.pig.TaskAttemptContext,parquet.hadoop.thrift.TProtocolFactory,java.lang.Class)
parquet/scrooge/ParquetScroogeSchemeTest/writeParquetFile(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/scrooge/ParquetScroogeSchemeTest/writeParquetFile(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#parquet/hadoop/thrift/ThriftToParquetFileWriter/write(parquet.hadoop.thrift.BytesWritable)
parquet/scrooge/ParquetScroogeSchemeTest/writeParquetFile(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)#parquet/hadoop/thrift/ThriftToParquetFileWriter/close()
parquet/proto/ProtoWriteSupport/BinaryWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/proto/ProtoWriteSupport/BinaryWriter/writeRawValue(java.lang.Object)#parquet/io/api/Binary/fromByteArray(byte[])
parquet/cascading/convert/TupleConverter/newConverter(parquet.schema.Type,int)#parquet/cascading/convert/TupleConverter/TuplePrimitiveConverter/TuplePrimitiveConverter(parquet.cascading.convert.TupleConverter,int)
parquet/cascading/convert/TupleConverter/newConverter(parquet.schema.Type,int)#parquet/schema/Type/isPrimitive()
parquet/cascading/convert/TupleConverter/newConverter(parquet.schema.Type,int)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/io/GroupColumnIO/getChild(int)#java/util/List/get(int)
parquet/io/GroupColumnIO/getChild(int)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String,java.lang.Throwable)
parquet/io/GroupColumnIO/getColumnNames()#java/util/ArrayList/ArrayList()
parquet/io/GroupColumnIO/getColumnNames()#java/util/ArrayList/addAll(java.util.Collection)
parquet/io/GroupColumnIO/getColumnNames()#parquet/io/ColumnIO/getColumnNames()
parquet/io/GroupColumnIO/getChild(java.lang.String)#java/util/Map/get(java.lang.Object)
parquet/io/GroupColumnIO/add(parquet.io.ColumnIO)#parquet/io/ColumnIO/getType()
parquet/io/GroupColumnIO/add(parquet.io.ColumnIO)#java/util/List/add(E)
parquet/io/GroupColumnIO/add(parquet.io.ColumnIO)#java/util/Map/put(K,V)
parquet/io/GroupColumnIO/add(parquet.io.ColumnIO)#parquet/schema/Type/getName()
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/getType()
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#java/util/Arrays/copyOf(T[],int)
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#java/util/Arrays/copyOf(int[],int)
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#java/util/List/add(E)
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/schema/Type/getName()
parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/getIndex()
parquet/io/GroupColumnIO/getLast()#parquet/io/ColumnIO/getLast()
parquet/io/GroupColumnIO/getLast()#java/util/List/size()
parquet/io/GroupColumnIO/getLast()#java/util/List/get(int)
parquet/io/GroupColumnIO/getFirst()#java/util/List/get(int)
parquet/io/GroupColumnIO/getFirst()#parquet/io/ColumnIO/getFirst()
parquet/pig/summary/TupleSummaryData/ensureSize(int)#parquet/pig/summary/FieldSummaryData/FieldSummaryData()
parquet/pig/summary/TupleSummaryData/ensureSize(int)#java/util/List/size()
parquet/pig/summary/TupleSummaryData/ensureSize(int)#java/util/List/add(E)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/SummaryData/add(java.lang.Object)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/SummaryData/getName(parquet.pig.convert.FieldSchema)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/SummaryData/getField(parquet.pig.convert.Schema,int)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/FieldSummaryData/setName(java.lang.String)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/SummaryData/getSchema(parquet.pig.convert.FieldSchema)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/logging/Logger/log(java.util.logging.Level,java.lang.String,java.lang.Object)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/FieldSummaryData/addError()
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/List/get(int)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/TupleSummaryData/ensureSize(int)
parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/summary/ValueStat/add(double)
parquet/pig/summary/TupleSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(parquet.pig.summary.SummaryData)
parquet/pig/summary/TupleSummaryData/merge(parquet.pig.summary.SummaryData)#java/util/List/size()
parquet/pig/summary/TupleSummaryData/merge(parquet.pig.summary.SummaryData)#java/util/List/get(int)
parquet/pig/summary/TupleSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/ValueStat/merge(parquet.pig.summary.ValueStat)
parquet/pig/summary/TupleSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/FieldSummaryData/merge(parquet.pig.summary.SummaryData)
parquet/pig/summary/TupleSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/TupleSummaryData/ensureSize(int)
parquet/schema/DecimalMetadata/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/hadoop/metadata/BlockMetaData/addColumn(parquet.hadoop.metadata.ColumnChunkMetaData)#java/util/List/add(E)
parquet/hadoop/metadata/BlockMetaData/getColumns()#java/util/Collections/unmodifiableList(java.util.List)
parquet/hadoop/metadata/BlockMetaData/getCompressedSize()#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalSize()
parquet/hadoop/metadata/BlockMetaData/getCompressedSize()#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/hadoop/metadata/BlockMetaData/getStartingPos()#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/hadoop/metadata/BlockMetaData/getStartingPos()#parquet/hadoop/metadata/ColumnChunkMetaData/getStartingPos()
parquet/hadoop/metadata/BlockMetaData/getStartingPos()#java/util/List/get(int)
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/ArrayList/ArrayList()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/schema/Type/toString()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/Footer/getFile()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/List/size()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/List/addAll(java.util.Collection)
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/List/isEmpty()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/Footer/getParquetMetadata()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/Log/info(java.lang.Object)
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/ParquetInputFormat/getFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getReadSupportMetadata()
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplits(java.util.List,parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)
parquet/hadoop/ClientSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/filter2/compat/RowGroupFilter/filterRowGroups(parquet.filter2.compat.FilterCompat.Filter,java.util.List,parquet.schema.MessageType)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#java/util/ArrayList/ArrayList()
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/addRowGroup(parquet.hadoop.metadata.BlockMetaData)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/HDFSBlocks/getCurrentBlock()
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getCompressedByteSize()
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#java/util/List/add(E)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#java/util/List/get(int)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/checkSorted(java.util.List)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/SplitInfo(parquet.hadoop.BlockLocation)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/HDFSBlocks/checkBelongingToANewHDFSBlock(parquet.hadoop.metadata.BlockMetaData)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getRowGroupCount()
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/HDFSBlocks/HDFSBlocks(parquet.hadoop.BlockLocation[])
parquet/hadoop/ClientSideMetadataSplitStrategy/checkSorted(java.util.List)#parquet/hadoop/metadata/BlockMetaData/getStartingPos()
parquet/hadoop/ClientSideMetadataSplitStrategy/checkSorted(java.util.List)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplits(java.util.List,parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#java/util/ArrayList/ArrayList()
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplits(java.util.List,parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/SplitInfo/getParquetInputSplit(parquet.hadoop.FileStatus,java.lang.String,java.util.Map)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplits(java.util.List,parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#java/util/List/add(E)
parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplits(java.util.List,parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplitInfo(java.util.List,parquet.hadoop.BlockLocation[],long,long)
parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)#parquet/pig/summary/SummaryData/add(java.lang.Object)
parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)#parquet/pig/summary/SummaryData/getName(parquet.pig.convert.FieldSchema)
parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)#parquet/pig/summary/SummaryData/getField(parquet.pig.convert.Schema,int)
parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)#parquet/pig/summary/FieldSummaryData/FieldSummaryData()
parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)#parquet/pig/summary/FieldSummaryData/setName(java.lang.String)
parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)#parquet/pig/summary/SummaryData/getSchema(parquet.pig.convert.FieldSchema)
parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)#parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)
parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)#parquet/pig/summary/ValueStat/add(double)
parquet/pig/summary/BagSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(parquet.pig.summary.SummaryData)
parquet/pig/summary/BagSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(T,T)
parquet/pig/summary/BagSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/ValueStat/merge(parquet.pig.summary.ValueStat)
parquet/hive/TestHiveBindingFactory/testBlankHiveVersion()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/hive/TestHiveBindingFactory/testHive011()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/hive/TestHiveBindingFactory/testHive013()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/hive/TestHiveBindingFactory/testNoHiveVersion()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/hive/TestHiveBindingFactory/setup()#parquet/hive/HiveBindingFactory/HiveBindingFactory()
parquet/hive/TestHiveBindingFactory/testHive010()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/hive/TestHiveBindingFactory/testNullHiveVersion()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/hive/TestHiveBindingFactory/testHive012()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/hive/TestHiveBindingFactory/testMissingHiveVersionInfoClass()#parquet/hive/TestHiveBindingFactory/NoopClassLoader/NoopClassLoader()
parquet/hive/TestHiveBindingFactory/testMissingHiveVersionInfoClass()#parquet/hive/HiveBindingFactory/create(java.lang.ClassLoader)
parquet/hive/TestHiveBindingFactory/testUnknownHiveVersion()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/hive/TestHiveBindingFactory/testHive010WithSpaces()#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/filter2/predicate/Operators/Not/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.Not)
parquet/filter2/predicate/Operators/Not/hashCode()#java/lang/Object/hashCode()
parquet/filter2/predicate/Operators/Not/hashCode()#java/lang/Object/getClass()
parquet/filter2/predicate/Operators/Not/equals(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
parquet/filter2/predicate/Operators/Not/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/example/data/simple/FloatValue/toString()#java/lang/String/valueOf(float)
parquet/example/data/simple/FloatValue/writeValue(parquet.io.api.RecordConsumer)#parquet/io/api/RecordConsumer/addFloat(float)
parquet/column/values/bitpacking/SixBitPackingWriter/write(int)#java/io/OutputStream/write(int)
parquet/column/values/bitpacking/SixBitPackingWriter/finish()#parquet/column/values/bitpacking/BaseBitPackingWriter/finish(int,int,java.io.OutputStream)
parquet/column/values/plain/PlainValuesWriter/getBufferedSize()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/plain/PlainValuesWriter/writeFloat(float)#parquet/bytes/LittleEndianDataOutputStream/writeFloat(float)
parquet/column/values/plain/PlainValuesWriter/writeFloat(float)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesWriter/getAllocatedSize()#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/column/values/plain/PlainValuesWriter/getBytes()#parquet/bytes/LittleEndianDataOutputStream/flush()
parquet/column/values/plain/PlainValuesWriter/getBytes()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/plain/PlainValuesWriter/getBytes()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/column/values/plain/PlainValuesWriter/getBytes()#parquet/Log/debug(java.lang.Object)
parquet/column/values/plain/PlainValuesWriter/getBytes()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesWriter/memUsageString(java.lang.String)#parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)
parquet/column/values/plain/PlainValuesWriter/writeByte(int)#parquet/bytes/LittleEndianDataOutputStream/write(int)
parquet/column/values/plain/PlainValuesWriter/writeByte(int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesWriter/writeInteger(int)#parquet/bytes/LittleEndianDataOutputStream/writeInt(int)
parquet/column/values/plain/PlainValuesWriter/writeInteger(int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesWriter/reset()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/column/values/plain/PlainValuesWriter/writeDouble(double)#parquet/bytes/LittleEndianDataOutputStream/writeDouble(double)
parquet/column/values/plain/PlainValuesWriter/writeDouble(double)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesWriter/writeLong(long)#parquet/bytes/LittleEndianDataOutputStream/writeLong(long)
parquet/column/values/plain/PlainValuesWriter/writeLong(long)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/length()
parquet/column/values/plain/PlainValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/writeTo(java.io.OutputStream)
parquet/column/values/plain/PlainValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/bytes/LittleEndianDataOutputStream/writeInt(int)
parquet/column/values/plain/PlainValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/schema/MessageTypeParser/parse(java.lang.String)#parquet/schema/MessageTypeParser/addGroupTypeFields(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)
parquet/schema/MessageTypeParser/parse(java.lang.String)#parquet/schema/Types/MessageTypeBuilder/named(java.lang.String)
parquet/schema/MessageTypeParser/parse(java.lang.String)#parquet/schema/MessageTypeParser/Tokenizer/nextToken()
parquet/schema/MessageTypeParser/parse(java.lang.String)#parquet/schema/MessageTypeParser/check(java.lang.String,java.lang.String,java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)
parquet/schema/MessageTypeParser/parse(java.lang.String)#parquet/schema/MessageTypeParser/Tokenizer/Tokenizer(java.lang.String,java.lang.String)
parquet/schema/MessageTypeParser/parse(java.lang.String)#parquet/schema/Types/buildMessage()
parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)#parquet/schema/MessageTypeParser/parse(java.lang.String)
parquet/schema/MessageTypeParser/asRepetition(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#parquet/schema/Type/Repetition/valueOf(java.lang.String)
parquet/schema/MessageTypeParser/asRepetition(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#java/lang/String/toUpperCase()
parquet/schema/MessageTypeParser/asRepetition(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#java/util/Arrays/toString(java.lang.Object[])
parquet/schema/MessageTypeParser/asRepetition(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/schema/MessageTypeParser/asRepetition(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#parquet/schema/Type/Repetition/values()
parquet/schema/MessageTypeParser/asRepetition(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#parquet/schema/MessageTypeParser/Tokenizer/getLocationString()
parquet/schema/MessageTypeParser/check(java.lang.String,java.lang.String,java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#java/lang/String/equalsIgnoreCase(java.lang.String)
parquet/schema/MessageTypeParser/check(java.lang.String,java.lang.String,java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/schema/MessageTypeParser/check(java.lang.String,java.lang.String,java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#parquet/schema/MessageTypeParser/Tokenizer/getLocationString()
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/String/equalsIgnoreCase(java.lang.String)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/Tokenizer/nextToken()
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/check(java.lang.String,java.lang.String,java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/OriginalType/valueOf(java.lang.String)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/PrimitiveBuilder/precision(int)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/String/equals(java.lang.Object)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/Integer/parseInt(java.lang.String)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/GroupBuilder/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/PrimitiveBuilder/scale(int)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/Builder/id(int)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/schema/MessageTypeParser/asPrimitive(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#parquet/schema/PrimitiveType/PrimitiveTypeName/values()
parquet/schema/MessageTypeParser/asPrimitive(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#java/lang/String/toUpperCase()
parquet/schema/MessageTypeParser/asPrimitive(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#java/util/Arrays/toString(java.lang.Object[])
parquet/schema/MessageTypeParser/asPrimitive(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#parquet/schema/MessageTypeParser/Tokenizer/getLocationString()
parquet/schema/MessageTypeParser/asPrimitive(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#parquet/schema/PrimitiveType/PrimitiveTypeName/valueOf(java.lang.String)
parquet/schema/MessageTypeParser/asPrimitive(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/Builder/id(int)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/Tokenizer/nextToken()
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/check(java.lang.String,java.lang.String,java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/OriginalType/valueOf(java.lang.String)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/String/equals(java.lang.Object)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/Integer/parseInt(java.lang.String)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/GroupBuilder/group(parquet.schema.Type.Repetition)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/addGroupTypeFields(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)
parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)#java/lang/String/equalsIgnoreCase(java.lang.String)
parquet/schema/MessageTypeParser/addType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#java/lang/String/equalsIgnoreCase(java.lang.String)
parquet/schema/MessageTypeParser/addType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/Tokenizer/nextToken()
parquet/schema/MessageTypeParser/addType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/asRepetition(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)
parquet/schema/MessageTypeParser/addType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/addPrimitiveType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)
parquet/schema/MessageTypeParser/addType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/asPrimitive(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)
parquet/schema/MessageTypeParser/addType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/addGroupType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Type.Repetition,parquet.schema.Types.GroupBuilder)
parquet/schema/MessageTypeParser/addGroupTypeFields(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/Tokenizer/nextToken()
parquet/schema/MessageTypeParser/addGroupTypeFields(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/check(java.lang.String,java.lang.String,java.lang.String,parquet.schema.MessageTypeParser.Tokenizer)
parquet/schema/MessageTypeParser/addGroupTypeFields(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#java/lang/String/equals(java.lang.Object)
parquet/schema/MessageTypeParser/addGroupTypeFields(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)#parquet/schema/MessageTypeParser/addType(java.lang.String,parquet.schema.MessageTypeParser.Tokenizer,parquet.schema.Types.GroupBuilder)
parquet/pig/PigSchemaConverter/convert(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/PigSchemaConverter/name(java.lang.String,java.lang.String)
parquet/pig/PigSchemaConverter/convert(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)
parquet/pig/PigSchemaConverter/convertFields(java.util.List)#java/util/ArrayList/ArrayList()
parquet/pig/PigSchemaConverter/convertFields(java.util.List)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/convertFields(java.util.List)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/pig/PigSchemaConverter/convertFields(java.util.List)#java/util/Arrays/asList(T[])
parquet/pig/PigSchemaConverter/convertFields(java.util.List)#parquet/pig/PigSchemaConverter/getFieldSchema(parquet.schema.Type)
parquet/pig/PigSchemaConverter/convertFields(java.util.List)#java/lang/Object/Object()
parquet/pig/PigSchemaConverter/getSimpleFieldSchema(java.lang.String,parquet.schema.Type)#parquet/pig/PigSchemaConverter/getSimpleFieldSchema(java/lang/String,parquet/schema/Type)/$anonymous1/()
parquet/pig/PigSchemaConverter/getSimpleFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/pig/PigSchemaConverter/getSimpleFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/Type/getOriginalType()
parquet/pig/PigSchemaConverter/getSimpleFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/PrimitiveType/PrimitiveTypeName/convert(parquet.schema.PrimitiveType.PrimitiveTypeNameConverter)
parquet/pig/PigSchemaConverter/getSimpleFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/Type/asPrimitiveType()
parquet/pig/PigSchemaConverter/convertTypes(parquet.pig.convert.Schema)#parquet/pig/PigSchemaConverter/convert(parquet.pig.convert.FieldSchema,int)
parquet/pig/PigSchemaConverter/serializeRequiredFieldList(parquet.pig.RequiredFieldList)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/convert(parquet.pig.convert.FieldSchema,int)#parquet/pig/PigSchemaConverter/convert(parquet.pig.convert.FieldSchema,java.lang.String)
parquet/pig/PigSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String,parquet.schema.OriginalType)
parquet/pig/PigSchemaConverter/filterTuple(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/GroupType/withNewFields(java.util.List)
parquet/pig/PigSchemaConverter/filterTuple(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/Log/debug(java.lang.Object)
parquet/pig/PigSchemaConverter/filterTuple(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/ColumnAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)
parquet/pig/PigSchemaConverter/convertMap(java.lang.String,parquet.pig.convert.FieldSchema)#parquet/schema/ConversionPatterns/stringKeyMapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type)
parquet/pig/PigSchemaConverter/convertMap(java.lang.String,parquet.pig.convert.FieldSchema)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/convertMap(java.lang.String,parquet.pig.convert.FieldSchema)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String)
parquet/pig/PigSchemaConverter/convertMap(java.lang.String,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/name(java.lang.String,java.lang.String)
parquet/pig/PigSchemaConverter/convertMap(java.lang.String,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)
parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/GroupType/withNewFields(java.util.List)
parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/Type/isPrimitive()
parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/Type/getOriginalType()
parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/GroupType/getFieldCount()
parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/GroupType/getType(int)
parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/Log/debug(java.lang.Object)
parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/schema/MessageType/MessageType(java.lang.String,java.util.List)
parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/Log/debug(java.lang.Object)
parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/schema/Type/getName()
parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/pig/PigSchemaConverter/ColumnAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)
parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)#parquet/schema/Type/asGroupType()
parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)#parquet/Log/debug(java.lang.Object)
parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/filterTuple(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/filterBag(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/PigSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/PigSchemaConverter/convertMap(java.lang.String,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String)
parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/PigSchemaConverter/convertBag(java.lang.String,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/PigSchemaConverter/convertTuple(java.lang.String,parquet.pig.convert.FieldSchema,parquet.schema.Type.Repetition)
parquet/pig/PigSchemaConverter/convertWithName(parquet.pig.convert.FieldSchema,java.lang.String)#parquet/pig/PigSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/GroupType/getFields()
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/Type/asGroupType()
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#java/lang/Enum/equals(java.lang.Object)
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String)
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/pig/PigSchemaConverter/convertFields(java.util.List)
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/pig/PigSchemaConverter/convertField(parquet.schema.Type)
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/GroupType/getType(int)
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/Type/isPrimitive()
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/GroupType/getFieldCount()
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#java/lang/Object/Object()
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/Type/getName()
parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)#parquet/schema/Type/getOriginalType()
parquet/pig/PigSchemaConverter/deserializeRequiredFieldList(java.lang.String)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/convertField(parquet.schema.Type)#parquet/pig/PigSchemaConverter/convertFields(java.util.List)
parquet/pig/PigSchemaConverter/convertField(parquet.schema.Type)#java/util/Arrays/asList(T[])
parquet/pig/PigSchemaConverter/convertBag(java.lang.String,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/convertTuple(java.lang.String,parquet.pig.convert.FieldSchema,parquet.schema.Type.Repetition)
parquet/pig/PigSchemaConverter/convertBag(java.lang.String,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/name(java.lang.String,java.lang.String)
parquet/pig/PigSchemaConverter/convertBag(java.lang.String,parquet.pig.convert.FieldSchema)#parquet/schema/ConversionPatterns/listType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type)
parquet/pig/PigSchemaConverter/convertTuple(java.lang.String,parquet.pig.convert.FieldSchema,parquet.schema.Type.Repetition)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,java.util.List)
parquet/pig/PigSchemaConverter/convertTuple(java.lang.String,parquet.pig.convert.FieldSchema,parquet.schema.Type.Repetition)#parquet/pig/PigSchemaConverter/convertTypes(parquet.pig.convert.Schema)
parquet/pig/PigSchemaConverter/primitive(java.lang.String,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String,parquet.schema.OriginalType)
parquet/pig/PigSchemaConverter/parsePigSchema(java.lang.String)#parquet/pig/SchemaConversionException/SchemaConversionException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/convert(parquet.pig.convert.Schema)#parquet/pig/PigSchemaConverter/convertTypes(parquet.pig.convert.Schema)
parquet/pig/PigSchemaConverter/convert(parquet.pig.convert.Schema)#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/pig/PigSchemaConverter/getFieldSchema(parquet.schema.Type)#parquet/pig/PigSchemaConverter/getSimpleFieldSchema(java.lang.String,parquet.schema.Type)
parquet/pig/PigSchemaConverter/getFieldSchema(parquet.schema.Type)#parquet/pig/PigSchemaConverter/getComplexFieldSchema(java.lang.String,parquet.schema.Type)
parquet/pig/PigSchemaConverter/getFieldSchema(parquet.schema.Type)#parquet/schema/Type/isPrimitive()
parquet/pig/PigSchemaConverter/getFieldSchema(parquet.schema.Type)#parquet/schema/Type/getName()
parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema)#parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)
parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/Type/asGroupType()
parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/GroupType/withNewFields(java.util.List)
parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/GroupType/withNewFields(parquet.schema.Type[])
parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/GroupType/getFieldCount()
parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/schema/GroupType/getType(int)
parquet/pig/PigSchemaConverter/filterMap(parquet.schema.GroupType,parquet.pig.convert.FieldSchema)#parquet/Log/debug(java.lang.Object)
parquet/pig/PigSchemaConverter/pigSchemaToString(parquet.pig.convert.Schema)#java/lang/String/length()
parquet/pig/PigSchemaConverter/pigSchemaToString(parquet.pig.convert.Schema)#java/lang/String/substring(int,int)
parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)#parquet/schema/GroupType/getFields()
parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)#parquet/pig/PigSchemaConverter/convertFields(java.util.List)
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/schema/Type/asGroupType()
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/endGroup()
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/example/data/Group/writeValue(int,int,parquet.io.api.RecordConsumer)
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/schema/Type/isPrimitive()
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/example/data/Group/getGroup(int,int)
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/schema/Type/getName()
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/example/data/GroupValueSource/getFieldRepetitionCount(int)
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/schema/GroupType/getType(int)
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/schema/GroupType/getFieldCount()
parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)#parquet/io/api/RecordConsumer/startGroup()
parquet/example/data/GroupWriter/write(parquet.example.data.Group)#parquet/io/api/RecordConsumer/startMessage()
parquet/example/data/GroupWriter/write(parquet.example.data.Group)#parquet/io/api/RecordConsumer/endMessage()
parquet/example/data/GroupWriter/write(parquet.example.data.Group)#parquet/example/data/GroupWriter/writeGroup(parquet.example.data.Group,parquet.schema.GroupType)
parquet/column/page/mem/MemPageReader/readPage()#java/util/Iterator/hasNext()
parquet/column/page/mem/MemPageReader/readPage()#java/util/Iterator/next()
parquet/column/page/mem/MemPageReader/readPage()#parquet/Log/debug(java.lang.Object)
parquet/column/page/mem/MemPageReader/readPage()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/reset()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/reset()
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/reset()#java/io/ByteArrayOutputStream/reset()
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBufferedSize()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/getBufferedSize()
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getAllocatedSize()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/getAllocatedSize()
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.Throwable)
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()#parquet/bytes/BytesUtils/writeIntLittleEndian(java.io.OutputStream,int)
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()#parquet/bytes/BytesInput/from(byte[])
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()#parquet/bytes/BytesInput/size()
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()#parquet/Ints/checkedCast(long)
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()#java/io/ByteArrayOutputStream/toByteArray()
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/memUsageString(java.lang.String)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/memUsageString(java.lang.String)#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getAllocatedSize()
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/writeBoolean(boolean)#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/writeInteger(int)
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/writeInteger(int)#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/writeInteger(int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.Throwable)
parquet/thrift/ThriftRecordConverter/CollectionConverter/getConverter(int)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/ThriftRecordConverter/CollectionConverter/end()#parquet/thrift/struct/ThriftTypeID/getThriftType()
parquet/thrift/ThriftRecordConverter/CollectionConverter/end()#parquet/thrift/ThriftRecordConverter/CollectionConverter/collectionEnd()
parquet/thrift/ThriftRecordConverter/CollectionConverter/end()#parquet/thrift/ThriftRecordConverter/CollectionConverter/collectionStart(int,byte)
parquet/thrift/ThriftRecordConverter/CollectionConverter/end()#parquet/thrift/ThriftRecordConverter/Counter/getCount()
parquet/thrift/ThriftRecordConverter/CollectionConverter/start()#parquet/thrift/ThriftRecordConverter/Counter/startCounting()
parquet/thrift/struct/ThriftType/StructType/equals(java.lang.Object)#java/util/Arrays/equals(java.lang.Object[],java.lang.Object[])
parquet/thrift/struct/ThriftType/StructType/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/thrift/struct/ThriftType/StructType/hashCode()#java/util/Arrays/hashCode(java.lang.Object[])
parquet/thrift/struct/ThriftType/StructType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.StructType)
parquet/schema/MessageType/getType(java.lang.String[])#parquet/schema/GroupType/getType(java.lang.String[],int)
parquet/schema/MessageType/getColumnDescription(java.lang.String[])#parquet/schema/MessageType/getType(java.lang.String[])
parquet/schema/MessageType/getColumnDescription(java.lang.String[])#parquet/column/ColumnDescriptor/ColumnDescriptor(java.lang.String[],parquet.schema.PrimitiveType.PrimitiveTypeName,int,int,int)
parquet/schema/MessageType/getColumnDescription(java.lang.String[])#parquet/schema/Type/asPrimitiveType()
parquet/schema/MessageType/getColumnDescription(java.lang.String[])#parquet/schema/PrimitiveType/getTypeLength()
parquet/schema/MessageType/getColumnDescription(java.lang.String[])#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/schema/MessageType/getColumnDescription(java.lang.String[])#parquet/schema/MessageType/getMaxDefinitionLevel(java.lang.String[])
parquet/schema/MessageType/getColumnDescription(java.lang.String[])#parquet/schema/MessageType/getMaxRepetitionLevel(java.lang.String[])
parquet/schema/MessageType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/GroupType/membersDisplayString(java.lang.StringBuilder,java.lang.String)
parquet/schema/MessageType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/StringBuilder/append(java.lang.String)
parquet/schema/MessageType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getName()
parquet/schema/MessageType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getOriginalType()
parquet/schema/MessageType/getMaxRepetitionLevel(java.lang.String[])#parquet/schema/GroupType/getMaxRepetitionLevel(java.lang.String[],int)
parquet/schema/MessageType/union(parquet.schema.MessageType,boolean)#parquet/schema/GroupType/mergeFields(parquet.schema.GroupType,boolean)
parquet/schema/MessageType/union(parquet.schema.MessageType,boolean)#parquet/schema/MessageType/MessageType(java.lang.String,java.util.List)
parquet/schema/MessageType/union(parquet.schema.MessageType,boolean)#parquet/schema/Type/getName()
parquet/schema/MessageType/convertWith(parquet.schema.TypeConverter)#parquet/schema/TypeConverter/convertMessageType(parquet.schema.MessageType,java.util.List)
parquet/schema/MessageType/convertWith(parquet.schema.TypeConverter)#java/util/ArrayList/add(E)
parquet/schema/MessageType/convertWith(parquet.schema.TypeConverter)#parquet/schema/GroupType/convertChildren(java.util.List,parquet.schema.TypeConverter)
parquet/schema/MessageType/convertWith(parquet.schema.TypeConverter)#java/util/ArrayList/ArrayList()
parquet/schema/MessageType/getColumns()#parquet/schema/MessageType/getType(java.lang.String[])
parquet/schema/MessageType/getColumns()#java/util/ArrayList/ArrayList(int)
parquet/schema/MessageType/getColumns()#parquet/column/ColumnDescriptor/ColumnDescriptor(java.lang.String[],parquet.schema.PrimitiveType.PrimitiveTypeName,int,int,int)
parquet/schema/MessageType/getColumns()#parquet/schema/Type/asPrimitiveType()
parquet/schema/MessageType/getColumns()#java/util/List/size()
parquet/schema/MessageType/getColumns()#parquet/schema/PrimitiveType/getTypeLength()
parquet/schema/MessageType/getColumns()#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/schema/MessageType/getColumns()#parquet/schema/MessageType/getMaxDefinitionLevel(java.lang.String[])
parquet/schema/MessageType/getColumns()#parquet/schema/GroupType/getPaths(int)
parquet/schema/MessageType/getColumns()#parquet/schema/MessageType/getMaxRepetitionLevel(java.lang.String[])
parquet/schema/MessageType/getColumns()#java/util/List/add(E)
parquet/schema/MessageType/accept(parquet.schema.TypeVisitor)#parquet/schema/TypeVisitor/visit(parquet.schema.MessageType)
parquet/schema/MessageType/getPaths()#parquet/schema/GroupType/getPaths(int)
parquet/schema/MessageType/getMaxDefinitionLevel(java.lang.String[])#parquet/schema/GroupType/getMaxDefinitionLevel(java.lang.String[],int)
parquet/schema/MessageType/checkContains(parquet.schema.Type)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/schema/MessageType/checkContains(parquet.schema.Type)#parquet/schema/GroupType/checkGroupContains(parquet.schema.Type)
parquet/schema/MessageType/union(parquet.schema.MessageType)#parquet/schema/MessageType/union(parquet.schema.MessageType,boolean)
parquet/schema/MessageType/containsPath(java.lang.String[])#parquet/schema/GroupType/containsPath(java.lang.String[],int)
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#java/lang/StringBuilder/append(java.lang.String)
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/common/schema/ColumnPath/toDotString()
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#java/util/Map/get(java.lang.Object)
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/filter2/predicate/Operators/Column/getColumnType()
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/filter2/predicate/ValidTypeMap/FullTypeDescriptor/FullTypeDescriptor(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#java/lang/Class/getName()
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#java/util/Set/contains(java.lang.Object)
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#java/lang/StringBuilder/StringBuilder()
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#java/lang/StringBuilder/toString()
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#java/lang/StringBuilder/append(java.lang.Object)
parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/predicate/ValidTypeMap/add(java.lang.Class,parquet.filter2.predicate.ValidTypeMap.FullTypeDescriptor)#java/util/Map/get(java.lang.Object)
parquet/filter2/predicate/ValidTypeMap/add(java.lang.Class,parquet.filter2.predicate.ValidTypeMap.FullTypeDescriptor)#java/util/Set/add(E)
parquet/filter2/predicate/ValidTypeMap/add(java.lang.Class,parquet.filter2.predicate.ValidTypeMap.FullTypeDescriptor)#java/util/Map/put(K,V)
parquet/filter2/predicate/ValidTypeMap/add(java.lang.Class,parquet.filter2.predicate.ValidTypeMap.FullTypeDescriptor)#java/util/HashSet/HashSet()
parquet/hadoop/DeprecatedOutputFormatTest/testReadWrite()#parquet/hadoop/DeprecatedOutputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/DeprecatedOutputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/example/GroupWriteSupport/setSchema(parquet.schema.MessageType,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/DeprecatedOutputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/DeprecatedOutputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/mapred/DeprecatedParquetOutputFormat/setCompression(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/DeprecatedOutputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/mapred/DeprecatedParquetOutputFormat/setWriteSupportClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithPlainValuesWriter()#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithPlainValuesWriter()#java/io/PrintStream/println(java.lang.String)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithPlainValuesWriter()#parquet/column/values/plain/PlainValuesWriter/getBytes()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithPlainValuesWriter()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithPlainValuesWriter()#parquet/column/values/plain/BinaryPlainValuesReader/BinaryPlainValuesReader()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithPlainValuesWriter()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithPlainValuesWriter()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#java/io/PrintStream/println(java.lang.String)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltastrings/DeltaByteArrayWriter/DeltaByteArrayWriter(int)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltastrings/DeltaByteArrayReader/DeltaByteArrayReader()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltastrings/DeltaByteArrayWriter/getBytes()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithPlainValuesWriter()#java/io/PrintStream/println(java.lang.String)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/plain/PlainValuesWriter/getBytes()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/plain/BinaryPlainValuesReader/BinaryPlainValuesReader()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithDeltaLengthByteArrayValuesWriter()#java/io/PrintStream/println(java.lang.String)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltastrings/DeltaByteArrayWriter/DeltaByteArrayWriter(int)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltastrings/DeltaByteArrayReader/DeltaByteArrayReader()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltastrings/DeltaByteArrayWriter/getBytes()
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray/benchmarkSortedStringsWithDeltaLengthByteArrayValuesWriter()#parquet/bytes/BytesInput/toByteArray()
parquet/thrift/ThriftRecordConverter/ListConverter/collectionStart(int,byte)#parquet/thrift/ThriftRecordConverter/ListConverter/collectionStart(int,byte)/$anonymous1/(java.lang.String)
parquet/schema/PrimitiveType/getPaths(int)#java/util/Arrays/asList(T[])
parquet/schema/PrimitiveType/typeEquals(parquet.schema.Type)#parquet/schema/PrimitiveType/equals(parquet.schema.Type)
parquet/schema/PrimitiveType/union(parquet.schema.Type)#parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)
parquet/schema/PrimitiveType/getMaxRepetitionLevel(java.lang.String[],int)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/schema/PrimitiveType/getMaxRepetitionLevel(java.lang.String[],int)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/schema/PrimitiveType/equals(parquet.schema.Type)#parquet/schema/Type/eqOrBothNull(java.lang.Object,java.lang.Object)
parquet/schema/PrimitiveType/equals(parquet.schema.Type)#parquet/schema/Type/asPrimitiveType()
parquet/schema/PrimitiveType/equals(parquet.schema.Type)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/schema/PrimitiveType/equals(parquet.schema.Type)#parquet/schema/Type/isPrimitive()
parquet/schema/PrimitiveType/equals(parquet.schema.Type)#parquet/schema/Type/equals(parquet.schema.Type)
parquet/schema/PrimitiveType/getType(java.lang.String[],int)#java/util/Arrays/toString(java.lang.Object[])
parquet/schema/PrimitiveType/getType(java.lang.String[],int)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/schema/PrimitiveType/accept(parquet.schema.TypeVisitor)#parquet/schema/TypeVisitor/visit(parquet.schema.PrimitiveType)
parquet/schema/PrimitiveType/typeHashCode()#parquet/schema/PrimitiveType/hashCode()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/PrimitiveType/getDecimalMetadata()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/StringBuilder/append(java.lang.String)
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/StringBuilder/append(int)
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getId()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/DecimalMetadata/getScale()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/StringBuilder/append(java.lang.Object)
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/Enum/name()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getRepetition()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/DecimalMetadata/getPrecision()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#java/lang/String/toLowerCase()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getName()
parquet/schema/PrimitiveType/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)#parquet/schema/Type/getOriginalType()
parquet/schema/PrimitiveType/getMaxDefinitionLevel(java.lang.String[],int)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/schema/PrimitiveType/getMaxDefinitionLevel(java.lang.String[],int)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/Type/getRepetition()
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#java/lang/Enum/equals(java.lang.Object)
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/Type/asPrimitiveType()
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/IncompatibleSchemaModificationException/IncompatibleSchemaModificationException(java.lang.String)
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/Type/isPrimitive()
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/Type/getName()
parquet/schema/PrimitiveType/union(parquet.schema.Type,boolean)#parquet/schema/Types/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)
parquet/schema/PrimitiveType/hashCode()#java/lang/Enum/hashCode()
parquet/schema/PrimitiveType/hashCode()#parquet/schema/Type/hashCode()
parquet/schema/PrimitiveType/hashCode()#parquet/schema/DecimalMetadata/hashCode()
parquet/schema/PrimitiveType/checkContains(parquet.schema.Type)#parquet/schema/Type/asPrimitiveType()
parquet/schema/PrimitiveType/checkContains(parquet.schema.Type)#parquet/schema/Type/isPrimitive()
parquet/schema/PrimitiveType/checkContains(parquet.schema.Type)#parquet/schema/Type/checkContains(parquet.schema.Type)
parquet/schema/PrimitiveType/checkContains(parquet.schema.Type)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/schema/PrimitiveType/convert(java.util.List,parquet.schema.TypeConverter)#parquet/schema/TypeConverter/convertPrimitiveType(java.util.List,parquet.schema.PrimitiveType)
parquet/schema/PrimitiveType/withId(int)#parquet/schema/Type/getRepetition()
parquet/schema/PrimitiveType/withId(int)#parquet/schema/Type/ID/ID(int)
parquet/schema/PrimitiveType/withId(int)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,int,java.lang.String,parquet.schema.OriginalType,parquet.schema.DecimalMetadata,parquet.schema.Type.ID)
parquet/schema/PrimitiveType/withId(int)#parquet/schema/Type/getName()
parquet/schema/PrimitiveType/withId(int)#parquet/schema/Type/getOriginalType()
org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetByteInspector/getPrimitiveWritableObject(java.lang.Object)#org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetByteInspector/get(java.lang.Object)
parquet/pig/GenerateIntTestFile/startFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/start()
parquet/pig/GenerateIntTestFile/startFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/ParquetFileWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.hadoop.Path)
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/MessageType/getColumns()
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetFileReader/ParquetFileReader(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List,java.util.List)
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/PrintStream/println(long)
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/column/page/PageReadStore/getRowCount()
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetFileReader/readNextRowGroup()
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/pig/GenerateIntTestFile/endFile(parquet.hadoop.ParquetFileWriter)#java/util/HashMap/HashMap()
parquet/pig/GenerateIntTestFile/endFile(parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/end(java.util.Map)
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/column/page/PageReader/getTotalValueCount()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/schema/MessageType/getColumns()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/startBlock(long)
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/column/page/Page/getValueEncoding()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/endBlock()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/bytes/BytesInput/size()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/column/page/Page/getBytes()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/column/page/PageReader/readPage()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/bytes/BytesInput/from(byte[])
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/column/page/Page/getDlEncoding()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/column/page/Page/getValueCount()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ParquetFileWriter/endColumn()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/column/page/Page/getRlEncoding()
parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)#parquet/bytes/BytesInput/toByteArray()
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/io/api/RecordConsumer/startMessage()
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/io/api/RecordConsumer/endMessage()
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#java/io/File/File(java.lang.String)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#java/io/File/toURI()
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#java/io/File/getAbsolutePath()
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/io/api/RecordConsumer/addInteger(int)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#java/io/File/exists()
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/pig/GenerateIntTestFile/writeToFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/pig/GenerateIntTestFile/main(java.lang.String[])#java/io/File/delete()
parquet/pig/GenerateIntTestFile/writeToFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int)#parquet/pig/GenerateIntTestFile/writeBlock(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int,parquet.hadoop.ParquetFileWriter)
parquet/pig/GenerateIntTestFile/writeToFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int)#parquet/pig/GenerateIntTestFile/startFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType)
parquet/pig/GenerateIntTestFile/writeToFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int)#parquet/pig/GenerateIntTestFile/endFile(parquet.hadoop.ParquetFileWriter)
parquet/hadoop/codec/NonBlockedCompressorStream/write(byte[],int,int)#java/io/IOException/IOException(java.lang.String)
parquet/hadoop/codec/NonBlockedCompressorStream/write(byte[],int,int)#java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException()
parquet/proto/ProtoInputOutputFormatTest/testInputOutput()#parquet/proto/ProtoInputOutputFormatTest/runMRJobs(parquet.proto.Message[])
parquet/proto/ProtoInputOutputFormatTest/runMRJobs(parquet.proto.Message[])#parquet/proto/utils/ReadUsingMR/read(parquet.hadoop.Path)
parquet/proto/ProtoInputOutputFormatTest/runMRJobs(parquet.proto.Message[])#parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])
parquet/proto/ProtoInputOutputFormatTest/runMRJobs(parquet.proto.Message[])#parquet/proto/utils/WriteUsingMR/WriteUsingMR()
parquet/proto/ProtoInputOutputFormatTest/runMRJobs(parquet.proto.Message[])#parquet/proto/utils/ReadUsingMR/ReadUsingMR()
parquet/proto/ProtoInputOutputFormatTest/testProjection()#parquet/proto/utils/ReadUsingMR/read(parquet.hadoop.Path)
parquet/proto/ProtoInputOutputFormatTest/testProjection()#parquet/proto/utils/WriteUsingMR/write(parquet.proto.Message[])
parquet/proto/ProtoInputOutputFormatTest/testProjection()#parquet/proto/utils/ReadUsingMR/setRequestedProjection(java.lang.String)
parquet/proto/ProtoInputOutputFormatTest/testProjection()#parquet/proto/utils/WriteUsingMR/WriteUsingMR()
parquet/proto/ProtoInputOutputFormatTest/testProjection()#parquet/proto/utils/ReadUsingMR/ReadUsingMR()
parquet/schema/ConversionPatterns/stringKeyMapType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type)#parquet/schema/ConversionPatterns/stringKeyMapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type)
parquet/schema/ConversionPatterns/listWrapper(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,parquet.schema.Type)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/schema/ConversionPatterns/listWrapper(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,parquet.schema.Type)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,parquet.schema.Type[])
parquet/schema/ConversionPatterns/listWrapper(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,parquet.schema.Type)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/schema/ConversionPatterns/listType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type)#parquet/schema/ConversionPatterns/listWrapper(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,parquet.schema.Type)
parquet/schema/ConversionPatterns/stringKeyMapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String,parquet.schema.OriginalType)
parquet/schema/ConversionPatterns/stringKeyMapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type)#parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type,parquet.schema.Type)
parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type,parquet.schema.Type)#parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type,parquet.schema.Type)
parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type,parquet.schema.Type)#parquet/schema/ConversionPatterns/listWrapper(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,parquet.schema.Type)
parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type,parquet.schema.Type)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,parquet.schema.Type[])
parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type,parquet.schema.Type)#java/lang/String/equals(java.lang.Object)
parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type,parquet.schema.Type)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,java.lang.String,parquet.schema.Type,parquet.schema.Type)#parquet/schema/Type/getName()
parquet/hadoop/example/ExampleOutputFormat/getSchema(parquet.proto.utils.Job)#parquet/hadoop/example/GroupWriteSupport/getSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/example/ExampleOutputFormat/getSchema(parquet.proto.utils.Job)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/example/ExampleOutputFormat/setSchema(parquet.proto.utils.Job,parquet.schema.MessageType)#parquet/hadoop/example/GroupWriteSupport/setSchema(parquet.schema.MessageType,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/example/ExampleOutputFormat/setSchema(parquet.proto.utils.Job,parquet.schema.MessageType)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredSets()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredSets()#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjectionWithThriftColumnFilter(java.lang.String,parquet.hadoop.thrift.TBase,parquet.hadoop.thrift.TBase,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredSets()#java/util/HashSet/HashSet()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredSets()#java/util/HashSet/HashSet(java.util.Collection)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredMaps()#java/util/HashMap/HashMap()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredMaps()#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjectionWithThriftColumnFilter(java.lang.String,parquet.hadoop.thrift.TBase,parquet.hadoop.thrift.TBase,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredMaps()#java/util/Map/put(K,V)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testReorderdOptionalFields()#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjectionWithThriftColumnFilter(java.lang.String,parquet.hadoop.thrift.TBase,parquet.hadoop.thrift.TBase,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredLists()#java/util/ArrayList/ArrayList()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredLists()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredLists()#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjectionWithThriftColumnFilter(java.lang.String,parquet.hadoop.thrift.TBase,parquet.hadoop.thrift.TBase,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInRequiredLists()#java/lang/Object/Object()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjectionWithThriftColumnFilter(java.lang.String,parquet.hadoop.thrift.TBase,parquet.hadoop.thrift.TBase,java.lang.Class)#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullingInRequiredStructWithFilter()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullingInRequiredStructWithFilter()#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjectionWithThriftColumnFilter(java.lang.String,parquet.hadoop.thrift.TBase,parquet.hadoop.thrift.TBase,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullingInRequiredStructWithFilter()#java/lang/Object/Object()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/ParquetInputFormat/getSplits(parquet.hadoop.util.JobContext)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/ParquetInputFormat/createRecordReader(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/thrift/ParquetThriftInputFormat/ParquetThriftInputFormat()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#java/io/ByteArrayOutputStream/toByteArray()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/thrift/ThriftToParquetFileWriter/ThriftToParquetFileWriter(parquet.hadoop.Path,parquet.pig.TaskAttemptContext,parquet.hadoop.thrift.TProtocolFactory,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/Log/info(java.lang.Object)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#java/lang/Object/Object()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/util/ContextUtil/newJobContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.JobID)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/thrift/ThriftToParquetFileWriter/write(parquet.hadoop.thrift.BytesWritable)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)#parquet/hadoop/thrift/ThriftToParquetFileWriter/close()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testPullInPrimitiveValues()#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjectionWithThriftColumnFilter(java.lang.String,parquet.hadoop.thrift.TBase,parquet.hadoop.thrift.TBase,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testThriftOptionalFieldsWithReadProjectionUsingParquetSchema()#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,T,T,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testThriftOptionalFieldsWithReadProjectionUsingParquetSchema()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testThriftOptionalFieldsWithReadProjectionUsingParquetSchema()#java/lang/Object/Object()
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testNotPullInOptionalFields()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testNotPullInOptionalFields()#parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/shouldDoProjectionWithThriftColumnFilter(java.lang.String,parquet.hadoop.thrift.TBase,parquet.hadoop.thrift.TBase,java.lang.Class)
parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection/testNotPullInOptionalFields()#java/lang/Object/Object()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/writeDouble(double)#parquet/column/values/dictionary/IntList/add(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/writeDouble(double)#parquet/column/values/ValuesWriter/writeDouble(double)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/writeDouble(double)#parquet/column/values/dictionary/DictionaryValuesWriter/checkAndFallbackIfNeeded()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/hasNext()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/next()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/ValuesWriter/writeDouble(double)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/iterator()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/ValuesWriter/createDictionaryPage()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/createDictionaryPage()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,parquet.column.Encoding)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/getBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/writeDouble(double)
org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter/getCurrentRecord()#org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter/getCurrentArray()
parquet/filter2/predicate/Operators/LogicalNotUserDefined/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.LogicalNotUserDefined)
parquet/filter2/predicate/Operators/LogicalNotUserDefined/hashCode()#parquet/filter2/predicate/Operators/UserDefined/hashCode()
parquet/filter2/predicate/Operators/LogicalNotUserDefined/hashCode()#java/lang/Object/hashCode()
parquet/filter2/predicate/Operators/LogicalNotUserDefined/hashCode()#java/lang/Object/getClass()
parquet/filter2/predicate/Operators/LogicalNotUserDefined/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/filter2/predicate/Operators/LogicalNotUserDefined/equals(java.lang.Object)#parquet/filter2/predicate/Operators/UserDefined/equals(java.lang.Object)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#java/lang/Math/ceil(double)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#java/io/DataInputStream/DataInputStream(java.io.InputStream)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#parquet/column/values/bitpacking/BytePacker/unpack8Values(byte[],int,int[],int)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#parquet/bytes/BytesUtils/readIntLittleEndianPaddedOnBitWidth(java.io.InputStream,int)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#java/io/DataInputStream/readFully(byte[],int,int)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#parquet/Log/debug(java.lang.Object)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#java/lang/Math/min(int,int)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#java/io/ByteArrayInputStream/available()
parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readNext()#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter/increment(long)#parquet/hadoop/util/ContextUtil/incrementCounter(parquet.hadoop.example.Counter,long)
parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest/prepare()#java/util/Random/nextInt(int)
parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest/prepare()#java/util/Random/Random()
parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest/writeDeltaPackingTest2()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/DeltaBinaryPackingValuesWriter(int,int,int)
parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest/writeDeltaPackingTest2()#parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)
parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest/writeDeltaPackingTest()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/DeltaBinaryPackingValuesWriter(int,int,int)
parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest/writeDeltaPackingTest()#parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)
parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest/writeRLETest()#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/RunLengthBitPackingHybridValuesWriter(int,int)
parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest/writeRLETest()#parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)
parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/readAll(parquet.hadoop.FSDataInputStream)#java/util/ArrayList/ArrayList(int)
parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/readAll(parquet.hadoop.FSDataInputStream)#parquet/hadoop/util/counters/BenchmarkCounter/incrementBytesRead(long)
parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/readAll(parquet.hadoop.FSDataInputStream)#parquet/hadoop/ParquetFileReader/Chunk/Chunk(parquet.hadoop.ParquetFileReader.ChunkDescriptor,byte[],int)
parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/readAll(parquet.hadoop.FSDataInputStream)#java/util/List/size()
parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/readAll(parquet.hadoop.FSDataInputStream)#java/util/List/add(E)
parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/readAll(parquet.hadoop.FSDataInputStream)#java/util/List/get(int)
parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/readAll(parquet.hadoop.FSDataInputStream)#parquet/hadoop/ParquetFileReader/WorkaroundChunk/WorkaroundChunk(parquet.hadoop.ParquetFileReader.ChunkDescriptor,byte[],int,parquet.hadoop.FSDataInputStream)
parquet/hadoop/ParquetFileReader/ConsecutiveChunkList/addChunk(parquet.hadoop.ParquetFileReader.ChunkDescriptor)#java/util/List/add(E)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#java/util/ArrayList/ArrayList()
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/column/statistics/Statistics/setNumNulls(long)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#java/util/List/add(E)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/filter2/compat/RowGroupFilter/filterRowGroups(parquet.filter2.compat.FilterCompat.Filter,java.util.List,parquet.schema.MessageType)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/filter2/predicate/FilterApi/intColumn(java.lang.String)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#parquet/column/statistics/IntStatistics/setMinMax(int,int)
parquet/filter2/compat/TestRowGroupFilter/testApplyRowGroupFilters()#java/util/Arrays/asList(T[])
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(parquet.thrift.TStructDescriptor)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(parquet.thrift.TStructDescriptor)#parquet/thrift/struct/ThriftField/Requirement/fromType(byte)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(parquet.thrift.TStructDescriptor)#java/util/List/add(E)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(parquet.thrift.TStructDescriptor)#parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(parquet.thrift.TStructDescriptor)#parquet/thrift/struct/ThriftType/StructType/StructType(java.util.List)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftField/ThriftField(java.lang.String,short,parquet.thrift.struct.ThriftField.Requirement,parquet.thrift.struct.ThriftType)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#java/util/ArrayList/ArrayList()
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/SetType/SetType(parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/I16Type/I16Type()
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftTypeID/fromByte(byte)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(java.lang.Class)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/ListType/ListType(parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/BoolType/BoolType()
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/ByteType/ByteType()
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/DoubleType/DoubleType()
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/EnumValue/EnumValue(int,java.lang.String)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/StringType/StringType()
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/EnumType/EnumType(java.util.List)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/I64Type/I64Type()
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#java/util/List/add(E)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/I32Type/I32Type()
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toThriftField(java.lang.String,parquet.thrift.Field,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/MapType/MapType(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/ThriftStructConverter/toStructType(java.lang.Class)
parquet/avro/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#java/lang/Thread/sleep(long)
parquet/avro/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/avro/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/avro/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#parquet/Log/info(java.lang.Object)
parquet/avro/TestInputOutputFormat/testReadWrite()#parquet/avro/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)
parquet/avro/TestInputOutputFormat/testReadWrite()#java/io/BufferedReader/close()
parquet/avro/TestInputOutputFormat/testReadWrite()#parquet/avro/AvroParquetOutputFormat/setSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)
parquet/avro/TestInputOutputFormat/testReadWrite()#java/io/File/File(java.lang.String,java.lang.String)
parquet/avro/TestInputOutputFormat/testReadWrite()#java/lang/String/indexOf(java.lang.String)
parquet/avro/TestInputOutputFormat/testReadWrite()#java/lang/String/substring(int)
parquet/avro/TestInputOutputFormat/testReadWrite()#parquet/avro/TestInputOutputFormat/nextRecord(java.lang.Integer)
parquet/avro/TestInputOutputFormat/testReadWrite()#java/io/BufferedReader/BufferedReader(java.io.Reader)
parquet/avro/TestInputOutputFormat/testReadWrite()#java/io/BufferedReader/readLine()
parquet/avro/TestInputOutputFormat/testReadWrite()#java/lang/Object/Object()
parquet/avro/TestInputOutputFormat/testReadWrite()#java/io/FileReader/FileReader(java.io.File)
parquet/avro/TestInputOutputFormat/nextRecord(java.lang.Integer)#java/lang/Object/Object()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/incompatibleSchema(parquet.schema.Type,parquet.schema.Type)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/GroupType/getFields()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/Type/getRepetition()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/incompatibleSchema(parquet.schema.Type,parquet.schema.Type)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/Type/accept(parquet.schema.TypeVisitor)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/GroupType/containsField(java.lang.String)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/Type/Repetition/isMoreRestrictiveThan(parquet.schema.Type.Repetition)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/GroupType/getType(int)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/Type/getName()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.MessageType)#parquet/io/MessageColumnIO/setLevels()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.MessageType)#parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.MessageType)#parquet/io/MessageColumnIO/MessageColumnIO(parquet.schema.MessageType,boolean)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.MessageType)#parquet/io/MessageColumnIO/setLeaves(java.util.List)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.PrimitiveType)#parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/incompatibleSchema(parquet.schema.Type,parquet.schema.Type)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.PrimitiveType)#parquet/io/GroupColumnIO/add(parquet.io.ColumnIO)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.PrimitiveType)#parquet/schema/Type/asPrimitiveType()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.PrimitiveType)#java/util/List/size()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.PrimitiveType)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.PrimitiveType)#parquet/io/PrimitiveColumnIO/PrimitiveColumnIO(parquet.schema.Type,parquet.io.GroupColumnIO,int,int)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.PrimitiveType)#java/util/List/add(E)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.PrimitiveType)#parquet/schema/Type/isPrimitive()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.GroupType)#parquet/schema/Type/asGroupType()
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.GroupType)#parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/incompatibleSchema(parquet.schema.Type,parquet.schema.Type)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.GroupType)#parquet/io/GroupColumnIO/add(parquet.io.ColumnIO)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.GroupType)#parquet/io/GroupColumnIO/GroupColumnIO(parquet.schema.GroupType,parquet.io.GroupColumnIO,int)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.GroupType)#parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visitChildren(parquet.io.GroupColumnIO,parquet.schema.GroupType,parquet.schema.GroupType)
parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/visit(parquet.schema.GroupType)#parquet/schema/Type/isPrimitive()
parquet/column/values/bitpacking/ByteBitPackingValuesReader/readInteger()#java/util/Arrays/copyOfRange(byte[],int,int)
parquet/column/values/bitpacking/ByteBitPackingValuesReader/readInteger()#parquet/column/values/bitpacking/BytePacker/unpack8Values(byte[],int,int[],int)
parquet/column/values/bitpacking/ByteBitPackingValuesReader/initFromPage(int,byte[],int)#parquet/bytes/BytesUtils/paddedByteCountFromBits(int)
parquet/column/values/bitpacking/ByteBitPackingValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/ByteBitPackingValuesReader/skip()#parquet/column/values/bitpacking/ByteBitPackingValuesReader/readInteger()
parquet/thrift/ThriftParquetReader/Builder/build()#parquet/hadoop/thrift/ThriftReadSupport/ThriftReadSupport(java.lang.Class)
parquet/thrift/ThriftParquetReader/Builder/build()#parquet/hadoop/thrift/ThriftReadSupport/ThriftReadSupport()
parquet/thrift/ThriftParquetReader/Builder/build()#parquet/hadoop/ParquetReader/builder(parquet.hadoop.api.ReadSupport,parquet.hadoop.Path)
parquet/thrift/ThriftParquetReader/Builder/withConf(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/thrift/ThriftParquetReader/Builder/withFilter(parquet.filter2.compat.FilterCompat.Filter)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/thrift/ThriftParquetReader/Builder/withThriftClass(java.lang.Class)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/io/api/Binary/ByteArrayBackedBinary/toStringUsingUTF8()#java/nio/charset/Charset/decode(java.nio.ByteBuffer)
parquet/io/api/Binary/ByteArrayBackedBinary/toStringUsingUTF8()#java/nio/CharBuffer/toString()
parquet/io/api/Binary/ByteArrayBackedBinary/toStringUsingUTF8()#java/nio/ByteBuffer/wrap(byte[])
parquet/io/api/Binary/ByteArrayBackedBinary/equals(parquet.io.api.Binary)#parquet/io/api/Binary/equals(byte[],int,int)
parquet/io/api/Binary/ByteArrayBackedBinary/compareTo(parquet.io.api.Binary)#parquet/io/api/Binary/compareTo(byte[],int,int)
parquet/io/api/Binary/ByteArrayBackedBinary/compareTo(byte[],int,int)#parquet/io/api/Binary/compareTwoByteArrays(byte[],int,int,byte[],int,int)
parquet/io/api/Binary/ByteArrayBackedBinary/equals(byte[],int,int)#parquet/io/api/Binary/equals(byte[],int,int,byte[],int,int)
parquet/io/api/Binary/ByteArrayBackedBinary/writeTo(java.io.DataOutput)#java/io/DataOutput/write(byte[])
parquet/io/api/Binary/ByteArrayBackedBinary/toByteBuffer()#java/nio/ByteBuffer/wrap(byte[])
parquet/io/api/Binary/ByteArrayBackedBinary/writeTo(java.io.OutputStream)#java/io/OutputStream/write(byte[])
parquet/io/api/Binary/ByteArrayBackedBinary/hashCode()#parquet/io/api/Binary/hashCode(byte[],int,int)
parquet/bytes/BytesInput/UnsignedVarIntBytesInput/writeAllTo(java.io.OutputStream)#parquet/bytes/BytesUtils/writeUnsignedVarInt(int,java.io.OutputStream)
parquet/bytes/BytesInput/UnsignedVarIntBytesInput/size()#java/lang/Integer/numberOfLeadingZeros(int)
parquet/cascading/ParquetTBaseScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/ParquetInputFormat/setReadSupportClass(parquet.proto.utils.Job,java.lang.Class)
parquet/cascading/ParquetTBaseScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/thrift/ThriftReadSupport/setRecordConverterClass(parquet.cascading.JobConf,java.lang.Class)
parquet/cascading/ParquetTBaseScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/cascading/ParquetValueScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)
parquet/cascading/ParquetTBaseScheme/sinkConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/thrift/ThriftWriteSupport/setThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)
parquet/cascading/ParquetTBaseScheme/sinkConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/mapred/DeprecatedParquetOutputFormat/setWriteSupportClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)
parquet/cascading/ParquetTBaseScheme/sinkConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/cascading/ParquetTBaseScheme/sinkConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/cascading/ParquetValueScheme/Config/getKlass()
parquet/tools/read/SimpleRecord/toString()#java/lang/Object/toString()
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/lang/String/valueOf(java.lang.Object)
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/io/PrintWriter/print(char[])
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/util/Arrays/toString(double[])
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#parquet/tools/read/SimpleRecord/NameValue/getName()
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/util/Arrays/toString(byte[])
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/util/Arrays/deepToString(java.lang.Object[])
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/util/Arrays/toString(int[])
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/io/PrintWriter/print(java.lang.String)
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/lang/Object/getClass()
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/io/PrintWriter/println(java.lang.String)
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/lang/Class/isAssignableFrom(java.lang.Class)
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/io/PrintWriter/println()
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/lang/Class/isArray()
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#parquet/tools/read/SimpleRecord/NameValue/getValue()
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/util/Arrays/toString(float[])
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/util/Arrays/toString(short[])
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/util/Arrays/toString(long[])
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)#java/util/Arrays/toString(boolean[])
parquet/tools/read/SimpleRecord/getValues()#java/util/Collections/unmodifiableList(java.util.List)
parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)#java/util/List/add(E)
parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)#parquet/tools/read/SimpleRecord/NameValue/NameValue(java.lang.String,java.lang.Object)
parquet/tools/read/SimpleRecord/prettyPrint()#parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter)
parquet/tools/read/SimpleRecord/prettyPrint()#java/io/PrintWriter/PrintWriter(java.io.OutputStream,boolean)
parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter)#parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter,int)
parquet/bytes/BytesInput/CapacityBAOSBytesInput/writeAllTo(java.io.OutputStream)#parquet/bytes/CapacityByteArrayOutputStream/writeTo(java.io.OutputStream)
parquet/bytes/BytesInput/CapacityBAOSBytesInput/size()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/hadoop/DeprecatedInputFormatTest/DeprecatedWriteMapper/map(java.lang.Void,parquet.hadoop.mapred.Container,parquet.hadoop.OutputCollector,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/example/data/GroupValueSource/getInteger(java.lang.String,int)
parquet/hadoop/DeprecatedInputFormatTest/DeprecatedWriteMapper/map(java.lang.Void,parquet.hadoop.mapred.Container,parquet.hadoop.OutputCollector,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/hadoop/mapred/Container/get()
parquet/hadoop/DeprecatedInputFormatTest/DeprecatedWriteMapper/map(java.lang.Void,parquet.hadoop.mapred.Container,parquet.hadoop.OutputCollector,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/example/data/GroupValueSource/getString(java.lang.String,int)
parquet/tools/util/PrettyPrintWriter/Span/countCharacter(char)#java/lang/String/charAt(int)
parquet/tools/util/PrettyPrintWriter/Span/countCharacter(char)#java/lang/String/length()
parquet/tools/util/PrettyPrintWriter/Span/length()#java/lang/String/length()
parquet/tools/util/PrettyPrintWriter/Span/indexOf(char,int)#java/lang/String/indexOf(int,int)
parquet/tools/util/PrettyPrintWriter/Span/spaceOut(int,int)#java/lang/Character/isWhitespace(char)
parquet/tools/util/PrettyPrintWriter/Span/spaceOut(int,int)#java/lang/String/charAt(int)
parquet/tools/util/PrettyPrintWriter/Span/spaceOut(int,int)#java/lang/String/length()
parquet/tools/util/PrettyPrintWriter/Span/spaceOut(int,int)#java/lang/String/substring(int,int)
parquet/tools/util/PrettyPrintWriter/Span/spaceOut(int,int)#java/lang/String/substring(int)
parquet/tools/util/PrettyPrintWriter/Span/canAppend(parquet.tools.util.PrettyPrintWriter.Span)#java/lang/String/equals(java.lang.Object)
parquet/tools/util/PrettyPrintWriter/Span/toString(java.lang.StringBuilder)#java/lang/StringBuilder/append(java.lang.String)
parquet/tools/util/PrettyPrintWriter/Span/toString()#parquet/tools/util/PrettyPrintWriter/Span/toString(java.lang.StringBuilder)
parquet/tools/util/PrettyPrintWriter/Span/toString()#java/lang/StringBuilder/StringBuilder()
parquet/tools/util/PrettyPrintWriter/Span/toString()#java/lang/StringBuilder/toString()
parquet/tools/util/PrettyPrintWriter/Span/isEmpty()#java/lang/String/isEmpty()
parquet/tools/util/PrettyPrintWriter/Span/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)#parquet/tools/util/PrettyPrintWriter/Span/length()
parquet/tools/util/PrettyPrintWriter/Span/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)#java/lang/String/substring(int,int)
parquet/tools/util/PrettyPrintWriter/Span/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)#parquet/tools/util/PrettyPrintWriter/Span/isEmpty()
parquet/schema/Type/eqOrBothNull(java.lang.Object,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
parquet/schema/Type/asPrimitiveType()#parquet/schema/Type/isPrimitive()
parquet/schema/Type/asPrimitiveType()#java/lang/ClassCastException/ClassCastException(java.lang.String)
parquet/schema/Type/asGroupType()#parquet/schema/Type/isPrimitive()
parquet/schema/Type/asGroupType()#java/lang/ClassCastException/ClassCastException(java.lang.String)
parquet/schema/Type/toString()#parquet/schema/Type/writeToStringBuilder(java.lang.StringBuilder,java.lang.String)
parquet/schema/Type/toString()#java/lang/StringBuilder/StringBuilder()
parquet/schema/Type/toString()#java/lang/StringBuilder/toString()
parquet/schema/Type/equals(java.lang.Object)#parquet/schema/Type/equals(parquet.schema.Type)
parquet/schema/Type/hashCode()#java/lang/String/hashCode()
parquet/schema/Type/hashCode()#parquet/schema/Type/ID/hashCode()
parquet/schema/Type/hashCode()#java/lang/Enum/hashCode()
parquet/schema/Type/checkContains(parquet.schema.Type)#java/lang/String/equals(java.lang.Object)
parquet/schema/Type/checkContains(parquet.schema.Type)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/schema/Type/equals(parquet.schema.Type)#parquet/schema/Type/eqOrBothNull(java.lang.Object,java.lang.Object)
parquet/schema/Type/equals(parquet.schema.Type)#java/lang/String/equals(java.lang.Object)
parquet/thrift/pig/TestParquetThriftStorer/execBatch(parquet.pig.PigServer)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/thrift/pig/TestParquetThriftStorer/testStorer()#java/util/ArrayList/ArrayList()
parquet/thrift/pig/TestParquetThriftStorer/testStorer()#java/util/Properties/setProperty(java.lang.String,java.lang.String)
parquet/thrift/pig/TestParquetThriftStorer/testStorer()#parquet/thrift/pig/TestParquetThriftStorer/execBatch(parquet.pig.PigServer)
parquet/thrift/pig/TestParquetThriftStorer/testStorer()#java/lang/Object/Object()
parquet/thrift/pig/TestParquetThriftStorer/testStorer()#java/util/Properties/Properties()
parquet/thrift/pig/TestParquetThriftStorer/testStorer()#java/lang/Class/getName()
parquet/hadoop/thrift/ThriftWriteSupport/getThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Class/forName(java.lang.String)
parquet/hadoop/thrift/ThriftWriteSupport/getThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String)
parquet/hadoop/thrift/ThriftWriteSupport/getThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/hadoop/thrift/ThriftWriteSupport/isPigLoaded()
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/thrift/ThriftMetaData/ThriftMetaData(java.lang.String,parquet.thrift.struct.ThriftType.StructType)
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/pig/PigMetaData/addToMetaData(java.util.Map)
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/thrift/ThriftMetaData/toExtraMetaData()
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/pig/PigMetaData/PigMetaData(parquet.pig.convert.Schema)
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)#parquet/hadoop/api/WriteSupport/WriteContext/WriteContext(parquet.schema.MessageType,java.util.Map)
parquet/hadoop/thrift/ThriftWriteSupport/write(T)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/hadoop/thrift/ThriftWriteSupport/isPigLoaded()#java/lang/Class/forName(java.lang.String)
parquet/hadoop/thrift/ThriftWriteSupport/isPigLoaded()#parquet/Log/info(java.lang.Object)
parquet/hadoop/thrift/ThriftWriteSupport/setThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/thrift/ThriftWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/hadoop/thrift/ThriftWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/hadoop/thrift/ThriftWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/thrift/ParquetWriteProtocol/ParquetWriteProtocol(parquet.io.api.RecordConsumer,parquet.io.MessageColumnIO,parquet.thrift.struct.ThriftType.StructType)
parquet/hadoop/thrift/ThriftWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/thrift/ThriftWriteSupport/getThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/thrift/ThriftWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/thrift/ThriftWriteSupport/init(java.lang.Class)
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/getCodec(parquet.cascading.JobConf)#parquet/hadoop/codec/CodecConfig/from(parquet.cascading.JobConf)
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/setCompression(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.metadata.CompressionCodecName)#java/lang/Enum/name()
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/setWriteSupportClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/getDefaultWorkFile(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/lang/Object/Object()
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/getRecordWriter(parquet.hadoop.example.FileSystem,parquet.cascading.JobConf,java.lang.String,parquet.hadoop.mapred.Progressable)#parquet/hadoop/mapred/DeprecatedParquetOutputFormat/RecordWriterWrapper/RecordWriterWrapper(parquet.hadoop.ParquetOutputFormat,parquet.hadoop.example.FileSystem,parquet.cascading.JobConf,java.lang.String,parquet.hadoop.mapred.Progressable)
parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/doIntegrationTest(int)#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/doIntegrationTest(int)#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/doIntegrationTest(int)#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/doIntegrationTest(int)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/doIntegrationTest(int)#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/RunLengthBitPackingHybridDecoder(int,java.io.ByteArrayInputStream)
parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/doIntegrationTest(int)#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/doIntegrationTest(int)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/integrationTest()#parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest/doIntegrationTest(int)
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#java/util/List/remove(int)
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#java/util/List/isEmpty()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/column/page/Page/getBytes()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/column/page/Page/getValueCount()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/column/page/Page/getStatistics()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/column/page/Page/Page(parquet.bytes.BytesInput,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/column/page/Page/getRlEncoding()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/hadoop/CodecFactory/BytesDecompressor/decompress(parquet.bytes.BytesInput,int)
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/column/page/Page/getValueEncoding()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/column/page/Page/getUncompressedSize()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readPage()#parquet/column/page/Page/getDlEncoding()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readDictionaryPage()#parquet/column/page/DictionaryPage/getUncompressedSize()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readDictionaryPage()#parquet/hadoop/CodecFactory/BytesDecompressor/decompress(parquet.bytes.BytesInput,int)
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readDictionaryPage()#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readDictionaryPage()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,parquet.column.Encoding)
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readDictionaryPage()#parquet/column/page/DictionaryPage/getBytes()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readDictionaryPage()#parquet/column/page/DictionaryPage/getEncoding()
parquet/hadoop/ColumnChunkPageReadStore/ColumnChunkPageReader/readDictionaryPage()#parquet/column/page/DictionaryPage/getDictionarySize()
parquet/pig/convert/TupleConverter/set(int,java.lang.Object)#parquet/pig/TupleConversionException/TupleConversionException(java.lang.String,java.lang.Throwable)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/FieldFloatConverter/FieldFloatConverter(parquet.pig.convert.ParentValueContainer)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/schema/Type/asGroupType()
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/MapConverter/MapConverter(parquet.schema.GroupType,parquet.pig.convert.FieldSchema,parquet.pig.convert.ParentValueContainer,boolean,boolean)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/FieldBooleanConverter/FieldBooleanConverter(parquet.pig.convert.ParentValueContainer)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/BagConverter/BagConverter(parquet.schema.GroupType,parquet.pig.convert.FieldSchema,parquet.pig.convert.ParentValueContainer,boolean,boolean)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/FieldByteArrayConverter/FieldByteArrayConverter(parquet.pig.convert.ParentValueContainer)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/schema/Type/getOriginalType()
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/FieldIntegerConverter/FieldIntegerConverter(parquet.pig.convert.ParentValueContainer)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/FieldLongConverter/FieldLongConverter(parquet.pig.convert.ParentValueContainer)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/FieldDoubleConverter/FieldDoubleConverter(parquet.pig.convert.ParentValueContainer)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/TupleConverter(parquet.schema.GroupType,parquet.pig.convert.Schema,boolean,boolean)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/convert/TupleConverter/FieldStringConverter/FieldStringConverter(parquet.pig.convert.ParentValueContainer,boolean)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/TupleConversionException/TupleConversionException(java.lang.String,java.lang.Throwable)
parquet/pig/convert/TupleConverter/newConverter(parquet.pig.convert.FieldSchema,parquet.schema.Type,parquet.pig.convert.ParentValueContainer,boolean,boolean)#parquet/pig/TupleConversionException/TupleConversionException(java.lang.String)
parquet/pig/convert/TupleConverter/start()#parquet/schema/GroupType/getFields()
parquet/pig/convert/TupleConverter/start()#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/pig/convert/TupleConverter/start()#parquet/schema/Type/asPrimitiveType()
parquet/pig/convert/TupleConverter/start()#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/pig/convert/TupleConverter/start()#parquet/schema/Type/isPrimitive()
parquet/pig/convert/TupleConverter/start()#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/convert/TupleConverter/getType(boolean,java.lang.String,int)#parquet/schema/GroupType/getType(int)
parquet/pig/convert/TupleConverter/getType(boolean,java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/pig/convert/TupleConverter/getType(boolean,java.lang.String,int)#parquet/schema/GroupType/getFieldCount()
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/RecordWriterWrapper/write(java.lang.Void,V)#parquet/hadoop/ParquetRecordWriter/write(java.lang.Void,T)
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/RecordWriterWrapper/write(java.lang.Void,V)#java/lang/Thread/interrupted()
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/RecordWriterWrapper/write(java.lang.Void,V)#java/io/IOException/IOException(java.lang.Throwable)
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/RecordWriterWrapper/close(org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#java/io/IOException/IOException(java.lang.Throwable)
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/RecordWriterWrapper/close(org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/hadoop/ParquetRecordWriter/close(parquet.pig.TaskAttemptContext)
parquet/hadoop/mapred/DeprecatedParquetOutputFormat/RecordWriterWrapper/close(org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#java/lang/Thread/interrupted()
parquet/filter/ColumnPredicates/equalTo(float)#parquet/filter/ColumnPredicates/equalTo(float)/$anonymous1/()
parquet/filter/ColumnPredicates/applyFunctionToFloat(parquet.filter.ColumnPredicates.FloatPredicateFunction)#parquet/filter/ColumnPredicates/applyFunctionToFloat(parquet/filter/ColumnPredicates/FloatPredicateFunction)/$anonymous1/()
parquet/filter/ColumnPredicates/equalTo(java.lang.String)#parquet/filter/ColumnPredicates/equalTo(java/lang/String)/$anonymous1/()
parquet/filter/ColumnPredicates/equalTo(java.lang.String)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter/ColumnPredicates/applyFunctionToString(parquet.filter.ColumnPredicates.PredicateFunction)#parquet/filter/ColumnPredicates/applyFunctionToString(parquet/filter/ColumnPredicates/PredicateFunction)/$anonymous1/()
parquet/filter/ColumnPredicates/equalTo(int)#parquet/filter/ColumnPredicates/equalTo(int)/$anonymous1/()
parquet/filter/ColumnPredicates/equalTo(long)#parquet/filter/ColumnPredicates/equalTo(long)/$anonymous1/()
parquet/filter/ColumnPredicates/equalTo(boolean)#parquet/filter/ColumnPredicates/equalTo(boolean)/$anonymous1/()
parquet/filter/ColumnPredicates/equalTo(double)#parquet/filter/ColumnPredicates/equalTo(double)/$anonymous1/()
parquet/filter/ColumnPredicates/applyFunctionToBinary(parquet.filter.ColumnPredicates.PredicateFunction)#parquet/filter/ColumnPredicates/applyFunctionToBinary(parquet/filter/ColumnPredicates/PredicateFunction)/$anonymous1/()
parquet/filter/ColumnPredicates/applyFunctionToInteger(parquet.filter.ColumnPredicates.IntegerPredicateFunction)#parquet/filter/ColumnPredicates/applyFunctionToInteger(parquet/filter/ColumnPredicates/IntegerPredicateFunction)/$anonymous1/()
parquet/filter/ColumnPredicates/equalTo(E)#java/lang/Enum/name()
parquet/filter/ColumnPredicates/equalTo(E)#parquet/filter/ColumnPredicates/equalTo(E)/$anonymous1/()
parquet/filter/ColumnPredicates/equalTo(E)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter/ColumnPredicates/applyFunctionToDouble(parquet.filter.ColumnPredicates.DoublePredicateFunction)#parquet/filter/ColumnPredicates/applyFunctionToDouble(parquet/filter/ColumnPredicates/DoublePredicateFunction)/$anonymous1/()
parquet/filter/ColumnPredicates/applyFunctionToLong(parquet.filter.ColumnPredicates.LongPredicateFunction)#parquet/filter/ColumnPredicates/applyFunctionToLong(parquet/filter/ColumnPredicates/LongPredicateFunction)/$anonymous1/()
parquet/filter/ColumnPredicates/applyFunctionToBoolean(parquet.filter.ColumnPredicates.BooleanPredicateFunction)#parquet/filter/ColumnPredicates/applyFunctionToBoolean(parquet/filter/ColumnPredicates/BooleanPredicateFunction)/$anonymous1/()
parquet/hadoop/codec/CodecConfig/from(parquet.pig.TaskAttemptContext)#parquet/hadoop/codec/CodecConfig/MapreduceCodecConfig/MapreduceCodecConfig(parquet.pig.TaskAttemptContext)
parquet/hadoop/codec/CodecConfig/getParquetCompressionCodec(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Enum/name()
parquet/hadoop/codec/CodecConfig/getParquetCompressionCodec(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/CompressionCodecName/fromConf(java.lang.String)
parquet/hadoop/codec/CodecConfig/from(parquet.cascading.JobConf)#parquet/hadoop/codec/CodecConfig/MapredCodecConfig/MapredCodecConfig(parquet.cascading.JobConf)
parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()#parquet/hadoop/metadata/CompressionCodecName/fromCompressionCodec(java.lang.Class)
parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()#parquet/hadoop/metadata/CompressionCodecName/getHadoopCompressionCodecClass()
parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()#java/lang/Throwable/getMessage()
parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()#parquet/hadoop/codec/CodecConfig/getHadoopOutputCompressorClass(java.lang.Class)
parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()#java/lang/Class/getName()
parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()#parquet/Log/warn(java.lang.Object,java.lang.Throwable)
parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()#parquet/Log/info(java.lang.Object)
parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()#parquet/hadoop/codec/CompressionCodecNotSupportedException/getCodecClass()
parquet/hadoop/codec/CodecConfig/getCodec()#java/lang/Enum/name()
parquet/hadoop/codec/CodecConfig/getCodec()#parquet/hadoop/codec/CodecConfig/isParquetCompressionSet(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/codec/CodecConfig/getCodec()#parquet/hadoop/codec/CodecConfig/getParquetCompressionCodec(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/codec/CodecConfig/getCodec()#parquet/hadoop/codec/CodecConfig/isHadoopCompressionSet()
parquet/hadoop/codec/CodecConfig/getCodec()#parquet/hadoop/codec/CodecConfig/getHadoopCompressionCodec()
parquet/hadoop/codec/CodecConfig/getCodec()#parquet/Log/info(java.lang.Object)
parquet/hadoop/codec/CodecConfig/getCodec()#parquet/hadoop/codec/CodecConfig/getConfiguration()
parquet/hadoop/example/GroupReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/hadoop/api/ReadSupport/getSchemaForRead(parquet.schema.MessageType,java.lang.String)
parquet/hadoop/example/GroupReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType)
parquet/hadoop/example/GroupReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/hadoop/example/GroupReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/thrift/projection/PathGlobPattern/matches(java.lang.CharSequence)#java/util/regex/Matcher/matches()
parquet/thrift/projection/PathGlobPattern/matches(java.lang.CharSequence)#java/util/regex/Pattern/matcher(java.lang.CharSequence)
parquet/thrift/projection/PathGlobPattern/error(java.lang.String,java.lang.String,int)#java/util/regex/PatternSyntaxException/PatternSyntaxException(java.lang.String,java.lang.String,int)
parquet/thrift/projection/PathGlobPattern/set(java.lang.String)#java/util/regex/Pattern/compile(java.lang.String)
parquet/thrift/projection/PathGlobPattern/set(java.lang.String)#java/lang/String/length()
parquet/thrift/projection/PathGlobPattern/set(java.lang.String)#java/lang/StringBuilder/append(char)
parquet/thrift/projection/PathGlobPattern/set(java.lang.String)#java/lang/StringBuilder/toString()
parquet/thrift/projection/PathGlobPattern/set(java.lang.String)#java/lang/StringBuilder/append(java.lang.String)
parquet/thrift/projection/PathGlobPattern/set(java.lang.String)#java/lang/String/charAt(int)
parquet/thrift/projection/PathGlobPattern/set(java.lang.String)#java/lang/StringBuilder/StringBuilder()
parquet/thrift/projection/PathGlobPattern/set(java.lang.String)#parquet/thrift/projection/PathGlobPattern/error(java.lang.String,java.lang.String,int)
parquet/filter2/predicate/Operators/Lt/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.Lt)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/evaluate(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/evaluate(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/updateNull()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/getResult()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/isKnown()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.And)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/BinaryLogical/getLeft()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.And)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.And)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/BinaryLogical/getRight()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Or)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/BinaryLogical/getLeft()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Or)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Or)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/BinaryLogical/getRight()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startMessage()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/FieldsMarker/reset(int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startMessage()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startMessage()#parquet/io/GroupColumnIO/getChildrenCount()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startMessage()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBinary(parquet.io.api.Binary)#parquet/column/ColumnWriter/write(parquet.io.api.Binary,int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/length()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBinary(parquet.io.api.Binary)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/getColumnWriter()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endMessage()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endMessage()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endMessage()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startField(java.lang.String,int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startField(java.lang.String,int)#parquet/io/GroupColumnIO/getChild(int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startField(java.lang.String,int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startField(java.lang.String,int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addFloat(float)#parquet/column/ColumnWriter/write(float,int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addFloat(float)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addFloat(float)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addFloat(float)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addFloat(float)#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addFloat(float)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/getColumnWriter()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startGroup()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/FieldsMarker/reset(int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startGroup()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startGroup()#parquet/io/GroupColumnIO/getChildrenCount()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/startGroup()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/getColumnWriter()#parquet/io/PrimitiveColumnIO/getId()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()#parquet/io/ColumnIO/getRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)#parquet/Log/debug(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endField(java.lang.String,int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endField(java.lang.String,int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/FieldsMarker/markWritten(int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endField(java.lang.String,int)#parquet/io/ColumnIO/getParent()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endField(java.lang.String,int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endField(java.lang.String,int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)#parquet/io/ColumnIO/getType()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)#parquet/io/PrimitiveColumnIO/getId()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)#parquet/io/GroupColumnIO/getChild(int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)#parquet/schema/Type/isPrimitive()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)#parquet/io/GroupColumnIO/getChildrenCount()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)#parquet/column/ColumnWriter/writeNull(int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/FieldsMarker/isWritten(int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#parquet/io/GroupColumnIO/getChild(int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNull(parquet.io.ColumnIO,int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#parquet/io/GroupColumnIO/getChildrenCount()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#java/util/Arrays/toString(java.lang.Object[])
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()#parquet/io/ColumnIO/getFieldPath()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBoolean(boolean)#parquet/column/ColumnWriter/write(boolean,int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBoolean(boolean)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBoolean(boolean)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBoolean(boolean)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBoolean(boolean)#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addBoolean(boolean)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/getColumnWriter()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addLong(long)#parquet/column/ColumnWriter/write(long,int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addLong(long)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addLong(long)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addLong(long)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addLong(long)#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addLong(long)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/getColumnWriter()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addDouble(double)#parquet/column/ColumnWriter/write(double,int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addDouble(double)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addDouble(double)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addDouble(double)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addDouble(double)#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addDouble(double)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/getColumnWriter()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endGroup()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/writeNullForMissingFieldsAtCurrentLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endGroup()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endGroup()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/endGroup()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addInteger(int)#parquet/column/ColumnWriter/write(int,int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addInteger(int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addInteger(int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/setRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addInteger(int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addInteger(int)#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/addInteger(int)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/getColumnWriter()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/log(java.lang.Object)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()#parquet/io/ColumnIO/getRepetitionLevel()
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()#java/util/Arrays/toString(java.lang.Object[])
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/printState()#parquet/io/ColumnIO/getFieldPath()
parquet/avro/TestInputOutputFormat/MyMapper/run(parquet.proto.utils.Context)#parquet/avro/TestInputOutputFormat/nextRecord(java.lang.Integer)
parquet/tools/command/Registry/allCommands()#java/util/Map/Entry/getValue()
parquet/tools/command/Registry/allCommands()#java/lang/Class/newInstance()
parquet/tools/command/Registry/allCommands()#java/util/Map/Entry/getKey()
parquet/tools/command/Registry/allCommands()#java/util/Map/put(K,V)
parquet/tools/command/Registry/allCommands()#java/util/Map/entrySet()
parquet/tools/command/Registry/allCommands()#java/util/LinkedHashMap/LinkedHashMap()
parquet/tools/command/Registry/getCommandByName(java.lang.String)#java/lang/Class/newInstance()
parquet/tools/command/Registry/getCommandByName(java.lang.String)#java/util/Map/get(java.lang.Object)
parquet/thrift/pig/TupleToThriftWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/thrift/ThriftWriteSupport/ThriftWriteSupport(java.lang.Class)
parquet/thrift/pig/TupleToThriftWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/column/values/bitpacking/OneBitPackingWriter/finish()#parquet/column/values/bitpacking/OneBitPackingWriter/write(int)
parquet/column/values/bitpacking/OneBitPackingWriter/write(int)#java/io/OutputStream/write(int)
parquet/example/data/simple/Primitive/getFloat()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/example/data/simple/Primitive/getInteger()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/example/data/simple/Primitive/getBoolean()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/example/data/simple/Primitive/getLong()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/example/data/simple/Primitive/getInt96()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/example/data/simple/Primitive/getBinary()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/example/data/simple/Primitive/getDouble()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/example/data/simple/Primitive/getString()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/pig/ParquetLoader/UnregisteringParquetInputFormat/createRecordReader(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/hadoop/ParquetInputFormat/createRecordReader(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/DeltaLengthByteArrayValuesWriter(int)
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/DeltaLengthByteArrayValuesReader()
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#java/io/PrintStream/println(java.lang.String)
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithDeltaLengthByteArrayValuesWriter()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithPlainValuesWriter()#java/io/PrintStream/println(java.lang.String)
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/plain/PlainValuesWriter/getBytes()
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/plain/BinaryPlainValuesReader/BinaryPlainValuesReader()
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray/benchmarkRandomStringsWithPlainValuesWriter()#parquet/bytes/BytesInput/toByteArray()
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat/testDefaultConstructor()#org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat/MapredParquetInputFormat()
org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat/testConstructorWithParquetInputFormat()#org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat/MapredParquetInputFormat()
parquet/column/page/Page/toString()#parquet/bytes/BytesInput/size()
parquet/hadoop/example/TestInputOutputFormat/MyWriteSupport/write(parquet.example.data.Group)#parquet/hadoop/api/DelegatingWriteSupport/write(T)
parquet/hadoop/example/TestInputOutputFormat/MyWriteSupport/finalizeWrite()#java/util/HashMap/HashMap()
parquet/hadoop/example/TestInputOutputFormat/MyWriteSupport/finalizeWrite()#parquet/hadoop/api/WriteSupport/FinalizedWriteContext/FinalizedWriteContext(java.util.Map)
parquet/hadoop/example/TestInputOutputFormat/MyWriteSupport/finalizeWrite()#java/util/Map/put(K,V)
parquet/hadoop/example/TestInputOutputFormat/MyWriteSupport/finalizeWrite()#java/lang/String/valueOf(long)
parquet/pig/summary/TestSummary/testPigScript()#parquet/pig/summary/TestSummary/b(parquet.pig.summary.Tuple[])
parquet/pig/summary/TestSummary/testPigScript()#java/util/ArrayList/ArrayList()
parquet/pig/summary/TestSummary/testPigScript()#java/lang/Class/getName()
parquet/pig/summary/TestSummary/testPigScript()#parquet/pig/summary/SummaryData/fromJSON(java.lang.String,java.lang.Class)
parquet/pig/summary/TestSummary/testPigScript()#parquet/pig/summary/TestSummary/m(java.lang.Object[])
parquet/pig/summary/TestSummary/testPigScript()#java/io/PrintStream/println(char[])
parquet/pig/summary/TestSummary/testPigScript()#java/io/PrintStream/println(java.lang.Object)
parquet/pig/summary/TestSummary/testPigScript()#parquet/pig/summary/TestSummary/t(java.lang.Object[])
parquet/pig/summary/TestSummary/testPigScript()#java/lang/Object/Object()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/BagSummaryData/getContent()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/FieldSummaryData/getNull()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/TupleSummaryData/getFields()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#java/lang/Long/longValue()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/SummaryData/fromJSON(java.lang.String,java.lang.Class)
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/FieldSummaryData/getMap()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/SummaryData/getCount()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#java/util/List/get(int)
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/MapSummaryData/getKey()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/FieldSummaryData/getTuple()
parquet/pig/summary/TestSummary/validate(java.lang.String,int)#parquet/pig/summary/FieldSummaryData/getBag()
parquet/pig/summary/TestSummary/m(java.lang.Object[])#java/util/HashMap/HashMap()
parquet/pig/summary/TestSummary/m(java.lang.Object[])#java/util/Map/put(K,V)
parquet/pig/summary/TestSummary/b(parquet.pig.summary.Tuple[])#java/util/Arrays/asList(T[])
parquet/pig/summary/TestSummary/testMaxIsZero()#parquet/pig/summary/FieldSummaryData/getNumber()
parquet/pig/summary/TestSummary/testMaxIsZero()#parquet/pig/summary/TupleSummaryData/getFields()
parquet/pig/summary/TestSummary/testMaxIsZero()#java/lang/Class/getName()
parquet/pig/summary/TestSummary/testMaxIsZero()#parquet/pig/summary/SummaryData/fromJSON(java.lang.String,java.lang.Class)
parquet/pig/summary/TestSummary/testMaxIsZero()#parquet/pig/summary/ValueStat/getMax()
parquet/pig/summary/TestSummary/testMaxIsZero()#java/util/List/get(int)
parquet/pig/summary/TestSummary/testMaxIsZero()#java/io/PrintStream/println(java.lang.Object)
parquet/pig/summary/TestSummary/testMaxIsZero()#parquet/pig/summary/TestSummary/t(java.lang.Object[])
parquet/pig/summary/TestSummary/testMaxIsZero()#java/lang/Object/Object()
parquet/pig/summary/TestSummary/testMaxIsZero()#parquet/pig/summary/NumberSummaryData/getValue()
parquet/pig/summary/TestSummary/testMaxIsZero()#java/util/ArrayList/ArrayList()
parquet/pig/summary/TestSummary/testEvalFunc()#parquet/pig/summary/TestSummary/validate(java.lang.String,int)
parquet/pig/summary/TestSummary/testEvalFunc()#parquet/pig/summary/Summary/exec(parquet.pig.convert.Tuple)
parquet/pig/summary/TestSummary/testEvalFunc()#parquet/pig/summary/Summary/Summary()
parquet/pig/summary/TestSummary/testEvalFunc()#parquet/pig/summary/TestSummary/t(java.lang.Object[])
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/TestSummary/b(parquet.pig.summary.Tuple[])
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/Summary/Final/exec(parquet.pig.convert.Tuple)
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/Summary/Intermediate/Intermediate()
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/TestSummary/validate(java.lang.String,int)
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/Summary/Initial/Initial()
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/Summary/Initial/exec(parquet.pig.convert.Tuple)
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/Summary/Final/Final()
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/TestSummary/t(java.lang.Object[])
parquet/pig/summary/TestSummary/testAlgebraic()#parquet/pig/summary/Summary/Intermediate/exec(parquet.pig.convert.Tuple)
parquet/pig/summary/TestSummary/t(java.lang.Object[])#java/util/Arrays/asList(T[])
parquet/hadoop/DeprecatedInputFormatTest/testReadWriteWithoutCounter()#parquet/hadoop/DeprecatedInputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/DeprecatedInputFormatTest/testReadWriteWithCountDeprecated()#parquet/hadoop/DeprecatedInputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/DeprecatedInputFormatTest/waitForJob(parquet.proto.utils.Job)#java/lang/Thread/sleep(long)
parquet/hadoop/DeprecatedInputFormatTest/waitForJob(parquet.proto.utils.Job)#java/io/PrintStream/println(char[])
parquet/hadoop/DeprecatedInputFormatTest/waitForJob(parquet.proto.utils.Job)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/DeprecatedInputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/example/ExampleOutputFormat/setSchema(parquet.proto.utils.Job,parquet.schema.MessageType)
parquet/hadoop/DeprecatedInputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/DeprecatedInputFormatTest/waitForJob(parquet.proto.utils.Job)
parquet/hadoop/DeprecatedInputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/DeprecatedInputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#java/lang/Class/getCanonicalName()
parquet/hadoop/DeprecatedInputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetOutputFormat/setCompression(parquet.proto.utils.Job,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/DeprecatedInputFormatTest/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#java/lang/Object/Object()
parquet/filter2/predicate/Operators/And/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.And)
parquet/proto/ProtoParquetReader/builder(parquet.hadoop.Path)#parquet/proto/ProtoReadSupport/ProtoReadSupport()
parquet/proto/ProtoParquetReader/builder(parquet.hadoop.Path)#parquet/hadoop/ParquetReader/builder(parquet.hadoop.api.ReadSupport,parquet.hadoop.Path)
parquet/thrift/ParquetProtocol/readListEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readMessageEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeI64(long)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeString(java.lang.String)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readSetEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readStructEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readI64()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readI32()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readMessageBegin()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeBool(boolean)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readMapBegin()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readFieldBegin()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readString()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeI16(short)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeStructEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readDouble()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeStructBegin(parquet.thrift.TStruct)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/getClassInfo()#java/lang/Class/getName()
parquet/thrift/ParquetProtocol/getClassInfo()#java/lang/Object/getClass()
parquet/thrift/ParquetProtocol/getClassInfo()#java/lang/Class/getEnclosingMethod()
parquet/thrift/ParquetProtocol/getClassInfo()#java/lang/reflect/Method/toGenericString()
parquet/thrift/ParquetProtocol/exception()#parquet/thrift/ParquetProtocol/getClassInfo()
parquet/thrift/ParquetProtocol/exception()#java/lang/Throwable/getStackTrace()
parquet/thrift/ParquetProtocol/exception()#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/thrift/ParquetProtocol/exception()#java/lang/StackTraceElement/getMethodName()
parquet/thrift/ParquetProtocol/exception()#java/lang/Exception/Exception()
parquet/thrift/ParquetProtocol/readMapEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeListBegin(parquet.thrift.TList)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeMessageEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readFieldEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readListBegin()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readBinary()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeSetEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readI16()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeI32(int)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeFieldStop()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readSetBegin()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readByte()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeListEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readBool()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/readStructBegin()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeMapEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeByte(byte)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeMapBegin(parquet.thrift.TMap)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeSetBegin(parquet.thrift.TSet)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeFieldBegin(parquet.thrift.TField)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeMessageBegin(parquet.thrift.TMessage)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeDouble(double)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeBinary(java.nio.ByteBuffer)#parquet/thrift/ParquetProtocol/exception()
parquet/thrift/ParquetProtocol/writeFieldEnd()#parquet/thrift/ParquetProtocol/exception()
parquet/column/statistics/Statistics/updateStats(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/StatisticsClassException/StatisticsClassException(java.lang.String,java.lang.String)
parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)#java/lang/Class/toString()
parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/incrementNumNulls(long)
parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)
parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)#java/lang/Object/getClass()
parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/Statistics/equals(parquet.column.statistics.Statistics)#java/util/Arrays/equals(byte[],byte[])
parquet/column/statistics/Statistics/equals(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/getMinBytes()
parquet/column/statistics/Statistics/equals(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/Statistics/equals(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/getMaxBytes()
parquet/column/statistics/Statistics/updateStats(boolean)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/statistics/Statistics/updateStats(long)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/statistics/Statistics/updateStats(double)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/statistics/Statistics/updateStats(parquet.io.api.Binary)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/UnknownColumnTypeException/UnknownColumnTypeException(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/BooleanStatistics/BooleanStatistics()
parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/FloatStatistics/FloatStatistics()
parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/DoubleStatistics/DoubleStatistics()
parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/LongStatistics/LongStatistics()
parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/column/statistics/Statistics/hashCode()#java/util/Arrays/hashCode(byte[])
parquet/column/statistics/Statistics/hashCode()#java/lang/Long/valueOf(long)
parquet/column/statistics/Statistics/hashCode()#parquet/column/statistics/Statistics/getMinBytes()
parquet/column/statistics/Statistics/hashCode()#java/lang/Long/hashCode()
parquet/column/statistics/Statistics/hashCode()#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/Statistics/hashCode()#parquet/column/statistics/Statistics/getMaxBytes()
parquet/column/statistics/Statistics/updateStats(float)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/bytes/BytesInput/StreamBytesInput/toByteArray()#java/io/DataInputStream/DataInputStream(java.io.InputStream)
parquet/bytes/BytesInput/StreamBytesInput/toByteArray()#parquet/Log/debug(java.lang.Object)
parquet/bytes/BytesInput/StreamBytesInput/toByteArray()#java/io/DataInputStream/readFully(byte[])
parquet/bytes/BytesInput/StreamBytesInput/writeAllTo(java.io.OutputStream)#parquet/bytes/BytesInput/StreamBytesInput/toByteArray()
parquet/bytes/BytesInput/StreamBytesInput/writeAllTo(java.io.OutputStream)#parquet/Log/debug(java.lang.Object)
parquet/bytes/BytesInput/StreamBytesInput/writeAllTo(java.io.OutputStream)#java/io/OutputStream/write(byte[])
parquet/avro/AvroIndexedRecordConverter/FieldStringConverter/addBinary(parquet.io.api.Binary)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldStringConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testNullMap()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testNullMap()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testNullContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testNullContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testRegularMap()#java/util/HashMap/HashMap()
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testRegularMap()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testRegularMap()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testRegularMap()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testHashMap()#java/util/HashMap/HashMap()
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testHashMap()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testHashMap()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testEmptyContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMap(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testEmptyContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector/getMapSize(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/testEmptyContainer()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/setUp()#org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector/TestableAbstractParquetMapInspector/TestableAbstractParquetMapInspector(org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
parquet/schema/Types/Builder/id(int)#parquet/schema/Types/Builder/self()
parquet/schema/Types/Builder/id(int)#parquet/schema/Type/ID/ID(int)
parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)#parquet/schema/Types/Builder/self()
parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/schema/Types/Builder/repetition(parquet.schema.Type.Repetition)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/schema/Types/Builder/as(parquet.schema.OriginalType)#parquet/schema/Types/Builder/self()
parquet/schema/Types/Builder/named(java.lang.String)#java/lang/Class/isAssignableFrom(java.lang.Class)
parquet/schema/Types/Builder/named(java.lang.String)#parquet/schema/Types/Builder/build(java.lang.String)
parquet/schema/Types/Builder/named(java.lang.String)#java/lang/Class/cast(java.lang.Object)
parquet/schema/Types/Builder/named(java.lang.String)#java/lang/Object/getClass()
parquet/schema/Types/Builder/named(java.lang.String)#parquet/schema/Types/GroupBuilder/addField(parquet.schema.Type)
parquet/schema/Types/Builder/named(java.lang.String)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/column/values/boundedint/BitWriter/writeByte(int)#parquet/column/values/boundedint/BitWriter/toBinary(int)
parquet/column/values/boundedint/BitWriter/writeByte(int)#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/column/values/boundedint/BitWriter/writeByte(int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/boundedint/BitWriter/writeBit(boolean)#parquet/column/values/boundedint/BitWriter/toBinary(int)
parquet/column/values/boundedint/BitWriter/writeBit(boolean)#parquet/column/values/boundedint/BitWriter/setBytePosition(int,int,boolean)
parquet/column/values/boundedint/BitWriter/writeBit(boolean)#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/column/values/boundedint/BitWriter/writeBit(boolean)#parquet/Log/debug(java.lang.Object)
parquet/column/values/boundedint/BitWriter/getMemSize()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/boundedint/BitWriter/writeNBitInteger(int,int)#parquet/column/values/boundedint/BitWriter/toBinary(int)
parquet/column/values/boundedint/BitWriter/writeNBitInteger(int,int)#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/column/values/boundedint/BitWriter/writeNBitInteger(int,int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/boundedint/BitWriter/writeNBitInteger(int,int)#parquet/column/values/boundedint/BitWriter/toBinary(int,int)
parquet/column/values/boundedint/BitWriter/writeUnsignedVarint(int)#parquet/column/values/boundedint/BitWriter/writeByte(int)
parquet/column/values/boundedint/BitWriter/toBinary(int,int)#java/lang/Integer/toBinaryString(int)
parquet/column/values/boundedint/BitWriter/toBinary(int,int)#java/lang/String/length()
parquet/column/values/boundedint/BitWriter/toBinary(int)#parquet/column/values/boundedint/BitWriter/toBinary(int,int)
parquet/column/values/boundedint/BitWriter/reset()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/column/values/boundedint/BitWriter/finish()#parquet/column/values/boundedint/BitWriter/toBinary(int)
parquet/column/values/boundedint/BitWriter/finish()#parquet/bytes/CapacityByteArrayOutputStream/write(int)
parquet/column/values/boundedint/BitWriter/finish()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/column/values/boundedint/BitWriter/finish()#parquet/Log/debug(java.lang.Object)
parquet/column/values/boundedint/BitWriter/getCapacity()#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/column/values/boundedint/BitWriter/memUsageString(java.lang.String)#parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)
parquet/hive/internal/Hive012Binding/pushFilters(parquet.cascading.JobConf,parquet.hive.internal.TableScanOperator)#parquet/Log/debug(java.lang.Object)
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,parquet.hadoop.Path)#parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,parquet.hadoop.Path)#parquet/hive/internal/Hive012Binding/init(parquet.cascading.JobConf)
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,parquet.hadoop.Path)#java/lang/Object/Object()
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/ArrayList/ArrayList()
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/Map/Entry/getValue()
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/Iterator/hasNext()
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#parquet/hive/internal/Hive012Binding/pushFilters(parquet.cascading.JobConf,parquet.hive.internal.TableScanOperator)
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/Iterator/next()
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/lang/String/equals(java.lang.Object)
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/Map/Entry/getKey()
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#parquet/Log/debug(java.lang.Object)
parquet/hive/internal/Hive012Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/ArrayList/add(E)
parquet/hive/internal/Hive012Binding/init(parquet.cascading.JobConf)#java/lang/String/length()
parquet/hive/internal/Hive012Binding/init(parquet.cascading.JobConf)#java/lang/Object/Object()
parquet/filter2/compat/FilterCompat/NoOpFilter/accept(parquet.filter2.compat.FilterCompat.Visitor)#parquet/filter2/compat/FilterCompat/Visitor/visit(parquet.filter2.compat.FilterCompat.NoOpFilter)
parquet/proto/ProtoMessageConverter/ProtoBooleanConverter/addBoolean(boolean)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#parquet/pig/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#parquet/io/ExpectationValidatingRecordConsumer/ExpectationValidatingRecordConsumer(java.util.Deque)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#parquet/pig/TupleWriteSupport/write(parquet.pig.convert.Tuple)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#java/util/Arrays/asList(T[])
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#parquet/pig/TupleWriteSupport/TupleWriteSupport(parquet.pig.convert.Schema)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#java/util/ArrayDeque/ArrayDeque(java.util.Collection)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#parquet/pig/PigSchemaConverter/PigSchemaConverter()
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#parquet/pig/TupleWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#parquet/Log/info(java.lang.Object)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)#java/lang/Object/Object()
parquet/thrift/TestParquetWriteProtocol/testOneOfEach()#parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testOneOfEach()#java/util/Arrays/copyOf(U[],int,java.lang.Class)
parquet/thrift/TestParquetWriteProtocol/testOneOfEach()#java/nio/ByteBuffer/wrap(byte[])
parquet/thrift/TestParquetWriteProtocol/testOneOfEach()#java/lang/String/getBytes()
parquet/thrift/TestParquetWriteProtocol/testOneOfEach()#parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testOneOfEach()#java/util/ArrayList/ArrayList()
parquet/thrift/TestParquetWriteProtocol/testMapInSet()#parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testMapInSet()#parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testMapInSet()#java/util/HashMap/HashMap()
parquet/thrift/TestParquetWriteProtocol/testMapInSet()#java/util/Set/add(E)
parquet/thrift/TestParquetWriteProtocol/testMapInSet()#java/util/Map/put(K,V)
parquet/thrift/TestParquetWriteProtocol/testMapInSet()#java/util/HashSet/HashSet()
parquet/thrift/TestParquetWriteProtocol/testStructInMap()#parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testStructInMap()#java/util/Collections/singletonMap(K,V)
parquet/thrift/TestParquetWriteProtocol/testStructInMap()#parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testStructInMap()#java/util/HashMap/HashMap()
parquet/thrift/TestParquetWriteProtocol/testStructInMap()#java/lang/Object/Object()
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/io/ExpectationValidatingRecordConsumer/ExpectationValidatingRecordConsumer(java.util.Deque)
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/io/RecordConsumerLoggingWrapper/RecordConsumerLoggingWrapper(parquet.io.api.RecordConsumer)
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#java/util/ArrayDeque/ArrayDeque(java.util.Collection)
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/Log/info(java.lang.Object)
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/thrift/ParquetWriteProtocol/ParquetWriteProtocol(parquet.io.api.RecordConsumer,parquet.io.MessageColumnIO,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)#java/util/Arrays/asList(T[])
parquet/thrift/TestParquetWriteProtocol/testProtocolAddressBook()#java/util/Arrays/copyOf(U[],int,java.lang.Class)
parquet/thrift/TestParquetWriteProtocol/testProtocolAddressBook()#java/lang/Object/Object()
parquet/thrift/TestParquetWriteProtocol/testProtocolAddressBook()#parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testProtocolAddressBook()#java/util/ArrayList/ArrayList()
parquet/thrift/TestParquetWriteProtocol/testProtocolAddressBook()#parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testProtocolAddressBook()#java/util/Arrays/asList(T[])
parquet/thrift/TestParquetWriteProtocol/testNameList()#parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testNameList()#java/util/List/add(E)
parquet/thrift/TestParquetWriteProtocol/testNameList()#parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testNameList()#java/util/ArrayList/ArrayList()
parquet/thrift/TestParquetWriteProtocol/testProtocolEmptyAdressBook()#parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testProtocolEmptyAdressBook()#parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testProtocolEmptyAdressBook()#java/util/ArrayList/ArrayList()
parquet/thrift/TestParquetWriteProtocol/testMap()#parquet/thrift/TestParquetWriteProtocol/validatePig(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testMap()#parquet/thrift/TestParquetWriteProtocol/validateThrift(java.lang.String[],parquet.thrift.TBase)
parquet/thrift/TestParquetWriteProtocol/testMap()#java/util/TreeMap/TreeMap()
parquet/thrift/TestParquetWriteProtocol/testMap()#java/util/Map/put(K,V)
parquet/bytes/LittleEndianDataInputStream/readDouble()#parquet/bytes/LittleEndianDataInputStream/readLong()
parquet/bytes/LittleEndianDataInputStream/readDouble()#java/lang/Double/longBitsToDouble(long)
parquet/bytes/LittleEndianDataInputStream/readFully(byte[],int,int)#java/io/InputStream/read(byte[],int,int)
parquet/bytes/LittleEndianDataInputStream/readFully(byte[],int,int)#java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException()
parquet/bytes/LittleEndianDataInputStream/readFully(byte[],int,int)#java/io/EOFException/EOFException()
parquet/bytes/LittleEndianDataInputStream/available()#java/io/InputStream/available()
parquet/bytes/LittleEndianDataInputStream/readFully(byte[])#parquet/bytes/LittleEndianDataInputStream/readFully(byte[],int,int)
parquet/bytes/LittleEndianDataInputStream/readLong()#parquet/bytes/LittleEndianDataInputStream/readFully(byte[],int,int)
parquet/bytes/LittleEndianDataInputStream/mark(int)#java/io/InputStream/mark(int)
parquet/bytes/LittleEndianDataInputStream/hashCode()#java/lang/Object/hashCode()
parquet/bytes/LittleEndianDataInputStream/readInt()#java/io/InputStream/read()
parquet/bytes/LittleEndianDataInputStream/readInt()#java/io/EOFException/EOFException()
parquet/bytes/LittleEndianDataInputStream/readByte()#java/io/InputStream/read()
parquet/bytes/LittleEndianDataInputStream/readByte()#java/io/EOFException/EOFException()
parquet/bytes/LittleEndianDataInputStream/skip(long)#java/io/InputStream/skip(long)
parquet/bytes/LittleEndianDataInputStream/markSupported()#java/io/InputStream/markSupported()
parquet/bytes/LittleEndianDataInputStream/read(byte[],int,int)#java/io/InputStream/read(byte[],int,int)
parquet/bytes/LittleEndianDataInputStream/readFloat()#java/lang/Float/intBitsToFloat(int)
parquet/bytes/LittleEndianDataInputStream/readFloat()#parquet/bytes/LittleEndianDataInputStream/readInt()
parquet/bytes/LittleEndianDataInputStream/readShort()#java/io/InputStream/read()
parquet/bytes/LittleEndianDataInputStream/readShort()#java/io/EOFException/EOFException()
parquet/bytes/LittleEndianDataInputStream/read(byte[])#java/io/InputStream/read(byte[])
parquet/bytes/LittleEndianDataInputStream/equals(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
parquet/bytes/LittleEndianDataInputStream/readUnsignedByte()#java/io/InputStream/read()
parquet/bytes/LittleEndianDataInputStream/readUnsignedByte()#java/io/EOFException/EOFException()
parquet/bytes/LittleEndianDataInputStream/reset()#java/io/InputStream/reset()
parquet/bytes/LittleEndianDataInputStream/skipBytes(int)#java/io/InputStream/skip(long)
parquet/bytes/LittleEndianDataInputStream/readUnsignedShort()#java/io/InputStream/read()
parquet/bytes/LittleEndianDataInputStream/readUnsignedShort()#java/io/EOFException/EOFException()
parquet/bytes/LittleEndianDataInputStream/readBoolean()#java/io/InputStream/read()
parquet/bytes/LittleEndianDataInputStream/readBoolean()#java/io/EOFException/EOFException()
parquet/bytes/LittleEndianDataInputStream/read()#java/io/InputStream/read()
parquet/bytes/LittleEndianDataInputStream/close()#java/io/InputStream/close()
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/io/api/RecordConsumer/startMessage()
parquet/pig/GenerateTPCH/main(java.lang.String[])#java/io/PrintStream/println(java.lang.String)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/memSize()
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/pig/GenerateIntTestFile/readTestFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/maxColMemSize()
parquet/pig/GenerateTPCH/main(java.lang.String[])#java/io/File/File(java.lang.String)
parquet/pig/GenerateTPCH/main(java.lang.String[])#java/io/File/toURI()
parquet/pig/GenerateTPCH/main(java.lang.String[])#java/io/File/getAbsolutePath()
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/allocatedSize()
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/memUsageString()
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/Log/error(java.lang.Object,java.lang.Throwable)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/io/api/RecordConsumer/endMessage()
parquet/pig/GenerateTPCH/main(java.lang.String[])#java/io/File/exists()
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/pig/GenerateIntTestFile/writeToFile(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,int)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/pig/GenerateTPCH/main(java.lang.String[])#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/GenerateTPCH/main(java.lang.String[])#java/io/PrintStream/printf(java.lang.String,java.lang.Object[])
parquet/pig/GenerateTPCH/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/pig/GenerateTPCH/main(java.lang.String[])#java/io/File/delete()
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#java/lang/Class/getName()
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#java/lang/Object/getClass()
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/pig/GenerateTPCH/writeField(parquet.io.api.RecordConsumer,int,java.lang.String,java.lang.Object)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/statistics/BinaryStatistics/initializeStats(parquet.io.api.Binary,parquet.io.api.Binary)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/BinaryStatistics/toString()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/statistics/BinaryStatistics/toString()#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/BinaryStatistics/toString()#parquet/io/api/Binary/toStringUsingUTF8()
parquet/column/statistics/BinaryStatistics/toString()#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/BinaryStatistics/getMinBytes()#parquet/io/api/Binary/getBytes()
parquet/column/statistics/BinaryStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/io/api/Binary/fromByteArray(byte[])
parquet/column/statistics/BinaryStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/BinaryStatistics/updateStats(parquet.io.api.Binary,parquet.io.api.Binary)#parquet/io/api/Binary/compareTo(parquet.io.api.Binary)
parquet/column/statistics/BinaryStatistics/setMinMax(parquet.io.api.Binary,parquet.io.api.Binary)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/BinaryStatistics/updateStats(parquet.io.api.Binary)#parquet/column/statistics/BinaryStatistics/initializeStats(parquet.io.api.Binary,parquet.io.api.Binary)
parquet/column/statistics/BinaryStatistics/updateStats(parquet.io.api.Binary)#parquet/column/statistics/BinaryStatistics/updateStats(parquet.io.api.Binary,parquet.io.api.Binary)
parquet/column/statistics/BinaryStatistics/updateStats(parquet.io.api.Binary)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/BinaryStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/BinaryStatistics/initializeStats(parquet.io.api.Binary,parquet.io.api.Binary)
parquet/column/statistics/BinaryStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/BinaryStatistics/getMax()
parquet/column/statistics/BinaryStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/BinaryStatistics/getMin()
parquet/column/statistics/BinaryStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/BinaryStatistics/updateStats(parquet.io.api.Binary,parquet.io.api.Binary)
parquet/column/statistics/BinaryStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/BinaryStatistics/getMaxBytes()#parquet/io/api/Binary/getBytes()
parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/schema/Types/Builder/named(java.lang.String)
parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/thrift/ThriftSchemaConvertVisitor/isCurrentlyMatchedFilter()
parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/schema/Types/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)
parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.I32Type)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.EnumType)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/projection/FieldsPath/push(parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftType/MapType/getValue()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type,parquet.schema.Type)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/projection/ThriftProjectionException/ThriftProjectionException(java.lang.String)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftType/MapType/getKey()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/projection/FieldsPath/pop()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/ThriftSchemaConvertVisitor/isCurrentlyMatchedFilter()#parquet/thrift/projection/FieldProjectionFilter/isMatched(parquet.thrift.projection.FieldsPath)
parquet/thrift/ThriftSchemaConvertVisitor/getConvertedMessageType()#parquet/schema/GroupType/getFields()
parquet/thrift/ThriftSchemaConvertVisitor/getConvertedMessageType()#parquet/schema/Type/asGroupType()
parquet/thrift/ThriftSchemaConvertVisitor/getConvertedMessageType()#java/util/ArrayList/ArrayList()
parquet/thrift/ThriftSchemaConvertVisitor/getConvertedMessageType()#parquet/schema/MessageType/MessageType(java.lang.String,java.util.List)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.I64Type)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#parquet/thrift/projection/FieldsPath/push(parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#java/util/ArrayList/ArrayList()
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#parquet/thrift/struct/ThriftField/getFieldId()
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#parquet/thrift/struct/ThriftType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#java/util/List/size()
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#parquet/thrift/struct/ThriftField/getName()
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#java/util/List/add(E)
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#java/util/List/get(int)
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#parquet/schema/Type/withId(int)
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#parquet/thrift/ThriftSchemaConvertVisitor/getRepetition(parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)#parquet/thrift/projection/FieldsPath/pop()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/struct/ThriftType/SetType/getValues()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/struct/ThriftType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#parquet/schema/ConversionPatterns/listType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/struct/ThriftType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#parquet/schema/ConversionPatterns/listType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/struct/ThriftType/ListType/getValues()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/ThriftSchemaConvertVisitor/getFieldsTypes(java.util.List)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,java.util.List)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/getChildren()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#java/util/List/size()
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.StringType)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.DoubleType)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.BoolType)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.I16Type)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/thrift/ThriftSchemaConvertVisitor/getRepetition(parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getRequirement()
parquet/thrift/ThriftSchemaConvertVisitor/getRepetition(parquet.thrift.struct.ThriftField)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/ThriftSchemaConvertVisitor/visit(parquet.thrift.struct.ThriftType.ByteType)#parquet/thrift/ThriftSchemaConvertVisitor/primitiveType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/filter2/statisticslevel/TestStatisticsFilter/SevensAndEightsUdp/inverseCanDrop(parquet.filter2.predicate.Statistics)#parquet/filter2/predicate/Statistics/getMax()
parquet/filter2/statisticslevel/TestStatisticsFilter/SevensAndEightsUdp/inverseCanDrop(parquet.filter2.predicate.Statistics)#parquet/filter2/predicate/Statistics/getMin()
parquet/filter2/statisticslevel/TestStatisticsFilter/SevensAndEightsUdp/canDrop(parquet.filter2.predicate.Statistics)#parquet/filter2/predicate/Statistics/getMax()
parquet/filter2/statisticslevel/TestStatisticsFilter/SevensAndEightsUdp/canDrop(parquet.filter2.predicate.Statistics)#parquet/filter2/predicate/Statistics/getMin()
parquet/filter2/statisticslevel/TestStatisticsFilter/SevensAndEightsUdp/keep(java.lang.Integer)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/avro/AvroIndexedRecordConverter/FieldDoubleConverter/addInt(int)#java/lang/Double/valueOf(double)
parquet/avro/AvroIndexedRecordConverter/FieldDoubleConverter/addInt(int)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldDoubleConverter/addFloat(float)#java/lang/Double/valueOf(double)
parquet/avro/AvroIndexedRecordConverter/FieldDoubleConverter/addFloat(float)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldDoubleConverter/addDouble(double)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldDoubleConverter/addLong(long)#java/lang/Double/valueOf(double)
parquet/avro/AvroIndexedRecordConverter/FieldDoubleConverter/addLong(long)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/thrift/struct/ThriftType/fromJSON(java.lang.String)#parquet/thrift/struct/JSON/fromJSON(java.lang.String,java.lang.Class)
parquet/thrift/struct/ThriftType/hashCode()#java/lang/Enum/hashCode()
parquet/thrift/struct/ThriftType/toJSON()#parquet/thrift/struct/JSON/toJSON(java.lang.Object)
parquet/thrift/struct/ThriftType/toString()#parquet/thrift/struct/ThriftType/toJSON()
parquet/cascading/ParquetTupleScheme/readSchema(parquet.cascading.FlowProcess,parquet.cascading.Tap)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/cascading/ParquetTupleScheme/readSchema(parquet.cascading.FlowProcess,parquet.cascading.Tap)#parquet/cascading/ParquetTupleScheme/getFooters(parquet.cascading.FlowProcess,parquet.cascading.Hfs)
parquet/cascading/ParquetTupleScheme/readSchema(parquet.cascading.FlowProcess,parquet.cascading.Tap)#java/util/List/get(int)
parquet/cascading/ParquetTupleScheme/readSchema(parquet.cascading.FlowProcess,parquet.cascading.Tap)#java/util/List/isEmpty()
parquet/cascading/ParquetTupleScheme/readSchema(parquet.cascading.FlowProcess,parquet.cascading.Tap)#parquet/hadoop/Footer/getParquetMetadata()
parquet/cascading/ParquetTupleScheme/readSchema(parquet.cascading.FlowProcess,parquet.cascading.Tap)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/cascading/ParquetTupleScheme/readSchema(parquet.cascading.FlowProcess,parquet.cascading.Tap)#java/lang/Object/Object()
parquet/cascading/ParquetTupleScheme/getFooters(parquet.cascading.FlowProcess,parquet.cascading.Hfs)#parquet/hadoop/mapred/DeprecatedParquetInputFormat/DeprecatedParquetInputFormat()
parquet/cascading/ParquetTupleScheme/getFooters(parquet.cascading.FlowProcess,parquet.cascading.Hfs)#parquet/hadoop/mapred/DeprecatedParquetInputFormat/getFooters(parquet.cascading.JobConf)
parquet/cascading/ParquetTupleScheme/retrieveSourceFields(parquet.cascading.FlowProcess,parquet.cascading.Tap)#parquet/cascading/ParquetTupleScheme/readSchema(parquet.cascading.FlowProcess,parquet.cascading.Tap)
parquet/cascading/ParquetTupleScheme/retrieveSourceFields(parquet.cascading.FlowProcess,parquet.cascading.Tap)#parquet/cascading/SchemaIntersection/SchemaIntersection(parquet.schema.MessageType,parquet.cascading.Fields)
parquet/cascading/ParquetTupleScheme/retrieveSourceFields(parquet.cascading.FlowProcess,parquet.cascading.Tap)#parquet/cascading/SchemaIntersection/getSourceFields()
parquet/cascading/ParquetTupleScheme/sinkConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/ParquetOutputFormat/setWriteSupportClass(parquet.proto.utils.Job,java.lang.Class)
parquet/cascading/ParquetTupleScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)
parquet/cascading/ParquetTupleScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/ParquetInputFormat/setReadSupportClass(parquet.proto.utils.Job,java.lang.Class)
parquet/cascading/ParquetTupleScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/cascading/TupleReadSupport/setRequestedFields(parquet.cascading.JobConf,parquet.cascading.Fields)
parquet/encoding/Generator/main(java.lang.String[])#parquet/encoding/bitpacking/IntBasedBitPackingGenerator/main(java.lang.String[])
parquet/encoding/Generator/main(java.lang.String[])#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/main(java.lang.String[])
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeFieldBegin(parquet.thrift.TField)#parquet/io/ColumnIO/getType()
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeFieldBegin(parquet.thrift.TField)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeFieldBegin(parquet.thrift.TField)#parquet/io/ColumnIO/getName()
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeFieldBegin(parquet.thrift.TField)#parquet/io/ColumnIO/getIndex()
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeFieldBegin(parquet.thrift.TField)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeFieldEnd()#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeFieldEnd()#parquet/io/ColumnIO/getName()
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeFieldEnd()#parquet/io/ColumnIO/getIndex()
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeStructBegin(parquet.thrift.TStruct)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeStructBegin(parquet.thrift.TStruct)#parquet/io/api/RecordConsumer/startGroup()
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeStructEnd()#parquet/io/api/RecordConsumer/endGroup()
parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/writeStructEnd()#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ThriftRecordConverter/GroupCounter/start()#parquet/io/api/GroupConverter/start()
parquet/thrift/ThriftRecordConverter/GroupCounter/end()#parquet/io/api/GroupConverter/end()
parquet/thrift/ThriftRecordConverter/GroupCounter/getConverter(int)#parquet/io/api/GroupConverter/getConverter(int)
parquet/thrift/struct/ThriftType/EnumValue/equals(java.lang.Object)#java/lang/String/equals(java.lang.Object)
parquet/thrift/struct/ThriftType/EnumValue/hashCode()#java/lang/String/hashCode()
parquet/filter2/recordlevel/TestRecordLevelFilters/StartWithP/keep(parquet.io.api.Binary)#java/lang/String/startsWith(java.lang.String)
parquet/filter2/recordlevel/TestRecordLevelFilters/StartWithP/keep(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/hadoop/api/DelegatingReadSupport/toString()#java/lang/Object/toString()
parquet/hadoop/api/DelegatingReadSupport/toString()#java/lang/Class/getName()
parquet/hadoop/api/DelegatingReadSupport/toString()#java/lang/Object/getClass()
parquet/hadoop/api/DelegatingReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/init(parquet.hadoop.api.InitContext)
parquet/hadoop/api/DelegatingReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/FixedLenByteArrayPlainValuesWriter(int,int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/ValuesWriter/createDictionaryPage()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/createDictionaryPage()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,parquet.column.Encoding)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/createDictionaryPage()#java/util/Iterator/next()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter/getBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/copy(parquet.io.api.Binary)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/dictionary/IntList/add(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFixedLenArrayDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/dictionary/DictionaryValuesWriter/checkAndFallbackIfNeeded()
parquet/io/api/Binary/ByteArraySliceBackedBinary/compareTo(parquet.io.api.Binary)#parquet/io/api/Binary/compareTo(byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/equals(parquet.io.api.Binary)#parquet/io/api/Binary/equals(byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/getBytes()#java/util/Arrays/copyOfRange(byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/compareTo(byte[],int,int)#parquet/io/api/Binary/compareTwoByteArrays(byte[],int,int,byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/hashCode()#parquet/io/api/Binary/hashCode(byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/toStringUsingUTF8()#java/nio/charset/Charset/decode(java.nio.ByteBuffer)
parquet/io/api/Binary/ByteArraySliceBackedBinary/toStringUsingUTF8()#java/nio/ByteBuffer/wrap(byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/toStringUsingUTF8()#java/nio/CharBuffer/toString()
parquet/io/api/Binary/ByteArraySliceBackedBinary/equals(byte[],int,int)#parquet/io/api/Binary/equals(byte[],int,int,byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/writeTo(java.io.DataOutput)#java/io/DataOutput/write(byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/writeTo(java.io.OutputStream)#java/io/OutputStream/write(byte[],int,int)
parquet/io/api/Binary/ByteArraySliceBackedBinary/toByteBuffer()#java/nio/ByteBuffer/wrap(byte[],int,int)
parquet/io/EmptyRecordReader/read()#parquet/io/api/RecordMaterializer/getCurrentRecord()
parquet/io/EmptyRecordReader/read()#parquet/io/api/GroupConverter/end()
parquet/io/EmptyRecordReader/read()#parquet/io/api/GroupConverter/start()
parquet/column/values/plain/FixedLenByteArrayPlainValuesReader/readBytes()#parquet/io/api/Binary/fromByteArray(byte[],int,int)
parquet/column/values/plain/FixedLenByteArrayPlainValuesReader/readBytes()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/FixedLenByteArrayPlainValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/tools/read/SimpleRecordConverter/StringConverter/addBinary(parquet.io.api.Binary)#parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)
parquet/tools/read/SimpleRecordConverter/StringConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.And)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/BinaryLogical/getLeft()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.And)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.And)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/BinaryLogical/getRight()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Or)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/BinaryLogical/getLeft()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Or)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Or)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/BinaryLogical/getRight()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/reset(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/reset(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/reset()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/Map/get(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getReadSupportMetadata()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter/DataWritableRecordConverter(parquet.schema.GroupType,parquet.schema.GroupType)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/getColumns(java.lang.String)#parquet/hive/HiveBinding/getColumns(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/getColumns(java.lang.String)#parquet/hive/HiveBindingFactory/create()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/getColumns(java.lang.String)#parquet/hive/HiveBindingFactory/HiveBindingFactory()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/schema/GroupType/containsField(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/schema/Type/toString()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType,java.util.Map)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/util/HashMap/HashMap()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/util/List/add(E)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/util/List/get(int)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/util/Map/put(K,V)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/getColumns(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/schema/Type/getName()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/util/List/size()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/schema/MessageType/MessageType(java.lang.String,java.util.List)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/schema/GroupType/getType(int)
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/schema/GroupType/getFieldCount()
org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#parquet/schema/GroupType/getType(java.lang.String)
parquet/column/statistics/FloatStatistics/toString()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/statistics/FloatStatistics/toString()#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/FloatStatistics/toString()#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/FloatStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/bytes/BytesUtils/bytesToInt(byte[])
parquet/column/statistics/FloatStatistics/setMinMaxFromBytes(byte[],byte[])#java/lang/Float/intBitsToFloat(int)
parquet/column/statistics/FloatStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/FloatStatistics/setMinMax(float,float)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/FloatStatistics/getMinBytes()#java/lang/Float/floatToIntBits(float)
parquet/column/statistics/FloatStatistics/getMinBytes()#parquet/bytes/BytesUtils/intToBytes(int)
parquet/column/statistics/FloatStatistics/initializeStats(float,float)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/FloatStatistics/updateStats(float)#parquet/column/statistics/FloatStatistics/updateStats(float,float)
parquet/column/statistics/FloatStatistics/updateStats(float)#parquet/column/statistics/FloatStatistics/initializeStats(float,float)
parquet/column/statistics/FloatStatistics/updateStats(float)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/FloatStatistics/getMaxBytes()#java/lang/Float/floatToIntBits(float)
parquet/column/statistics/FloatStatistics/getMaxBytes()#parquet/bytes/BytesUtils/intToBytes(int)
parquet/column/statistics/FloatStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/FloatStatistics/initializeStats(float,float)
parquet/column/statistics/FloatStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/FloatStatistics/getMin()
parquet/column/statistics/FloatStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/FloatStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/FloatStatistics/updateStats(float,float)
parquet/column/statistics/FloatStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/FloatStatistics/getMax()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/Or/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/Visitor/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Or)
parquet/avro/AvroParquetWriter/writeSupport(parquet.pig.convert.Schema)#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/AvroParquetWriter/writeSupport(parquet.pig.convert.Schema)#parquet/avro/AvroWriteSupport/AvroWriteSupport(parquet.schema.MessageType,parquet.pig.convert.Schema)
parquet/avro/AvroParquetWriter/writeSupport(parquet.pig.convert.Schema)#parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)
parquet/hadoop/ClientSideMetadataSplitStrategy/HDFSBlocks/checkBelongingToANewHDFSBlock(parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/ClientSideMetadataSplitStrategy/HDFSBlocks/getHDFSBlockEndingPosition(int)
parquet/hadoop/ClientSideMetadataSplitStrategy/HDFSBlocks/checkBelongingToANewHDFSBlock(parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/BlockMetaData/getCompressedSize()
parquet/hadoop/ClientSideMetadataSplitStrategy/HDFSBlocks/checkBelongingToANewHDFSBlock(parquet.hadoop.metadata.BlockMetaData)#parquet/hadoop/metadata/BlockMetaData/getStartingPos()
parquet/hadoop/ClientSideMetadataSplitStrategy/HDFSBlocks/checkBelongingToANewHDFSBlock(parquet.hadoop.metadata.BlockMetaData)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/proto/ProtoReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/getSchemaForRead(parquet.schema.MessageType,java.lang.String)
parquet/proto/ProtoReadSupport/init(parquet.hadoop.api.InitContext)#java/lang/String/trim()
parquet/proto/ProtoReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getConfiguration()
parquet/proto/ProtoReadSupport/init(parquet.hadoop.api.InitContext)#java/lang/String/isEmpty()
parquet/proto/ProtoReadSupport/init(parquet.hadoop.api.InitContext)#parquet/Log/debug(java.lang.Object)
parquet/proto/ProtoReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getFileSchema()
parquet/proto/ProtoReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType)
parquet/proto/ProtoReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/proto/ProtoReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/proto/ProtoRecordMaterializer/ProtoRecordMaterializer(parquet.schema.MessageType,java.lang.Class)
parquet/proto/ProtoReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/Map/get(java.lang.Object)
parquet/proto/ProtoReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/Log/debug(java.lang.Object)
parquet/proto/ProtoReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/TaskSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/ArrayList/ArrayList()
parquet/hadoop/TaskSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/hadoop/TaskSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/schema/Type/toString()
parquet/hadoop/TaskSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#java/util/List/addAll(java.util.Collection)
parquet/hadoop/TaskSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)
parquet/hadoop/TaskSideMetadataSplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getReadSupportMetadata()
parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet/hadoop/BlockLocation[],parquet/hadoop/FileStatus,java/lang/String,java/util/Map,long,long)/$anonymous1/()
parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#java/util/ArrayList/ArrayList()
parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#java/util/Arrays/sort(T[],java.util.Comparator)
parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#parquet/hadoop/ParquetInputSplit/ParquetInputSplit(parquet.hadoop.Path,long,long,long,java.lang.String[],long[],java.lang.String,java.util.Map)
parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#java/util/List/add(E)
parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#parquet/hadoop/TaskSideMetadataSplitStrategy/findBlockIndex(parquet.hadoop.BlockLocation[],long)
parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/tools/read/SimpleRecordConverter/start()#parquet/tools/read/SimpleRecord/SimpleRecord()
parquet/tools/read/SimpleRecordConverter/createConverter(parquet.schema.Type)#parquet/schema/Type/asGroupType()
parquet/tools/read/SimpleRecordConverter/createConverter(parquet.schema.Type)#parquet/schema/Type/isPrimitive()
parquet/tools/read/SimpleRecordConverter/createConverter(parquet.schema.Type)#parquet/tools/read/SimpleRecordConverter/SimpleRecordConverter(parquet.schema.GroupType,java.lang.String,parquet.tools.read.SimpleRecordConverter)
parquet/tools/read/SimpleRecordConverter/createConverter(parquet.schema.Type)#parquet/tools/read/SimpleRecordConverter/StringConverter/StringConverter(java.lang.String)
parquet/tools/read/SimpleRecordConverter/createConverter(parquet.schema.Type)#parquet/tools/read/SimpleRecordConverter/SimplePrimitiveConverter/SimplePrimitiveConverter(java.lang.String)
parquet/tools/read/SimpleRecordConverter/createConverter(parquet.schema.Type)#parquet/schema/Type/getName()
parquet/tools/read/SimpleRecordConverter/createConverter(parquet.schema.Type)#parquet/schema/Type/getOriginalType()
parquet/tools/read/SimpleRecordConverter/end()#parquet/tools/read/SimpleRecordConverter/getCurrentRecord()
parquet/tools/read/SimpleRecordConverter/end()#parquet/tools/read/SimpleRecord/add(java.lang.String,java.lang.Object)
parquet/pig/convert/TupleConverter/FieldBooleanConverter/addBinary(parquet.io.api.Binary)#java/lang/Boolean/parseBoolean(java.lang.String)
parquet/pig/convert/TupleConverter/FieldBooleanConverter/addBinary(parquet.io.api.Binary)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldBooleanConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/pig/convert/TupleConverter/FieldBooleanConverter/addInt(int)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldBooleanConverter/addFloat(float)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldBooleanConverter/addDouble(double)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldBooleanConverter/addBoolean(boolean)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldBooleanConverter/addLong(long)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/summary/Summary/JSONTuple/iterator()#parquet/pig/summary/Summary/JSONTuple/getAll()
parquet/pig/summary/Summary/JSONTuple/iterator()#java/util/List/iterator()
parquet/pig/summary/Summary/JSONTuple/compareTo(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/pig/summary/Summary/JSONTuple/set(int,java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/pig/summary/Summary/JSONTuple/append(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/pig/summary/Summary/JSONTuple/json()#parquet/pig/summary/SummaryData/toJSON(parquet.pig.summary.SummaryData)
parquet/pig/summary/Summary/JSONTuple/get(int)#parquet/pig/summary/Summary/JSONTuple/json()
parquet/pig/summary/Summary/JSONTuple/getAll()#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/pig/summary/Summary/JSONTuple/getAll()#java/util/Arrays/asList(T[])
parquet/pig/summary/Summary/JSONTuple/getAll()#parquet/pig/summary/Summary/JSONTuple/json()
parquet/pig/summary/Summary/JSONTuple/reference(parquet.pig.convert.Tuple)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/pig/summary/Summary/JSONTuple/toDelimitedString(java.lang.String)#parquet/pig/summary/Summary/JSONTuple/json()
parquet/pig/summary/Summary/JSONTuple/write(java.io.DataOutput)#parquet/pig/summary/Summary/JSONTuple/json()
parquet/pig/summary/Summary/JSONTuple/readFields(java.io.DataInput)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/lt(C,T)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/Operators/LogicalNotUserDefined/LogicalNotUserDefined(parquet.filter2.predicate.Operators.UserDefined)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/LogicalInverter/invert(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/not(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/ltEq(C,T)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/gt(C,T)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/gtEq(C,T)
parquet/filter2/predicate/TestLogicalInverter/testBaseCases()#parquet/filter2/predicate/FilterApi/userDefined(parquet.filter2.predicate.Operators.Column,java.lang.Class)
parquet/filter2/predicate/TestLogicalInverter/testComplex()#parquet/filter2/predicate/LogicalInverter/invert(parquet.filter2.predicate.FilterPredicate)
parquet/hive/internal/Hive010Binding/pushFilters(parquet.cascading.JobConf,parquet.hive.internal.TableScanOperator)#parquet/Log/debug(java.lang.Object)
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,parquet.hadoop.Path)#parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,parquet.hadoop.Path)#parquet/hive/internal/Hive010Binding/init(parquet.cascading.JobConf)
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,parquet.hadoop.Path)#java/lang/Object/Object()
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/ArrayList/ArrayList()
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/Map/Entry/getValue()
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/Iterator/next()
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/lang/String/equals(java.lang.Object)
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/Map/Entry/getKey()
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#parquet/Log/debug(java.lang.Object)
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/ArrayList/add(E)
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#java/util/Iterator/hasNext()
parquet/hive/internal/Hive010Binding/pushProjectionsAndFilters(parquet.cascading.JobConf,java.lang.String,java.lang.String)#parquet/hive/internal/Hive010Binding/pushFilters(parquet.cascading.JobConf,parquet.hive.internal.TableScanOperator)
parquet/hive/internal/Hive010Binding/init(parquet.cascading.JobConf)#java/lang/String/length()
parquet/hive/internal/Hive010Binding/init(parquet.cascading.JobConf)#java/lang/Object/Object()
parquet/avro/AvroIndexedRecordConverter/FieldBytesConverter/addBinary(parquet.io.api.Binary)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/FieldBytesConverter/addBinary(parquet.io.api.Binary)#java/nio/ByteBuffer/wrap(byte[])
parquet/avro/AvroIndexedRecordConverter/FieldBytesConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/example/data/GroupValueSource/getBoolean(java.lang.String,int)#parquet/example/data/GroupValueSource/getBoolean(int,int)
parquet/example/data/GroupValueSource/getBoolean(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getBoolean(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getInt96(java.lang.String,int)#parquet/example/data/GroupValueSource/getInt96(int,int)
parquet/example/data/GroupValueSource/getInt96(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getInt96(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getLong(java.lang.String,int)#parquet/example/data/GroupValueSource/getLong(int,int)
parquet/example/data/GroupValueSource/getLong(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getLong(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getGroup(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getGroup(java.lang.String,int)#parquet/example/data/GroupValueSource/getGroup(int,int)
parquet/example/data/GroupValueSource/getGroup(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getBinary(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getBinary(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getBinary(java.lang.String,int)#parquet/example/data/GroupValueSource/getBinary(int,int)
parquet/example/data/GroupValueSource/getFieldRepetitionCount(java.lang.String)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getFieldRepetitionCount(java.lang.String)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getFieldRepetitionCount(java.lang.String)#parquet/example/data/GroupValueSource/getFieldRepetitionCount(int)
parquet/example/data/GroupValueSource/getFloat(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getFloat(java.lang.String,int)#parquet/example/data/GroupValueSource/getFloat(int,int)
parquet/example/data/GroupValueSource/getFloat(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getInteger(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getInteger(java.lang.String,int)#parquet/example/data/GroupValueSource/getInteger(int,int)
parquet/example/data/GroupValueSource/getInteger(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getString(java.lang.String,int)#parquet/example/data/GroupValueSource/getString(int,int)
parquet/example/data/GroupValueSource/getString(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getString(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/GroupValueSource/getDouble(java.lang.String,int)#parquet/example/data/GroupValueSource/getDouble(int,int)
parquet/example/data/GroupValueSource/getDouble(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/GroupValueSource/getDouble(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testOne_0()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testOne_1()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testOne_9_1s()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/toString(int[])#java/lang/StringBuilder/append(java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/toString(int[])#java/lang/StringBuilder/append(int)
parquet/column/values/bitpacking/TestBitPacking/toString(int[])#java/lang/StringBuilder/StringBuilder()
parquet/column/values/bitpacking/TestBitPacking/toString(int[])#java/lang/StringBuilder/toString()
parquet/column/values/bitpacking/TestBitPacking/testOne()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/BitPacking/BitPackingWriter/finish()
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/BitPacking/BitPackingWriter/write(int)
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/BitPacking/BitPackingReader/read()
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#parquet/column/values/bitpacking/TestBitPacking/toString(byte[])
parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)#java/io/ByteArrayOutputStream/toByteArray()
parquet/column/values/bitpacking/TestBitPacking/testOne_0_0()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testOne_1_1()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testSeven()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testFive()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testOne_9_0s()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testThree()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testFour()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testSix()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testOne_9_0s_1_1()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testOne_7_0s_1_1()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testZero()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/testTwo()#parquet/column/values/bitpacking/TestBitPacking/validateEncodeDecode(int,int[],java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/toString(byte[])#java/lang/StringBuilder/append(java.lang.String)
parquet/column/values/bitpacking/TestBitPacking/toString(byte[])#java/lang/Integer/toBinaryString(int)
parquet/column/values/bitpacking/TestBitPacking/toString(byte[])#java/lang/String/length()
parquet/column/values/bitpacking/TestBitPacking/toString(byte[])#java/lang/StringBuilder/StringBuilder()
parquet/column/values/bitpacking/TestBitPacking/toString(byte[])#java/lang/StringBuilder/toString()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testRandomStrings()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/DeltaLengthByteArrayValuesWriter(int)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testRandomStrings()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/DeltaLengthByteArrayValuesReader()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testRandomStrings()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testRandomStrings()#parquet/column/values/Utils/getRandomStringSamples(int,int)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testRandomStrings()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testRandomStrings()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testRandomStrings()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testRandomStrings()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testLengths()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/DeltaLengthByteArrayValuesWriter(int)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testLengths()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testLengths()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testLengths()#java/lang/String/length()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testLengths()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/DeltaBinaryPackingValuesReader()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testLengths()#parquet/column/values/Utils/readInts(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testLengths()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testSerialization()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/DeltaLengthByteArrayValuesWriter(int)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testSerialization()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader/DeltaLengthByteArrayValuesReader()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testSerialization()#parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testSerialization()#parquet/column/values/Utils/readData(parquet.column.values.ValuesReader,byte[],int)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testSerialization()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testSerialization()#parquet/column/values/Utils/writeData(parquet.column.values.ValuesWriter,java.lang.String[])
parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray/testSerialization()#parquet/bytes/BytesInput/toByteArray()
parquet/thrift/ThriftRecordConverter/SetConverter/collectionStart(int,byte)#parquet/thrift/ThriftRecordConverter/SetConverter/collectionStart(int,byte)/$anonymous1/(java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionary()#parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionary()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionary()#parquet/column/values/dictionary/TestDictionary/checkRepeated(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionary()#parquet/column/values/dictionary/TestDictionary/checkDistinct(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionary()#parquet/column/values/dictionary/TestDictionary/writeDistinct(int,parquet.column.values.ValuesWriter,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionary()#parquet/column/values/dictionary/TestDictionary/writeRepeated(int,parquet.column.values.ValuesWriter,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/PlainBinaryDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionary()#parquet/column/values/plain/BinaryPlainValuesReader/BinaryPlainValuesReader()
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/reset()
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/ValuesReader/readBytes()
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/getBufferedSize()
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/getEncoding()
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/io/api/Binary/length()
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/PlainBinaryDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryFallBack()#parquet/column/values/plain/BinaryPlainValuesReader/BinaryPlainValuesReader()
parquet/column/values/dictionary/TestDictionary/roundTripInt(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesReader/readInteger()
parquet/column/values/dictionary/TestDictionary/roundTripInt(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()
parquet/column/values/dictionary/TestDictionary/roundTripInt(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/dictionary/DictionaryValuesWriter/getEncoding()
parquet/column/values/dictionary/TestDictionary/roundTripInt(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/dictionary/TestDictionary/roundTripInt(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/roundTripInt(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)#parquet/bytes/BytesInput/copy(parquet.bytes.BytesInput)
parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)#parquet/column/values/ValuesWriter/getEncoding()
parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)#parquet/column/values/ValuesWriter/reset()
parquet/column/values/dictionary/TestDictionary/writeRepeatedWithReuse(int,parquet.column.values.ValuesWriter,java.lang.String)#parquet/io/api/Binary/length()
parquet/column/values/dictionary/TestDictionary/writeRepeatedWithReuse(int,parquet.column.values.ValuesWriter,java.lang.String)#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/dictionary/TestDictionary/writeRepeatedWithReuse(int,parquet.column.values.ValuesWriter,java.lang.String)#parquet/io/api/Binary/getBytes()
parquet/column/values/dictionary/TestDictionary/writeRepeatedWithReuse(int,parquet.column.values.ValuesWriter,java.lang.String)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/dictionary/TestDictionary/writeRepeatedWithReuse(int,parquet.column.values.ValuesWriter,java.lang.String)#java/lang/System/arraycopy(java.lang.Object,int,java.lang.Object,int,int)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryChangedValues()#parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryChangedValues()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryChangedValues()#parquet/column/values/dictionary/TestDictionary/writeRepeatedWithReuse(int,parquet.column.values.ValuesWriter,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryChangedValues()#parquet/column/values/dictionary/TestDictionary/checkRepeated(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryChangedValues()#parquet/column/values/dictionary/TestDictionary/checkDistinct(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryChangedValues()#parquet/column/values/dictionary/TestDictionary/writeDistinct(int,parquet.column.values.ValuesWriter,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryChangedValues()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/PlainBinaryDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testBinaryDictionaryChangedValues()#parquet/column/values/plain/BinaryPlainValuesReader/BinaryPlainValuesReader()
parquet/column/values/dictionary/TestDictionary/testDoubleDictionary()#parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/values/dictionary/TestDictionary/testDoubleDictionary()#parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/testDoubleDictionary()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testDoubleDictionary()#parquet/column/values/dictionary/DictionaryValuesReader/readDouble()
parquet/column/values/dictionary/TestDictionary/testDoubleDictionary()#parquet/column/values/ValuesWriter/writeDouble(double)
parquet/column/values/dictionary/TestDictionary/testDoubleDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/TestDictionary/testDoubleDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/PlainDoubleDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testDoubleDictionary()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/testIntDictionaryFallBack()#parquet/column/values/dictionary/TestDictionary/roundTripInt(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)
parquet/column/values/dictionary/TestDictionary/testIntDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/resetDictionary()
parquet/column/values/dictionary/TestDictionary/testIntDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/PlainIntegerDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testIntDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/reset()
parquet/column/values/dictionary/TestDictionary/testIntDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/getBufferedSize()
parquet/column/values/dictionary/TestDictionary/testIntDictionaryFallBack()#parquet/column/values/plain/PlainValuesReader/IntegerPlainValuesReader/IntegerPlainValuesReader()
parquet/column/values/dictionary/TestDictionary/checkDistinct(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)#parquet/column/values/ValuesReader/readBytes()
parquet/column/values/dictionary/TestDictionary/checkDistinct(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/checkDistinct(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/column/values/dictionary/TestDictionary/checkDistinct(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/testFloatDictionary()#parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/values/dictionary/TestDictionary/testFloatDictionary()#parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/testFloatDictionary()#parquet/column/values/ValuesWriter/writeFloat(float)
parquet/column/values/dictionary/TestDictionary/testFloatDictionary()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testFloatDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/PlainFloatDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testFloatDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/TestDictionary/testFloatDictionary()#parquet/column/values/dictionary/DictionaryValuesReader/readFloat()
parquet/column/values/dictionary/TestDictionary/testFloatDictionary()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/values/ValuesWriter/createDictionaryPage()
parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/ColumnDescriptor/ColumnDescriptor(java.lang.String[],parquet.schema.PrimitiveType.PrimitiveTypeName,int,int)
parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/Encoding/initDictionary(parquet.column.ColumnDescriptor,parquet.column.page.DictionaryPage)
parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/page/DictionaryPage/copy()
parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)#parquet/column/values/dictionary/DictionaryValuesReader/DictionaryValuesReader(parquet.column.Dictionary)
parquet/column/values/dictionary/TestDictionary/testFloatDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/resetDictionary()
parquet/column/values/dictionary/TestDictionary/testFloatDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/PlainFloatDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testFloatDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/reset()
parquet/column/values/dictionary/TestDictionary/testFloatDictionaryFallBack()#parquet/column/values/dictionary/TestDictionary/roundTripFloat(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)
parquet/column/values/dictionary/TestDictionary/testFloatDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/getBufferedSize()
parquet/column/values/dictionary/TestDictionary/testFloatDictionaryFallBack()#parquet/column/values/plain/PlainValuesReader/FloatPlainValuesReader/FloatPlainValuesReader()
parquet/column/values/dictionary/TestDictionary/roundTripLong(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/dictionary/DictionaryValuesWriter/getEncoding()
parquet/column/values/dictionary/TestDictionary/roundTripLong(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesWriter/writeLong(long)
parquet/column/values/dictionary/TestDictionary/roundTripLong(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/roundTripLong(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/roundTripLong(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()
parquet/column/values/dictionary/TestDictionary/roundTripLong(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesReader/readLong()
parquet/column/values/dictionary/TestDictionary/testSecondPageFallBack()#parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/values/dictionary/TestDictionary/testSecondPageFallBack()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testSecondPageFallBack()#parquet/column/values/dictionary/TestDictionary/checkRepeated(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testSecondPageFallBack()#parquet/column/values/dictionary/TestDictionary/checkDistinct(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testSecondPageFallBack()#parquet/column/values/dictionary/TestDictionary/writeDistinct(int,parquet.column.values.ValuesWriter,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testSecondPageFallBack()#parquet/column/values/dictionary/TestDictionary/writeRepeated(int,parquet.column.values.ValuesWriter,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testSecondPageFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/PlainBinaryDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testSecondPageFallBack()#parquet/column/values/plain/BinaryPlainValuesReader/BinaryPlainValuesReader()
parquet/column/values/dictionary/TestDictionary/testFirstPageFallBack()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testFirstPageFallBack()#parquet/column/values/dictionary/TestDictionary/checkRepeated(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testFirstPageFallBack()#parquet/column/values/dictionary/TestDictionary/checkDistinct(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testFirstPageFallBack()#parquet/column/values/dictionary/TestDictionary/writeDistinct(int,parquet.column.values.ValuesWriter,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testFirstPageFallBack()#parquet/column/values/dictionary/TestDictionary/writeRepeated(int,parquet.column.values.ValuesWriter,java.lang.String)
parquet/column/values/dictionary/TestDictionary/testFirstPageFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/PlainBinaryDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testFirstPageFallBack()#parquet/column/values/plain/BinaryPlainValuesReader/BinaryPlainValuesReader()
parquet/column/values/dictionary/TestDictionary/testIntDictionary()#parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/values/dictionary/TestDictionary/testIntDictionary()#parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/testIntDictionary()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testIntDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/PlainIntegerDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testIntDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/TestDictionary/testIntDictionary()#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/dictionary/TestDictionary/testIntDictionary()#parquet/column/values/dictionary/DictionaryValuesReader/readInteger()
parquet/column/values/dictionary/TestDictionary/testIntDictionary()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/testDoubleDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/resetDictionary()
parquet/column/values/dictionary/TestDictionary/testDoubleDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/reset()
parquet/column/values/dictionary/TestDictionary/testDoubleDictionaryFallBack()#parquet/column/values/dictionary/TestDictionary/roundTripDouble(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)
parquet/column/values/dictionary/TestDictionary/testDoubleDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/getBufferedSize()
parquet/column/values/dictionary/TestDictionary/testDoubleDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainDoubleDictionaryValuesWriter/PlainDoubleDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testDoubleDictionaryFallBack()#parquet/column/values/plain/PlainValuesReader/DoublePlainValuesReader/DoublePlainValuesReader()
parquet/column/values/dictionary/TestDictionary/roundTripFloat(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesReader/readFloat()
parquet/column/values/dictionary/TestDictionary/roundTripFloat(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesWriter/writeFloat(float)
parquet/column/values/dictionary/TestDictionary/roundTripFloat(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()
parquet/column/values/dictionary/TestDictionary/roundTripFloat(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/dictionary/DictionaryValuesWriter/getEncoding()
parquet/column/values/dictionary/TestDictionary/roundTripFloat(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/roundTripFloat(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/testZeroValues()#parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/values/dictionary/TestDictionary/testZeroValues()#parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/testZeroValues()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testZeroValues()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/PlainIntegerDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testZeroValues()#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/dictionary/TestDictionary/checkRepeated(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)#parquet/column/values/ValuesReader/readBytes()
parquet/column/values/dictionary/TestDictionary/checkRepeated(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/checkRepeated(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/column/values/dictionary/TestDictionary/checkRepeated(int,parquet.bytes.BytesInput,parquet.column.values.ValuesReader,java.lang.String)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/roundTripDouble(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()
parquet/column/values/dictionary/TestDictionary/roundTripDouble(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/dictionary/DictionaryValuesWriter/getEncoding()
parquet/column/values/dictionary/TestDictionary/roundTripDouble(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesWriter/writeDouble(double)
parquet/column/values/dictionary/TestDictionary/roundTripDouble(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/roundTripDouble(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/column/values/ValuesReader/readDouble()
parquet/column/values/dictionary/TestDictionary/roundTripDouble(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/writeDistinct(int,parquet.column.values.ValuesWriter,java.lang.String)#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/dictionary/TestDictionary/writeDistinct(int,parquet.column.values.ValuesWriter,java.lang.String)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/values/dictionary/TestDictionary/testLongDictionary()#parquet/column/values/dictionary/TestDictionary/initDicReader(parquet.column.values.ValuesWriter,parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/values/dictionary/TestDictionary/testLongDictionary()#parquet/column/values/dictionary/DictionaryValuesReader/initFromPage(int,byte[],int)
parquet/column/values/dictionary/TestDictionary/testLongDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/PlainLongDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testLongDictionary()#parquet/column/values/dictionary/TestDictionary/getBytesAndCheckEncoding(parquet.column.values.ValuesWriter,parquet.column.Encoding)
parquet/column/values/dictionary/TestDictionary/testLongDictionary()#parquet/column/values/ValuesWriter/writeLong(long)
parquet/column/values/dictionary/TestDictionary/testLongDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/TestDictionary/testLongDictionary()#parquet/column/values/dictionary/DictionaryValuesReader/readLong()
parquet/column/values/dictionary/TestDictionary/testLongDictionary()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/dictionary/TestDictionary/testLongDictionaryFallBack()#parquet/column/values/dictionary/TestDictionary/roundTripLong(parquet.column.values.dictionary.DictionaryValuesWriter,parquet.column.values.ValuesReader,int)
parquet/column/values/dictionary/TestDictionary/testLongDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/resetDictionary()
parquet/column/values/dictionary/TestDictionary/testLongDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/reset()
parquet/column/values/dictionary/TestDictionary/testLongDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/getBufferedSize()
parquet/column/values/dictionary/TestDictionary/testLongDictionaryFallBack()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/PlainLongDictionaryValuesWriter(int,int)
parquet/column/values/dictionary/TestDictionary/testLongDictionaryFallBack()#parquet/column/values/plain/PlainValuesReader/LongPlainValuesReader/LongPlainValuesReader()
parquet/column/values/dictionary/TestDictionary/writeRepeated(int,parquet.column.values.ValuesWriter,java.lang.String)#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/dictionary/TestDictionary/writeRepeated(int,parquet.column.values.ValuesWriter,java.lang.String)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/hadoop/metadata/ParquetMetadata/fromJSON(java.lang.String)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/hadoop/metadata/ParquetMetadata/fromJSON(java.lang.String)#java/io/StringReader/StringReader(java.lang.String)
parquet/hadoop/metadata/ParquetMetadata/fromJSON(java.lang.String)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/metadata/ParquetMetadata/toJSON(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/toJSON(parquet.hadoop.metadata.ParquetMetadata,parquet.thrift.struct.ObjectMapper)
parquet/hadoop/metadata/ParquetMetadata/toJSON(parquet.hadoop.metadata.ParquetMetadata,parquet.thrift.struct.ObjectMapper)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/hadoop/metadata/ParquetMetadata/toJSON(parquet.hadoop.metadata.ParquetMetadata,parquet.thrift.struct.ObjectMapper)#java/io/StringWriter/StringWriter()
parquet/hadoop/metadata/ParquetMetadata/toJSON(parquet.hadoop.metadata.ParquetMetadata,parquet.thrift.struct.ObjectMapper)#java/io/StringWriter/toString()
parquet/hadoop/metadata/ParquetMetadata/toJSON(parquet.hadoop.metadata.ParquetMetadata,parquet.thrift.struct.ObjectMapper)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/metadata/ParquetMetadata/toPrettyJSON(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/toJSON(parquet.hadoop.metadata.ParquetMetadata,parquet.thrift.struct.ObjectMapper)
parquet/tools/read/SimpleRecordMaterializer/getCurrentRecord()#parquet/tools/read/SimpleRecordConverter/getCurrentRecord()
parquet/avro/AvroIndexedRecordConverter/end()#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/end()#parquet/avro/AvroIndexedRecordConverter/fillInDefaults()
parquet/avro/AvroIndexedRecordConverter/start()#java/lang/Object/Object()
parquet/avro/AvroIndexedRecordConverter/getAvroField(java.lang.String)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/avro/AvroIndexedRecordConverter/getAvroField(java.lang.String)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/schema/Type/asGroupType()
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/AvroIndexedRecordConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer,parquet.schema.GroupType,parquet.pig.convert.Schema)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldEnumConverter/FieldEnumConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer,parquet.pig.convert.Schema)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldIntegerConverter/FieldIntegerConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldFloatConverter/FieldFloatConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldBooleanConverter/FieldBooleanConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldFixedConverter/FieldFixedConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer,parquet.pig.convert.Schema)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/MapConverter/MapConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer,parquet.schema.Type,parquet.pig.convert.Schema)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/AvroArrayConverter/AvroArrayConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer,parquet.schema.Type,parquet.pig.convert.Schema)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/AvroUnionConverter/AvroUnionConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer,parquet.schema.Type,parquet.pig.convert.Schema)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldLongConverter/FieldLongConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldBytesConverter/FieldBytesConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldDoubleConverter/FieldDoubleConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)
parquet/avro/AvroIndexedRecordConverter/newConverter(parquet.pig.convert.Schema,parquet.schema.Type,parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)#parquet/avro/AvroIndexedRecordConverter/FieldStringConverter/FieldStringConverter(parquet.avro.AvroIndexedRecordConverter.ParentValueContainer)
parquet/avro/AvroIndexedRecordConverter/fillInDefaults()#parquet/avro/AvroIndexedRecordConverter/deepCopy(parquet.pig.convert.Schema,java.lang.Object)
parquet/column/values/ValuesReader/readFloat()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/values/ValuesReader/readInteger()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/values/ValuesReader/readLong()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/values/ValuesReader/readValueDictionaryId()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/values/ValuesReader/readBoolean()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/values/ValuesReader/readBytes()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/values/ValuesReader/getNextOffset()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/column/values/ValuesReader/readDouble()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/hadoop/ParquetReader/Builder/withConf(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/hadoop/ParquetReader/Builder/build()#parquet/hadoop/ParquetReader/ParquetReader(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.api.ReadSupport,parquet.filter2.compat.FilterCompat.Filter)
parquet/hadoop/ParquetReader/Builder/withFilter(parquet.filter2.compat.FilterCompat.Filter)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter2/predicate/Operators/Eq/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.Eq)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/FieldsMarker/reset(int)#java/util/BitSet/clear(int,int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/FieldsMarker/isWritten(int)#java/util/BitSet/get(int)
parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/FieldsMarker/markWritten(int)#java/util/BitSet/set(int)
parquet/column/values/deltastrings/DeltaByteArrayReader/readBytes()#parquet/column/values/ValuesReader/readInteger()
parquet/column/values/deltastrings/DeltaByteArrayReader/readBytes()#parquet/io/api/Binary/length()
parquet/column/values/deltastrings/DeltaByteArrayReader/readBytes()#parquet/io/api/Binary/fromByteArray(byte[])
parquet/column/values/deltastrings/DeltaByteArrayReader/readBytes()#parquet/column/values/ValuesReader/readBytes()
parquet/column/values/deltastrings/DeltaByteArrayReader/readBytes()#parquet/io/api/Binary/getBytes()
parquet/column/values/deltastrings/DeltaByteArrayReader/readBytes()#java/lang/System/arraycopy(java.lang.Object,int,java.lang.Object,int,int)
parquet/column/values/deltastrings/DeltaByteArrayReader/skip()#parquet/column/values/ValuesReader/skip()
parquet/column/values/deltastrings/DeltaByteArrayReader/initFromPage(int,byte[],int)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/deltastrings/DeltaByteArrayReader/initFromPage(int,byte[],int)#parquet/column/values/ValuesReader/getNextOffset()
parquet/hadoop/ParquetFileWriter/writeDataPages(parquet.bytes.BytesInput,long,long,parquet.column.statistics.Statistics,java.util.List)#parquet/hadoop/ParquetFileWriter/STATE/write()
parquet/hadoop/ParquetFileWriter/writeDataPages(parquet.bytes.BytesInput,long,long,parquet.column.statistics.Statistics,java.util.List)#java/util/Set/addAll(java.util.Collection)
parquet/hadoop/ParquetFileWriter/writeDataPages(parquet.bytes.BytesInput,long,long,parquet.column.statistics.Statistics,java.util.List)#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/hadoop/ParquetFileWriter/writeDataPages(parquet.bytes.BytesInput,long,long,parquet.column.statistics.Statistics,java.util.List)#parquet/bytes/BytesInput/size()
parquet/hadoop/ParquetFileWriter/writeDataPages(parquet.bytes.BytesInput,long,long,parquet.column.statistics.Statistics,java.util.List)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/getGlobalMetaData(java.util.List,boolean)#parquet/hadoop/Footer/getParquetMetadata()
parquet/hadoop/ParquetFileWriter/getGlobalMetaData(java.util.List,boolean)#parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)
parquet/hadoop/ParquetFileWriter/getGlobalMetaData(java.util.List,boolean)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData)#parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/hadoop/ParquetFileWriter/mergeInto(parquet.schema.MessageType,parquet.schema.MessageType,boolean)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/schema/Type/equals(java.lang.Object)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/Set/addAll(java.util.Collection)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/Map/putAll(java.util.Map)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/Map/get(java.lang.Object)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/hadoop/metadata/GlobalMetaData/GlobalMetaData(parquet.schema.MessageType,java.util.Map,java.util.Set)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/HashMap/HashMap()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/Map/Entry/getKey()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/hadoop/metadata/FileMetaData/getCreatedBy()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/Map/put(K,V)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/HashSet/HashSet()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/Map/entrySet()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/hadoop/metadata/GlobalMetaData/getKeyValueMetaData()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/hadoop/metadata/GlobalMetaData/getSchema()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/Map/Entry/getValue()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/hadoop/metadata/GlobalMetaData/getCreatedBy()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#java/util/Set/add(E)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/hadoop/metadata/FileMetaData/getKeyValueMetaData()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData,boolean)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/hadoop/ParquetFileWriter/start()#parquet/hadoop/ParquetFileWriter/STATE/start()
parquet/hadoop/ParquetFileWriter/start()#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/hadoop/metadata/GlobalMetaData/merge()
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/hadoop/Footer/getFile()
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#java/lang/String/substring(int)
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#java/util/List/add(E)
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#java/lang/String/startsWith(java.lang.String)
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/hadoop/metadata/BlockMetaData/setPath(java.lang.String)
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#java/lang/String/length()
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/hadoop/Footer/getParquetMetadata()
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/hadoop/metadata/ParquetMetadata/ParquetMetadata(parquet.hadoop.metadata.FileMetaData,java.util.List)
parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)#parquet/hadoop/ParquetFileWriter/mergeInto(parquet.hadoop.metadata.FileMetaData,parquet.hadoop.metadata.GlobalMetaData)
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.schema.MessageType,parquet.schema.MessageType)#parquet/hadoop/ParquetFileWriter/mergeInto(parquet.schema.MessageType,parquet.schema.MessageType,boolean)
parquet/hadoop/ParquetFileWriter/writeMetadataFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.example.FileSystem,java.lang.String)#parquet/hadoop/ParquetFileWriter/serializeFooter(parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.FSDataOutputStream)
parquet/hadoop/ParquetFileWriter/writeMetadataFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.example.FileSystem,java.lang.String)#java/lang/Object/Object()
parquet/hadoop/ParquetFileWriter/startBlock(long)#parquet/hadoop/ParquetFileWriter/STATE/startBlock()
parquet/hadoop/ParquetFileWriter/startBlock(long)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/startBlock(long)#parquet/hadoop/metadata/BlockMetaData/BlockMetaData()
parquet/hadoop/ParquetFileWriter/mergeInto(parquet.schema.MessageType,parquet.schema.MessageType,boolean)#parquet/schema/MessageType/union(parquet.schema.MessageType,boolean)
parquet/hadoop/ParquetFileWriter/endBlock()#parquet/hadoop/ParquetFileWriter/STATE/endBlock()
parquet/hadoop/ParquetFileWriter/endBlock()#parquet/hadoop/metadata/BlockMetaData/setRowCount(long)
parquet/hadoop/ParquetFileWriter/endBlock()#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/endBlock()#java/util/List/add(E)
parquet/hadoop/ParquetFileWriter/getGlobalMetaData(java.util.List)#parquet/hadoop/ParquetFileWriter/getGlobalMetaData(java.util.List,boolean)
parquet/hadoop/ParquetFileWriter/end(java.util.Map)#parquet/hadoop/metadata/FileMetaData/FileMetaData(parquet.schema.MessageType,java.util.Map,java.lang.String)
parquet/hadoop/ParquetFileWriter/end(java.util.Map)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/end(java.util.Map)#parquet/hadoop/ParquetFileWriter/serializeFooter(parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.FSDataOutputStream)
parquet/hadoop/ParquetFileWriter/end(java.util.Map)#parquet/hadoop/metadata/ParquetMetadata/ParquetMetadata(parquet.hadoop.metadata.FileMetaData,java.util.List)
parquet/hadoop/ParquetFileWriter/end(java.util.Map)#parquet/hadoop/ParquetFileWriter/STATE/end()
parquet/hadoop/ParquetFileWriter/endColumn()#parquet/hadoop/metadata/BlockMetaData/addColumn(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/hadoop/ParquetFileWriter/endColumn()#parquet/hadoop/metadata/BlockMetaData/setTotalByteSize(long)
parquet/hadoop/ParquetFileWriter/endColumn()#parquet/hadoop/ParquetFileWriter/STATE/endColumn()
parquet/hadoop/ParquetFileWriter/endColumn()#parquet/hadoop/metadata/BlockMetaData/getTotalByteSize()
parquet/hadoop/ParquetFileWriter/endColumn()#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/endColumn()#parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/hadoop/ParquetFileWriter/endColumn()#parquet/Log/info(java.lang.Object)
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/hadoop/ParquetFileWriter/STATE/write()
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/size()
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#java/util/Set/add(E)
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/format/converter/ParquetMetadataConverter/writeDataPageHeader(int,int,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding,java.io.OutputStream)
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/writeMetadataFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List)#parquet/hadoop/ParquetFileWriter/mergeFooters(parquet.hadoop.Path,java.util.List)
parquet/hadoop/ParquetFileWriter/writeMetadataFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List)#parquet/hadoop/ParquetFileWriter/writeMetadataFile(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.example.FileSystem,java.lang.String)
parquet/hadoop/ParquetFileWriter/writeMetadataFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List)#java/util/List/clear()
parquet/hadoop/ParquetFileWriter/writeMetadataFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/hadoop/ParquetFileWriter/STATE/write()
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/column/statistics/Statistics/mergeStatistics(parquet.column.statistics.Statistics)
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/size()
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#java/util/Set/add(E)
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/format/converter/ParquetMetadataConverter/writeDataPageHeader(int,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding,java.io.OutputStream)
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/hadoop/ParquetFileWriter/STATE/write()
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getUncompressedSize()
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/bytes/BytesInput/size()
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#java/util/Set/add(E)
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/format/converter/ParquetMetadataConverter/writeDictionaryPageHeader(int,int,int,parquet.column.Encoding,java.io.OutputStream)
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getBytes()
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getEncoding()
parquet/hadoop/ParquetFileWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getDictionarySize()
parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)#parquet/column/ColumnDescriptor/getType()
parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)#parquet/column/ColumnDescriptor/getPath()
parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)#parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetFileWriter/STATE/startColumn()
parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)#java/util/HashSet/HashSet()
parquet/hadoop/ParquetFileWriter/serializeFooter(parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.FSDataOutputStream)#parquet/format/converter/ParquetMetadataConverter/ParquetMetadataConverter()
parquet/hadoop/ParquetFileWriter/serializeFooter(parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.FSDataOutputStream)#parquet/bytes/BytesUtils/writeIntLittleEndian(java.io.OutputStream,int)
parquet/hadoop/ParquetFileWriter/serializeFooter(parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.FSDataOutputStream)#parquet/format/converter/ParquetMetadataConverter/toParquetMetadata(int,parquet.hadoop.metadata.ParquetMetadata)
parquet/hadoop/ParquetFileWriter/serializeFooter(parquet.hadoop.metadata.ParquetMetadata,parquet.hadoop.FSDataOutputStream)#parquet/Log/debug(java.lang.Object)
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.Not)#parquet/filter2/predicate/LogicalInverter/invert(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.Not)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/LogicalInverseRewriter/visit(parquet.filter2.predicate.Operators.Not)#parquet/filter2/predicate/Operators/Not/getPredicate()
parquet/filter2/predicate/LogicalInverseRewriter/rewrite(parquet.filter2.predicate.FilterPredicate)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/predicate/LogicalInverseRewriter/rewrite(parquet.filter2.predicate.FilterPredicate)#parquet/Preconditions/checkNotNull(T,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/equals(java.lang.Object)#parquet/io/api/Binary/equals(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/getString()#parquet/io/api/Binary/toStringUsingUTF8()
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/getBytes()#parquet/io/api/Binary/getBytes()
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/hashCode()#java/lang/Object/hashCode()
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/write(java.io.DataOutput)#java/io/DataOutput/writeInt(int)
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/write(java.io.DataOutput)#parquet/io/api/Binary/writeTo(java.io.DataOutput)
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/write(java.io.DataOutput)#parquet/io/api/Binary/length()
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/readFields(java.io.DataInput)#java/io/DataInput/readInt()
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/readFields(java.io.DataInput)#parquet/io/api/Binary/fromByteArray(byte[])
org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/readFields(java.io.DataInput)#java/io/DataInput/readFully(byte[])
parquet/io/MessageColumnIO/getType()#parquet/io/ColumnIO/getType()
parquet/io/MessageColumnIO/setLevels()#parquet/io/GroupColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)
parquet/io/MessageColumnIO/setLevels()#java/util/Arrays/asList(T[])
parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter.UnboundRecordFilter)#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter.UnboundRecordFilter)#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer)#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)#parquet/io/RecordConsumerLoggingWrapper/RecordConsumerLoggingWrapper(parquet.io.api.RecordConsumer)
parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)#parquet/io/MessageColumnIO/getType()
parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)#parquet/io/ValidatingRecordConsumer/ValidatingRecordConsumer(parquet.io.api.RecordConsumer,parquet.schema.MessageType)
parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)#parquet/io/MessageColumnIO/MessageColumnIORecordConsumer/MessageColumnIORecordConsumer(parquet.column.ColumnWriteStore)
parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)#parquet/filter2/compat/FilterCompat/Filter/accept(parquet.filter2.compat.FilterCompat.Visitor)
parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)#java/util/List/isEmpty()
parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)#parquet/io/EmptyRecordReader/EmptyRecordReader(parquet.io.api.RecordMaterializer)
parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)#parquet/io/MessageColumnIO/getRecordReader(parquet/column/page/PageReadStore,parquet/io/api/RecordMaterializer,parquet/filter2/compat/FilterCompat/Filter)/$anonymous1/()
parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/io/MessageColumnIO/getColumnNames()#parquet/io/GroupColumnIO/getColumnNames()
parquet/io/PrimitiveColumnIO/getColumnNames()#parquet/io/ColumnIO/getFieldPath()
parquet/io/PrimitiveColumnIO/getColumnNames()#java/util/Arrays/asList(T[])
parquet/io/PrimitiveColumnIO/isLast(int)#parquet/io/PrimitiveColumnIO/getLast(int)
parquet/io/PrimitiveColumnIO/getFirst(int)#parquet/io/ColumnIO/getParent(int)
parquet/io/PrimitiveColumnIO/getFirst(int)#parquet/io/ColumnIO/getFirst()
parquet/io/PrimitiveColumnIO/getPrimitive()#parquet/io/ColumnIO/getType()
parquet/io/PrimitiveColumnIO/getPrimitive()#parquet/schema/Type/asPrimitiveType()
parquet/io/PrimitiveColumnIO/getPrimitive()#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/io/PrimitiveColumnIO/getLast(int)#parquet/io/ColumnIO/getParent(int)
parquet/io/PrimitiveColumnIO/getLast(int)#parquet/io/ColumnIO/getLast()
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/getType()
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/column/ColumnDescriptor/ColumnDescriptor(java.lang.String[],parquet.schema.PrimitiveType.PrimitiveTypeName,int,int,int)
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#java/util/List/size()
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/schema/PrimitiveType/getTypeLength()
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/getDefinitionLevel()
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/io/ColumnIO/getRepetitionLevel()
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#java/util/List/toArray(T[])
parquet/io/PrimitiveColumnIO/setLevels(int,int,java.lang.String[],int[],java.util.List,java.util.List)#parquet/schema/Type/asPrimitiveType()
parquet/io/PrimitiveColumnIO/isFirst(int)#parquet/io/PrimitiveColumnIO/getFirst(int)
parquet/example/data/simple/SimpleGroupFactory/newGroup()#parquet/example/data/simple/SimpleGroup/SimpleGroup(parquet.schema.GroupType)
parquet/io/BaseRecordReader/endMessage()#parquet/io/api/RecordConsumer/endMessage()
parquet/io/BaseRecordReader/endMessage()#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/io/BaseRecordReader/endMessage()#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/startGroup(java.lang.String,int)#parquet/io/BaseRecordReader/startField(java.lang.String,int)
parquet/io/BaseRecordReader/startGroup(java.lang.String,int)#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/startGroup(java.lang.String,int)#parquet/io/api/RecordConsumer/startGroup()
parquet/io/BaseRecordReader/read()#parquet/io/BaseRecordReader/readOneRecord()
parquet/io/BaseRecordReader/read()#parquet/io/api/RecordMaterializer/getCurrentRecord()
parquet/io/BaseRecordReader/currentLevel(int)#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/addPrimitiveINT32(java.lang.String,int,int)#parquet/io/BaseRecordReader/startField(java.lang.String,int)
parquet/io/BaseRecordReader/addPrimitiveINT32(java.lang.String,int,int)#parquet/io/BaseRecordReader/endField(java.lang.String,int)
parquet/io/BaseRecordReader/addPrimitiveINT32(java.lang.String,int,int)#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/addPrimitiveINT32(java.lang.String,int,int)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/io/BaseRecordReader/addPrimitiveBINARY(java.lang.String,int,parquet.io.api.Binary)#parquet/io/BaseRecordReader/startField(java.lang.String,int)
parquet/io/BaseRecordReader/addPrimitiveBINARY(java.lang.String,int,parquet.io.api.Binary)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/io/BaseRecordReader/addPrimitiveBINARY(java.lang.String,int,parquet.io.api.Binary)#parquet/io/BaseRecordReader/endField(java.lang.String,int)
parquet/io/BaseRecordReader/addPrimitiveBINARY(java.lang.String,int,parquet.io.api.Binary)#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/error(java.lang.String)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/io/BaseRecordReader/startField(java.lang.String,int)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/io/BaseRecordReader/startField(java.lang.String,int)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/io/BaseRecordReader/startField(java.lang.String,int)#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/getCaseId(int,int,int,int)#parquet/io/RecordReaderImplementation/Case/getID()
parquet/io/BaseRecordReader/getCaseId(int,int,int,int)#parquet/io/RecordReaderImplementation/State/getCase(int,int,int)
parquet/io/BaseRecordReader/endField(java.lang.String,int)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/io/BaseRecordReader/endField(java.lang.String,int)#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/endGroup(java.lang.String,int)#parquet/io/api/RecordConsumer/endGroup()
parquet/io/BaseRecordReader/endGroup(java.lang.String,int)#parquet/io/BaseRecordReader/endField(java.lang.String,int)
parquet/io/BaseRecordReader/endGroup(java.lang.String,int)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/io/BaseRecordReader/endGroup(java.lang.String,int)#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/startMessage()#parquet/io/api/RecordConsumer/startMessage()
parquet/io/BaseRecordReader/startMessage()#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/addPrimitiveINT64(java.lang.String,int,long)#parquet/io/BaseRecordReader/startField(java.lang.String,int)
parquet/io/BaseRecordReader/addPrimitiveINT64(java.lang.String,int,long)#parquet/io/BaseRecordReader/endField(java.lang.String,int)
parquet/io/BaseRecordReader/addPrimitiveINT64(java.lang.String,int,long)#parquet/Log/debug(java.lang.Object)
parquet/io/BaseRecordReader/addPrimitiveINT64(java.lang.String,int,long)#parquet/io/api/RecordConsumer/addLong(long)
parquet/io/BaseRecordReader/log(java.lang.String)#parquet/Log/debug(java.lang.Object)
parquet/filter2/predicate/Operators/Gt/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.Gt)
parquet/hadoop/util/ContextUtil/incrementCounter(parquet.hadoop.example.Counter,long)#parquet/hadoop/util/ContextUtil/invoke(java.lang.reflect.Method,java.lang.Object,java.lang.Object[])
parquet/hadoop/util/ContextUtil/invoke(java.lang.reflect.Method,java.lang.Object,java.lang.Object[])#java/lang/reflect/Method/getName()
parquet/hadoop/util/ContextUtil/invoke(java.lang.reflect.Method,java.lang.Object,java.lang.Object[])#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/hadoop/util/ContextUtil/invoke(java.lang.reflect.Method,java.lang.Object,java.lang.Object[])#java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object[])
parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)#java/lang/reflect/Constructor/newInstance(java.lang.Object[])
parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/hadoop/util/ContextUtil/newJobContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.JobID)#java/lang/reflect/Constructor/newInstance(java.lang.Object[])
parquet/hadoop/util/ContextUtil/newJobContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.JobID)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)#java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object[])
parquet/hadoop/util/ContextUtil/newGenericCounter(java.lang.String,java.lang.String,long)#java/lang/reflect/Constructor/newInstance(java.lang.Object[])
parquet/hadoop/util/ContextUtil/newGenericCounter(java.lang.String,java.lang.String,long)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/hadoop/util/ContextUtil/getCounter(parquet.hadoop.util.TaskInputOutputContext,java.lang.String,java.lang.String)#parquet/hadoop/util/ContextUtil/invoke(java.lang.reflect.Method,java.lang.Object,java.lang.Object[])
parquet/proto/utils/ReadUsingMR/read(parquet.hadoop.Path)#parquet/proto/ProtoParquetInputFormat/setRequestedProjection(parquet.proto.utils.Job,java.lang.String)
parquet/proto/utils/ReadUsingMR/read(parquet.hadoop.Path)#java/util/ArrayList/ArrayList()
parquet/proto/utils/ReadUsingMR/read(parquet.hadoop.Path)#java/util/Collections/unmodifiableList(java.util.List)
parquet/proto/utils/ReadUsingMR/read(parquet.hadoop.Path)#parquet/proto/utils/WriteUsingMR/waitForJob(parquet.proto.utils.Job)
parquet/proto/utils/ReadUsingMR/read(parquet.hadoop.Path)#java/lang/Object/Object()
parquet/avro/TestReadWrite/testAll()#java/util/ArrayList/ArrayList()
parquet/avro/TestReadWrite/testAll()#java/lang/Class/getSimpleName()
parquet/avro/TestReadWrite/testAll()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestReadWrite/testAll()#parquet/avro/AvroParquetWriter/AvroParquetWriter(parquet.hadoop.Path,parquet.pig.convert.Schema)
parquet/avro/TestReadWrite/testAll()#java/util/Arrays/asList(T[])
parquet/avro/TestReadWrite/testAll()#java/lang/String/getBytes(java.lang.String)
parquet/avro/TestReadWrite/testAll()#java/nio/ByteBuffer/wrap(byte[])
parquet/avro/TestReadWrite/testAll()#java/lang/Object/getClass()
parquet/avro/TestReadWrite/testAll()#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/avro/TestReadWrite/testAll()#java/io/File/deleteOnExit()
parquet/avro/TestReadWrite/testAll()#java/io/File/getPath()
parquet/avro/TestReadWrite/testAll()#java/io/File/delete()
parquet/avro/TestReadWrite/testAll()#java/lang/Object/Object()
parquet/avro/TestReadWrite/testEmptyMap()#java/lang/Class/getSimpleName()
parquet/avro/TestReadWrite/testEmptyMap()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestReadWrite/testEmptyMap()#parquet/avro/AvroParquetWriter/AvroParquetWriter(parquet.hadoop.Path,parquet.pig.convert.Schema)
parquet/avro/TestReadWrite/testEmptyMap()#java/lang/Object/getClass()
parquet/avro/TestReadWrite/testEmptyMap()#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/avro/TestReadWrite/testEmptyMap()#java/io/File/deleteOnExit()
parquet/avro/TestReadWrite/testEmptyMap()#java/io/File/getPath()
parquet/avro/TestReadWrite/testEmptyMap()#java/io/File/delete()
parquet/avro/TestReadWrite/testEmptyMap()#java/lang/Object/Object()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/util/ArrayList/ArrayList()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/lang/Class/getSimpleName()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#parquet/hadoop/ParquetWriter/ParquetWriter(parquet.hadoop.Path,parquet.hadoop.api.WriteSupport)
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/util/Arrays/asList(T[])
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()/$anonymous1/()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/lang/String/getBytes(java.lang.String)
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/lang/Object/getClass()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/util/HashMap/HashMap()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#parquet/hadoop/ParquetWriter/write(T)
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/nio/ByteBuffer/wrap(byte[])
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/util/Map/put(K,V)
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#parquet/hadoop/ParquetWriter/close()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/io/File/deleteOnExit()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/io/File/getPath()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/io/File/delete()
parquet/avro/TestReadWrite/testAllUsingDefaultAvroSchema()#java/lang/Object/Object()
parquet/avro/TestReadWrite/testMapWithUtf8Key()#java/lang/Class/getSimpleName()
parquet/avro/TestReadWrite/testMapWithUtf8Key()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestReadWrite/testMapWithUtf8Key()#parquet/avro/AvroParquetWriter/AvroParquetWriter(parquet.hadoop.Path,parquet.pig.convert.Schema)
parquet/avro/TestReadWrite/testMapWithUtf8Key()#java/lang/Object/getClass()
parquet/avro/TestReadWrite/testMapWithUtf8Key()#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/avro/TestReadWrite/testMapWithUtf8Key()#java/io/File/deleteOnExit()
parquet/avro/TestReadWrite/testMapWithUtf8Key()#java/io/File/getPath()
parquet/avro/TestReadWrite/testMapWithUtf8Key()#java/io/File/delete()
parquet/avro/TestReadWrite/testMapWithUtf8Key()#java/lang/Object/Object()
parquet/avro/TestReadWrite/testEmptyArray()#java/util/ArrayList/ArrayList()
parquet/avro/TestReadWrite/testEmptyArray()#java/lang/Class/getSimpleName()
parquet/avro/TestReadWrite/testEmptyArray()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestReadWrite/testEmptyArray()#parquet/avro/AvroParquetWriter/AvroParquetWriter(parquet.hadoop.Path,parquet.pig.convert.Schema)
parquet/avro/TestReadWrite/testEmptyArray()#java/lang/Object/getClass()
parquet/avro/TestReadWrite/testEmptyArray()#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/avro/TestReadWrite/testEmptyArray()#java/io/File/deleteOnExit()
parquet/avro/TestReadWrite/testEmptyArray()#java/io/File/getPath()
parquet/avro/TestReadWrite/testEmptyArray()#java/io/File/delete()
parquet/avro/TestReadWrite/testEmptyArray()#java/lang/Object/Object()
parquet/proto/ProtoParquetInputFormat/setRequestedProjection(parquet.proto.utils.Job,java.lang.String)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/proto/ProtoParquetInputFormat/setRequestedProjection(parquet.proto.utils.Job,java.lang.String)#parquet/proto/ProtoReadSupport/setRequestedProjection(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/extractClassFromOption(java.lang.reflect.Type)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/getEnumList(java.lang.String)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#java/lang/Class/getName()
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/EnumValue/EnumValue(int,java.lang.String)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/EnumType/EnumType(java.util.List)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#java/util/List/add(E)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/ScroogeEnumDesc/getEnumDesc(java.lang.Object)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/isOptional(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#java/util/ArrayList/ArrayList()
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#java/lang/String/toUpperCase()
parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)#java/lang/String/replaceAll(java.lang.String,java.lang.String)
parquet/scrooge/ScroogeStructConverter/convertSetTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/SetType/SetType(parquet.thrift.struct.ThriftField)
parquet/scrooge/ScroogeStructConverter/convertSetTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#java/util/List/get(int)
parquet/scrooge/ScroogeStructConverter/convertSetTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)
parquet/scrooge/ScroogeStructConverter/convertSetTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/generateFieldWithoutId(java.lang.String,parquet.thrift.struct.ThriftField.Requirement,parquet.thrift.struct.ThriftType)
parquet/scrooge/ScroogeStructConverter/convertSetTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/getTypeArguments(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/extractClassFromOption(java.lang.reflect.Type)#java/lang/reflect/ParameterizedType/getActualTypeArguments()
parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)#parquet/scrooge/ScroogeStructConverter/convertStructFromClassName(java.lang.String)
parquet/scrooge/ScroogeStructConverter/convert(java.lang.Class)#java/lang/Class/getName()
parquet/scrooge/ScroogeStructConverter/getEnumList(java.lang.String)#java/lang/Class/forName(java.lang.String)
parquet/scrooge/ScroogeStructConverter/getEnumList(java.lang.String)#java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object[])
parquet/scrooge/ScroogeStructConverter/getEnumList(java.lang.String)#java/lang/Class/getMethod(java.lang.String,java.lang.Class<?>[])
parquet/scrooge/ScroogeStructConverter/getEnumList(java.lang.String)#java/lang/Class/getField(java.lang.String)
parquet/scrooge/ScroogeStructConverter/getEnumList(java.lang.String)#java/lang/reflect/Field/get(java.lang.Object)
parquet/scrooge/ScroogeStructConverter/convertListTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#java/util/List/get(int)
parquet/scrooge/ScroogeStructConverter/convertListTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)
parquet/scrooge/ScroogeStructConverter/convertListTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/ListType/ListType(parquet.thrift.struct.ThriftField)
parquet/scrooge/ScroogeStructConverter/convertListTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/generateFieldWithoutId(java.lang.String,parquet.thrift.struct.ThriftField.Requirement,parquet.thrift.struct.ThriftType)
parquet/scrooge/ScroogeStructConverter/convertListTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/getTypeArguments(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)#parquet/thrift/struct/ThriftType/StructType/StructType(java.util.List)
parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)#java/util/List/add(E)
parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)#parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)#java/lang/Class/getField(java.lang.String)
parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)#java/lang/reflect/Field/get(java.lang.Object)
parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)#java/lang/Class/getName()
parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)#java/util/LinkedList/LinkedList()
parquet/scrooge/ScroogeStructConverter/convertStructTypeField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/extractClassFromOption(java.lang.reflect.Type)
parquet/scrooge/ScroogeStructConverter/convertStructTypeField(parquet.scrooge.ThriftStructField)#java/lang/Class/getName()
parquet/scrooge/ScroogeStructConverter/convertStructTypeField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/convertStructFromClassName(java.lang.String)
parquet/scrooge/ScroogeStructConverter/convertStructTypeField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/isOptional(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#parquet/scrooge/ScroogeStructConverter/convertStructFromClassName(java.lang.String)
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#parquet/thrift/struct/ThriftType/I16Type/I16Type()
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#java/lang/Class/getName()
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#parquet/thrift/struct/ThriftType/I64Type/I64Type()
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#parquet/thrift/struct/ThriftType/I32Type/I32Type()
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#parquet/thrift/struct/ThriftType/BoolType/BoolType()
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#parquet/thrift/struct/ThriftType/ByteType/ByteType()
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#parquet/thrift/struct/ThriftType/DoubleType/DoubleType()
parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)#parquet/thrift/struct/ThriftType/StringType/StringType()
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/convertEnumTypeField(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftField/ThriftField(java.lang.String,short,parquet.thrift.struct.ThriftField.Requirement,parquet.thrift.struct.ThriftType)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/isOptional(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftTypeID/fromByte(byte)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/convertListTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/convertStructTypeField(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/I64Type/I64Type()
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/convertMapTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/scrooge/ScroogeStructConverter/convertSetTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/I16Type/I16Type()
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/BoolType/BoolType()
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/ByteType/ByteType()
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/DoubleType/DoubleType()
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/StringType/StringType()
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/scrooge/ScroogeStructConverter/toThriftField(parquet.scrooge.ThriftStructField)#parquet/thrift/struct/ThriftType/I32Type/I32Type()
parquet/scrooge/ScroogeStructConverter/convertMapTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#java/util/List/get(int)
parquet/scrooge/ScroogeStructConverter/convertMapTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/generateFieldWithoutId(java.lang.String,parquet.thrift.struct.ThriftField.Requirement,parquet.thrift.struct.ThriftType)
parquet/scrooge/ScroogeStructConverter/convertMapTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/getTypeArguments(parquet.scrooge.ThriftStructField)
parquet/scrooge/ScroogeStructConverter/convertMapTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/thrift/struct/ThriftType/MapType/MapType(parquet.thrift.struct.ThriftField,parquet.thrift.struct.ThriftField)
parquet/scrooge/ScroogeStructConverter/convertMapTypeField(parquet.scrooge.ThriftStructField,parquet.thrift.struct.ThriftField.Requirement)#parquet/scrooge/ScroogeStructConverter/convertClassToThriftType(java.lang.Class)
parquet/scrooge/ScroogeStructConverter/convertStructFromClassName(java.lang.String)#java/lang/Class/forName(java.lang.String)
parquet/scrooge/ScroogeStructConverter/convertStructFromClassName(java.lang.String)#parquet/scrooge/ScroogeStructConverter/convertCompanionClassToStruct(java.lang.Class)
parquet/scrooge/ScroogeStructConverter/convertStructFromClassName(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)
parquet/scrooge/ScroogeStructConverter/generateFieldWithoutId(java.lang.String,parquet.thrift.struct.ThriftField.Requirement,parquet.thrift.struct.ThriftType)#parquet/thrift/struct/ThriftField/ThriftField(java.lang.String,short,parquet.thrift.struct.ThriftField.Requirement,parquet.thrift.struct.ThriftType)
parquet/scrooge/ScroogeStructConverter/getTypeArguments(parquet.scrooge.ThriftStructField)#java/util/ArrayList/ArrayList()
parquet/scrooge/ScroogeStructConverter/getTypeArguments(parquet.scrooge.ThriftStructField)#java/util/List/add(E)
parquet/proto/ProtoWriteSupport/ArrayWriter/writeRawValue(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/proto/ProtoWriteSupport/ArrayWriter/writeField(java.lang.Object)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/proto/ProtoWriteSupport/ArrayWriter/writeField(java.lang.Object)#parquet/proto/ProtoWriteSupport/FieldWriter/writeRawValue(java.lang.Object)
parquet/proto/ProtoWriteSupport/ArrayWriter/writeField(java.lang.Object)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/hadoop/api/ReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()
parquet/hadoop/api/ReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getConfiguration()
parquet/hadoop/api/ReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)
parquet/hadoop/api/ReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getFileSchema()
parquet/hadoop/api/ReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/hadoop/api/ReadSupport/getSchemaForRead(parquet.schema.MessageType,parquet.schema.MessageType)#parquet/schema/MessageType/checkContains(parquet.schema.Type)
parquet/hadoop/api/ReadSupport/getSchemaForRead(parquet.schema.MessageType,java.lang.String)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/api/ReadSupport/getSchemaForRead(parquet.schema.MessageType,java.lang.String)#parquet/hadoop/api/ReadSupport/getSchemaForRead(parquet.schema.MessageType,parquet.schema.MessageType)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/ParquetInputSplitWrapper/write(java.io.DataOutput)#parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/ParquetInputSplitWrapper/readFields(java.io.DataInput)#parquet/hadoop/ParquetInputSplit/ParquetInputSplit()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/ParquetInputSplitWrapper/readFields(java.io.DataInput)#parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)
parquet/thrift/TestParquetReadProtocol/testReadEmpty()#parquet/thrift/TestParquetReadProtocol/validate(T)
parquet/thrift/TestParquetReadProtocol/testOneOfEach()#java/util/ArrayList/ArrayList()
parquet/thrift/TestParquetReadProtocol/testOneOfEach()#parquet/thrift/TestParquetReadProtocol/validate(T)
parquet/thrift/TestParquetReadProtocol/testOneOfEach()#java/util/List/add(E)
parquet/thrift/TestParquetReadProtocol/testOneOfEach()#java/nio/ByteBuffer/wrap(byte[])
parquet/thrift/TestParquetReadProtocol/testOneOfEach()#java/lang/String/getBytes()
parquet/thrift/TestParquetReadProtocol/testRead()#parquet/thrift/TestParquetReadProtocol/validate(T)
parquet/thrift/TestParquetReadProtocol/testRead()#java/util/Arrays/asList(T[])
parquet/thrift/TestParquetReadProtocol/testRead()#java/lang/Object/Object()
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/Log/info(java.lang.Object)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/thrift/TBaseRecordConverter/TBaseRecordConverter(java.lang.Class,parquet.schema.MessageType,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/thrift/TestParquetReadProtocol/validate(T)#java/lang/Object/getClass()
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/thrift/ParquetWriteProtocol/ParquetWriteProtocol(parquet.io.api.RecordConsumer,parquet.io.MessageColumnIO,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/TestParquetReadProtocol/validate(T)#parquet/io/RecordReader/read()
parquet/thrift/TestParquetReadProtocol/testList()#java/util/ArrayList/ArrayList()
parquet/thrift/TestParquetReadProtocol/testList()#parquet/thrift/TestParquetReadProtocol/validate(T)
parquet/thrift/TestParquetReadProtocol/testList()#java/util/List/add(E)
parquet/thrift/TestParquetReadProtocol/testMap()#parquet/thrift/TestParquetReadProtocol/validate(T)
parquet/thrift/TestParquetReadProtocol/testMap()#java/util/HashMap/HashMap()
parquet/thrift/TestParquetReadProtocol/testMap()#java/util/Map/put(K,V)
parquet/thrift/TestParquetReadProtocol/testStructInMap()#parquet/thrift/TestParquetReadProtocol/validate(T)
parquet/thrift/TestParquetReadProtocol/testStructInMap()#java/util/Collections/singletonMap(K,V)
parquet/thrift/TestParquetReadProtocol/testStructInMap()#java/util/HashMap/HashMap()
parquet/thrift/TestParquetReadProtocol/testStructInMap()#java/lang/Object/Object()
parquet/thrift/TestParquetReadProtocol/testSet()#parquet/thrift/TestParquetReadProtocol/validate(T)
parquet/thrift/TestParquetReadProtocol/testSet()#java/util/Set/add(E)
parquet/thrift/TestParquetReadProtocol/testSet()#java/util/HashSet/HashSet()
parquet/hadoop/ParquetInputSplit/readUTF8(java.io.DataInput)#java/lang/String/String(byte[],java.nio.charset.Charset)
parquet/hadoop/ParquetInputSplit/readUTF8(java.io.DataInput)#java/lang/String/intern()
parquet/hadoop/ParquetInputSplit/readUTF8(java.io.DataInput)#parquet/hadoop/ParquetInputSplit/readArray(java.io.DataInput)
parquet/hadoop/ParquetInputSplit/writeArray(java.io.DataOutput,byte[])#java/io/DataOutput/write(byte[],int,int)
parquet/hadoop/ParquetInputSplit/writeArray(java.io.DataOutput,byte[])#java/io/DataOutput/writeInt(int)
parquet/hadoop/ParquetInputSplit/writeUTF8(java.io.DataOutput,java.lang.String)#parquet/hadoop/ParquetInputSplit/writeArray(java.io.DataOutput,byte[])
parquet/hadoop/ParquetInputSplit/writeUTF8(java.io.DataOutput,java.lang.String)#java/lang/String/getBytes(java.nio.charset.Charset)
parquet/hadoop/ParquetInputSplit/readKeyValues(java.io.DataInput)#parquet/hadoop/ParquetInputSplit/readUTF8(java.io.DataInput)
parquet/hadoop/ParquetInputSplit/readKeyValues(java.io.DataInput)#java/io/DataInput/readInt()
parquet/hadoop/ParquetInputSplit/readKeyValues(java.io.DataInput)#java/util/HashMap/HashMap(int)
parquet/hadoop/ParquetInputSplit/readKeyValues(java.io.DataInput)#java/lang/String/intern()
parquet/hadoop/ParquetInputSplit/readKeyValues(java.io.DataInput)#java/util/Map/put(K,V)
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#parquet/hadoop/ParquetInputSplit/writeKeyValues(java.io.DataOutput,java.util.Map)
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#java/io/DataOutputStream/writeInt(int)
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#parquet/hadoop/ParquetInputSplit/writeUTF8(java.io.DataOutput,java.lang.String)
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#java/io/FilterOutputStream/close()
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#parquet/hadoop/ParquetInputSplit/writeArray(java.io.DataOutput,byte[])
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#java/util/zip/GZIPOutputStream/GZIPOutputStream(java.io.OutputStream)
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#java/io/DataOutputStream/writeBoolean(boolean)
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#java/io/DataOutputStream/writeLong(long)
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#java/io/DataOutputStream/DataOutputStream(java.io.OutputStream)
parquet/hadoop/ParquetInputSplit/write(java.io.DataOutput)#java/io/ByteArrayOutputStream/toByteArray()
parquet/hadoop/ParquetInputSplit/readArray(java.io.DataInput)#java/io/DataInput/readInt()
parquet/hadoop/ParquetInputSplit/readArray(java.io.DataInput)#java/io/DataInput/readFully(byte[])
parquet/hadoop/ParquetInputSplit/writeKeyValues(java.io.DataOutput,java.util.Map)#java/io/DataOutput/writeInt(int)
parquet/hadoop/ParquetInputSplit/writeKeyValues(java.io.DataOutput,java.util.Map)#java/util/Map/Entry/getValue()
parquet/hadoop/ParquetInputSplit/writeKeyValues(java.io.DataOutput,java.util.Map)#parquet/hadoop/ParquetInputSplit/writeUTF8(java.io.DataOutput,java.lang.String)
parquet/hadoop/ParquetInputSplit/writeKeyValues(java.io.DataOutput,java.util.Map)#java/util/Map/size()
parquet/hadoop/ParquetInputSplit/writeKeyValues(java.io.DataOutput,java.util.Map)#java/util/Map/Entry/getKey()
parquet/hadoop/ParquetInputSplit/writeKeyValues(java.io.DataOutput,java.util.Map)#java/util/Map/entrySet()
parquet/hadoop/ParquetInputSplit/toString()#java/lang/Class/getSimpleName()
parquet/hadoop/ParquetInputSplit/toString()#java/lang/Object/getClass()
parquet/hadoop/ParquetInputSplit/toString()#parquet/hadoop/ParquetInputSplit/getEnd()
parquet/hadoop/ParquetInputSplit/toString()#java/util/Arrays/toString(long[])
parquet/hadoop/ParquetInputSplit/offsets(java.util.List)#java/util/List/size()
parquet/hadoop/ParquetInputSplit/offsets(java.util.List)#java/util/List/get(int)
parquet/hadoop/ParquetInputSplit/offsets(java.util.List)#parquet/hadoop/metadata/BlockMetaData/getStartingPos()
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#java/util/zip/GZIPInputStream/GZIPInputStream(java.io.InputStream)
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#java/io/DataInputStream/readBoolean()
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#parquet/hadoop/ParquetInputSplit/readUTF8(java.io.DataInput)
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#java/io/DataInputStream/readInt()
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#java/io/DataInputStream/DataInputStream(java.io.InputStream)
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#java/io/FilterInputStream/close()
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#parquet/hadoop/ParquetInputSplit/readArray(java.io.DataInput)
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#parquet/hadoop/ParquetInputSplit/readKeyValues(java.io.DataInput)
parquet/hadoop/ParquetInputSplit/readFields(java.io.DataInput)#java/io/DataInputStream/readLong()
parquet/hadoop/ParquetInputSplit/end(java.util.List)#java/util/List/size()
parquet/hadoop/ParquetInputSplit/end(java.util.List)#parquet/hadoop/metadata/BlockMetaData/getCompressedSize()
parquet/hadoop/ParquetInputSplit/end(java.util.List)#java/util/List/get(int)
parquet/hadoop/ParquetInputSplit/end(java.util.List)#parquet/hadoop/metadata/BlockMetaData/getStartingPos()
parquet/schema/MessageTypeParser/Tokenizer/nextToken()#java/lang/String/equals(java.lang.Object)
parquet/schema/MessageTypeParser/Tokenizer/nextToken()#parquet/schema/MessageTypeParser/Tokenizer/isWhitespace(java.lang.String)
parquet/schema/MessageTypeParser/Tokenizer/nextToken()#java/lang/StringBuffer/append(java.lang.String)
parquet/schema/MessageTypeParser/Tokenizer/nextToken()#java/util/StringTokenizer/hasMoreTokens()
parquet/schema/MessageTypeParser/Tokenizer/nextToken()#java/lang/StringBuffer/setLength(int)
parquet/schema/MessageTypeParser/Tokenizer/nextToken()#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/schema/MessageTypeParser/Tokenizer/nextToken()#java/util/StringTokenizer/nextToken()
parquet/schema/MessageTypeParser/Tokenizer/isWhitespace(java.lang.String)#java/lang/String/equals(java.lang.Object)
parquet/schema/MessageTypeParser/Tokenizer/getLocationString()#java/lang/StringBuffer/toString()
parquet/bytes/BytesInput/BAOSBytesInput/writeAllTo(java.io.OutputStream)#java/io/ByteArrayOutputStream/writeTo(java.io.OutputStream)
parquet/bytes/BytesInput/BAOSBytesInput/size()#java/io/ByteArrayOutputStream/size()
parquet/hadoop/TestLruCache/testRemove()#parquet/hadoop/LruCache/LruCache(int)
parquet/hadoop/TestLruCache/testRemove()#parquet/hadoop/LruCache/size()
parquet/hadoop/TestLruCache/testRemove()#parquet/hadoop/LruCache/remove(K)
parquet/hadoop/TestLruCache/testRemove()#parquet/hadoop/LruCache/put(K,V)
parquet/hadoop/TestLruCache/testRemove()#parquet/hadoop/TestLruCache/SimpleValue/SimpleValue(boolean,boolean)
parquet/hadoop/TestLruCache/testRemove()#parquet/hadoop/LruCache/getCurrentValue(K)
parquet/hadoop/TestLruCache/testCurrentValueOverwritesExisting()#parquet/hadoop/LruCache/LruCache(int)
parquet/hadoop/TestLruCache/testCurrentValueOverwritesExisting()#parquet/hadoop/LruCache/size()
parquet/hadoop/TestLruCache/testCurrentValueOverwritesExisting()#parquet/hadoop/LruCache/put(K,V)
parquet/hadoop/TestLruCache/testCurrentValueOverwritesExisting()#parquet/hadoop/TestLruCache/SimpleValue/SimpleValue(boolean,boolean)
parquet/hadoop/TestLruCache/testCurrentValueOverwritesExisting()#parquet/hadoop/LruCache/getCurrentValue(K)
parquet/hadoop/TestLruCache/testMaxSize()#parquet/hadoop/LruCache/LruCache(int)
parquet/hadoop/TestLruCache/testMaxSize()#parquet/hadoop/LruCache/size()
parquet/hadoop/TestLruCache/testMaxSize()#parquet/hadoop/LruCache/put(K,V)
parquet/hadoop/TestLruCache/testMaxSize()#parquet/hadoop/TestLruCache/SimpleValue/SimpleValue(boolean,boolean)
parquet/hadoop/TestLruCache/testMaxSize()#parquet/hadoop/LruCache/getCurrentValue(K)
parquet/hadoop/TestLruCache/testOlderValueIsIgnored()#parquet/hadoop/LruCache/LruCache(int)
parquet/hadoop/TestLruCache/testOlderValueIsIgnored()#parquet/hadoop/LruCache/put(K,V)
parquet/hadoop/TestLruCache/testOlderValueIsIgnored()#parquet/hadoop/TestLruCache/SimpleValue/SimpleValue(boolean,boolean)
parquet/hadoop/TestLruCache/testOlderValueIsIgnored()#parquet/hadoop/LruCache/getCurrentValue(K)
parquet/hadoop/TestLruCache/testClear()#parquet/hadoop/LruCache/LruCache(int)
parquet/hadoop/TestLruCache/testClear()#parquet/hadoop/LruCache/size()
parquet/hadoop/TestLruCache/testClear()#parquet/hadoop/LruCache/put(K,V)
parquet/hadoop/TestLruCache/testClear()#parquet/hadoop/TestLruCache/SimpleValue/SimpleValue(boolean,boolean)
parquet/hadoop/TestLruCache/testClear()#parquet/hadoop/LruCache/clear()
parquet/hadoop/TestLruCache/testClear()#parquet/hadoop/LruCache/getCurrentValue(K)
parquet/hadoop/TestLruCache/testGetOutdatedValueReturnsNull()#parquet/hadoop/TestLruCache/SimpleValue/setCurrent(boolean)
parquet/hadoop/TestLruCache/testGetOutdatedValueReturnsNull()#parquet/hadoop/LruCache/LruCache(int)
parquet/hadoop/TestLruCache/testGetOutdatedValueReturnsNull()#parquet/hadoop/LruCache/size()
parquet/hadoop/TestLruCache/testGetOutdatedValueReturnsNull()#parquet/hadoop/LruCache/put(K,V)
parquet/hadoop/TestLruCache/testGetOutdatedValueReturnsNull()#parquet/hadoop/TestLruCache/SimpleValue/SimpleValue(boolean,boolean)
parquet/hadoop/TestLruCache/testGetOutdatedValueReturnsNull()#parquet/hadoop/LruCache/getCurrentValue(K)
parquet/hadoop/TestLruCache/testOutdatedValueIsIgnored()#parquet/hadoop/LruCache/LruCache(int)
parquet/hadoop/TestLruCache/testOutdatedValueIsIgnored()#parquet/hadoop/LruCache/size()
parquet/hadoop/TestLruCache/testOutdatedValueIsIgnored()#parquet/hadoop/LruCache/put(K,V)
parquet/hadoop/TestLruCache/testOutdatedValueIsIgnored()#parquet/hadoop/TestLruCache/SimpleValue/SimpleValue(boolean,boolean)
parquet/hadoop/TestLruCache/testOutdatedValueIsIgnored()#parquet/hadoop/LruCache/getCurrentValue(K)
parquet/avro/AvroIndexedRecordConverter/AvroArrayConverter/end()#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader/getCounterByNameAndFlag(java.lang.String,java.lang.String,java.lang.String)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader/getCounterByNameAndFlag(java.lang.String,java.lang.String,java.lang.String)#parquet/hadoop/util/counters/BenchmarkCounter/NullCounter/NullCounter()
parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader/getCounterByNameAndFlag(java.lang.String,java.lang.String,java.lang.String)#parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter/MapReduceCounterAdapter(parquet.hadoop.example.Counter)
parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader/getCounterByNameAndFlag(java.lang.String,java.lang.String,java.lang.String)#parquet/hadoop/util/ContextUtil/getCounter(parquet.hadoop.util.TaskInputOutputContext,java.lang.String,java.lang.String)
parquet/thrift/struct/CompatibilityCheckerTest/testAddOptionalField()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/thrift/struct/CompatibilityCheckerTest/testAddRequiredField()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)#parquet/thrift/struct/CompatibilityReport/isCompatible()
parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)#parquet/thrift/struct/CompatibilityChecker/checkCompatibility(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)#parquet/thrift/struct/CompatibilityChecker/CompatibilityChecker()
parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)#parquet/thrift/struct/CompatibilityCheckerTest/struct(java.lang.Class)
parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)#java/io/PrintStream/println(java.lang.Object)
parquet/thrift/struct/CompatibilityCheckerTest/testReuirementChange()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/thrift/struct/CompatibilityCheckerTest/struct(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/struct/CompatibilityCheckerTest/struct(java.lang.Class)#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/struct/CompatibilityCheckerTest/testList()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/thrift/struct/CompatibilityCheckerTest/testRemoveOptionalField()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/thrift/struct/CompatibilityCheckerTest/testRenameField()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/thrift/struct/CompatibilityCheckerTest/testMap()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/thrift/struct/CompatibilityCheckerTest/testTypeChange()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/thrift/struct/CompatibilityCheckerTest/testSet()#parquet/thrift/struct/CompatibilityCheckerTest/verifyCompatible(java.lang.Class,java.lang.Class,boolean)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/accept(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.Visitor)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/Visitor/visit(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(float)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(double)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/getResult()#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/setResult(boolean)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(boolean)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(long)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/updateNull()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(parquet.io.api.Binary)#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/recordlevel/FilteringRecordMaterializer/skipCurrentRecord()#parquet/io/api/RecordMaterializer/skipCurrentRecord()
parquet/filter2/recordlevel/FilteringRecordMaterializer/getIndexFieldPathList(parquet.io.PrimitiveColumnIO)#parquet/io/ColumnIO/getIndexFieldPath()
parquet/filter2/recordlevel/FilteringRecordMaterializer/getIndexFieldPathList(parquet.io.PrimitiveColumnIO)#parquet/filter2/recordlevel/FilteringRecordMaterializer/intArrayToList(int[])
parquet/filter2/recordlevel/FilteringRecordMaterializer/getCurrentRecord()#parquet/io/api/RecordMaterializer/getCurrentRecord()
parquet/filter2/recordlevel/FilteringRecordMaterializer/getCurrentRecord()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator/evaluate(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/FilteringRecordMaterializer/getCurrentRecord()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/reset(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/FilteringRecordMaterializer/intArrayToList(int[])#java/util/ArrayList/ArrayList(int)
parquet/filter2/recordlevel/FilteringRecordMaterializer/intArrayToList(int[])#java/util/List/add(E)
parquet/hadoop/ColumnChunkPageReadStore/addColumn(parquet.column.ColumnDescriptor,parquet.hadoop.ColumnChunkPageReadStore.ColumnChunkPageReader)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/ColumnChunkPageReadStore/addColumn(parquet.column.ColumnDescriptor,parquet.hadoop.ColumnChunkPageReadStore.ColumnChunkPageReader)#java/util/Map/put(K,V)
parquet/hadoop/ColumnChunkPageReadStore/getPageReader(parquet.column.ColumnDescriptor)#java/util/Map/get(java.lang.Object)
parquet/hadoop/ColumnChunkPageReadStore/getPageReader(parquet.column.ColumnDescriptor)#java/util/Map/keySet()
parquet/hadoop/ColumnChunkPageReadStore/getPageReader(parquet.column.ColumnDescriptor)#java/util/Map/containsKey(java.lang.Object)
parquet/hadoop/ColumnChunkPageReadStore/getPageReader(parquet.column.ColumnDescriptor)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/column/values/bitpacking/BaseBitPackingReader/alignToBytes(int)#parquet/bytes/BytesUtils/paddedByteCountFromBits(int)
parquet/hadoop/api/WriteSupport/finalizeWrite()#java/util/HashMap/HashMap()
parquet/hadoop/api/WriteSupport/finalizeWrite()#parquet/hadoop/api/WriteSupport/FinalizedWriteContext/FinalizedWriteContext(java.util.Map)
parquet/column/Dictionary/decodeToFloat(int)#java/lang/Class/getName()
parquet/column/Dictionary/decodeToFloat(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/Dictionary/decodeToFloat(int)#java/lang/Object/getClass()
parquet/column/Dictionary/decodeToDouble(int)#java/lang/Class/getName()
parquet/column/Dictionary/decodeToDouble(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/Dictionary/decodeToDouble(int)#java/lang/Object/getClass()
parquet/column/Dictionary/decodeToInt(int)#java/lang/Class/getName()
parquet/column/Dictionary/decodeToInt(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/Dictionary/decodeToInt(int)#java/lang/Object/getClass()
parquet/column/Dictionary/decodeToBoolean(int)#java/lang/Class/getName()
parquet/column/Dictionary/decodeToBoolean(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/Dictionary/decodeToBoolean(int)#java/lang/Object/getClass()
parquet/column/Dictionary/decodeToBinary(int)#java/lang/Class/getName()
parquet/column/Dictionary/decodeToBinary(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/Dictionary/decodeToBinary(int)#java/lang/Object/getClass()
parquet/column/Dictionary/decodeToLong(int)#java/lang/Class/getName()
parquet/column/Dictionary/decodeToLong(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/column/Dictionary/decodeToLong(int)#java/lang/Object/getClass()
parquet/io/RecordReaderImplementation/log(java.lang.String)#parquet/Log/debug(java.lang.Object)
parquet/io/RecordReaderImplementation/read()#parquet/io/api/RecordMaterializer/getCurrentRecord()
parquet/io/RecordReaderImplementation/read()#parquet/io/api/GroupConverter/end()
parquet/io/RecordReaderImplementation/read()#parquet/io/api/RecordMaterializer/skipCurrentRecord()
parquet/io/RecordReaderImplementation/read()#parquet/column/ColumnReader/getCurrentDefinitionLevel()
parquet/io/RecordReaderImplementation/read()#parquet/io/api/GroupConverter/start()
parquet/io/RecordReaderImplementation/read()#parquet/column/ColumnReader/getCurrentRepetitionLevel()
parquet/io/RecordReaderImplementation/read()#parquet/column/ColumnReader/consume()
parquet/io/RecordReaderImplementation/read()#parquet/column/ColumnReader/writeCurrentValueToConverter()
parquet/io/RecordReaderImplementation/getCommonParentLevel(java.lang.String[],java.lang.String[])#java/lang/String/equals(java.lang.Object)
parquet/io/RecordReaderImplementation/getCommonParentLevel(java.lang.String[],java.lang.String[])#java/lang/Math/min(int,int)
parquet/io/RecordReaderImplementation/getColumnReaders()#java/util/Arrays/asList(T[])
parquet/io/RecordReaderImplementation/wrap(parquet.io.api.RecordConsumer)#parquet/io/RecordConsumerLoggingWrapper/RecordConsumerLoggingWrapper(parquet.io.api.RecordConsumer)
parquet/io/RecordReaderImplementation/validator(parquet.io.api.RecordConsumer,boolean,parquet.schema.MessageType)#parquet/io/ValidatingRecordConsumer/ValidatingRecordConsumer(parquet.io.api.RecordConsumer,parquet.schema.MessageType)
parquet/pig/convert/TupleConverter/FieldStringConverter/addValueFromDictionary(int)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldStringConverter/setDictionary(parquet.column.Dictionary)#parquet/column/Dictionary/decodeToBinary(int)
parquet/pig/convert/TupleConverter/FieldStringConverter/setDictionary(parquet.column.Dictionary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/pig/convert/TupleConverter/FieldStringConverter/setDictionary(parquet.column.Dictionary)#parquet/column/Dictionary/getMaxId()
parquet/pig/convert/TupleConverter/FieldStringConverter/addFloat(float)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldStringConverter/addFloat(float)#java/lang/Float/toString(float)
parquet/pig/convert/TupleConverter/FieldStringConverter/addBinary(parquet.io.api.Binary)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldStringConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/pig/convert/TupleConverter/FieldStringConverter/addLong(long)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldStringConverter/addLong(long)#java/lang/Long/toString(long)
parquet/pig/convert/TupleConverter/FieldStringConverter/addDouble(double)#java/lang/Double/toString(double)
parquet/pig/convert/TupleConverter/FieldStringConverter/addDouble(double)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldStringConverter/addBoolean(boolean)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldStringConverter/addBoolean(boolean)#java/lang/Boolean/toString(boolean)
parquet/pig/convert/TupleConverter/FieldStringConverter/addInt(int)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldStringConverter/addInt(int)#java/lang/Integer/toString(int)
parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/zip/GZIPInputStream/GZIPInputStream(java.io.InputStream)
parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/IOException/IOException(java.lang.String,java.lang.Throwable)
parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/ObjectInputStream/readObject()
parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/Closeables/close(java.io.Closeable)
parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/String/getBytes(java.lang.String)
parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/ObjectInputStream/ObjectInputStream(java.io.InputStream)
parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/zip/GZIPOutputStream/GZIPOutputStream(java.io.OutputStream)
parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/String/String(byte[],java.lang.String)
parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/Closeables/close(java.io.Closeable)
parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/ObjectOutputStream/writeObject(java.lang.Object)
parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/ObjectOutputStream/ObjectOutputStream(java.io.OutputStream)
parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/io/ByteArrayOutputStream/toByteArray()
parquet/pig/convert/TupleConverter/FieldDoubleConverter/addBinary(parquet.io.api.Binary)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldDoubleConverter/addBinary(parquet.io.api.Binary)#java/lang/Double/parseDouble(java.lang.String)
parquet/pig/convert/TupleConverter/FieldDoubleConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/pig/convert/TupleConverter/FieldDoubleConverter/addInt(int)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldDoubleConverter/addFloat(float)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldDoubleConverter/addLong(long)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldDoubleConverter/addDouble(double)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldDoubleConverter/addBoolean(boolean)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/proto/ProtoWriteSupport/FieldWriter/writeField(java.lang.Object)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/proto/ProtoWriteSupport/FieldWriter/writeField(java.lang.Object)#parquet/proto/ProtoWriteSupport/FieldWriter/writeRawValue(java.lang.Object)
parquet/proto/ProtoWriteSupport/FieldWriter/writeField(java.lang.Object)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/hadoop/ParquetInputFormat/FootersCacheValue/isCurrent(parquet.hadoop.ParquetInputFormat.FileStatusWrapper)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetInputFormat/FootersCacheValue/isCurrent(parquet.hadoop.ParquetInputFormat.FileStatusWrapper)#parquet/hadoop/ParquetInputFormat/FileStatusWrapper/getModificationTime()
parquet/hadoop/ParquetInputFormat/FootersCacheValue/getPath()#parquet/hadoop/Footer/getFile()
parquet/column/values/dictionary/DictionaryValuesWriter/getAllocatedSize()#parquet/column/values/dictionary/IntList/size()
parquet/column/values/dictionary/DictionaryValuesWriter/getAllocatedSize()#parquet/column/values/ValuesWriter/getAllocatedSize()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/dictionary/IntList/IntIterator/hasNext()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/bytes/BytesUtils/getWidthFromMaxInt(int)
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/bytes/BytesInput/size()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/dictionary/DictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/dictionary/DictionaryValuesWriter/fallBackToPlainEncoding()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/bytes/BytesInput/from(byte[])
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/dictionary/IntList/IntIterator/next()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/column/values/dictionary/IntList/iterator()
parquet/column/values/dictionary/DictionaryValuesWriter/getBytes()#parquet/Log/debug(java.lang.Object)
parquet/column/values/dictionary/DictionaryValuesWriter/fallBackToPlainEncoding()#parquet/column/values/dictionary/DictionaryValuesWriter/clearDictionaryContent()
parquet/column/values/dictionary/DictionaryValuesWriter/fallBackToPlainEncoding()#parquet/column/values/dictionary/DictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/DictionaryValuesWriter/fallBackToPlainEncoding()#parquet/Log/debug(java.lang.Object)
parquet/column/values/dictionary/DictionaryValuesWriter/fallBackToPlainEncoding()#parquet/column/values/dictionary/DictionaryValuesWriter/fallBackDictionaryEncodedData()
parquet/column/values/dictionary/DictionaryValuesWriter/fallBackToPlainEncoding()#parquet/column/values/dictionary/IntList/IntList()
parquet/column/values/dictionary/DictionaryValuesWriter/resetDictionary()#parquet/column/values/dictionary/DictionaryValuesWriter/clearDictionaryContent()
parquet/column/values/dictionary/DictionaryValuesWriter/getEncoding()#parquet/column/values/dictionary/DictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/DictionaryValuesWriter/getEncoding()#parquet/column/values/ValuesWriter/getEncoding()
parquet/column/values/dictionary/DictionaryValuesWriter/memUsageString(java.lang.String)#parquet/column/values/dictionary/IntList/size()
parquet/column/values/dictionary/DictionaryValuesWriter/memUsageString(java.lang.String)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/values/dictionary/DictionaryValuesWriter/memUsageString(java.lang.String)#java/lang/String/valueOf(int)
parquet/column/values/dictionary/DictionaryValuesWriter/memUsageString(java.lang.String)#parquet/column/values/ValuesWriter/memUsageString(java.lang.String)
parquet/column/values/dictionary/DictionaryValuesWriter/reset()#parquet/column/values/dictionary/IntList/IntList()
parquet/column/values/dictionary/DictionaryValuesWriter/reset()#parquet/column/values/ValuesWriter/reset()
parquet/column/values/dictionary/DictionaryValuesWriter/checkAndFallbackIfNeeded()#parquet/column/values/dictionary/DictionaryValuesWriter/fallBackToPlainEncoding()
parquet/column/values/dictionary/DictionaryValuesWriter/checkAndFallbackIfNeeded()#parquet/column/values/dictionary/DictionaryValuesWriter/getDictionarySize()
parquet/column/values/bitpacking/BitPackingValuesWriter/getAllocatedSize()#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/column/values/bitpacking/BitPackingValuesWriter/memUsageString(java.lang.String)#parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)
parquet/column/values/bitpacking/BitPackingValuesWriter/reset()#parquet/column/values/bitpacking/BitPackingValuesWriter/init()
parquet/column/values/bitpacking/BitPackingValuesWriter/reset()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/column/values/bitpacking/BitPackingValuesWriter/getBufferedSize()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/bitpacking/BitPackingValuesWriter/init()#parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)
parquet/column/values/bitpacking/BitPackingValuesWriter/writeInteger(int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.Throwable)
parquet/column/values/bitpacking/BitPackingValuesWriter/writeInteger(int)#parquet/column/values/bitpacking/BitPacking/BitPackingWriter/write(int)
parquet/column/values/bitpacking/BitPackingValuesWriter/getBytes()#parquet/column/values/bitpacking/BitPacking/BitPackingWriter/finish()
parquet/column/values/bitpacking/BitPackingValuesWriter/getBytes()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.Throwable)
parquet/column/values/bitpacking/BitPackingValuesWriter/getBytes()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/column/values/bitpacking/TwoBitPackingWriter/finish()#parquet/column/values/bitpacking/TwoBitPackingWriter/write(int)
parquet/column/values/bitpacking/TwoBitPackingWriter/write(int)#java/io/OutputStream/write(int)
parquet/proto/ProtoMessageConverter/ProtoStringConverter/addBinary(parquet.io.api.Binary)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/proto/ProtoMessageConverter/ProtoStringConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/proto/ProtoMessageConverter/ProtoDoubleConverter/addDouble(double)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/example/data/simple/SimpleGroup/add(int,java.lang.String)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)
parquet/example/data/simple/SimpleGroup/add(int,java.lang.String)#parquet/example/data/simple/BinaryValue/BinaryValue(parquet.io.api.Binary)
parquet/example/data/simple/SimpleGroup/add(int,java.lang.String)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.Group)#java/util/List/add(E)
parquet/example/data/simple/SimpleGroup/getBoolean(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getBoolean(int,int)#parquet/example/data/simple/BooleanValue/getBoolean()
parquet/example/data/simple/SimpleGroup/add(int,double)#parquet/example/data/simple/DoubleValue/DoubleValue(double)
parquet/example/data/simple/SimpleGroup/add(int,double)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)
parquet/example/data/simple/SimpleGroup/getGroup(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getValueToString(int,int)#java/lang/String/valueOf(java.lang.Object)
parquet/example/data/simple/SimpleGroup/getValueToString(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getFloat(int,int)#parquet/example/data/simple/FloatValue/getFloat()
parquet/example/data/simple/SimpleGroup/getFloat(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#parquet/schema/Type/asPrimitiveType()
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#parquet/example/data/simple/SimpleGroup/getType()
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#parquet/schema/GroupType/getType(int)
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#parquet/example/data/simple/Int96Value/Int96Value(parquet.io.api.Binary)
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#parquet/schema/Type/getName()
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#parquet/example/data/simple/BinaryValue/BinaryValue(parquet.io.api.Binary)
parquet/example/data/simple/SimpleGroup/add(int,parquet.io.api.Binary)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/example/data/simple/SimpleGroup/toString()#parquet/example/data/simple/SimpleGroup/toString(java.lang.String)
parquet/example/data/simple/SimpleGroup/getLong(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getLong(int,int)#parquet/example/data/simple/LongValue/getLong()
parquet/example/data/simple/SimpleGroup/add(int,float)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)
parquet/example/data/simple/SimpleGroup/add(int,float)#parquet/example/data/simple/FloatValue/FloatValue(float)
parquet/example/data/simple/SimpleGroup/getTimeNanos(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getTimeNanos(int,int)#parquet/example/data/simple/NanoTime/fromInt96(parquet.example.data.simple.Int96Value)
parquet/example/data/simple/SimpleGroup/addGroup(int)#parquet/schema/Type/asGroupType()
parquet/example/data/simple/SimpleGroup/addGroup(int)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.Group)
parquet/example/data/simple/SimpleGroup/addGroup(int)#parquet/example/data/simple/SimpleGroup/SimpleGroup(parquet.schema.GroupType)
parquet/example/data/simple/SimpleGroup/addGroup(int)#parquet/schema/GroupType/getType(int)
parquet/example/data/simple/SimpleGroup/getValue(int,int)#parquet/schema/GroupType/getFieldName(int)
parquet/example/data/simple/SimpleGroup/getValue(int,int)#java/util/List/get(int)
parquet/example/data/simple/SimpleGroup/getValue(int,int)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/example/data/simple/SimpleGroup/add(int,long)#parquet/example/data/simple/LongValue/LongValue(long)
parquet/example/data/simple/SimpleGroup/add(int,long)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)
parquet/example/data/simple/SimpleGroup/getInt96(int,int)#parquet/example/data/simple/Int96Value/getInt96()
parquet/example/data/simple/SimpleGroup/getInt96(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getString(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getString(int,int)#parquet/example/data/simple/BinaryValue/getString()
parquet/example/data/simple/SimpleGroup/getDouble(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getDouble(int,int)#parquet/example/data/simple/DoubleValue/getDouble()
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.NanoTime)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.NanoTime)#parquet/example/data/simple/NanoTime/toInt96()
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)#parquet/schema/Type/isRepetition(parquet.schema.Type.Repetition)
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)#java/util/List/isEmpty()
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)#parquet/schema/GroupType/getType(int)
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)#java/util/List/add(E)
parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)#parquet/schema/Type/getName()
parquet/example/data/simple/SimpleGroup/add(int,int)#parquet/example/data/simple/IntegerValue/IntegerValue(int)
parquet/example/data/simple/SimpleGroup/add(int,int)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)
parquet/example/data/simple/SimpleGroup/writeValue(int,int,parquet.io.api.RecordConsumer)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/writeValue(int,int,parquet.io.api.RecordConsumer)#parquet/example/data/simple/Primitive/writeValue(parquet.io.api.RecordConsumer)
parquet/example/data/simple/SimpleGroup/add(int,boolean)#parquet/example/data/simple/SimpleGroup/add(int,parquet.example.data.simple.Primitive)
parquet/example/data/simple/SimpleGroup/add(int,boolean)#parquet/example/data/simple/BooleanValue/BooleanValue(boolean)
parquet/example/data/simple/SimpleGroup/getInteger(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getInteger(int,int)#parquet/example/data/simple/IntegerValue/getInteger()
parquet/example/data/simple/SimpleGroup/getFieldRepetitionCount(int)#java/util/List/size()
parquet/example/data/simple/SimpleGroup/getBinary(int,int)#parquet/example/data/simple/SimpleGroup/getValue(int,int)
parquet/example/data/simple/SimpleGroup/getBinary(int,int)#parquet/example/data/simple/BinaryValue/getBinary()
parquet/example/data/simple/SimpleGroup/toString(java.lang.String)#parquet/schema/GroupType/getFields()
parquet/example/data/simple/SimpleGroup/toString(java.lang.String)#java/lang/Object/toString()
parquet/example/data/simple/SimpleGroup/toString(java.lang.String)#java/util/List/size()
parquet/example/data/simple/SimpleGroup/toString(java.lang.String)#parquet/example/data/simple/SimpleGroup/toString(java.lang.String)
parquet/example/data/simple/SimpleGroup/toString(java.lang.String)#parquet/schema/Type/getName()
parquet/format/converter/ParquetMetadataConverter/EncodingList/equals(java.lang.Object)#java/util/Set/size()
parquet/format/converter/ParquetMetadataConverter/EncodingList/equals(java.lang.Object)#java/util/Set/containsAll(java.util.Collection)
parquet/format/converter/ParquetMetadataConverter/EncodingList/hashCode()#java/lang/Enum/hashCode()
parquet/hadoop/DeprecatedOutputFormatTest/DeprecatedMapper/map(parquet.hadoop.example.LongWritable,parquet.hadoop.example.Text,parquet.hadoop.OutputCollector,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/example/data/Group/append(java.lang.String,int)
parquet/hadoop/DeprecatedOutputFormatTest/DeprecatedMapper/map(parquet.hadoop.example.LongWritable,parquet.hadoop.example.Text,parquet.hadoop.OutputCollector,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/example/data/simple/SimpleGroupFactory/newGroup()
parquet/hadoop/DeprecatedOutputFormatTest/DeprecatedMapper/map(parquet.hadoop.example.LongWritable,parquet.hadoop.example.Text,parquet.hadoop.OutputCollector,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/example/data/Group/append(java.lang.String,parquet.example.data.simple.NanoTime)
parquet/hadoop/DeprecatedOutputFormatTest/DeprecatedMapper/configure(parquet.cascading.JobConf)#parquet/hadoop/example/GroupWriteSupport/getSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/DeprecatedOutputFormatTest/DeprecatedMapper/configure(parquet.cascading.JobConf)#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/pig/PerfTest/main(java.lang.String[])#java/util/ArrayList/ArrayList()
parquet/pig/PerfTest/main(java.lang.String[])#java/lang/StringBuilder/append(java.lang.String)
parquet/pig/PerfTest/main(java.lang.String[])#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/pig/PerfTest/main(java.lang.String[])#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/PerfTest/main(java.lang.String[])#java/io/PrintStream/println(java.lang.Object)
parquet/pig/PerfTest/main(java.lang.String[])#java/lang/Object/Object()
parquet/pig/PerfTest/main(java.lang.String[])#java/lang/StringBuilder/toString()
parquet/pig/PerfTest/main(java.lang.String[])#parquet/pig/PerfTest/load(java.lang.String,int)
parquet/pig/PerfTest/main(java.lang.String[])#java/lang/Class/getName()
parquet/pig/PerfTest/load(java.lang.String,int)#java/lang/StringBuilder/append(java.lang.String)
parquet/pig/PerfTest/load(java.lang.String,int)#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/pig/PerfTest/load(java.lang.String,int)#java/lang/Long/longValue()
parquet/pig/PerfTest/load(java.lang.String,int)#java/lang/Class/getName()
parquet/pig/PerfTest/load(java.lang.String,int)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/PerfTest/load(java.lang.String,int)#java/lang/System/currentTimeMillis()
parquet/pig/PerfTest/load(java.lang.String,int)#java/lang/Object/Object()
parquet/column/values/boundedint/BoundedIntValuesWriter/writeInteger(int)#parquet/column/values/boundedint/BoundedIntValuesWriter/serializeCurrentValue()
parquet/column/values/boundedint/BoundedIntValuesWriter/writeInteger(int)#parquet/column/values/boundedint/BoundedIntValuesWriter/newCurrentValue(int)
parquet/column/values/boundedint/BoundedIntValuesWriter/getBytes()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/values/boundedint/BoundedIntValuesWriter/getBytes()#parquet/bytes/BytesInput/fromInt(int)
parquet/column/values/boundedint/BoundedIntValuesWriter/getBytes()#parquet/column/values/boundedint/BitWriter/finish()
parquet/column/values/boundedint/BoundedIntValuesWriter/getBytes()#parquet/bytes/BytesInput/size()
parquet/column/values/boundedint/BoundedIntValuesWriter/getBytes()#parquet/Log/debug(java.lang.Object)
parquet/column/values/boundedint/BoundedIntValuesWriter/getBytes()#parquet/column/values/boundedint/BoundedIntValuesWriter/serializeCurrentValue()
parquet/column/values/boundedint/BoundedIntValuesWriter/reset()#parquet/column/values/boundedint/BitWriter/reset()
parquet/column/values/boundedint/BoundedIntValuesWriter/getBufferedSize()#parquet/column/values/boundedint/BitWriter/getMemSize()
parquet/column/values/boundedint/BoundedIntValuesWriter/serializeCurrentValue()#parquet/column/values/boundedint/BitWriter/writeBit(boolean)
parquet/column/values/boundedint/BoundedIntValuesWriter/serializeCurrentValue()#parquet/column/values/boundedint/BitWriter/writeNBitInteger(int,int)
parquet/column/values/boundedint/BoundedIntValuesWriter/serializeCurrentValue()#parquet/column/values/boundedint/BitWriter/writeUnsignedVarint(int)
parquet/column/values/boundedint/BoundedIntValuesWriter/getAllocatedSize()#parquet/column/values/boundedint/BitWriter/getCapacity()
parquet/column/values/boundedint/BoundedIntValuesWriter/memUsageString(java.lang.String)#parquet/column/values/boundedint/BitWriter/memUsageString(java.lang.String)
parquet/thrift/struct/ThriftType/ListType/equals(java.lang.Object)#parquet/thrift/struct/ThriftType/equals(java.lang.Object)
parquet/thrift/struct/ThriftType/ListType/equals(java.lang.Object)#parquet/thrift/struct/ThriftField/equals(java.lang.Object)
parquet/thrift/struct/ThriftType/ListType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.ListType)
parquet/thrift/struct/ThriftType/ListType/hashCode()#parquet/thrift/struct/ThriftField/hashCode()
parquet/thrift/struct/ThriftType/ListType/hashCode()#parquet/thrift/struct/ThriftType/hashCode()
parquet/avro/AvroIndexedRecordConverter/FieldBooleanConverter/addBoolean(boolean)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/hadoop/codec/CodecConfig/MapreduceCodecConfig/getConfiguration()#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/column/values/bitpacking/FiveBitPackingReader/read()#java/io/InputStream/read()
parquet/column/values/bitpacking/FiveBitPackingReader/read()#parquet/column/values/bitpacking/BaseBitPackingReader/alignToBytes(int)
parquet/hadoop/metadata/ColumnChunkMetaData/toString()#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/hadoop/metadata/ColumnChunkMetaData/toString()#parquet/hadoop/metadata/ColumnChunkProperties/toString()
parquet/hadoop/metadata/ColumnChunkMetaData/getCodec()#parquet/hadoop/metadata/ColumnChunkProperties/getCodec()
parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)#parquet/hadoop/metadata/IntColumnChunkMetaData/IntColumnChunkMetaData(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)#parquet/hadoop/metadata/ColumnChunkMetaData/positiveLongFitsInAnInt(long)
parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)#parquet/hadoop/metadata/LongColumnChunkMetaData/LongColumnChunkMetaData(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/hadoop/metadata/ColumnChunkMetaData/getEncodings()#parquet/hadoop/metadata/ColumnChunkProperties/getEncodings()
parquet/hadoop/metadata/ColumnChunkMetaData/getType()#parquet/hadoop/metadata/ColumnChunkProperties/getType()
parquet/hadoop/metadata/ColumnChunkMetaData/getStartingPos()#parquet/hadoop/metadata/ColumnChunkMetaData/getDictionaryPageOffset()
parquet/hadoop/metadata/ColumnChunkMetaData/getStartingPos()#parquet/hadoop/metadata/ColumnChunkMetaData/getFirstDataPageOffset()
parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,long,long,long,long,long)#parquet/hadoop/metadata/IntColumnChunkMetaData/IntColumnChunkMetaData(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,long,long,long,long,long)#parquet/hadoop/metadata/ColumnChunkMetaData/positiveLongFitsInAnInt(long)
parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,long,long,long,long,long)#parquet/hadoop/metadata/LongColumnChunkMetaData/LongColumnChunkMetaData(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,long,long,long,long,long)#parquet/column/statistics/BooleanStatistics/BooleanStatistics()
parquet/hadoop/metadata/ColumnChunkMetaData/getPath()#parquet/hadoop/metadata/ColumnChunkProperties/getPath()
parquet/hadoop/PrintFooter/ColStats/add(long,long,long,java.util.Collection,parquet.column.statistics.Statistics)#java/util/Set/addAll(java.util.Collection)
parquet/hadoop/PrintFooter/ColStats/add(long,long,long,java.util.Collection,parquet.column.statistics.Statistics)#parquet/hadoop/PrintFooter/Stats/add(long)
parquet/hadoop/PrintFooter/ColStats/toString()#parquet/hadoop/PrintFooter/humanReadable(long)
parquet/hadoop/PrintFooter/ColStats/toString()#parquet/column/statistics/Statistics/toString()
parquet/hadoop/PrintFooter/ColStats/toString()#parquet/hadoop/PrintFooter/Stats/toString(int)
parquet/hadoop/DeprecatedInputFormatTest/ReadMapper/setup(parquet.proto.utils.Context)#parquet/hadoop/example/GroupWriteSupport/getSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/DeprecatedInputFormatTest/ReadMapper/setup(parquet.proto.utils.Context)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/DeprecatedInputFormatTest/ReadMapper/setup(parquet.proto.utils.Context)#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/hadoop/DeprecatedInputFormatTest/ReadMapper/map(parquet.hadoop.example.LongWritable,parquet.hadoop.example.Text,parquet.proto.utils.Context)#parquet/example/data/Group/append(java.lang.String,int)
parquet/hadoop/DeprecatedInputFormatTest/ReadMapper/map(parquet.hadoop.example.LongWritable,parquet.hadoop.example.Text,parquet.proto.utils.Context)#parquet/example/data/simple/SimpleGroupFactory/newGroup()
parquet/hadoop/DeprecatedInputFormatTest/ReadMapper/map(parquet.hadoop.example.LongWritable,parquet.hadoop.example.Text,parquet.proto.utils.Context)#parquet/example/data/Group/append(java.lang.String,parquet.example.data.simple.NanoTime)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/length()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/writeBytes(parquet.io.api.Binary)#java/io/OutputStream/write(byte[])
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getAllocatedSize()#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getAllocatedSize()#parquet/column/values/ValuesWriter/getAllocatedSize()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()#parquet/bytes/LittleEndianDataOutputStream/flush()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()#parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()#parquet/Log/debug(java.lang.Object)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBytes()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/reset()#parquet/bytes/CapacityByteArrayOutputStream/reset()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/reset()#parquet/column/values/ValuesWriter/reset()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBufferedSize()#parquet/column/values/ValuesWriter/getBufferedSize()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/getBufferedSize()#parquet/bytes/CapacityByteArrayOutputStream/size()
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/memUsageString(java.lang.String)#parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)
parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter/memUsageString(java.lang.String)#parquet/column/values/ValuesWriter/memUsageString(java.lang.String)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/ValuesWriter/writeFloat(float)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/hasNext()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/next()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/iterator()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/ValuesWriter/createDictionaryPage()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/createDictionaryPage()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,parquet.column.Encoding)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/writeFloat(float)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/getBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/writeFloat(float)#parquet/column/values/ValuesWriter/writeFloat(float)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/writeFloat(float)#parquet/column/values/dictionary/IntList/add(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainFloatDictionaryValuesWriter/writeFloat(float)#parquet/column/values/dictionary/DictionaryValuesWriter/checkAndFallbackIfNeeded()
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/proto/ProtoSchemaConverter/convert(java.lang.Class)
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/proto/ProtoWriteSupport/MessageWriter/MessageWriter(Descriptors.Descriptor,parquet.schema.GroupType)
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Class/getName()
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/proto/ProtoSchemaConverter/ProtoSchemaConverter()
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/HashMap/HashMap()
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/proto/ProtoWriteSupport/serializeDescriptor(java.lang.Class)
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/Map/put(K,V)
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/WriteSupport/WriteContext/WriteContext(parquet.schema.MessageType,java.util.Map)
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String)
parquet/proto/ProtoWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/proto/ProtoWriteSupport/validatedMapping(Descriptors.Descriptor,parquet.schema.GroupType)
parquet/proto/ProtoWriteSupport/validatedMapping(Descriptors.Descriptor,parquet.schema.GroupType)#parquet/schema/IncompatibleSchemaModificationException/IncompatibleSchemaModificationException(java.lang.String)
parquet/proto/ProtoWriteSupport/validatedMapping(Descriptors.Descriptor,parquet.schema.GroupType)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/proto/ProtoWriteSupport/unknownType(Descriptors.FieldDescriptor)#parquet/io/InvalidRecordException/InvalidRecordException(java.lang.String)
parquet/proto/ProtoWriteSupport/write(T)#parquet/io/api/RecordConsumer/startMessage()
parquet/proto/ProtoWriteSupport/write(T)#parquet/Log/error(java.lang.Object)
parquet/proto/ProtoWriteSupport/write(T)#parquet/io/api/RecordConsumer/endMessage()
parquet/proto/ProtoWriteSupport/write(T)#parquet/proto/ProtoWriteSupport/MessageWriter/writeTopLevelMessage(java.lang.Object)
parquet/proto/ProtoWriteSupport/write(T)#java/lang/Throwable/getMessage()
parquet/hadoop/api/DelegatingWriteSupport/finalizeWrite()#parquet/hadoop/api/WriteSupport/finalizeWrite()
parquet/hadoop/api/DelegatingWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/WriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/api/DelegatingWriteSupport/write(T)#parquet/hadoop/api/WriteSupport/write(T)
parquet/hadoop/api/DelegatingWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/hadoop/api/WriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)
parquet/hadoop/api/DelegatingWriteSupport/toString()#java/lang/Object/toString()
parquet/hadoop/api/DelegatingWriteSupport/toString()#java/lang/Class/getName()
parquet/hadoop/api/DelegatingWriteSupport/toString()#java/lang/Object/getClass()
parquet/column/values/bitpacking/SevenBitPackingWriter/finish()#parquet/column/values/bitpacking/BaseBitPackingWriter/finish(int,long,java.io.OutputStream)
parquet/column/values/bitpacking/SevenBitPackingWriter/write(int)#java/io/OutputStream/write(int)
parquet/tools/util/PrettyPrintWriter/Builder/build()#parquet/tools/util/PrettyPrintWriter/PrettyPrintWriter(java.io.OutputStream,boolean,boolean,boolean,parquet.tools.util.PrettyPrintWriter.Span,int,int,char,int,int,long,boolean,parquet.tools.util.PrettyPrintWriter.WhiteSpaceHandler)
parquet/tools/util/PrettyPrintWriter/Builder/withAutoColumn(char)#parquet/tools/util/PrettyPrintWriter/Builder/withAutoColumn(char,int)
parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop(int,java.lang.String)#parquet/tools/util/PrettyPrintWriter/mkspan(java.lang.String)
parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop(int,java.lang.String)#parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop(int,parquet.tools.util.PrettyPrintWriter.Span)
parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop()#parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop(int)
parquet/tools/util/PrettyPrintWriter/Builder/withAutoColumn()#parquet/tools/util/PrettyPrintWriter/Builder/withAutoColumn(char)
parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop(int)#parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop(int,parquet.tools.util.PrettyPrintWriter.Span)
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withWhitespaceHandler(parquet.tools.util.PrettyPrintWriter.WhiteSpaceHandler)
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata)
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/command/ArgsOnlyCommand/execute(parquet.tools.command.CommandLine)
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/stdoutPrettyPrinter()
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/build()
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withAutoColumn()
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withColumnPadding(int)
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/flushColumns()
parquet/tools/command/ShowMetaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/withAutoCrop()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])#java/io/IOException/IOException(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/IncrementallyUpdatedFilterPredicateGenerator(java.io.File)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])#java/io/File/getAbsoluteFile()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])#java/io/File/exists()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])#java/io/File/File(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])#java/io/File/mkdirs()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/main(java.lang.String[])#java/io/File/getParentFile()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addUdpCase(parquet.filter2.IncrementallyUpdatedFilterPredicateGenerator.TypeInfo,boolean)#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/add(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addInequalityCase(parquet.filter2.IncrementallyUpdatedFilterPredicateGenerator.TypeInfo,java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addUdpCase(parquet.filter2.IncrementallyUpdatedFilterPredicateGenerator.TypeInfo,boolean)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addUdpBegin()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()#java/io/OutputStreamWriter/close()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addVisitEnd()
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addEqNotEqCase(parquet.filter2.IncrementallyUpdatedFilterPredicateGenerator.TypeInfo,boolean)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addVisitBegin(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/run()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/add(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addVisitEnd()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/add(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addEqNotEqCase(parquet.filter2.IncrementallyUpdatedFilterPredicateGenerator.TypeInfo,boolean)#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/compareEquality(java.lang.String,java.lang.String,boolean)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addEqNotEqCase(parquet.filter2.IncrementallyUpdatedFilterPredicateGenerator.TypeInfo,boolean)#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/add(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addVisitBegin(java.lang.String)#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/add(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addInequalityCase(parquet.filter2.IncrementallyUpdatedFilterPredicateGenerator.TypeInfo,java.lang.String)#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/add(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/addUdpBegin()#parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/add(java.lang.String)
parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator/add(java.lang.String)#java/io/Writer/write(java.lang.String)
parquet/cascading/ParquetValueScheme/Config/withFilterPredicate(parquet.filter2.predicate.FilterPredicate)#parquet/cascading/ParquetValueScheme/Config/Config(java.lang.Class,parquet.filter2.predicate.FilterPredicate,java.lang.String)
parquet/cascading/ParquetValueScheme/Config/withFilterPredicate(parquet.filter2.predicate.FilterPredicate)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/cascading/ParquetValueScheme/Config/withProjectionString(java.lang.String)#parquet/cascading/ParquetValueScheme/Config/Config(java.lang.Class,parquet.filter2.predicate.FilterPredicate,java.lang.String)
parquet/cascading/ParquetValueScheme/Config/withProjectionString(java.lang.String)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/cascading/ParquetValueScheme/Config/withRecordClass(java.lang.Class)#parquet/cascading/ParquetValueScheme/Config/Config(java.lang.Class,parquet.filter2.predicate.FilterPredicate,java.lang.String)
parquet/cascading/ParquetValueScheme/Config/withRecordClass(java.lang.Class)#parquet/Preconditions/checkNotNull(T,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo,parquet.schema.Type.Repetition)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertStructType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.StructTypeInfo)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo,parquet.schema.Type.Repetition)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo,parquet.schema.Type.Repetition)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo,parquet.schema.Type.Repetition)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo,parquet.schema.Type.Repetition)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertMapType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.convert.MapTypeInfo)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo,parquet.schema.Type.Repetition)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertArrayType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.convert.ListTypeInfo)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertTypes(java.util.List,java.util.List)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertTypes(java.util.List,java.util.List)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertTypes(java.util.List,java.util.List)#java/util/List/size()
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertTypes(java.util.List,java.util.List)#java/util/List/get(int)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convert(java.util.List,java.util.List)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertTypes(java.util.List,java.util.List)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convert(java.util.List,java.util.List)#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/listWrapper(java.lang.String,parquet.schema.OriginalType,parquet.schema.GroupType)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.OriginalType,parquet.schema.Type[])
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertMapType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.convert.MapTypeInfo)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo,parquet.schema.Type.Repetition)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertMapType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.convert.MapTypeInfo)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertMapType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.convert.MapTypeInfo)#parquet/schema/ConversionPatterns/mapType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type,parquet.schema.Type)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertArrayType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.convert.ListTypeInfo)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,java.util.List)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertArrayType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.convert.ListTypeInfo)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertArrayType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.convert.ListTypeInfo)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/listWrapper(java.lang.String,parquet.schema.OriginalType,parquet.schema.GroupType)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertStructType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.StructTypeInfo)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertTypes(java.util.List,java.util.List)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertStructType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.StructTypeInfo)#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,java.util.List)
org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convertType(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.serde.TypeInfo,parquet.schema.Type.Repetition)
parquet/column/values/delta/DeltaBinaryPackingConfig/readConfig(java.io.InputStream)#parquet/column/values/delta/DeltaBinaryPackingConfig/DeltaBinaryPackingConfig(int,int)
parquet/column/values/delta/DeltaBinaryPackingConfig/readConfig(java.io.InputStream)#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/delta/DeltaBinaryPackingConfig/toBytesInput()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/values/delta/DeltaBinaryPackingConfig/toBytesInput()#parquet/bytes/BytesInput/fromUnsignedVarInt(int)
parquet/avro/AvroParquetOutputFormat/setSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/avro/AvroParquetOutputFormat/setSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)#parquet/avro/AvroWriteSupport/setSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.pig.convert.Schema)
parquet/pig/summary/Summary/Initial/setUDFContextSignature(java.lang.String)#parquet/pig/summary/Summary/getInputSchema(java.lang.String)
parquet/pig/summary/Summary/Initial/exec(parquet.pig.convert.Tuple)#parquet/pig/summary/Summary/sumUp(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)
parquet/pig/summary/Summary/Initial/exec(parquet.pig.convert.Tuple)#parquet/pig/summary/Summary/JSONTuple/JSONTuple(parquet.pig.summary.TupleSummaryData)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])#java/io/ByteArrayOutputStream/toByteArray()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])#parquet/Log/info(java.lang.Object)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])#parquet/hadoop/thrift/ThriftToParquetFileWriter/write(parquet.hadoop.thrift.BytesWritable)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])#parquet/hadoop/thrift/ThriftToParquetFileWriter/close()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])#java/lang/Object/getClass()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])#parquet/hadoop/thrift/ThriftToParquetFileWriter/ThriftToParquetFileWriter(parquet.hadoop.Path,parquet.pig.TaskAttemptContext,parquet.hadoop.thrift.TProtocolFactory,java.lang.Class)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#parquet/example/data/Group/getGroup(java.lang.String,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#parquet/example/data/GroupValueSource/getFieldRepetitionCount(java.lang.String)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#parquet/hadoop/ParquetReader/read()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#parquet/example/data/Group/getGroup(int,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#parquet/example/data/GroupValueSource/getString(java.lang.String,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFile()#java/lang/Object/Object()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#parquet/example/data/GroupValueSource/getBinary(java.lang.String,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#java/util/HashMap/HashMap()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#parquet/example/data/Group/getGroup(java.lang.String,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#parquet/io/api/Binary/toStringUsingUTF8()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#parquet/hadoop/ParquetReader/read()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfLists()#java/util/Map/put(K,V)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)#parquet/hadoop/ParquetReader/ParquetReader(parquet.hadoop.Path,parquet.hadoop.api.ReadSupport)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)#parquet/hadoop/example/GroupReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)#parquet/hadoop/example/GroupReadSupport/GroupReadSupport()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileListOfMap()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileListOfMap()#java/util/HashMap/HashMap()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileListOfMap()#parquet/example/data/Group/getGroup(java.lang.String,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileListOfMap()#parquet/example/data/GroupValueSource/getFieldRepetitionCount(java.lang.String)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileListOfMap()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileListOfMap()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileListOfMap()#parquet/hadoop/ParquetReader/read()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileListOfMap()#java/util/Map/put(K,V)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/Statistics/equals(parquet.column.statistics.Statistics)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/IntStatistics/IntStatistics()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/LongStatistics/setMinMax(long,long)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/IntStatistics/setMinMax(int,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/hadoop/metadata/ColumnChunkMetaData/getType()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/common/schema/ColumnPath/toString()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/DoubleStatistics/setMinMax(double,double)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/BooleanStatistics/BooleanStatistics()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/DoubleStatistics/DoubleStatistics()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/LongStatistics/LongStatistics()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/BooleanStatistics/setMinMax(boolean,boolean)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteStatistics()#parquet/column/statistics/BinaryStatistics/setMinMax(parquet.io.api.Binary,parquet.io.api.Binary)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createFile(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#java/util/Map/get(java.lang.Object)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#java/util/HashMap/HashMap()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#parquet/example/data/Group/getGroup(java.lang.String,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#parquet/io/api/Binary/toStringUsingUTF8()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#parquet/example/data/GroupValueSource/getFieldRepetitionCount(int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#parquet/example/data/GroupValueSource/getBinary(java.lang.String,int)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#java/util/List/size()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#java/util/Arrays/asList(T[])
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#parquet/hadoop/thrift/TestThriftToParquetFileWriter/createRecordReader(parquet.hadoop.Path)
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#parquet/hadoop/ParquetReader/read()
parquet/hadoop/thrift/TestThriftToParquetFileWriter/testWriteFileMapOfList()#java/util/Map/put(K,V)
parquet/hadoop/ParquetWriter/write(T)#parquet/hadoop/InternalParquetRecordWriter/write(T)
parquet/hadoop/ParquetWriter/write(T)#java/io/IOException/IOException(java.lang.Throwable)
parquet/hadoop/ParquetWriter/close()#parquet/hadoop/InternalParquetRecordWriter/close()
parquet/hadoop/ParquetWriter/close()#java/io/IOException/IOException(java.lang.Throwable)
parquet/filter2/predicate/Operators/UserDefined/hashCode()#parquet/filter2/predicate/Operators/Column/hashCode()
parquet/filter2/predicate/Operators/UserDefined/hashCode()#java/lang/Object/hashCode()
parquet/filter2/predicate/Operators/UserDefined/hashCode()#java/lang/Object/getClass()
parquet/filter2/predicate/Operators/UserDefined/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.UserDefined)
parquet/filter2/predicate/Operators/UserDefined/getUserDefinedPredicate()#java/lang/Class/newInstance()
parquet/filter2/predicate/Operators/UserDefined/getUserDefinedPredicate()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/filter2/predicate/Operators/UserDefined/getUserDefinedPredicate()#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/filter2/predicate/Operators/UserDefined/equals(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
parquet/filter2/predicate/Operators/UserDefined/equals(java.lang.Object)#parquet/filter2/predicate/Operators/Column/equals(java.lang.Object)
parquet/filter2/predicate/Operators/UserDefined/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRepeatedZeros()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRepeatedZeros()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRepeatedZeros()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRepeatedZeros()#parquet/bytes/BytesUtils/readIntLittleEndianOnOneByte(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRepeatedZeros()#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRepeatedZeros()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRepeatedZeros()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRepeatedZeros()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#java/util/List/get(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOverflow()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#parquet/bytes/BytesUtils/readIntLittleEndianOnTwoBytes(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#java/util/List/get(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testSwitchingModes()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRLEOnly()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRLEOnly()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRLEOnly()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRLEOnly()#parquet/bytes/BytesUtils/readIntLittleEndianOnOneByte(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRLEOnly()#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRLEOnly()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRLEOnly()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testRLEOnly()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#java/util/List/get(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitPackingOnly()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)#java/util/ArrayList/ArrayList(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)#java/util/List/size()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)#java/util/List/add(E)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)#parquet/column/values/bitpacking/BytePacker/unpack8Values(byte[],int,int[],int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)#parquet/column/values/bitpacking/Packer/newBytePacker(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#parquet/bytes/BytesUtils/readIntLittleEndianOnOneByte(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#java/util/Arrays/asList(T[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testTransitionFromBitPackingToRle()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitWidthZero()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitWidthZero()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitWidthZero()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitWidthZero()#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitWidthZero()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitWidthZero()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testBitWidthZero()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/toBytes()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/writeInt(int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#parquet/column/values/rle/RunLengthBitPackingHybridEncoder/RunLengthBitPackingHybridEncoder(int,int)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#java/util/Arrays/asList(T[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/unpack(int,int,java.io.ByteArrayInputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#java/io/ByteArrayInputStream/read()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testPaddingZerosOnUnfinishedBitPackedRuns()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testGroupBoundary()#java/io/ByteArrayInputStream/available()
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testGroupBoundary()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testGroupBoundary()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/RunLengthBitPackingHybridDecoder(int,java.io.ByteArrayInputStream)
parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder/testGroupBoundary()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/scrooge/ScroogeStructConverter/ScroogeEnumDesc/getEnumDesc(java.lang.Object)#java/lang/Object/getClass()
parquet/scrooge/ScroogeStructConverter/ScroogeEnumDesc/getEnumDesc(java.lang.Object)#java/lang/Class/getMethod(java.lang.String,java.lang.Class<?>[])
parquet/scrooge/ScroogeStructConverter/ScroogeEnumDesc/getEnumDesc(java.lang.Object)#parquet/scrooge/ScroogeStructConverter/ScroogeEnumDesc/ScroogeEnumDesc()
parquet/scrooge/ScroogeStructConverter/ScroogeEnumDesc/getEnumDesc(java.lang.Object)#java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object[])
parquet/proto/utils/WriteUsingMR/WritingMapper/run(parquet.proto.utils.Context)#parquet/Log/debug(java.lang.Object)
parquet/proto/utils/WriteUsingMR/WritingMapper/run(parquet.proto.utils.Context)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/proto/ProtoWriteSupport/FloatWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/addFloat(float)
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/testRegularMap()#org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/testRegularMap()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/testNullMap()#org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/testNullContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/testEmptyContainer()#org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/testEmptyContainer()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/testHashMap()#org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/testHashMap()#java/util/HashMap/HashMap()
org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector/setUp()#org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector/DeepParquetHiveMapInspector(org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
parquet/column/page/mem/MemPageStore/getPageWriter(parquet.column.ColumnDescriptor)#parquet/column/page/mem/MemPageWriter/MemPageWriter()
parquet/column/page/mem/MemPageStore/getPageWriter(parquet.column.ColumnDescriptor)#java/util/Map/get(java.lang.Object)
parquet/column/page/mem/MemPageStore/getPageWriter(parquet.column.ColumnDescriptor)#java/util/Map/put(K,V)
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#parquet/column/page/mem/MemPageWriter/getDictionaryPage()
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#java/util/Map/get(java.lang.Object)
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#java/util/List/size()
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#parquet/column/page/mem/MemPageReader/MemPageReader(long,java.util.Iterator,parquet.column.page.DictionaryPage)
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#parquet/Log/debug(java.lang.Object)
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#parquet/column/page/mem/MemPageWriter/getTotalValueCount()
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#java/util/List/iterator()
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#parquet/column/page/mem/MemPageWriter/getPages()
parquet/column/page/mem/MemPageStore/getPageReader(parquet.column.ColumnDescriptor)#parquet/column/UnknownColumnException/UnknownColumnException(parquet.column.ColumnDescriptor)
parquet/scrooge/ScroogeRecordConverter/getCodec(java.lang.Class)#java/lang/Class/forName(java.lang.String)
parquet/scrooge/ScroogeRecordConverter/getCodec(java.lang.Class)#java/lang/Class/getName()
parquet/scrooge/ScroogeRecordConverter/getCodec(java.lang.Class)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/scrooge/ScroogeRecordConverter/getCodec(java.lang.Class)#java/lang/Class/getField(java.lang.String)
parquet/scrooge/ScroogeRecordConverter/getCodec(java.lang.Class)#java/lang/reflect/Field/get(java.lang.Object)
parquet/scrooge/ScroogeRecordConverter/getCodec(java.lang.Class)#java/lang/Thread/currentThread()
parquet/scrooge/ScroogeRecordConverter/getCodec(java.lang.Class)#java/lang/Thread/interrupt()
parquet/avro/TestAvroSchemaConverter/testUnionOfTwoTypes()#java/util/Arrays/asList(T[])
parquet/avro/TestAvroSchemaConverter/testUnionOfTwoTypes()#parquet/avro/TestAvroSchemaConverter/testAvroToParquetConversion(parquet.pig.convert.Schema,java.lang.String)
parquet/avro/TestAvroSchemaConverter/testUnionOfTwoTypes()#java/lang/Object/Object()
parquet/avro/TestAvroSchemaConverter/testTopLevelMustBeARecord()#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/TestAvroSchemaConverter/testTopLevelMustBeARecord()#parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)
parquet/avro/TestAvroSchemaConverter/testRoundTripConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/avro/TestAvroSchemaConverter/testRoundTripConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/schema/Type/toString()
parquet/avro/TestAvroSchemaConverter/testRoundTripConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/TestAvroSchemaConverter/testRoundTripConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)
parquet/avro/TestAvroSchemaConverter/testRoundTripConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/avro/AvroSchemaConverter/convert(parquet.schema.MessageType)
parquet/avro/TestAvroSchemaConverter/testArrayOfOptionalRecords()#java/io/PrintStream/println(char[])
parquet/avro/TestAvroSchemaConverter/testArrayOfOptionalRecords()#java/lang/Object/Object()
parquet/avro/TestAvroSchemaConverter/testArrayOfOptionalRecords()#parquet/avro/TestAvroSchemaConverter/optional(parquet.pig.convert.Schema)
parquet/avro/TestAvroSchemaConverter/testArrayOfOptionalRecords()#parquet/avro/TestAvroSchemaConverter/testAvroToParquetConversion(parquet.pig.convert.Schema,java.lang.String)
parquet/avro/TestAvroSchemaConverter/testParquetMapWithNonStringKeyFails()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/avro/TestAvroSchemaConverter/testParquetMapWithNonStringKeyFails()#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/TestAvroSchemaConverter/testParquetMapWithNonStringKeyFails()#parquet/avro/AvroSchemaConverter/convert(parquet.schema.MessageType)
parquet/avro/TestAvroSchemaConverter/testAllTypesParquetToAvro()#parquet/avro/TestAvroSchemaConverter/testParquetToAvroConversion(parquet.pig.convert.Schema,java.lang.String)
parquet/avro/TestAvroSchemaConverter/testOptionalFields()#java/util/Arrays/asList(T[])
parquet/avro/TestAvroSchemaConverter/testOptionalFields()#java/lang/Object/Object()
parquet/avro/TestAvroSchemaConverter/testOptionalFields()#parquet/avro/TestAvroSchemaConverter/optional(parquet.pig.convert.Schema)
parquet/avro/TestAvroSchemaConverter/testOptionalFields()#parquet/avro/TestAvroSchemaConverter/testAvroToParquetConversion(parquet.pig.convert.Schema,java.lang.String)
parquet/avro/TestAvroSchemaConverter/testParquetToAvroConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/avro/TestAvroSchemaConverter/testParquetToAvroConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/TestAvroSchemaConverter/testParquetToAvroConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/avro/AvroSchemaConverter/convert(parquet.schema.MessageType)
parquet/avro/TestAvroSchemaConverter/testAllTypes()#parquet/avro/TestAvroSchemaConverter/testAvroToParquetConversion(parquet.pig.convert.Schema,java.lang.String)
parquet/avro/TestAvroSchemaConverter/testAvroToParquetConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/avro/TestAvroSchemaConverter/testAvroToParquetConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/schema/Type/toString()
parquet/avro/TestAvroSchemaConverter/testAvroToParquetConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/avro/AvroSchemaConverter/AvroSchemaConverter()
parquet/avro/TestAvroSchemaConverter/testAvroToParquetConversion(parquet.pig.convert.Schema,java.lang.String)#parquet/avro/AvroSchemaConverter/convert(parquet.pig.convert.Schema)
parquet/hadoop/ColumnChunkPageWriteStore/getPageWriter(parquet.column.ColumnDescriptor)#parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/ColumnChunkPageWriter(parquet.column.ColumnDescriptor,parquet.hadoop.CodecFactory.BytesCompressor,int)
parquet/hadoop/ColumnChunkPageWriteStore/getPageWriter(parquet.column.ColumnDescriptor)#java/util/Map/get(java.lang.Object)
parquet/hadoop/ColumnChunkPageWriteStore/getPageWriter(parquet.column.ColumnDescriptor)#java/util/Map/containsKey(java.lang.Object)
parquet/hadoop/ColumnChunkPageWriteStore/getPageWriter(parquet.column.ColumnDescriptor)#java/util/Map/put(K,V)
parquet/hadoop/ColumnChunkPageWriteStore/flushToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/hadoop/ColumnChunkPageWriteStore/ColumnChunkPageWriter/writeToFileWriter(parquet.hadoop.ParquetFileWriter)
parquet/hadoop/ColumnChunkPageWriteStore/flushToFileWriter(parquet.hadoop.ParquetFileWriter)#parquet/schema/MessageType/getColumns()
parquet/hadoop/ColumnChunkPageWriteStore/flushToFileWriter(parquet.hadoop.ParquetFileWriter)#java/util/Map/get(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/util/Map/get(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector/getMapValueElement(java.lang.Object,java.lang.Object)#java/lang/Object/getClass()
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#java/util/Map/Entry/getValue()
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#parquet/pig/summary/SummaryData/add(java.lang.Object)
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#parquet/pig/summary/SummaryData/getName(parquet.pig.convert.FieldSchema)
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#parquet/pig/summary/SummaryData/getField(parquet.pig.convert.Schema,int)
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#parquet/pig/summary/FieldSummaryData/FieldSummaryData()
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#parquet/pig/summary/SummaryData/getSchema(parquet.pig.convert.FieldSchema)
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#java/util/Map/Entry/getKey()
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#parquet/pig/summary/FieldSummaryData/setName(java.lang.String)
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#java/util/Map/size()
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#java/util/Map/entrySet()
parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)#parquet/pig/summary/ValueStat/add(double)
parquet/pig/summary/MapSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(parquet.pig.summary.SummaryData)
parquet/pig/summary/MapSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(T,T)
parquet/pig/summary/MapSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/ValueStat/merge(parquet.pig.summary.ValueStat)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/column/statistics/Statistics/genericGetMax()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/filter2/predicate/UserDefinedPredicate/canDrop(parquet.filter2.predicate.Statistics)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/filter2/predicate/Statistics/Statistics(T,T)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/filter2/predicate/UserDefinedPredicate/inverseCanDrop(parquet.filter2.predicate.Statistics)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/filter2/predicate/Operators/UserDefined/getUserDefinedPredicate()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/filter2/predicate/Operators/UserDefined/getColumn()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)#parquet/column/statistics/Statistics/genericGetMin()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/column/statistics/Statistics/genericGetMin()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Lt)#java/lang/Comparable/compareTo(T)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Lt)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.And)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getValueCount()
parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)#parquet/column/statistics/Statistics/getNumNulls()
parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/hasNulls(parquet.hadoop.metadata.ColumnChunkMetaData)#parquet/column/statistics/Statistics/getNumNulls()
parquet/filter2/statisticslevel/StatisticsFilter/hasNulls(parquet.hadoop.metadata.ColumnChunkMetaData)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/column/statistics/Statistics/genericGetMax()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.GtEq)#java/lang/Comparable/compareTo(T)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.GtEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)#parquet/filter2/statisticslevel/StatisticsFilter/StatisticsFilter(java.util.List)
parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)#parquet/common/schema/ColumnPath/toDotString()
parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)#java/util/Map/get(java.lang.Object)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/column/statistics/Statistics/genericGetMin()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LtEq)#java/lang/Comparable/compareTo(T)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LtEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/column/statistics/Statistics/genericGetMax()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/statisticslevel/StatisticsFilter/hasNulls(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/column/statistics/Statistics/genericGetMin()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#java/lang/Comparable/compareTo(T)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.NotEq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined)#parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/column/statistics/Statistics/genericGetMax()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Gt)#java/lang/Comparable/compareTo(T)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Gt)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/column/statistics/Statistics/genericGetMax()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getValue()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/statisticslevel/StatisticsFilter/isAllNulls(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/statisticslevel/StatisticsFilter/hasNulls(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/column/statistics/Statistics/genericGetMin()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/statisticslevel/StatisticsFilter/getColumnChunk(parquet.common.schema.ColumnPath)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#java/lang/Comparable/compareTo(T)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/predicate/Operators/Column/getColumnPath()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Eq)#parquet/filter2/predicate/Operators/ColumnFilterPredicate/getColumn()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LogicalNotUserDefined)#parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.UserDefined,boolean)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.LogicalNotUserDefined)#parquet/filter2/predicate/Operators/LogicalNotUserDefined/getUserDefined()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getLeft()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/FilterPredicate/accept(parquet.filter2.predicate.FilterPredicate.Visitor)
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Or)#parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/getRight()
parquet/filter2/statisticslevel/StatisticsFilter/visit(parquet.filter2.predicate.Operators.Not)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/struct/ThriftType/MapType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.MapType)
parquet/thrift/struct/ThriftType/MapType/equals(java.lang.Object)#parquet/thrift/struct/ThriftType/equals(java.lang.Object)
parquet/thrift/struct/ThriftType/MapType/equals(java.lang.Object)#parquet/thrift/struct/ThriftField/equals(java.lang.Object)
parquet/thrift/struct/ThriftType/MapType/hashCode()#parquet/thrift/struct/ThriftField/hashCode()
parquet/thrift/struct/ThriftType/MapType/hashCode()#parquet/thrift/struct/ThriftType/hashCode()
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/filter/ColumnPredicates/equalTo(java.lang.String)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/filter/ColumnPredicates/applyFunctionToString(parquet.filter.ColumnPredicates.PredicateFunction)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#java/util/List/size()
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/io/TestFiltered/readAll(parquet.io.RecordReader)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/io/TestFiltered/StringEndsWithAPredicate/StringEndsWithAPredicate()
parquet/io/TestFiltered/testApplyFunctionFilterOnString()#parquet/io/TestFiltered/readOne(parquet.io.RecordReader,java.lang.String,parquet.example.data.Group)
parquet/io/TestFiltered/testPaged()#parquet/example/data/simple/SimpleGroup/toString()
parquet/io/TestFiltered/testPaged()#parquet/filter/PagedRecordFilter/page(long,long)
parquet/io/TestFiltered/testPaged()#java/lang/Object/toString()
parquet/io/TestFiltered/testPaged()#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testPaged()#parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)
parquet/io/TestFiltered/testPaged()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestFiltered/testPaged()#java/util/List/size()
parquet/io/TestFiltered/testPaged()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestFiltered/testPaged()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestFiltered/testPaged()#parquet/io/TestFiltered/readAll(parquet.io.RecordReader)
parquet/io/TestFiltered/testPaged()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/TestFiltered/testPaged()#java/util/List/get(int)
parquet/io/TestFiltered/testFilterOnString()#parquet/filter/ColumnPredicates/equalTo(java.lang.String)
parquet/io/TestFiltered/testFilterOnString()#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testFilterOnString()#parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)
parquet/io/TestFiltered/testFilterOnString()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestFiltered/testFilterOnString()#java/util/List/size()
parquet/io/TestFiltered/testFilterOnString()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilterOnString()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilterOnString()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/io/TestFiltered/testFilterOnString()#parquet/io/TestFiltered/readAll(parquet.io.RecordReader)
parquet/io/TestFiltered/testFilterOnString()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/TestFiltered/testFilterOnString()#parquet/io/TestFiltered/readOne(parquet.io.RecordReader,java.lang.String,parquet.example.data.Group)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/example/data/simple/SimpleGroup/toString()
parquet/io/TestFiltered/testFilteredOrPaged()#java/lang/Object/toString()
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/io/TestFiltered/readAll(parquet.io.RecordReader)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/filter/OrRecordFilter/or(parquet.filter.UnboundRecordFilter,parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/TestFiltered/testFilteredOrPaged()#java/util/List/get(int)
parquet/io/TestFiltered/testFilteredOrPaged()#parquet/filter/ColumnPredicates/equalTo(long)
parquet/io/TestFiltered/testFilteredOrPaged()#java/util/List/size()
parquet/io/TestFiltered/readAll(parquet.io.RecordReader)#java/util/ArrayList/ArrayList()
parquet/io/TestFiltered/readAll(parquet.io.RecordReader)#java/util/List/add(E)
parquet/io/TestFiltered/readAll(parquet.io.RecordReader)#parquet/io/RecordReader/read()
parquet/io/TestFiltered/readOne(parquet.io.RecordReader,java.lang.String,parquet.example.data.Group)#java/lang/Object/toString()
parquet/io/TestFiltered/readOne(parquet.io.RecordReader,java.lang.String,parquet.example.data.Group)#java/util/List/size()
parquet/io/TestFiltered/readOne(parquet.io.RecordReader,java.lang.String,parquet.example.data.Group)#parquet/io/TestFiltered/readAll(parquet.io.RecordReader)
parquet/io/TestFiltered/readOne(parquet.io.RecordReader,java.lang.String,parquet.example.data.Group)#java/util/List/get(int)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/example/data/simple/SimpleGroup/toString()
parquet/io/TestFiltered/testFilteredNotPaged()#java/lang/Object/toString()
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/io/TestFiltered/readAll(parquet.io.RecordReader)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/TestFiltered/testFilteredNotPaged()#java/util/List/get(int)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/filter/NotRecordFilter/not(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestFiltered/testFilteredNotPaged()#parquet/filter/ColumnPredicates/equalTo(long)
parquet/io/TestFiltered/testFilteredNotPaged()#java/util/List/size()
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/filter/ColumnPredicates/equalTo(long)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/io/TestFiltered/LongGreaterThan15Predicate/LongGreaterThan15Predicate()
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/filter/ColumnPredicates/applyFunctionToLong(parquet.filter.ColumnPredicates.LongPredicateFunction)
parquet/io/TestFiltered/testApplyFunctionFilterOnLong()#parquet/io/TestFiltered/readOne(parquet.io.RecordReader,java.lang.String,parquet.example.data.Group)
parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/filter/ColumnPredicates/equalTo(long)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/TestFiltered/testFilterOnInteger()#parquet/io/TestFiltered/readOne(parquet.io.RecordReader,java.lang.String,parquet.example.data.Group)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/example/data/simple/SimpleGroup/toString()
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/filter/PagedRecordFilter/page(long,long)
parquet/io/TestFiltered/testFilteredAndPaged()#java/lang/Object/toString()
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/io/TestFiltered/writeTestRecords(parquet.io.MessageColumnIO,int)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/io/TestFiltered/readAll(parquet.io.RecordReader)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/io/TestFiltered/testFilteredAndPaged()#java/util/List/get(int)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/filter/ColumnPredicates/equalTo(long)
parquet/io/TestFiltered/testFilteredAndPaged()#java/util/List/size()
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)
parquet/io/TestFiltered/testFilteredAndPaged()#parquet/filter/AndRecordFilter/and(parquet.filter.UnboundRecordFilter,parquet.filter.UnboundRecordFilter)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/writeLong(long)#parquet/column/values/dictionary/IntList/add(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/writeLong(long)#parquet/column/values/ValuesWriter/writeLong(long)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/writeLong(long)#parquet/column/values/dictionary/DictionaryValuesWriter/checkAndFallbackIfNeeded()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/hasNext()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/next()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/ValuesWriter/writeLong(long)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/iterator()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/ValuesWriter/createDictionaryPage()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/createDictionaryPage()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,parquet.column.Encoding)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/getBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainLongDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/writeLong(long)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/ListType)/$anonymous2/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/ListType)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.ListType)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.I16Type)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/I16Type)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.I16Type)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.I32Type)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/I32Type)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.I32Type)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/SetType)/$anonymous2/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/SetType)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.ByteType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/ByteType)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.ByteType)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/ReadFieldBeginProtocol/ReadFieldBeginProtocol(parquet.thrift.struct.ThriftField)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/getChildren()
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/projection/amend/DefaultEventsVisitor/StructBeginProtocol/StructBeginProtocol(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.I64Type)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/I64Type)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.I64Type)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.StringType)#parquet/thrift/projection/amend/DefaultEventsVisitor/StringProtocol/StringProtocol(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.StringType)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.DoubleType)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.DoubleType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/DoubleType)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/MapType)/$anonymous2/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/MapType)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.BoolType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/BoolType)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.BoolType)#java/util/List/add(E)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.EnumType)#parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet/thrift/struct/ThriftType/EnumType)/$anonymous1/(java.lang.String)
parquet/thrift/projection/amend/DefaultEventsVisitor/visit(parquet.thrift.struct.ThriftType.EnumType)#java/util/List/add(E)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/hasNext()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/next()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/iterator()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/writeInteger(int)#parquet/column/values/dictionary/IntList/add(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/writeInteger(int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/writeInteger(int)#parquet/column/values/dictionary/DictionaryValuesWriter/checkAndFallbackIfNeeded()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/ValuesWriter/createDictionaryPage()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/createDictionaryPage()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,parquet.column.Encoding)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/getBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainIntegerDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/writeInteger(int)
parquet/column/values/bitpacking/ThreeBitPackingReader/read()#java/io/InputStream/read()
parquet/column/values/bitpacking/ThreeBitPackingReader/read()#parquet/column/values/bitpacking/BaseBitPackingReader/alignToBytes(int)
parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)#parquet/filter2/compat/FilterCompat/UnboundRecordFilterCompat/UnboundRecordFilterCompat(parquet.filter.UnboundRecordFilter)
parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)#parquet/filter2/predicate/LogicalInverseRewriter/rewrite(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)#java/lang/Object/equals(java.lang.Object)
parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)#parquet/Log/info(java.lang.Object)
parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)#parquet/filter2/compat/FilterCompat/FilterPredicateCompat/FilterPredicateCompat(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate,parquet.filter.UnboundRecordFilter)#parquet/filter2/compat/FilterCompat/get(parquet.filter.UnboundRecordFilter)
parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate,parquet.filter.UnboundRecordFilter)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate,parquet.filter.UnboundRecordFilter)#parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListElement(java.lang.Object,int)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListElement(java.lang.Object,int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListElement(java.lang.Object,int)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getList(java.lang.Object)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getList(java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getList(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getList(java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/create(int)#java/util/ArrayList/ArrayList(int)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/create(int)#java/util/ArrayList/add(E)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListLength(java.lang.Object)#java/lang/Class/getCanonicalName()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListLength(java.lang.Object)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/getListLength(java.lang.Object)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/resize(java.lang.Object,int)#java/util/ArrayList/remove(int)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/resize(java.lang.Object,int)#java/util/ArrayList/ensureCapacity(int)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/resize(java.lang.Object,int)#java/util/ArrayList/size()
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/resize(java.lang.Object,int)#java/util/ArrayList/add(E)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/set(java.lang.Object,int,java.lang.Object)#java/util/ArrayList/set(int,E)
org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addValueFromDictionary(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/setDictionary(parquet.column.Dictionary)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addBoolean(boolean)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(boolean)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addBoolean(boolean)#parquet/io/api/PrimitiveConverter/addBoolean(boolean)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addDouble(double)#parquet/io/api/PrimitiveConverter/addDouble(double)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addDouble(double)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(double)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addLong(long)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(long)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addLong(long)#parquet/io/api/PrimitiveConverter/addLong(long)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addInt(int)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addInt(int)#parquet/io/api/PrimitiveConverter/addInt(int)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addFloat(float)#parquet/io/api/PrimitiveConverter/addFloat(float)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addFloat(float)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(float)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(parquet.io.api.Binary)
parquet/filter2/recordlevel/FilteringPrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/PrimitiveConverter/addBinary(parquet.io.api.Binary)
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type[])
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/Types/GroupBuilder/repeated(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/Types/GroupBuilder/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/Types/buildMessage()
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/Types/GroupBuilder/optionalGroup()
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testPaperExample()#parquet/schema/Types/GroupBuilder/repeatedGroup()
parquet/schema/TestTypeBuilders/testPrimitiveTypeConstruction()#java/lang/Enum/toString()
parquet/schema/TestTypeBuilders/testPrimitiveTypeConstruction()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testPrimitiveTypeConstruction()#parquet/schema/Types/repeated(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testPrimitiveTypeConstruction()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/schema/TestTypeBuilders/testPrimitiveTypeConstruction()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testPrimitiveTypeConstruction()#parquet/schema/Types/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testPrimitiveTypeConstruction()#parquet/schema/Type/Repetition/values()
parquet/schema/TestTypeBuilders/testPrimitiveTypeConstruction()#parquet/schema/Types/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)
parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)#java/lang/Class/getName()
parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)#java/util/concurrent/Callable/call()
parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)#java/lang/Object/getClass()
parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()#parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()/$anonymous4/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()#parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()/$anonymous3/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()#parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()/$anonymous2/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()#parquet/schema/TestTypeBuilders/testDecimalAnnotationLengthCheck()/$anonymous1/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()#parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()/$anonymous3/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()#parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()/$anonymous2/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()#parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()/$anonymous1/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()#parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingPrecision()/$anonymous4/()
parquet/schema/TestTypeBuilders/testFixedLengthEquals()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/schema/TestTypeBuilders/testFixedLengthEquals()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testFixedLengthEquals()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testFixedLengthEquals()#parquet/schema/Type/equals(parquet.schema.Type)
parquet/schema/TestTypeBuilders/testBinaryAnnotationsRejectsNonBinary()#parquet/schema/TestTypeBuilders/testBinaryAnnotationsRejectsNonBinary()/$anonymous2/()
parquet/schema/TestTypeBuilders/testBinaryAnnotationsRejectsNonBinary()#parquet/schema/TestTypeBuilders/testBinaryAnnotationsRejectsNonBinary()/$anonymous1/()
parquet/schema/TestTypeBuilders/testBinaryAnnotationsRejectsNonBinary()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testFixedTypeConstruction()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/schema/TestTypeBuilders/testFixedTypeConstruction()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testFixedTypeConstruction()#parquet/schema/Types/repeated(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testFixedTypeConstruction()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testFixedTypeConstruction()#parquet/schema/Type/Repetition/values()
parquet/schema/TestTypeBuilders/testFixedTypeConstruction()#parquet/schema/Types/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)
parquet/schema/TestTypeBuilders/testFixedTypeConstruction()#parquet/schema/Types/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testFixedTypeConstruction()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,int,java.lang.String)
parquet/schema/TestTypeBuilders/testBinaryAnnotations()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String,parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testBinaryAnnotations()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testBinaryAnnotations()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testBinaryAnnotations()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testIntervalAnnotation()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/schema/TestTypeBuilders/testIntervalAnnotation()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,int,java.lang.String,parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testIntervalAnnotation()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testIntervalAnnotation()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testIntervalAnnotation()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testIntervalAnnotationRejectsNonFixed()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testIntervalAnnotationRejectsNonFixed()#parquet/schema/TestTypeBuilders/testIntervalAnnotationRejectsNonFixed()/$anonymous1/()
parquet/schema/TestTypeBuilders/testInt64Annotations()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String,parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testInt64Annotations()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testInt64Annotations()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testInt64Annotations()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/Types/PrimitiveBuilder/precision(int)
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,int,java.lang.String,parquet.schema.OriginalType,parquet.schema.DecimalMetadata,parquet.schema.Type.ID)
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/Types/buildMessage()
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/DecimalMetadata/DecimalMetadata(int,int)
parquet/schema/TestTypeBuilders/testDecimalAnnotation()#parquet/schema/Types/PrimitiveBuilder/scale(int)
parquet/schema/TestTypeBuilders/testFixedWithLength()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/schema/TestTypeBuilders/testFixedWithLength()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testFixedWithLength()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testFixedWithLength()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,int,java.lang.String)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/DecimalMetadata/DecimalMetadata(int,int)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/Types/PrimitiveBuilder/precision(int)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,int,java.lang.String,parquet.schema.OriginalType,parquet.schema.DecimalMetadata,parquet.schema.Type.ID)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testDecimalAnnotationMissingScale()#parquet/schema/Types/buildMessage()
parquet/schema/TestTypeBuilders/testEmptyGroup()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testEmptyGroup()#parquet/schema/TestTypeBuilders/testEmptyGroup()/$anonymous3/()
parquet/schema/TestTypeBuilders/testEmptyGroup()#parquet/schema/TestTypeBuilders/testEmptyGroup()/$anonymous2/()
parquet/schema/TestTypeBuilders/testEmptyGroup()#parquet/schema/TestTypeBuilders/testEmptyGroup()/$anonymous1/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()#parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()/$anonymous4/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()#parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()/$anonymous3/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()#parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()/$anonymous2/()
parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()#parquet/schema/TestTypeBuilders/testDecimalAnnotationPrecisionScaleBound()/$anonymous1/()
parquet/schema/TestTypeBuilders/testInt64AnnotationsRejectNonInt64()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testInt64AnnotationsRejectNonInt64()#parquet/schema/TestTypeBuilders/testInt64AnnotationsRejectNonInt64()/$anonymous2/()
parquet/schema/TestTypeBuilders/testInt64AnnotationsRejectNonInt64()#parquet/schema/TestTypeBuilders/testInt64AnnotationsRejectNonInt64()/$anonymous1/()
parquet/schema/TestTypeBuilders/testInt32Annotations()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String,parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testInt32Annotations()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testInt32Annotations()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testInt32Annotations()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testIntervalAnnotationRejectsNonFixed12()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testIntervalAnnotationRejectsNonFixed12()#parquet/schema/TestTypeBuilders/testIntervalAnnotationRejectsNonFixed12()/$anonymous1/()
parquet/schema/TestTypeBuilders/testInt32AnnotationsRejectNonInt32()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testInt32AnnotationsRejectNonInt32()#parquet/schema/TestTypeBuilders/testInt32AnnotationsRejectNonInt32()/$anonymous2/()
parquet/schema/TestTypeBuilders/testInt32AnnotationsRejectNonInt32()#parquet/schema/TestTypeBuilders/testInt32AnnotationsRejectNonInt32()/$anonymous1/()
parquet/schema/TestTypeBuilders/testDECIMALAnnotationRejectsUnsupportedTypes()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testDECIMALAnnotationRejectsUnsupportedTypes()#parquet/schema/TestTypeBuilders/testDECIMALAnnotationRejectsUnsupportedTypes()/$anonymous1/()
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type[])
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/buildGroup(parquet.schema.Type.Repetition)
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/GroupBuilder/addFields(parquet.schema.Type[])
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/optionalGroup()
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/GroupBuilder/requiredGroup()
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/repeatedGroup()
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/GroupBuilder/repeatedGroup()
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Type/Repetition/values()
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/GroupBuilder/addField(parquet.schema.Type)
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/GroupBuilder/group(parquet.schema.Type.Repetition)
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/requiredGroup()
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/GroupBuilder/optionalGroup()
parquet/schema/TestTypeBuilders/testGroupTypeConstruction()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testFixedWithoutLength()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/schema/TestTypeBuilders/testFixedWithoutLength()#parquet/schema/Types/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/schema/TestTypeBuilders/testEmptyMessage()#parquet/schema/TestTypeBuilders/assertThrows(java.lang.String,java.lang.Class,java.util.concurrent.Callable)
parquet/schema/TestTypeBuilders/testEmptyMessage()#parquet/schema/TestTypeBuilders/testEmptyMessage()/$anonymous1/()
parquet/pig/convert/TupleConverter/BagConverter/getConverter(int)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/pig/convert/TupleConverter/BagConverter/end()#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/pig/convert/TupleConverter/BagConverter/end()#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/hadoop/ParquetRecordReader/initialize(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetRecordReader/initialize(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/Log/error(java.lang.Object)
parquet/hadoop/ParquetRecordReader/initialize(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetRecordReader/initialize(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/hadoop/util/counters/BenchmarkCounter/initCounterFromContext(parquet.hadoop.util.counters.TaskInputOutputContext)
parquet/hadoop/ParquetRecordReader/getProgress()#parquet/hadoop/InternalParquetRecordReader/getProgress()
parquet/hadoop/ParquetRecordReader/getCurrentValue()#parquet/hadoop/InternalParquetRecordReader/getCurrentValue()
parquet/hadoop/ParquetRecordReader/nextKeyValue()#parquet/hadoop/InternalParquetRecordReader/nextKeyValue()
parquet/hadoop/ParquetRecordReader/close()#parquet/hadoop/InternalParquetRecordReader/close()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputSplit/getReadSupportMetadata()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/List/size()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputSplit/getRequestedSchema()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/Set/add(E)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/Set/contains(java.lang.Object)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/List/add(E)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/List/get(int)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.format.converter.ParquetMetadataConverter.MetadataFilter)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/format/converter/ParquetMetadataConverter/range(long,long)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputSplit/getRowGroupOffsets()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputFormat/getFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputSplit/getEnd()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/BlockMetaData/getStartingPos()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/HashSet/HashSet()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/FileMetaData/getKeyValueMetaData()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/filter2/compat/RowGroupFilter/filterRowGroups(parquet.filter2.compat.FilterCompat.Filter,java.util.List,parquet.schema.MessageType)
parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/Arrays/toString(long[])
parquet/hadoop/ParquetRecordReader/initialize(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/hadoop/util/counters/BenchmarkCounter/initCounterFromReporter(org.apache.hadoop.hive.ql.io.parquet.read.Reporter,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetRecordReader/initialize(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration,org.apache.hadoop.hive.ql.io.parquet.read.Reporter)#parquet/hadoop/ParquetRecordReader/initializeInternalReader(parquet.hadoop.ParquetInputSplit,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/proto/ProtoSchemaConverter/addField(Descriptors.FieldDescriptor,parquet.schema.Types.GroupBuilder)#parquet/proto/ProtoSchemaConverter/convertFields(parquet.schema.Types.GroupBuilder,java.util.List)
parquet/proto/ProtoSchemaConverter/addField(Descriptors.FieldDescriptor,parquet.schema.Types.GroupBuilder)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/proto/ProtoSchemaConverter/addField(Descriptors.FieldDescriptor,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/GroupBuilder/primitive(parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.Type.Repetition)
parquet/proto/ProtoSchemaConverter/addField(Descriptors.FieldDescriptor,parquet.schema.Types.GroupBuilder)#parquet/proto/ProtoSchemaConverter/getRepetition(Descriptors.FieldDescriptor)
parquet/proto/ProtoSchemaConverter/addField(Descriptors.FieldDescriptor,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/proto/ProtoSchemaConverter/addField(Descriptors.FieldDescriptor,parquet.schema.Types.GroupBuilder)#parquet/schema/Types/GroupBuilder/group(parquet.schema.Type.Repetition)
parquet/proto/ProtoSchemaConverter/convertFields(parquet.schema.Types.GroupBuilder,java.util.List)#parquet/proto/ProtoSchemaConverter/addField(Descriptors.FieldDescriptor,parquet.schema.Types.GroupBuilder)
parquet/proto/ProtoSchemaConverter/convert(java.lang.Class)#parquet/proto/ProtoSchemaConverter/convertFields(parquet.schema.Types.GroupBuilder,java.util.List)
parquet/proto/ProtoSchemaConverter/convert(java.lang.Class)#parquet/Log/debug(java.lang.Object)
parquet/proto/ProtoSchemaConverter/convert(java.lang.Class)#parquet/schema/Types/buildMessage()
parquet/pig/TestParquetStorer/testComplexSchema()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetStorer/testComplexSchema()#java/lang/String/replaceAll(java.lang.String,java.lang.String)
parquet/pig/TestParquetStorer/testComplexSchema()#java/lang/Class/getName()
parquet/pig/TestParquetStorer/testComplexSchema()#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/TestParquetStorer/testComplexSchema()#java/util/Collections/shuffle(java.util.List)
parquet/pig/TestParquetStorer/testComplexSchema()#java/lang/Object/Object()
parquet/pig/TestParquetStorer/testStorerCompressed()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetStorer/testStorerCompressed()#java/util/Properties/setProperty(java.lang.String,java.lang.String)
parquet/pig/TestParquetStorer/testStorerCompressed()#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/TestParquetStorer/testStorerCompressed()#java/lang/Object/Object()
parquet/pig/TestParquetStorer/testStorerCompressed()#java/util/Properties/Properties()
parquet/pig/TestParquetStorer/testStorerCompressed()#java/lang/Class/getName()
parquet/pig/TestParquetStorer/testMultipleSchema()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetStorer/testMultipleSchema()#java/util/Properties/setProperty(java.lang.String,java.lang.String)
parquet/pig/TestParquetStorer/testMultipleSchema()#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/TestParquetStorer/testMultipleSchema()#java/lang/Object/Object()
parquet/pig/TestParquetStorer/testMultipleSchema()#java/util/Properties/Properties()
parquet/pig/TestParquetStorer/testMultipleSchema()#java/lang/Class/getName()
parquet/pig/TestParquetStorer/testStorer()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetStorer/testStorer()#java/util/Properties/setProperty(java.lang.String,java.lang.String)
parquet/pig/TestParquetStorer/testStorer()#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/TestParquetStorer/testStorer()#java/lang/Object/Object()
parquet/pig/TestParquetStorer/testStorer()#java/util/Properties/Properties()
parquet/pig/TestParquetStorer/testStorer()#java/lang/Class/getName()
parquet/thrift/TestThriftSchemaConverter/testToProjectedThriftType()#parquet/thrift/TestThriftSchemaConverter/shouldGetProjectedSchema(java.lang.String,java.lang.String,java.lang.Class)
parquet/thrift/TestThriftSchemaConverter/testProjectOnlyKeyInMap()#parquet/thrift/TestThriftSchemaConverter/shouldGetProjectedSchema(java.lang.String,java.lang.String,java.lang.Class)
parquet/thrift/TestThriftSchemaConverter/testToThriftType()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestThriftSchemaConverter/testToThriftType()#parquet/thrift/struct/ThriftType/fromJSON(java.lang.String)
parquet/thrift/TestThriftSchemaConverter/testToThriftType()#java/io/PrintStream/println(java.lang.String)
parquet/thrift/TestThriftSchemaConverter/testToThriftType()#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/thrift/TestThriftSchemaConverter/testToThriftType()#parquet/thrift/struct/ThriftType/toJSON()
parquet/thrift/TestThriftSchemaConverter/getFilteredSchema(java.lang.String,java.lang.Class)#parquet/thrift/projection/FieldProjectionFilter/FieldProjectionFilter(java.lang.String)
parquet/thrift/TestThriftSchemaConverter/getFilteredSchema(java.lang.String,java.lang.Class)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter(parquet.thrift.projection.FieldProjectionFilter)
parquet/thrift/TestThriftSchemaConverter/getFilteredSchema(java.lang.String,java.lang.Class)#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/thrift/TestThriftSchemaConverter/testToMessageType()#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/thrift/TestThriftSchemaConverter/testToMessageType()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/thrift/TestThriftSchemaConverter/testToMessageType()#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/thrift/TestThriftSchemaConverter/testProjectOnlyValueInMap()#parquet/thrift/TestThriftSchemaConverter/getFilteredSchema(java.lang.String,java.lang.Class)
parquet/thrift/TestThriftSchemaConverter/testProjectOnlyValueInMap()#java/io/PrintStream/println(char[])
parquet/thrift/TestThriftSchemaConverter/testProjectMapThriftType()#parquet/thrift/TestThriftSchemaConverter/shouldGetProjectedSchema(java.lang.String,java.lang.String,java.lang.Class)
parquet/thrift/TestThriftSchemaConverter/shouldGetProjectedSchema(java.lang.String,java.lang.String,java.lang.Class)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/thrift/TestThriftSchemaConverter/shouldGetProjectedSchema(java.lang.String,java.lang.String,java.lang.Class)#parquet/thrift/TestThriftSchemaConverter/getFilteredSchema(java.lang.String,java.lang.Class)
parquet/example/data/simple/NanoTime/fromBinary(parquet.io.api.Binary)#parquet/example/data/simple/NanoTime/NanoTime(int,long)
parquet/example/data/simple/NanoTime/fromBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toByteBuffer()
parquet/example/data/simple/NanoTime/fromBinary(parquet.io.api.Binary)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/example/data/simple/NanoTime/fromBinary(parquet.io.api.Binary)#parquet/io/api/Binary/length()
parquet/example/data/simple/NanoTime/fromBinary(parquet.io.api.Binary)#java/nio/ByteBuffer/getLong()
parquet/example/data/simple/NanoTime/fromBinary(parquet.io.api.Binary)#java/nio/ByteBuffer/getInt()
parquet/example/data/simple/NanoTime/fromInt96(parquet.example.data.simple.Int96Value)#parquet/example/data/simple/NanoTime/NanoTime(int,long)
parquet/example/data/simple/NanoTime/fromInt96(parquet.example.data.simple.Int96Value)#parquet/example/data/simple/Int96Value/getInt96()
parquet/example/data/simple/NanoTime/fromInt96(parquet.example.data.simple.Int96Value)#parquet/io/api/Binary/toByteBuffer()
parquet/example/data/simple/NanoTime/fromInt96(parquet.example.data.simple.Int96Value)#java/nio/ByteBuffer/getLong()
parquet/example/data/simple/NanoTime/fromInt96(parquet.example.data.simple.Int96Value)#java/nio/ByteBuffer/getInt()
parquet/example/data/simple/NanoTime/toBinary()#java/nio/ByteBuffer/putLong(long)
parquet/example/data/simple/NanoTime/toBinary()#java/nio/Buffer/flip()
parquet/example/data/simple/NanoTime/toBinary()#java/nio/ByteBuffer/putInt(int)
parquet/example/data/simple/NanoTime/toBinary()#java/nio/ByteBuffer/allocate(int)
parquet/example/data/simple/NanoTime/toBinary()#parquet/io/api/Binary/fromByteBuffer(java.nio.ByteBuffer)
parquet/example/data/simple/NanoTime/toInt96()#parquet/example/data/simple/NanoTime/toBinary()
parquet/example/data/simple/NanoTime/toInt96()#parquet/example/data/simple/Int96Value/Int96Value(parquet.io.api.Binary)
parquet/example/data/simple/NanoTime/writeValue(parquet.io.api.RecordConsumer)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/example/data/simple/NanoTime/writeValue(parquet.io.api.RecordConsumer)#parquet/example/data/simple/NanoTime/toBinary()
parquet/tools/util/PrettyPrintWriter/Line/toString(java.lang.StringBuilder)#parquet/tools/util/PrettyPrintWriter/Span/toString(java.lang.StringBuilder)
parquet/tools/util/PrettyPrintWriter/Line/indexOf(char,int)#parquet/tools/util/PrettyPrintWriter/Span/length()
parquet/tools/util/PrettyPrintWriter/Line/indexOf(char,int)#parquet/tools/util/PrettyPrintWriter/Span/indexOf(char,int)
parquet/tools/util/PrettyPrintWriter/Line/countCharacter(char)#parquet/tools/util/PrettyPrintWriter/Span/countCharacter(char)
parquet/tools/util/PrettyPrintWriter/Line/spaceOut(int,int)#parquet/tools/util/PrettyPrintWriter/Span/length()
parquet/tools/util/PrettyPrintWriter/Line/spaceOut(int,int)#parquet/tools/util/PrettyPrintWriter/Span/spaceOut(int,int)
parquet/tools/util/PrettyPrintWriter/Line/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)#parquet/tools/util/PrettyPrintWriter/Span/length()
parquet/tools/util/PrettyPrintWriter/Line/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)#java/util/List/remove(int)
parquet/tools/util/PrettyPrintWriter/Line/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)#java/util/List/size()
parquet/tools/util/PrettyPrintWriter/Line/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)#java/util/List/get(int)
parquet/tools/util/PrettyPrintWriter/Line/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)#parquet/tools/util/PrettyPrintWriter/Span/trimTo(int,parquet.tools.util.PrettyPrintWriter.Span)
parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)#parquet/tools/util/PrettyPrintWriter/Span/length()
parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)#parquet/tools/util/PrettyPrintWriter/Span/append(parquet.tools.util.PrettyPrintWriter.Span)
parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)#java/util/List/isEmpty()
parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)#java/util/List/size()
parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)#parquet/tools/util/PrettyPrintWriter/Span/canAppend(parquet.tools.util.PrettyPrintWriter.Span)
parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)#java/util/List/add(E)
parquet/tools/util/PrettyPrintWriter/Line/append(parquet.tools.util.PrettyPrintWriter.Span)#java/util/List/get(int)
parquet/filter2/predicate/Operators/NotEq/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.NotEq)
parquet/hadoop/PrintFooter/percentComp(long,long)#parquet/hadoop/PrintFooter/percent(long,long)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/ArrayList/ArrayList()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/io/PrintStream/println(java.lang.String)
parquet/hadoop/PrintFooter/main(java.lang.String[])#parquet/hadoop/PrintFooter/main(java/lang/String[])/$anonymous2/()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/Arrays/asList(T[])
parquet/hadoop/PrintFooter/main(java.lang.String[])#parquet/hadoop/PrintFooter/percent(long,long)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/Deque/removeFirst()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/Map/Entry/getValue()
parquet/hadoop/PrintFooter/main(java.lang.String[])#parquet/hadoop/PrintFooter/humanReadable(long)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/io/PrintStream/print(java.lang.String)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/net/URI/URI(java.lang.String)
parquet/hadoop/PrintFooter/main(java.lang.String[])#parquet/hadoop/Footer/getParquetMetadata()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/Collection/isEmpty()
parquet/hadoop/PrintFooter/main(java.lang.String[])#parquet/hadoop/ParquetFileReader/readSummaryFile(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.FileStatus)
parquet/hadoop/PrintFooter/main(java.lang.String[])#parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/Deque/add(E)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/Map/Entry/getKey()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/io/PrintStream/println(char[])
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/io/PrintStream/print(char)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/concurrent/ExecutorService/shutdownNow()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/concurrent/Executors/newFixedThreadPool(int)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/lang/System/currentTimeMillis()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/concurrent/Future/isDone()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/Map/entrySet()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/Deque/addLast(E)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/concurrent/Future/get()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/lang/Object/Object()
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/concurrent/ExecutorService/submit(java.util.concurrent.Callable)
parquet/hadoop/PrintFooter/main(java.lang.String[])#java/util/concurrent/LinkedBlockingDeque/LinkedBlockingDeque()
parquet/hadoop/PrintFooter/humanReadable(long)#java/lang/String/valueOf(long)
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/common/schema/ColumnPath/toArray()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/PrintFooter/add(parquet.column.ColumnDescriptor,long,long,long,java.util.Collection,parquet.column.statistics.Statistics)
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ColumnChunkMetaData/getValueCount()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/BlockMetaData/getRowCount()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalSize()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ParquetMetadata/getBlocks()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ColumnChunkMetaData/getStatistics()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ColumnChunkMetaData/getTotalUncompressedSize()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ColumnChunkMetaData/getPath()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/hadoop/PrintFooter/add(parquet.hadoop.metadata.ParquetMetadata)#parquet/hadoop/metadata/ColumnChunkMetaData/getEncodings()
parquet/hadoop/PrintFooter/add(parquet.column.ColumnDescriptor,long,long,long,java.util.Collection,parquet.column.statistics.Statistics)#java/util/Map/get(java.lang.Object)
parquet/hadoop/PrintFooter/add(parquet.column.ColumnDescriptor,long,long,long,java.util.Collection,parquet.column.statistics.Statistics)#parquet/hadoop/PrintFooter/ColStats/add(long,long,long,java.util.Collection,parquet.column.statistics.Statistics)
parquet/hadoop/PrintFooter/add(parquet.column.ColumnDescriptor,long,long,long,java.util.Collection,parquet.column.statistics.Statistics)#java/util/Map/put(K,V)
parquet/hadoop/PrintFooter/add(parquet.column.ColumnDescriptor,long,long,long,java.util.Collection,parquet.column.statistics.Statistics)#parquet/hadoop/PrintFooter/ColStats/ColStats()
parquet/hadoop/PrintFooter/printTotalString(java.lang.String,long,long)#parquet/hadoop/PrintFooter/percentComp(long,long)
parquet/hadoop/PrintFooter/printTotalString(java.lang.String,long,long)#parquet/hadoop/PrintFooter/humanReadable(long)
parquet/hadoop/PrintFooter/printTotalString(java.lang.String,long,long)#java/io/PrintStream/println(java.lang.String)
parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)#java/io/PrintStream/println(java.lang.String)
parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)#java/lang/System/nanoTime()
parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)#parquet/bytes/BytesInput/size()
parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)#parquet/column/values/ValuesWriter/reset()
parquet/column/values/dictionary/PlainValuesDictionary/PlainDoubleDictionary/toString()#java/lang/StringBuilder/append(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainDoubleDictionary/toString()#java/lang/StringBuilder/append(int)
parquet/column/values/dictionary/PlainValuesDictionary/PlainDoubleDictionary/toString()#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainDoubleDictionary/toString()#java/lang/StringBuilder/append(double)
parquet/column/values/dictionary/PlainValuesDictionary/PlainDoubleDictionary/toString()#java/lang/StringBuilder/toString()
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#java/io/PrintWriter/println()
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetReader/ParquetReader(parquet.hadoop.Path,parquet.hadoop.api.ReadSupport)
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#java/lang/Long/parseLong(java.lang.String)
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/command/ArgsOnlyCommand/execute(parquet.tools.command.CommandLine)
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetReader/close()
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/read/SimpleRecord/prettyPrint(java.io.PrintWriter)
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/read/SimpleReadSupport/SimpleReadSupport()
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetReader/read()
parquet/tools/command/HeadCommand/execute(parquet.tools.command.CommandLine)#java/io/PrintWriter/PrintWriter(java.io.OutputStream,boolean)
parquet/filter2/compat/FilterCompat/UnboundRecordFilterCompat/accept(parquet.filter2.compat.FilterCompat.Visitor)#parquet/filter2/compat/FilterCompat/Visitor/visit(parquet.filter2.compat.FilterCompat.UnboundRecordFilterCompat)
parquet/example/data/Group/add(java.lang.String,parquet.example.data.Group)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,parquet.example.data.Group)#parquet/example/data/Group/add(int,parquet.example.data.Group)
parquet/example/data/Group/add(java.lang.String,parquet.example.data.Group)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/add(java.lang.String,parquet.example.data.simple.NanoTime)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,parquet.example.data.simple.NanoTime)#parquet/example/data/Group/add(int,parquet.example.data.simple.NanoTime)
parquet/example/data/Group/add(java.lang.String,parquet.example.data.simple.NanoTime)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/add(java.lang.String,boolean)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,boolean)#parquet/example/data/Group/add(int,boolean)
parquet/example/data/Group/add(java.lang.String,boolean)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/add(java.lang.String,float)#parquet/example/data/Group/add(int,float)
parquet/example/data/Group/add(java.lang.String,float)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,float)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/append(java.lang.String,float)#parquet/example/data/Group/add(java.lang.String,float)
parquet/example/data/Group/append(java.lang.String,int)#parquet/example/data/Group/add(java.lang.String,int)
parquet/example/data/Group/append(java.lang.String,double)#parquet/example/data/Group/add(java.lang.String,double)
parquet/example/data/Group/add(java.lang.String,double)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,double)#parquet/example/data/Group/add(int,double)
parquet/example/data/Group/add(java.lang.String,double)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/addGroup(java.lang.String)#parquet/example/data/Group/addGroup(int)
parquet/example/data/Group/addGroup(java.lang.String)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/addGroup(java.lang.String)#parquet/Log/debug(java.lang.Object)
parquet/example/data/Group/addGroup(java.lang.String)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/addGroup(java.lang.String)#parquet/schema/Type/getName()
parquet/example/data/Group/add(java.lang.String,parquet.io.api.Binary)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,parquet.io.api.Binary)#parquet/example/data/Group/add(int,parquet.io.api.Binary)
parquet/example/data/Group/add(java.lang.String,parquet.io.api.Binary)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/append(java.lang.String,boolean)#parquet/example/data/Group/add(java.lang.String,boolean)
parquet/example/data/Group/append(java.lang.String,parquet.io.api.Binary)#parquet/example/data/Group/add(java.lang.String,parquet.io.api.Binary)
parquet/example/data/Group/append(java.lang.String,java.lang.String)#parquet/example/data/Group/add(java.lang.String,parquet.io.api.Binary)
parquet/example/data/Group/append(java.lang.String,java.lang.String)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/example/data/Group/getGroup(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/getGroup(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/getGroup(java.lang.String,int)#parquet/example/data/Group/getGroup(int,int)
parquet/example/data/Group/add(java.lang.String,java.lang.String)#parquet/example/data/Group/add(int,java.lang.String)
parquet/example/data/Group/add(java.lang.String,java.lang.String)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,java.lang.String)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/append(java.lang.String,long)#parquet/example/data/Group/add(java.lang.String,long)
parquet/example/data/Group/add(java.lang.String,long)#parquet/example/data/Group/add(int,long)
parquet/example/data/Group/add(java.lang.String,long)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,long)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/example/data/Group/append(java.lang.String,parquet.example.data.simple.NanoTime)#parquet/example/data/Group/add(java.lang.String,parquet.example.data.simple.NanoTime)
parquet/example/data/Group/add(java.lang.String,int)#parquet/example/data/Group/add(int,int)
parquet/example/data/Group/add(java.lang.String,int)#parquet/example/data/GroupValueSource/getType()
parquet/example/data/Group/add(java.lang.String,int)#parquet/schema/GroupType/getFieldIndex(java.lang.String)
parquet/thrift/ThriftRecordConverter/MapConverter/getConverter(int)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/thrift/ThriftRecordConverter/MapConverter/end()#parquet/thrift/ThriftRecordConverter/MapConverter/end()/$anonymous1/(java.lang.String)
parquet/thrift/ThriftRecordConverter/MapConverter/end()#parquet/thrift/ThriftRecordConverter/GroupCounter/getCount()
parquet/thrift/ThriftRecordConverter/MapConverter/start()#parquet/thrift/ThriftRecordConverter/GroupCounter/startCounting()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(byte[],int,int)#parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(byte[],int,int)#java/nio/ByteBuffer/arrayOffset()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(byte[],int,int)#java/nio/Buffer/position()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(byte[],int,int)#java/nio/Buffer/remaining()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(byte[],int,int)#java/nio/ByteBuffer/hasArray()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(byte[],int,int)#parquet/io/api/Binary/equals(byte[],int,int,byte[],int,int)
parquet/io/api/Binary/ByteBufferBackedBinary/equals(byte[],int,int)#java/nio/ByteBuffer/array()
parquet/io/api/Binary/ByteBufferBackedBinary/writeTo(java.io.OutputStream)#parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()
parquet/io/api/Binary/ByteBufferBackedBinary/writeTo(java.io.OutputStream)#java/io/OutputStream/write(byte[])
parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()#java/nio/Buffer/reset()
parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()#java/nio/ByteBuffer/get(byte[])
parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()#java/nio/Buffer/remaining()
parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()#java/nio/Buffer/mark()
parquet/io/api/Binary/ByteBufferBackedBinary/writeObject(java.io.ObjectOutputStream)#parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()
parquet/io/api/Binary/ByteBufferBackedBinary/writeObject(java.io.ObjectOutputStream)#java/io/ObjectOutputStream/writeInt(int)
parquet/io/api/Binary/ByteBufferBackedBinary/writeObject(java.io.ObjectOutputStream)#java/io/ObjectOutputStream/write(byte[])
parquet/io/api/Binary/ByteBufferBackedBinary/hashCode()#parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()
parquet/io/api/Binary/ByteBufferBackedBinary/hashCode()#java/nio/ByteBuffer/arrayOffset()
parquet/io/api/Binary/ByteBufferBackedBinary/hashCode()#java/nio/Buffer/position()
parquet/io/api/Binary/ByteBufferBackedBinary/hashCode()#java/nio/Buffer/remaining()
parquet/io/api/Binary/ByteBufferBackedBinary/hashCode()#parquet/io/api/Binary/hashCode(byte[],int,int)
parquet/io/api/Binary/ByteBufferBackedBinary/hashCode()#java/nio/ByteBuffer/array()
parquet/io/api/Binary/ByteBufferBackedBinary/hashCode()#java/nio/ByteBuffer/hasArray()
parquet/io/api/Binary/ByteBufferBackedBinary/toStringUsingUTF8()#java/nio/charset/Charset/decode(java.nio.ByteBuffer)
parquet/io/api/Binary/ByteBufferBackedBinary/toStringUsingUTF8()#java/nio/CharBuffer/toString()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(parquet.io.api.Binary)#parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(parquet.io.api.Binary)#java/nio/ByteBuffer/arrayOffset()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(parquet.io.api.Binary)#java/nio/Buffer/position()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(parquet.io.api.Binary)#java/nio/Buffer/remaining()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(parquet.io.api.Binary)#parquet/io/api/Binary/equals(byte[],int,int)
parquet/io/api/Binary/ByteBufferBackedBinary/equals(parquet.io.api.Binary)#java/nio/ByteBuffer/array()
parquet/io/api/Binary/ByteBufferBackedBinary/equals(parquet.io.api.Binary)#java/nio/ByteBuffer/hasArray()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(byte[],int,int)#parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(byte[],int,int)#java/nio/ByteBuffer/arrayOffset()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(byte[],int,int)#java/nio/Buffer/position()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(byte[],int,int)#java/nio/Buffer/remaining()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(byte[],int,int)#parquet/io/api/Binary/compareTwoByteArrays(byte[],int,int,byte[],int,int)
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(byte[],int,int)#java/nio/ByteBuffer/array()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(byte[],int,int)#java/nio/ByteBuffer/hasArray()
parquet/io/api/Binary/ByteBufferBackedBinary/length()#java/nio/Buffer/remaining()
parquet/io/api/Binary/ByteBufferBackedBinary/writeTo(java.io.DataOutput)#parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()
parquet/io/api/Binary/ByteBufferBackedBinary/writeTo(java.io.DataOutput)#java/io/DataOutput/write(byte[])
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(parquet.io.api.Binary)#parquet/io/api/Binary/compareTo(byte[],int,int)
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(parquet.io.api.Binary)#parquet/io/api/Binary/ByteBufferBackedBinary/getBytes()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(parquet.io.api.Binary)#java/nio/ByteBuffer/arrayOffset()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(parquet.io.api.Binary)#java/nio/Buffer/position()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(parquet.io.api.Binary)#java/nio/Buffer/remaining()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(parquet.io.api.Binary)#java/nio/ByteBuffer/array()
parquet/io/api/Binary/ByteBufferBackedBinary/compareTo(parquet.io.api.Binary)#java/nio/ByteBuffer/hasArray()
parquet/io/api/Binary/ByteBufferBackedBinary/readObjectNoData()#java/nio/ByteBuffer/wrap(byte[])
parquet/io/api/Binary/ByteBufferBackedBinary/readObject(java.io.ObjectInputStream)#java/io/ObjectInputStream/readFully(byte[],int,int)
parquet/io/api/Binary/ByteBufferBackedBinary/readObject(java.io.ObjectInputStream)#java/io/ObjectInputStream/readInt()
parquet/io/api/Binary/ByteBufferBackedBinary/readObject(java.io.ObjectInputStream)#java/nio/ByteBuffer/wrap(byte[])
parquet/thrift/struct/ThriftType/EnumType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.EnumType)
parquet/thrift/struct/ThriftType/EnumType/prepareEnumLookUp()#parquet/thrift/struct/ThriftType/EnumValue/getId()
parquet/thrift/struct/ThriftType/EnumType/prepareEnumLookUp()#java/util/HashMap/HashMap()
parquet/thrift/struct/ThriftType/EnumType/prepareEnumLookUp()#java/util/Map/put(K,V)
parquet/thrift/struct/ThriftType/EnumType/hashCode()#java/util/List/hashCode()
parquet/thrift/struct/ThriftType/EnumType/hashCode()#parquet/thrift/struct/ThriftType/hashCode()
parquet/thrift/struct/ThriftType/EnumType/getEnumValueById(int)#parquet/thrift/struct/ThriftType/EnumType/prepareEnumLookUp()
parquet/thrift/struct/ThriftType/EnumType/getEnumValueById(int)#java/util/Map/get(java.lang.Object)
parquet/thrift/struct/ThriftType/EnumType/getValues()#parquet/thrift/struct/ThriftType/EnumType/getValues()/$anonymous1/()
parquet/thrift/struct/ThriftType/EnumType/equals(java.lang.Object)#parquet/thrift/struct/ThriftType/equals(java.lang.Object)
parquet/thrift/struct/ThriftType/EnumType/equals(java.lang.Object)#java/util/List/equals(java.lang.Object)
parquet/column/impl/ColumnWriterImpl/updateStatisticsNumNulls()#parquet/column/statistics/Statistics/incrementNumNulls()
parquet/column/impl/ColumnWriterImpl/initStatistics()#parquet/column/ColumnDescriptor/getType()
parquet/column/impl/ColumnWriterImpl/initStatistics()#parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/impl/ColumnWriterImpl/updateStatistics(double)#parquet/column/statistics/Statistics/updateStats(double)
parquet/column/impl/ColumnWriterImpl/log(java.lang.Object,int,int)#parquet/Log/debug(java.lang.Object)
parquet/column/impl/ColumnWriterImpl/write(float,int,int)#parquet/column/values/ValuesWriter/writeFloat(float)
parquet/column/impl/ColumnWriterImpl/write(float,int,int)#parquet/column/impl/ColumnWriterImpl/updateStatistics(float)
parquet/column/impl/ColumnWriterImpl/write(float,int,int)#parquet/column/impl/ColumnWriterImpl/log(java.lang.Object,int,int)
parquet/column/impl/ColumnWriterImpl/write(float,int,int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/impl/ColumnWriterImpl/write(float,int,int)#parquet/column/impl/ColumnWriterImpl/accountForValueWritten()
parquet/column/impl/ColumnWriterImpl/updateStatistics(boolean)#parquet/column/statistics/Statistics/updateStats(boolean)
parquet/column/impl/ColumnWriterImpl/getBufferedSizeInMemory()#parquet/column/values/ValuesWriter/getBufferedSize()
parquet/column/impl/ColumnWriterImpl/getBufferedSizeInMemory()#parquet/column/page/PageWriter/getMemSize()
parquet/column/impl/ColumnWriterImpl/updateStatistics(long)#parquet/column/statistics/Statistics/updateStats(long)
parquet/column/impl/ColumnWriterImpl/write(long,int,int)#parquet/column/impl/ColumnWriterImpl/updateStatistics(long)
parquet/column/impl/ColumnWriterImpl/write(long,int,int)#parquet/column/values/ValuesWriter/writeLong(long)
parquet/column/impl/ColumnWriterImpl/write(long,int,int)#parquet/column/impl/ColumnWriterImpl/log(java.lang.Object,int,int)
parquet/column/impl/ColumnWriterImpl/write(long,int,int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/impl/ColumnWriterImpl/write(long,int,int)#parquet/column/impl/ColumnWriterImpl/accountForValueWritten()
parquet/column/impl/ColumnWriterImpl/updateStatistics(parquet.io.api.Binary)#parquet/column/statistics/Statistics/updateStats(parquet.io.api.Binary)
parquet/column/impl/ColumnWriterImpl/writeNull(int,int)#parquet/column/impl/ColumnWriterImpl/updateStatisticsNumNulls()
parquet/column/impl/ColumnWriterImpl/writeNull(int,int)#parquet/column/impl/ColumnWriterImpl/log(java.lang.Object,int,int)
parquet/column/impl/ColumnWriterImpl/writeNull(int,int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/impl/ColumnWriterImpl/writeNull(int,int)#parquet/column/impl/ColumnWriterImpl/accountForValueWritten()
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#parquet/column/impl/ColumnWriterImpl/getBufferedSizeInMemory()
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#java/lang/StringBuilder/append(java.lang.String)
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#java/lang/StringBuilder/append(java.lang.Object)
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#parquet/column/impl/ColumnWriterImpl/allocatedSize()
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#java/lang/StringBuilder/toString()
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#parquet/column/values/ValuesWriter/memUsageString(java.lang.String)
parquet/column/impl/ColumnWriterImpl/memUsageString(java.lang.String)#parquet/column/page/PageWriter/memUsageString(java.lang.String)
parquet/column/impl/ColumnWriterImpl/flush()#parquet/column/values/ValuesWriter/createDictionaryPage()
parquet/column/impl/ColumnWriterImpl/flush()#parquet/column/page/PageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)
parquet/column/impl/ColumnWriterImpl/flush()#parquet/column/impl/ColumnWriterImpl/writePage()
parquet/column/impl/ColumnWriterImpl/flush()#parquet/column/values/ValuesWriter/resetDictionary()
parquet/column/impl/ColumnWriterImpl/flush()#parquet/Log/debug(java.lang.Object)
parquet/column/impl/ColumnWriterImpl/flush()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/impl/ColumnWriterImpl/allocatedSize()#parquet/column/page/PageWriter/allocatedSize()
parquet/column/impl/ColumnWriterImpl/allocatedSize()#parquet/column/values/ValuesWriter/getAllocatedSize()
parquet/column/impl/ColumnWriterImpl/updateStatistics(float)#parquet/column/statistics/Statistics/updateStats(float)
parquet/column/impl/ColumnWriterImpl/write(double,int,int)#parquet/column/impl/ColumnWriterImpl/updateStatistics(double)
parquet/column/impl/ColumnWriterImpl/write(double,int,int)#parquet/column/values/ValuesWriter/writeDouble(double)
parquet/column/impl/ColumnWriterImpl/write(double,int,int)#parquet/column/impl/ColumnWriterImpl/log(java.lang.Object,int,int)
parquet/column/impl/ColumnWriterImpl/write(double,int,int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/impl/ColumnWriterImpl/write(double,int,int)#parquet/column/impl/ColumnWriterImpl/accountForValueWritten()
parquet/column/impl/ColumnWriterImpl/write(int,int,int)#parquet/column/impl/ColumnWriterImpl/log(java.lang.Object,int,int)
parquet/column/impl/ColumnWriterImpl/write(int,int,int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/impl/ColumnWriterImpl/write(int,int,int)#parquet/column/impl/ColumnWriterImpl/accountForValueWritten()
parquet/column/impl/ColumnWriterImpl/write(int,int,int)#parquet/column/impl/ColumnWriterImpl/updateStatistics(int)
parquet/column/impl/ColumnWriterImpl/accountForValueWritten()#parquet/column/values/ValuesWriter/getBufferedSize()
parquet/column/impl/ColumnWriterImpl/accountForValueWritten()#parquet/column/impl/ColumnWriterImpl/writePage()
parquet/column/impl/ColumnWriterImpl/writePage()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/impl/ColumnWriterImpl/writePage()#parquet/Log/debug(java.lang.Object)
parquet/column/impl/ColumnWriterImpl/writePage()#parquet/column/impl/ColumnWriterImpl/resetStatistics()
parquet/column/impl/ColumnWriterImpl/writePage()#parquet/column/values/ValuesWriter/getEncoding()
parquet/column/impl/ColumnWriterImpl/writePage()#parquet/column/values/ValuesWriter/getBytes()
parquet/column/impl/ColumnWriterImpl/writePage()#parquet/column/values/ValuesWriter/reset()
parquet/column/impl/ColumnWriterImpl/writePage()#parquet/column/page/PageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/column/impl/ColumnWriterImpl/writePage()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/column/impl/ColumnWriterImpl/write(boolean,int,int)#parquet/column/impl/ColumnWriterImpl/updateStatistics(boolean)
parquet/column/impl/ColumnWriterImpl/write(boolean,int,int)#parquet/column/values/ValuesWriter/writeBoolean(boolean)
parquet/column/impl/ColumnWriterImpl/write(boolean,int,int)#parquet/column/impl/ColumnWriterImpl/log(java.lang.Object,int,int)
parquet/column/impl/ColumnWriterImpl/write(boolean,int,int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/impl/ColumnWriterImpl/write(boolean,int,int)#parquet/column/impl/ColumnWriterImpl/accountForValueWritten()
parquet/column/impl/ColumnWriterImpl/resetStatistics()#parquet/column/ColumnDescriptor/getType()
parquet/column/impl/ColumnWriterImpl/resetStatistics()#parquet/column/statistics/Statistics/getStatsBasedOnType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/column/impl/ColumnWriterImpl/write(parquet.io.api.Binary,int,int)#parquet/column/impl/ColumnWriterImpl/updateStatistics(parquet.io.api.Binary)
parquet/column/impl/ColumnWriterImpl/write(parquet.io.api.Binary,int,int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/impl/ColumnWriterImpl/write(parquet.io.api.Binary,int,int)#parquet/column/impl/ColumnWriterImpl/accountForValueWritten()
parquet/column/impl/ColumnWriterImpl/write(parquet.io.api.Binary,int,int)#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/impl/ColumnWriterImpl/write(parquet.io.api.Binary,int,int)#parquet/column/impl/ColumnWriterImpl/log(java.lang.Object,int,int)
parquet/column/impl/ColumnWriterImpl/updateStatistics(int)#parquet/column/statistics/Statistics/updateStats(int)
parquet/hadoop/example/TestInputOutputFormat/MyReadSupport/init(parquet.hadoop.api.InitContext)#java/util/Set/size()
parquet/hadoop/example/TestInputOutputFormat/MyReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getKeyValueMetadata()
parquet/hadoop/example/TestInputOutputFormat/MyReadSupport/init(parquet.hadoop.api.InitContext)#java/util/Map/get(java.lang.Object)
parquet/hadoop/example/TestInputOutputFormat/MyReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/DelegatingReadSupport/init(parquet.hadoop.api.InitContext)
parquet/column/values/bitpacking/EightBitPackingWriter/write(int)#java/io/OutputStream/write(int)
parquet/pig/summary/EnumStat/add(java.lang.String)#parquet/pig/summary/EnumStat/EnumValueCount/add()
parquet/pig/summary/EnumStat/add(java.lang.String)#java/util/Map/get(java.lang.Object)
parquet/pig/summary/EnumStat/add(java.lang.String)#parquet/pig/summary/EnumStat/checkValues()
parquet/pig/summary/EnumStat/add(java.lang.String)#parquet/pig/summary/EnumStat/EnumValueCount/EnumValueCount(java.lang.String)
parquet/pig/summary/EnumStat/add(java.lang.String)#java/util/Map/put(K,V)
parquet/pig/summary/EnumStat/merge(parquet.pig.summary.EnumStat)#java/util/Map/get(java.lang.Object)
parquet/pig/summary/EnumStat/merge(parquet.pig.summary.EnumStat)#parquet/pig/summary/EnumStat/checkValues()
parquet/pig/summary/EnumStat/merge(parquet.pig.summary.EnumStat)#parquet/pig/summary/EnumStat/EnumValueCount/add(int)
parquet/pig/summary/EnumStat/merge(parquet.pig.summary.EnumStat)#java/util/Map/put(K,V)
parquet/pig/summary/EnumStat/merge(parquet.pig.summary.EnumStat)#parquet/pig/summary/EnumStat/getValues()
parquet/pig/summary/EnumStat/setValues(java.util.Collection)#parquet/pig/summary/EnumStat/EnumValueCount/getValue()
parquet/pig/summary/EnumStat/setValues(java.util.Collection)#java/util/Map/put(K,V)
parquet/pig/summary/EnumStat/checkValues()#java/util/Map/size()
parquet/pig/summary/EnumStat/getValues()#java/util/Map/values()
parquet/example/data/simple/BinaryValue/getString()#parquet/io/api/Binary/toStringUsingUTF8()
parquet/example/data/simple/BinaryValue/writeValue(parquet.io.api.RecordConsumer)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/example/data/simple/BinaryValue/toString()#parquet/example/data/simple/BinaryValue/getString()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/getPos()#parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/getProgress()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/close()#parquet/hadoop/ParquetRecordReader/close()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/getProgress()#parquet/hadoop/ParquetRecordReader/getProgress()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/getProgress()#java/lang/Thread/interrupted()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/getProgress()#java/io/IOException/IOException(java.lang.Throwable)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/next(java.lang.Void,parquet.hadoop.mapred.Container)#parquet/hadoop/mapred/Container/set(T)
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/next(java.lang.Void,parquet.hadoop.mapred.Container)#parquet/hadoop/ParquetRecordReader/getCurrentValue()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/next(java.lang.Void,parquet.hadoop.mapred.Container)#parquet/hadoop/ParquetRecordReader/nextKeyValue()
parquet/hadoop/mapred/DeprecatedParquetInputFormat/RecordReaderWrapper/next(java.lang.Void,parquet.hadoop.mapred.Container)#java/io/IOException/IOException(java.lang.Throwable)
parquet/bytes/LittleEndianDataOutputStream/write(int)#java/io/OutputStream/write(int)
parquet/bytes/LittleEndianDataOutputStream/write(byte[],int,int)#java/io/OutputStream/write(byte[],int,int)
parquet/bytes/LittleEndianDataOutputStream/writeInt(int)#java/io/OutputStream/write(int)
parquet/bytes/LittleEndianDataOutputStream/writeFloat(float)#java/lang/Float/floatToIntBits(float)
parquet/bytes/LittleEndianDataOutputStream/writeFloat(float)#parquet/bytes/LittleEndianDataOutputStream/writeInt(int)
parquet/bytes/LittleEndianDataOutputStream/writeDouble(double)#java/lang/Double/doubleToLongBits(double)
parquet/bytes/LittleEndianDataOutputStream/writeDouble(double)#parquet/bytes/LittleEndianDataOutputStream/writeLong(long)
parquet/bytes/LittleEndianDataOutputStream/writeLong(long)#java/io/OutputStream/write(byte[],int,int)
parquet/bytes/LittleEndianDataOutputStream/writeBoolean(boolean)#java/io/OutputStream/write(int)
parquet/bytes/LittleEndianDataOutputStream/writeShort(int)#java/io/OutputStream/write(int)
parquet/bytes/LittleEndianDataOutputStream/flush()#java/io/OutputStream/flush()
parquet/bytes/LittleEndianDataOutputStream/writeByte(int)#java/io/OutputStream/write(int)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/checkRead()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/unpackMiniBlock(parquet.column.values.bitpacking.BytePacker)#parquet/column/values/delta/DeltaBinaryPackingValuesReader/unpack8Values(parquet.column.values.bitpacking.BytePacker)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/readBitWidthsForMiniBlocks()#parquet/bytes/BytesUtils/readIntLittleEndianOnOneByte(java.io.InputStream)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/readBitWidthsForMiniBlocks()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/loadNewBlockToBuffer()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/unpackMiniBlock(parquet.column.values.bitpacking.BytePacker)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/loadNewBlockToBuffer()#parquet/bytes/BytesUtils/readZigZagVarInt(java.io.InputStream)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/loadNewBlockToBuffer()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/loadNewBlockToBuffer()#parquet/column/values/bitpacking/Packer/newBytePacker(int)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/loadNewBlockToBuffer()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/readBitWidthsForMiniBlocks()
parquet/column/values/delta/DeltaBinaryPackingValuesReader/unpack8Values(parquet.column.values.bitpacking.BytePacker)#java/io/ByteArrayInputStream/available()
parquet/column/values/delta/DeltaBinaryPackingValuesReader/unpack8Values(parquet.column.values.bitpacking.BytePacker)#parquet/column/values/bitpacking/BytePacker/getBitWidth()
parquet/column/values/delta/DeltaBinaryPackingValuesReader/unpack8Values(parquet.column.values.bitpacking.BytePacker)#parquet/column/values/bitpacking/BytePacker/unpack8Values(byte[],int,int[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/unpack8Values(parquet.column.values.bitpacking.BytePacker)#java/io/ByteArrayInputStream/skip(long)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/readInteger()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/checkRead()
parquet/column/values/delta/DeltaBinaryPackingValuesReader/skip()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/checkRead()
parquet/column/values/delta/DeltaBinaryPackingValuesReader/allocateValuesBuffer()#java/lang/Math/ceil(double)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[],int,int)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)#java/io/ByteArrayInputStream/available()
parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)#parquet/bytes/BytesUtils/readZigZagVarInt(java.io.InputStream)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)#parquet/column/values/delta/DeltaBinaryPackingConfig/readConfig(java.io.InputStream)
parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)#parquet/column/values/delta/DeltaBinaryPackingValuesReader/allocateValuesBuffer()
parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)#parquet/column/values/delta/DeltaBinaryPackingValuesReader/loadNewBlockToBuffer()
parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)#parquet/bytes/BytesUtils/readUnsignedVarInt(java.io.InputStream)
parquet/thrift/ThriftRecordConverter/getCurrentRecord()#parquet/thrift/ParquetReadProtocol/addAll(java.util.Collection)
parquet/thrift/ThriftRecordConverter/getCurrentRecord()#parquet/thrift/projection/amend/ProtocolEventsAmender/ProtocolEventsAmender(java.util.List)
parquet/thrift/ThriftRecordConverter/getCurrentRecord()#parquet/thrift/projection/amend/ProtocolEventsAmender/amendMissingRequiredFields(parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/ThriftRecordConverter/getCurrentRecord()#parquet/thrift/ThriftReader/readOneRecord(parquet.thrift.TProtocol)
parquet/thrift/ThriftRecordConverter/getCurrentRecord()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/GroupType/getFields()
parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)#parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)
parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/GroupType/containsField(java.lang.String)
parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/Type/isPrimitive()
parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/Type/getName()
parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/GroupType/getType(java.lang.String)
parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/Type/asGroupType()
parquet/thrift/ThriftRecordConverter/hasMissingRequiredFieldInGroupType(parquet.schema.GroupType,parquet.schema.GroupType)#parquet/schema/Type/getRepetition()
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/schema/Type/asGroupType()
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/FieldPrimitiveConverter(java.util.List,parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/ThriftRecordConverter/StructConverter/StructConverter(java.util.List,parquet.schema.GroupType,parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/ThriftRecordConverter/FieldStringConverter/FieldStringConverter(java.util.List,parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/ThriftRecordConverter/FieldEnumConverter/FieldEnumConverter(java.util.List,parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/ThriftRecordConverter/ListConverter/ListConverter(java.util.List,parquet.schema.GroupType,parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/struct/ThriftType/getType()
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/ThriftRecordConverter/MapConverter/MapConverter(java.util.List,parquet.schema.GroupType,parquet.thrift.struct.ThriftField)
parquet/thrift/ThriftRecordConverter/newConverter(java.util.List,parquet.schema.Type,parquet.thrift.struct.ThriftField)#parquet/thrift/ThriftRecordConverter/SetConverter/SetConverter(java.util.List,parquet.schema.GroupType,parquet.thrift.struct.ThriftField)
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/getAllocatedSize()#java/util/List/size()
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/pack()#parquet/column/values/bitpacking/BytePacker/pack8Values(int[],int,byte[],int)
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/getBufferSize()#parquet/bytes/BytesUtils/paddedByteCountFromBits(int)
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/memUsageString(java.lang.String)#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/getAllocatedSize()
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/memUsageString(java.lang.String)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/memUsageString(java.lang.String)#java/util/List/size()
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/toBytes()#parquet/bytes/BytesUtils/paddedByteCountFromBits(int)
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/toBytes()#parquet/bytes/BytesInput/from(byte[],int,int)
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/toBytes()#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/pack()
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/toBytes()#java/util/List/size()
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/toBytes()#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/toBytes()#parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/toBytes()#parquet/bytes/BytesInput/concat(java.util.List)
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/writeInt(int)#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/pack()
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/writeInt(int)#parquet/bytes/BytesInput/from(byte[])
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/writeInt(int)#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/initPackedSlab()
parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/writeInt(int)#java/util/List/add(E)
parquet/proto/ProtoRecordConverterTest/testRepeatedMessages()#parquet/proto/TestUtils/testData(T[])
parquet/proto/ProtoRecordConverterTest/testRepeatedInt()#parquet/proto/TestUtils/testData(T[])
parquet/proto/ProtoRecordConverterTest/testAllTypesMultiple()#parquet/proto/TestUtils/testData(T[])
parquet/proto/ProtoRecordConverterTest/testAllTypes()#parquet/proto/TestUtils/testData(T[])
parquet/proto/ProtoRecordConverterTest/testLargeProtobufferFieldId()#parquet/proto/TestUtils/testData(T[])
parquet/proto/ProtoRecordConverterTest/testDefaults()#parquet/proto/TestUtils/testData(T[])
parquet/proto/ProtoRecordConverterTest/testSimple()#parquet/proto/TestUtils/testData(T[])
parquet/pig/TestParquetLoader/testProjectionPushdown()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetLoader/testProjectionPushdown()#java/lang/Class/getName()
parquet/pig/TestParquetLoader/testProjectionPushdown()#java/lang/Object/Object()
parquet/pig/TestParquetLoader/testTypePersuasion()#java/lang/Boolean/toString()
parquet/pig/TestParquetLoader/testTypePersuasion()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetLoader/testTypePersuasion()#java/util/Properties/setProperty(java.lang.String,java.lang.String)
parquet/pig/TestParquetLoader/testTypePersuasion()#java/io/PrintStream/println(java.lang.String)
parquet/pig/TestParquetLoader/testTypePersuasion()#java/lang/Integer/toString(int)
parquet/pig/TestParquetLoader/testTypePersuasion()#java/lang/Object/Object()
parquet/pig/TestParquetLoader/testTypePersuasion()#java/util/Properties/Properties()
parquet/pig/TestParquetLoader/testTypePersuasion()#java/lang/Class/getName()
parquet/pig/TestParquetLoader/testColumnIndexAccess()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetLoader/testColumnIndexAccess()#java/lang/Class/getName()
parquet/pig/TestParquetLoader/testColumnIndexAccess()#java/lang/Object/Object()
parquet/pig/TestParquetLoader/testReqestedSchemaColumnPruning()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetLoader/testReqestedSchemaColumnPruning()#java/lang/Class/getName()
parquet/pig/TestParquetLoader/testReqestedSchemaColumnPruning()#java/lang/Object/Object()
parquet/pig/TestParquetLoader/testNullPadding()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetLoader/testNullPadding()#java/lang/Class/getName()
parquet/pig/TestParquetLoader/testNullPadding()#java/lang/Object/Object()
parquet/pig/TestParquetLoader/testColumnIndexAccessProjection()#java/util/ArrayList/ArrayList()
parquet/pig/TestParquetLoader/testColumnIndexAccessProjection()#java/lang/Class/getName()
parquet/pig/TestParquetLoader/testColumnIndexAccessProjection()#java/lang/Object/Object()
parquet/pig/TestParquetLoader/testSchema()#parquet/pig/ParquetLoader/pushProjection(parquet.pig.RequiredFieldList)
parquet/pig/TestParquetLoader/testSchema()#parquet/pig/ParquetLoader/ParquetLoader(java.lang.String)
parquet/pig/TestParquetLoader/testSchema()#java/util/Arrays/asList(T[])
parquet/pig/TestParquetLoader/testSchema()#parquet/pig/TupleReadSupport/getPigSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/pig/TestParquetLoader/testSchema()#java/lang/Object/Object()
parquet/pig/TestParquetLoader/testSchema()#parquet/pig/ParquetLoader/setLocation(java.lang.String,parquet.proto.utils.Job)
parquet/pig/TestParquetLoader/testSchema()#parquet/pig/ParquetLoader/getSchema(java.lang.String,parquet.proto.utils.Job)
parquet/hadoop/metadata/ColumnChunkProperties/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set)#parquet/hadoop/metadata/ColumnChunkProperties/ColumnChunkProperties(parquet.hadoop.metadata.CompressionCodecName,parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,java.util.Set)
parquet/hadoop/metadata/ColumnChunkProperties/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set)#parquet/common/internal/Canonicalizer/canonicalize(T)
parquet/hadoop/metadata/ColumnChunkProperties/hashCode()#parquet/common/schema/ColumnPath/hashCode()
parquet/hadoop/metadata/ColumnChunkProperties/hashCode()#java/util/Set/toArray()
parquet/hadoop/metadata/ColumnChunkProperties/hashCode()#java/lang/Enum/hashCode()
parquet/hadoop/metadata/ColumnChunkProperties/hashCode()#java/util/Arrays/hashCode(java.lang.Object[])
parquet/hadoop/metadata/ColumnChunkProperties/equals(java.util.Set,java.util.Set)#java/util/Set/size()
parquet/hadoop/metadata/ColumnChunkProperties/equals(java.util.Set,java.util.Set)#java/util/Set/containsAll(java.util.Collection)
parquet/hadoop/metadata/ColumnChunkProperties/equals(java.lang.Object)#parquet/common/schema/ColumnPath/equals(java.lang.Object)
parquet/hadoop/metadata/ColumnChunkProperties/equals(java.lang.Object)#parquet/hadoop/metadata/ColumnChunkProperties/equals(java.util.Set,java.util.Set)
parquet/hadoop/example/GroupWriteSupport/getSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/example/GroupWriteSupport/setSchema(parquet.schema.MessageType,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/Type/toString()
parquet/hadoop/example/GroupWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/example/GroupWriteSupport/getSchema(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/example/GroupWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/HashMap/HashMap()
parquet/hadoop/example/GroupWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/WriteSupport/WriteContext/WriteContext(parquet.schema.MessageType,java.util.Map)
parquet/hadoop/example/GroupWriteSupport/write(parquet.example.data.Group)#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/hadoop/example/GroupWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/filter2/predicate/ValidTypeMap/FullTypeDescriptor/hashCode()#java/lang/Enum/hashCode()
parquet/filter2/predicate/ValidTypeMap/FullTypeDescriptor/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/hive/HiveBindingFactory/create()#parquet/hive/HiveBindingFactory/create(java.lang.ClassLoader)
parquet/hive/HiveBindingFactory/create()#java/lang/Class/newInstance()
parquet/hive/HiveBindingFactory/create()#parquet/hive/HiveBindingFactory/HiveBindingInstantiationError/HiveBindingInstantiationError(java.lang.String,java.lang.Exception)
parquet/hive/HiveBindingFactory/create()#java/lang/Class/getCanonicalName()
parquet/hive/HiveBindingFactory/create()#java/lang/Class/getClassLoader()
parquet/hive/HiveBindingFactory/trimVersion(java.lang.String)#java/lang/String/trim()
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#java/lang/String/equalsIgnoreCase(java.lang.String)
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#java/lang/Class/getSimpleName()
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#parquet/hive/HiveBindingFactory/UnexpectedHiveVersionProviderError/UnexpectedHiveVersionProviderError(java.lang.String,java.lang.Exception)
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#parquet/Log/debug(java.lang.Object)
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#parquet/hive/HiveBindingFactory/trimVersion(java.lang.String)
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#java/lang/String/startsWith(java.lang.String)
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#parquet/hive/HiveBindingFactory/HiveBindingInstantiationError/HiveBindingInstantiationError(java.lang.String)
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object[])
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#parquet/hive/HiveBindingFactory/createBindingForUnknownVersion()
parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)#java/lang/Class/getMethod(java.lang.String,java.lang.Class<?>[])
parquet/hive/HiveBindingFactory/createBindingForUnknownVersion()#java/lang/Class/forName(java.lang.String)
parquet/hive/HiveBindingFactory/createBindingForUnknownVersion()#java/lang/Class/getDeclaredMethods()
parquet/hive/HiveBindingFactory/createBindingForUnknownVersion()#java/lang/String/equals(java.lang.Object)
parquet/hive/HiveBindingFactory/createBindingForUnknownVersion()#java/lang/reflect/Method/getName()
parquet/hive/HiveBindingFactory/createBindingForUnknownVersion()#parquet/Log/debug(java.lang.Object)
parquet/hive/HiveBindingFactory/create(java.lang.ClassLoader)#java/lang/Class/getSimpleName()
parquet/hive/HiveBindingFactory/create(java.lang.ClassLoader)#parquet/Log/debug(java.lang.Object)
parquet/hive/HiveBindingFactory/create(java.lang.ClassLoader)#java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)
parquet/hive/HiveBindingFactory/create(java.lang.ClassLoader)#parquet/hive/HiveBindingFactory/createInternal(java.lang.Class)
parquet/thrift/ThriftRecordConverter/GroupFieldhandler/end()#parquet/io/api/GroupConverter/end()
parquet/thrift/ThriftRecordConverter/GroupFieldhandler/start()#parquet/io/api/GroupConverter/start()
parquet/thrift/ThriftRecordConverter/GroupFieldhandler/getConverter(int)#parquet/io/api/GroupConverter/getConverter(int)
parquet/pig/summary/FieldSummaryData/setName(java.lang.String)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/pig/summary/FieldSummaryData/setName(java.lang.String)#java/lang/String/equals(java.lang.Object)
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/StringSummaryData/add(java.lang.String)
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/SummaryData/add(java.lang.Object)
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/TupleSummaryData/addTuple(parquet.pig.convert.Schema,parquet.pig.convert.Tuple)
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/BagSummaryData/add(parquet.pig.convert.Schema,parquet.pig.DataBag)
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/NumberSummaryData/add(java.lang.Number)
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/NumberSummaryData/NumberSummaryData()
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/MapSummaryData/add(parquet.pig.convert.Schema,java.util.Map)
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/MapSummaryData/MapSummaryData()
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/StringSummaryData/StringSummaryData()
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/BagSummaryData/BagSummaryData()
parquet/pig/summary/FieldSummaryData/add(parquet.pig.convert.Schema,java.lang.Object)#parquet/pig/summary/TupleSummaryData/TupleSummaryData()
parquet/pig/summary/FieldSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(parquet.pig.summary.SummaryData)
parquet/pig/summary/FieldSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/FieldSummaryData/setName(java.lang.String)
parquet/pig/summary/FieldSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(T,T)
parquet/column/values/bitpacking/FourBitPackingWriter/finish()#parquet/column/values/bitpacking/FourBitPackingWriter/write(int)
parquet/column/values/bitpacking/FourBitPackingWriter/write(int)#java/io/OutputStream/write(int)
parquet/cascading/ParquetValueScheme/setRecordClass(parquet.cascading.JobConf)#parquet/hadoop/thrift/ParquetThriftInputFormat/setThriftClass(parquet.cascading.JobConf,java.lang.Class)
parquet/cascading/ParquetValueScheme/setProjectionPushdown(parquet.cascading.JobConf)#parquet/hadoop/thrift/ThriftReadSupport/setProjectionPushdown(parquet.cascading.JobConf,java.lang.String)
parquet/cascading/ParquetValueScheme/setPredicatePushdown(parquet.cascading.JobConf)#parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)
parquet/cascading/ParquetValueScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/cascading/ParquetValueScheme/setRecordClass(parquet.cascading.JobConf)
parquet/cascading/ParquetValueScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/cascading/ParquetValueScheme/setProjectionPushdown(parquet.cascading.JobConf)
parquet/cascading/ParquetValueScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/cascading/ParquetValueScheme/setPredicatePushdown(parquet.cascading.JobConf)
parquet/cascading/ParquetValueScheme/source(parquet.cascading.FlowProcess,parquet.cascading.SourceCall)#parquet/hadoop/mapred/Container/get()
parquet/cascading/ParquetValueScheme/sink(parquet.cascading.FlowProcess,parquet.cascading.SinkCall)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/io/FilteredRecordReader/read()#parquet/io/RecordReaderImplementation/read()
parquet/io/FilteredRecordReader/read()#parquet/io/FilteredRecordReader/skipToMatch()
parquet/io/FilteredRecordReader/skipToMatch()#parquet/column/ColumnReader/consume()
parquet/io/FilteredRecordReader/skipToMatch()#parquet/io/RecordReaderImplementation/getState(int)
parquet/io/FilteredRecordReader/skipToMatch()#parquet/filter/RecordFilter/isMatch()
parquet/io/FilteredRecordReader/skipToMatch()#parquet/column/ColumnReader/skip()
parquet/io/FilteredRecordReader/skipToMatch()#parquet/column/ColumnReader/getCurrentDefinitionLevel()
parquet/io/FilteredRecordReader/skipToMatch()#parquet/column/ColumnReader/getCurrentRepetitionLevel()
parquet/io/FilteredRecordReader/skipToMatch()#parquet/io/RecordReaderImplementation/State/getNextState(int)
parquet/hadoop/codec/SnappyCodec/createInputStream(java.io.InputStream,parquet.hadoop.codec.Decompressor)#parquet/hadoop/codec/NonBlockedDecompressorStream/NonBlockedDecompressorStream(java.io.InputStream,parquet.hadoop.codec.Decompressor,int)
parquet/hadoop/codec/SnappyCodec/createInputStream(java.io.InputStream)#parquet/hadoop/codec/SnappyCodec/createInputStream(java.io.InputStream,parquet.hadoop.codec.Decompressor)
parquet/hadoop/codec/SnappyCodec/createInputStream(java.io.InputStream)#parquet/hadoop/codec/SnappyCodec/createDecompressor()
parquet/hadoop/codec/SnappyCodec/createCompressor()#parquet/hadoop/codec/SnappyCompressor/SnappyCompressor()
parquet/hadoop/codec/SnappyCodec/createDecompressor()#parquet/hadoop/codec/SnappyDecompressor/SnappyDecompressor()
parquet/hadoop/codec/SnappyCodec/createOutputStream(java.io.OutputStream)#parquet/hadoop/codec/SnappyCodec/createOutputStream(java.io.OutputStream,parquet.hadoop.codec.Compressor)
parquet/hadoop/codec/SnappyCodec/createOutputStream(java.io.OutputStream)#parquet/hadoop/codec/SnappyCodec/createCompressor()
parquet/hadoop/codec/SnappyCodec/createOutputStream(java.io.OutputStream,parquet.hadoop.codec.Compressor)#parquet/hadoop/codec/NonBlockedCompressorStream/NonBlockedCompressorStream(java.io.OutputStream,parquet.hadoop.codec.Compressor,int)
parquet/thrift/ThriftRecordConverter/FieldEnumConverter/addBinary(parquet.io.api.Binary)#java/util/Map/get(java.lang.Object)
parquet/thrift/ThriftRecordConverter/FieldEnumConverter/addBinary(parquet.io.api.Binary)#parquet/thrift/ThriftRecordConverter/FieldEnumConverter/addBinary(parquet/io/api/Binary)/$anonymous1/(java.lang.String)
parquet/hadoop/thrift/ParquetThriftInputFormat/setThriftClass(parquet.cascading.JobConf,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/thrift/ParquetThriftInputFormat/setThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)#java/lang/Class/getName()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRangedNumbersWithSmallVariations()#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRangedNumbersWithSmallVariations()#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRangedNumbersWithSmallVariations()/$anonymous1/()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRangedNumbersWithSmallVariations()#java/util/Random/Random()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/estimatedSize()#java/lang/Math/ceil(double)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testSmallNumberVariation()#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testSmallNumberVariation()/$anonymous1/()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testSmallNumberVariation()#java/util/Random/Random()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testSmallNumberVariation()#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testBigNumbers()#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testBigNumbers()/$anonymous1/()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testBigNumbers()#java/util/Random/Random()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testBigNumbers()#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testSmallNumbersWithSmallVariations()#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testSmallNumbersWithSmallVariations()/$anonymous1/()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testSmallNumbersWithSmallVariations()#java/util/Random/Random()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testSmallNumbersWithSmallVariations()#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/IntFunc/getIntValue()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/estimatedSize()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/RunLengthBitPackingHybridValuesWriter(int,int)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#java/io/PrintStream/println(java.lang.String)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/bytes/BytesInput/size()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/getBytes()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/writeInteger(int)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/writeInteger(int)
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/getBytes()
parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize/testRandomIntegers(parquet.column.values.delta.benchmark.BenchmarkIntegerOutputSize.IntFunc,int)#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/DeltaBinaryPackingValuesWriter(int,int,int)
parquet/scrooge/ParquetScroogeScheme/sinkConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/scrooge/ParquetScroogeScheme/sink(parquet.cascading.FlowProcess,parquet.cascading.SinkCall)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/scrooge/ParquetScroogeScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/ParquetInputFormat/setReadSupportClass(parquet.proto.utils.Job,java.lang.Class)
parquet/scrooge/ParquetScroogeScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/hadoop/thrift/ThriftReadSupport/setRecordConverterClass(parquet.cascading.JobConf,java.lang.Class)
parquet/scrooge/ParquetScroogeScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)#parquet/cascading/ParquetValueScheme/sourceConfInit(parquet.cascading.FlowProcess,parquet.cascading.Tap,parquet.cascading.JobConf)
parquet/thrift/ProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/ProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/ProtocolReadToWrite/readOneList(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/ProtocolReadToWrite/readCollectionElements(parquet.thrift.TProtocol,parquet.thrift.TProtocol,int,byte)
parquet/thrift/ProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,parquet.thrift.TProtocol,byte)#parquet/thrift/ProtocolReadToWrite/readOneList(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/ProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,parquet.thrift.TProtocol,byte)#parquet/thrift/ProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/ProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,parquet.thrift.TProtocol,byte)#parquet/thrift/ProtocolReadToWrite/readOneSet(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/ProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,parquet.thrift.TProtocol,byte)#parquet/thrift/ProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/thrift/ProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/ProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,parquet.thrift.TProtocol,byte)
parquet/thrift/ProtocolReadToWrite/readCollectionElements(parquet.thrift.TProtocol,parquet.thrift.TProtocol,int,byte)#parquet/thrift/ProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,parquet.thrift.TProtocol,byte)
parquet/thrift/ProtocolReadToWrite/readOneSet(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/ProtocolReadToWrite/readCollectionElements(parquet.thrift.TProtocol,parquet.thrift.TProtocol,int,byte)
parquet/thrift/ProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/ProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,parquet.thrift.TProtocol,byte)
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/getSchemaForRead(parquet.schema.MessageType,java.lang.String)
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/thrift/projection/FieldProjectionFilter/FieldProjectionFilter(java.lang.String)
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getConfiguration()
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/thrift/ThriftReadSupport/initThriftClassFromMultipleFiles(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#java/lang/String/isEmpty()
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/thrift/ThriftReadSupport/getProjectedSchema(parquet.thrift.projection.FieldProjectionFilter)
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/thrift/projection/ThriftProjectionException/ThriftProjectionException(java.lang.String)
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getFileSchema()
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getKeyValueMetadata()
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType)
parquet/hadoop/thrift/ThriftReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/getSchemaForRead(parquet.schema.MessageType,parquet.schema.MessageType)
parquet/hadoop/thrift/ThriftReadSupport/initThriftClassFromMultipleFiles(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Class/forName(java.lang.String)
parquet/hadoop/thrift/ThriftReadSupport/initThriftClassFromMultipleFiles(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/Set/size()
parquet/hadoop/thrift/ThriftReadSupport/initThriftClassFromMultipleFiles(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/Iterator/next()
parquet/hadoop/thrift/ThriftReadSupport/initThriftClassFromMultipleFiles(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/Set/iterator()
parquet/hadoop/thrift/ThriftReadSupport/initThriftClassFromMultipleFiles(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/thrift/ThriftMetaData/getThriftClassNames(java.util.Map)
parquet/hadoop/thrift/ThriftReadSupport/initThriftClassFromMultipleFiles(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/hadoop/thrift/ThriftReadSupport/setRecordConverterClass(parquet.cascading.JobConf,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/thrift/ThriftReadSupport/getProjectedSchema(parquet.thrift.projection.FieldProjectionFilter)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter(parquet.thrift.projection.FieldProjectionFilter)
parquet/hadoop/thrift/ThriftReadSupport/getProjectedSchema(parquet.thrift.projection.FieldProjectionFilter)#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/hadoop/thrift/ThriftReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/lang/Class/forName(java.lang.String)
parquet/hadoop/thrift/ThriftReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/lang/reflect/Constructor/newInstance(java.lang.Object[])
parquet/hadoop/thrift/ThriftReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/thrift/ThriftReadSupport/initThriftClass(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/thrift/ThriftReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/lang/Class/getConstructor(java.lang.Class<?>[])
parquet/hadoop/thrift/ThriftReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/thrift/ThriftMetaData/getDescriptor()
parquet/hadoop/thrift/ThriftReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/hadoop/thrift/ThriftReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/hadoop/api/ReadSupport/ReadContext/getRequestedSchema()
parquet/hadoop/thrift/ThriftReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/thrift/ThriftMetaData/fromExtraMetaData(java.util.Map)
parquet/hadoop/thrift/ThriftReadSupport/initThriftClass(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Class/forName(java.lang.String)
parquet/hadoop/thrift/ThriftReadSupport/initThriftClass(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/thrift/ThriftMetaData/fromExtraMetaData(java.util.Map)
parquet/hadoop/thrift/ThriftReadSupport/initThriftClass(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/thrift/ThriftMetaData/getThriftClass()
parquet/hadoop/thrift/ThriftReadSupport/initThriftClass(java.util.Map,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/util/Map/Entry/getValue()
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/util/Set/size()
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/util/Map/Entry/getKey()
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/util/Set/iterator()
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/util/Map/entrySet()
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/util/Iterator/next()
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/util/HashMap/HashMap()
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/api/InitContext/getMergedKeyValueMetaData()#java/util/Map/put(K,V)
parquet/column/values/plain/BooleanPlainValuesReader/getNextOffset()#parquet/column/values/bitpacking/ByteBitPackingValuesReader/getNextOffset()
parquet/column/values/plain/BooleanPlainValuesReader/readBoolean()#parquet/column/values/bitpacking/ByteBitPackingValuesReader/readInteger()
parquet/column/values/plain/BooleanPlainValuesReader/skip()#parquet/column/values/bitpacking/ByteBitPackingValuesReader/readInteger()
parquet/column/values/plain/BooleanPlainValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/plain/BooleanPlainValuesReader/initFromPage(int,byte[],int)#parquet/column/values/bitpacking/ByteBitPackingValuesReader/initFromPage(int,byte[],int)
parquet/bytes/CapacityByteArrayOutputStream/writeTo(java.io.OutputStream)#java/io/OutputStream/write(byte[],int,int)
parquet/bytes/CapacityByteArrayOutputStream/writeTo(java.io.OutputStream)#java/util/List/get(int)
parquet/bytes/CapacityByteArrayOutputStream/getSlabCount()#java/util/List/size()
parquet/bytes/CapacityByteArrayOutputStream/write(int)#parquet/bytes/CapacityByteArrayOutputStream/addSlab(int)
parquet/bytes/CapacityByteArrayOutputStream/setByte(long,byte)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/bytes/CapacityByteArrayOutputStream/setByte(long,byte)#java/util/List/get(int)
parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)#java/lang/Class/getSimpleName()
parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)#java/util/List/size()
parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)#parquet/bytes/CapacityByteArrayOutputStream/getCapacity()
parquet/bytes/CapacityByteArrayOutputStream/memUsageString(java.lang.String)#java/lang/Object/getClass()
parquet/bytes/CapacityByteArrayOutputStream/initSlabs(int)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/bytes/CapacityByteArrayOutputStream/initSlabs(int)#java/util/List/add(E)
parquet/bytes/CapacityByteArrayOutputStream/initSlabs(int)#java/util/List/clear()
parquet/bytes/CapacityByteArrayOutputStream/initSlabs(int)#parquet/Log/debug(java.lang.Object)
parquet/bytes/CapacityByteArrayOutputStream/reset()#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/bytes/CapacityByteArrayOutputStream/reset()#parquet/bytes/CapacityByteArrayOutputStream/initSlabs(int)
parquet/bytes/CapacityByteArrayOutputStream/reset()#java/lang/Math/max(int,int)
parquet/bytes/CapacityByteArrayOutputStream/reset()#java/util/List/size()
parquet/bytes/CapacityByteArrayOutputStream/reset()#parquet/Log/debug(java.lang.Object)
parquet/bytes/CapacityByteArrayOutputStream/reset()#java/util/List/get(int)
parquet/bytes/CapacityByteArrayOutputStream/reset()#java/util/List/subList(int,int)
parquet/bytes/CapacityByteArrayOutputStream/reset()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/bytes/CapacityByteArrayOutputStream/write(byte[],int,int)#java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException()
parquet/bytes/CapacityByteArrayOutputStream/write(byte[],int,int)#parquet/bytes/CapacityByteArrayOutputStream/addSlab(int)
parquet/bytes/CapacityByteArrayOutputStream/write(byte[],int,int)#java/lang/System/arraycopy(java.lang.Object,int,java.lang.Object,int,int)
parquet/bytes/CapacityByteArrayOutputStream/getCurrentIndex()#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/bytes/CapacityByteArrayOutputStream/addSlab(int)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/bytes/CapacityByteArrayOutputStream/addSlab(int)#java/util/List/size()
parquet/bytes/CapacityByteArrayOutputStream/addSlab(int)#java/util/List/set(int,E)
parquet/bytes/CapacityByteArrayOutputStream/addSlab(int)#parquet/Log/debug(java.lang.Object)
parquet/bytes/CapacityByteArrayOutputStream/addSlab(int)#java/util/List/add(E)
parquet/bytes/CapacityByteArrayOutputStream/addSlab(int)#java/util/List/get(int)
parquet/hadoop/util/counters/BenchmarkCounter/getTotalBytes()#parquet/hadoop/util/counters/ICounter/getCount()
parquet/hadoop/util/counters/BenchmarkCounter/getTime()#parquet/hadoop/util/counters/ICounter/getCount()
parquet/hadoop/util/counters/BenchmarkCounter/initCounterFromContext(parquet.hadoop.util.counters.TaskInputOutputContext)#parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader/MapReduceCounterLoader(parquet.hadoop.util.counters.TaskInputOutputContext)
parquet/hadoop/util/counters/BenchmarkCounter/initCounterFromContext(parquet.hadoop.util.counters.TaskInputOutputContext)#parquet/hadoop/util/counters/BenchmarkCounter/loadCounters()
parquet/hadoop/util/counters/BenchmarkCounter/initCounterFromReporter(org.apache.hadoop.hive.ql.io.parquet.read.Reporter,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/util/counters/mapred/MapRedCounterLoader/MapRedCounterLoader(org.apache.hadoop.hive.ql.io.parquet.read.Reporter,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/util/counters/BenchmarkCounter/initCounterFromReporter(org.apache.hadoop.hive.ql.io.parquet.read.Reporter,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/util/counters/BenchmarkCounter/loadCounters()
parquet/hadoop/util/counters/BenchmarkCounter/incrementTotalBytes(long)#parquet/hadoop/util/counters/ICounter/increment(long)
parquet/hadoop/util/counters/BenchmarkCounter/incrementTime(long)#parquet/hadoop/util/counters/ICounter/increment(long)
parquet/hadoop/util/counters/BenchmarkCounter/incrementBytesRead(long)#parquet/hadoop/util/counters/ICounter/increment(long)
parquet/hadoop/util/counters/BenchmarkCounter/loadCounters()#parquet/hadoop/util/counters/BenchmarkCounter/getCounterWhenFlagIsSet(java.lang.String,java.lang.String,java.lang.String)
parquet/hadoop/util/counters/BenchmarkCounter/getCounterWhenFlagIsSet(java.lang.String,java.lang.String,java.lang.String)#parquet/hadoop/util/counters/CounterLoader/getCounterByNameAndFlag(java.lang.String,java.lang.String,java.lang.String)
parquet/hadoop/util/counters/BenchmarkCounter/getBytesRead()#parquet/hadoop/util/counters/ICounter/getCount()
parquet/avro/TestSpecificInputOutputFormat/ElectricCarFilter/bind(java.lang.Iterable)#parquet/filter/UnboundRecordFilter/bind(java.lang.Iterable)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPack()#parquet/column/values/bitpacking/TestByteBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPack()#parquet/column/values/bitpacking/TestByteBitPacking/generateValues(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPack()#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPack()#parquet/column/values/bitpacking/Packer/newBytePacker(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPack()#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/column/values/bitpacking/TestByteBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])#parquet/column/values/bitpacking/BytePacker/pack32Values(int[],int,byte[],int)
parquet/column/values/bitpacking/TestByteBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])#parquet/column/values/bitpacking/BytePacker/getBitWidth()
parquet/column/values/bitpacking/TestByteBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])#parquet/column/values/bitpacking/BytePacker/unpack32Values(byte[],int,int[],int)
parquet/column/values/bitpacking/TestByteBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestByteBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])#parquet/column/values/bitpacking/TestBitPacking/toString(byte[])
parquet/column/values/bitpacking/TestByteBitPacking/generateValues(int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestByteBitPacking/generateValues(int)#java/lang/Math/pow(double,double)
parquet/column/values/bitpacking/TestByteBitPacking/generateValues(int)#java/lang/Math/random()
parquet/column/values/bitpacking/TestByteBitPacking/generateValues(int)#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BitPacking/BitPackingWriter/write(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/TestByteBitPacking/generateValues(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BitPacking/BitPackingReader/read()
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BytePacker/pack32Values(int[],int,byte[],int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/Packer/newBytePacker(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/TestBitPacking/toString(byte[])
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstHandWritten()#java/io/ByteArrayOutputStream/toByteArray()
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/Packer/newIntPacker(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/BytePacker/pack32Values(int[],int,byte[],int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/TestByteBitPacking/generateValues(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#java/lang/Enum/name()
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/Packer/values()
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/Packer/newBytePacker(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#java/io/ByteArrayOutputStream/write(int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/BytePacker/unpack32Values(byte[],int,int[],int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/IntPacker/pack32Values(int[],int,int[],int)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#parquet/column/values/bitpacking/TestBitPacking/toString(byte[])
parquet/column/values/bitpacking/TestByteBitPacking/testPackUnPackAgainstLemire()#java/io/ByteArrayOutputStream/toByteArray()
parquet/hadoop/util/counters/mapred/MapRedCounterLoader/getCounterByNameAndFlag(java.lang.String,java.lang.String,java.lang.String)#parquet/hadoop/util/counters/BenchmarkCounter/NullCounter/NullCounter()
parquet/hadoop/util/counters/mapred/MapRedCounterLoader/getCounterByNameAndFlag(java.lang.String,java.lang.String,java.lang.String)#parquet/hadoop/util/counters/mapred/MapRedCounterAdapter/MapRedCounterAdapter(Counters.Counter)
parquet/schema/TestMessageType/test()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/schema/TestMessageType/test()#parquet/schema/Type/toString()
parquet/schema/TestMessageType/testIDs()#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type[])
parquet/schema/TestMessageType/testIDs()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/schema/TestMessageType/testIDs()#parquet/schema/Type/toString()
parquet/schema/TestMessageType/testIDs()#parquet/schema/GroupType/withId(int)
parquet/schema/TestMessageType/testIDs()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/schema/TestMessageType/testIDs()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/schema/TestMessageType/testIDs()#parquet/schema/PrimitiveType/withId(int)
parquet/schema/TestMessageType/testMergeSchema()#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type[])
parquet/schema/TestMessageType/testMergeSchema()#java/lang/Throwable/getMessage()
parquet/schema/TestMessageType/testMergeSchema()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/schema/TestMessageType/testMergeSchema()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/schema/TestMessageType/testMergeSchema()#parquet/schema/MessageType/union(parquet.schema.MessageType)
parquet/schema/TestMessageType/testNestedTypes()#parquet/schema/MessageType/getType(java.lang.String[])
parquet/schema/TestMessageType/testNestedTypes()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/schema/TestMessageType/testNestedTypes()#parquet/schema/Type/toString()
parquet/schema/TestMessageType/testNestedTypes()#parquet/schema/Type/asPrimitiveType()
parquet/schema/TestMessageType/testNestedTypes()#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/schema/TestMessageType/testNestedTypes()#parquet/schema/MessageType/getMaxDefinitionLevel(java.lang.String[])
parquet/schema/TestMessageType/testNestedTypes()#parquet/schema/MessageType/getMaxRepetitionLevel(java.lang.String[])
parquet/tools/command/ShowSchemaCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/metadata/ParquetMetadata/getFileMetaData()
parquet/tools/command/ShowSchemaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/MetadataUtils/showDetails(parquet.tools.util.PrettyPrintWriter,parquet.hadoop.metadata.ParquetMetadata)
parquet/tools/command/ShowSchemaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/command/ArgsOnlyCommand/execute(parquet.tools.command.CommandLine)
parquet/tools/command/ShowSchemaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/stdoutPrettyPrinter()
parquet/tools/command/ShowSchemaCommand/execute(parquet.tools.command.CommandLine)#parquet/tools/util/PrettyPrintWriter/Builder/build()
parquet/tools/command/ShowSchemaCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/ParquetFileReader/readFooter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path)
parquet/tools/command/ShowSchemaCommand/execute(parquet.tools.command.CommandLine)#java/io/PrintStream/println(java.lang.Object)
parquet/tools/command/ShowSchemaCommand/execute(parquet.tools.command.CommandLine)#parquet/hadoop/metadata/FileMetaData/getSchema()
parquet/column/values/plain/BinaryPlainValuesReader/readBytes()#parquet/io/api/Binary/fromByteArray(byte[],int,int)
parquet/column/values/plain/BinaryPlainValuesReader/readBytes()#parquet/bytes/BytesUtils/readIntLittleEndian(byte[],int)
parquet/column/values/plain/BinaryPlainValuesReader/readBytes()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/BinaryPlainValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/plain/BinaryPlainValuesReader/skip()#parquet/bytes/BytesUtils/readIntLittleEndian(byte[],int)
parquet/column/values/plain/BinaryPlainValuesReader/skip()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/hadoop/InternalParquetRecordReader/checkRead()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType,parquet.schema.MessageType,boolean)
parquet/hadoop/InternalParquetRecordReader/checkRead()#java/io/IOException/IOException(java.lang.String)
parquet/hadoop/InternalParquetRecordReader/checkRead()#parquet/hadoop/util/counters/BenchmarkCounter/incrementTime(long)
parquet/hadoop/InternalParquetRecordReader/checkRead()#parquet/column/page/PageReadStore/getRowCount()
parquet/hadoop/InternalParquetRecordReader/checkRead()#parquet/hadoop/ParquetFileReader/readNextRowGroup()
parquet/hadoop/InternalParquetRecordReader/checkRead()#parquet/Log/debug(java.lang.Object)
parquet/hadoop/InternalParquetRecordReader/checkRead()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer,parquet.filter2.compat.FilterCompat.Filter)
parquet/hadoop/InternalParquetRecordReader/checkRead()#java/lang/System/currentTimeMillis()
parquet/hadoop/InternalParquetRecordReader/checkRead()#parquet/Log/info(java.lang.Object)
parquet/hadoop/InternalParquetRecordReader/contains(parquet.schema.GroupType,java.lang.String[],int)#parquet/schema/Type/asGroupType()
parquet/hadoop/InternalParquetRecordReader/contains(parquet.schema.GroupType,java.lang.String[],int)#parquet/schema/GroupType/containsField(java.lang.String)
parquet/hadoop/InternalParquetRecordReader/contains(parquet.schema.GroupType,java.lang.String[],int)#parquet/hadoop/InternalParquetRecordReader/contains(parquet.schema.GroupType,java.lang.String[],int)
parquet/hadoop/InternalParquetRecordReader/contains(parquet.schema.GroupType,java.lang.String[],int)#parquet/schema/Type/isPrimitive()
parquet/hadoop/InternalParquetRecordReader/contains(parquet.schema.GroupType,java.lang.String[],int)#parquet/schema/GroupType/getType(java.lang.String)
parquet/hadoop/InternalParquetRecordReader/nextKeyValue()#parquet/hadoop/InternalParquetRecordReader/checkRead()
parquet/hadoop/InternalParquetRecordReader/nextKeyValue()#parquet/io/RecordReader/shouldSkipCurrentRecord()
parquet/hadoop/InternalParquetRecordReader/nextKeyValue()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/hadoop/InternalParquetRecordReader/nextKeyValue()#parquet/Log/debug(java.lang.Object)
parquet/hadoop/InternalParquetRecordReader/nextKeyValue()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/hadoop/InternalParquetRecordReader/nextKeyValue()#parquet/io/RecordReader/read()
parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/metadata/BlockMetaData/getRowCount()
parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/MessageType/getColumns()
parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetFileReader/ParquetFileReader(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,java.util.List,java.util.List)
parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType,java.util.Map)
parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/List/size()
parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/ReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)
parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/MessageType/getPaths()
parquet/hadoop/InternalParquetRecordReader/initialize(parquet.schema.MessageType,parquet.schema.MessageType,java.util.Map,java.util.Map,parquet.hadoop.Path,java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/Log/info(java.lang.Object)
parquet/hadoop/InternalParquetRecordReader/close()#parquet/hadoop/ParquetFileReader/close()
parquet/filter2/predicate/Operators/LtEq/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.LtEq)
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#java/util/Collections/emptyMap()
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/io/BufferedReader/close()
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/io/File/File(java.lang.String)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/lang/String/indexOf(java.lang.String)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/lang/String/substring(int)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/io/FileReader/FileReader(java.io.File)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/io/File/File(java.lang.String,java.lang.String)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/io/BufferedReader/BufferedReader(java.io.Reader)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/io/BufferedReader/readLine()
parquet/hadoop/example/TestInputOutputFormat/testProjection()#parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite()#parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/example/TestInputOutputFormat/testReadWriteWithCounter()#parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/example/TestInputOutputFormat/testReadWriteWithCounter()#parquet/hadoop/example/TestInputOutputFormat/value(parquet.proto.utils.Job,java.lang.String,java.lang.String)
parquet/hadoop/example/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#java/lang/Thread/sleep(long)
parquet/hadoop/example/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/example/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/hadoop/example/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)#parquet/Log/info(java.lang.Object)
parquet/hadoop/example/TestInputOutputFormat/value(parquet.proto.utils.Job,java.lang.String,java.lang.String)#java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object[])
parquet/hadoop/example/TestInputOutputFormat/value(parquet.proto.utils.Job,java.lang.String,java.lang.String)#java/lang/Class/getMethod(java.lang.String,java.lang.Class<?>[])
parquet/hadoop/example/TestInputOutputFormat/testReadWriteTaskSideMD()#parquet/hadoop/example/TestInputOutputFormat/testReadWriteTaskSideMD()/$anonymous1/()
parquet/hadoop/example/TestInputOutputFormat/testReadWriteTaskSideMD()#parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#parquet/hadoop/example/GroupWriteSupport/setSchema(parquet.schema.MessageType,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#parquet/hadoop/ParquetInputFormat/setReadSupportClass(parquet.proto.utils.Job,java.lang.Class)
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/util/Map/Entry/getValue()
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#parquet/hadoop/example/TestInputOutputFormat/waitForJob(parquet.proto.utils.Job)
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/util/Map/Entry/getKey()
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#parquet/hadoop/ParquetOutputFormat/setWriteSupportClass(parquet.proto.utils.Job,java.lang.Class)
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#parquet/hadoop/ParquetOutputFormat/setCompression(parquet.proto.utils.Job,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/util/Map/entrySet()
parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)#java/lang/Object/Object()
parquet/hadoop/example/TestInputOutputFormat/testReadWriteWithoutCounter()#parquet/hadoop/example/TestInputOutputFormat/runMapReduceJob(parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/example/TestInputOutputFormat/testReadWriteWithoutCounter()#parquet/hadoop/example/TestInputOutputFormat/value(parquet.proto.utils.Job,java.lang.String,java.lang.String)
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName)#java/util/Collections/emptyMap()
parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/example/TestInputOutputFormat/testReadWrite(parquet.hadoop.metadata.CompressionCodecName,java.util.Map)
parquet/pig/convert/MapConverter/end()#java/util/HashMap/HashMap(java.util.Map)
parquet/pig/convert/MapConverter/end()#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/MapConverter/start()#java/util/Map/clear()
parquet/pig/convert/MapConverter/getConverter(int)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/filter2/recordlevel/PhoneBookWriter/User/equals(java.lang.Object)#parquet/filter2/recordlevel/PhoneBookWriter/Location/equals(java.lang.Object)
parquet/filter2/recordlevel/PhoneBookWriter/User/equals(java.lang.Object)#java/lang/String/equals(java.lang.Object)
parquet/filter2/recordlevel/PhoneBookWriter/User/equals(java.lang.Object)#java/util/List/equals(java.lang.Object)
parquet/filter2/recordlevel/PhoneBookWriter/User/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/filter2/recordlevel/PhoneBookWriter/User/hashCode()#parquet/filter2/recordlevel/PhoneBookWriter/Location/hashCode()
parquet/filter2/recordlevel/PhoneBookWriter/User/hashCode()#java/lang/String/hashCode()
parquet/filter2/recordlevel/PhoneBookWriter/User/hashCode()#java/util/List/hashCode()
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/deserializeAndSerializeLazySimple(org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/getObjectInspector()
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/deserializeAndSerializeLazySimple(org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/getSerDeStats()
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/deserializeAndSerializeLazySimple(org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/serialize(java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.serde.ObjectInspector)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/deserializeAndSerializeLazySimple(org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/arrayWritableEquals(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/deserializeAndSerializeLazySimple(org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#java/lang/Object/getClass()
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/deserializeAndSerializeLazySimple(org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/deserialize(org.apache.hadoop.hive.ql.io.parquet.Writable)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/arrayWritableEquals(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)#org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/arrayWritableEquals(org.apache.hadoop.hive.ql.io.parquet.ArrayWritable,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#java/lang/Throwable/printStackTrace()
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/ParquetHiveSerDe()
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#java/io/PrintStream/println(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/deserializeAndSerializeLazySimple(org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.ql.io.parquet.ArrayWritable)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe/initialize(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Properties)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable/BinaryWritable(parquet.io.api.Binary)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#parquet/io/api/Binary/fromString(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/createProperties()
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/testParquetHiveSerDe()#java/lang/Object/Object()
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/createProperties()#java/util/Properties/setProperty(java.lang.String,java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe/createProperties()#java/util/Properties/Properties()
parquet/filter2/compat/RowGroupFilter/visit(parquet.filter2.compat.FilterCompat.FilterPredicateCompat)#java/util/ArrayList/ArrayList()
parquet/filter2/compat/RowGroupFilter/visit(parquet.filter2.compat.FilterCompat.FilterPredicateCompat)#parquet/hadoop/metadata/BlockMetaData/getColumns()
parquet/filter2/compat/RowGroupFilter/visit(parquet.filter2.compat.FilterCompat.FilterPredicateCompat)#parquet/filter2/compat/FilterCompat/FilterPredicateCompat/getFilterPredicate()
parquet/filter2/compat/RowGroupFilter/visit(parquet.filter2.compat.FilterCompat.FilterPredicateCompat)#parquet/filter2/statisticslevel/StatisticsFilter/canDrop(parquet.filter2.predicate.FilterPredicate,java.util.List)
parquet/filter2/compat/RowGroupFilter/visit(parquet.filter2.compat.FilterCompat.FilterPredicateCompat)#parquet/filter2/predicate/SchemaCompatibilityValidator/validate(parquet.filter2.predicate.FilterPredicate,parquet.schema.MessageType)
parquet/filter2/compat/RowGroupFilter/visit(parquet.filter2.compat.FilterCompat.FilterPredicateCompat)#java/util/List/add(E)
parquet/filter2/compat/RowGroupFilter/filterRowGroups(parquet.filter2.compat.FilterCompat.Filter,java.util.List,parquet.schema.MessageType)#parquet/filter2/compat/RowGroupFilter/RowGroupFilter(java.util.List,parquet.schema.MessageType)
parquet/filter2/compat/RowGroupFilter/filterRowGroups(parquet.filter2.compat.FilterCompat.Filter,java.util.List,parquet.schema.MessageType)#parquet/filter2/compat/FilterCompat/Filter/accept(parquet.filter2.compat.FilterCompat.Visitor)
parquet/filter2/compat/RowGroupFilter/filterRowGroups(parquet.filter2.compat.FilterCompat.Filter,java.util.List,parquet.schema.MessageType)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/hadoop/util/ConfigurationUtil/getClassFromConfig(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String,java.lang.Class)#java/lang/Class/isAssignableFrom(java.lang.Class)
parquet/hadoop/util/ConfigurationUtil/getClassFromConfig(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String,java.lang.Class)#java/lang/Class/getCanonicalName()
parquet/hadoop/util/ConfigurationUtil/getClassFromConfig(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String,java.lang.Class)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String)
parquet/hadoop/util/ConfigurationUtil/getClassFromConfig(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String,java.lang.Class)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/avro/TestSpecificInputOutputFormat/nextRecord(int)#java/lang/String/getBytes()
parquet/avro/TestSpecificInputOutputFormat/waitForJob(parquet.proto.utils.Job)#java/lang/Thread/sleep(long)
parquet/avro/TestSpecificInputOutputFormat/waitForJob(parquet.proto.utils.Job)#parquet/Log/debug(java.lang.Object)
parquet/avro/TestSpecificInputOutputFormat/waitForJob(parquet.proto.utils.Job)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/avro/TestSpecificInputOutputFormat/waitForJob(parquet.proto.utils.Job)#parquet/Log/info(java.lang.Object)
parquet/avro/TestSpecificInputOutputFormat/createParquetFile()#parquet/avro/AvroParquetOutputFormat/setSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)
parquet/avro/TestSpecificInputOutputFormat/createParquetFile()#parquet/avro/TestSpecificInputOutputFormat/waitForJob(parquet.proto.utils.Job)
parquet/avro/TestSpecificInputOutputFormat/createParquetFile()#java/lang/Object/Object()
parquet/avro/TestSpecificInputOutputFormat/testReadWrite()#parquet/avro/AvroParquetInputFormat/setRequestedProjection(parquet.proto.utils.Job,parquet.pig.convert.Schema)
parquet/avro/TestSpecificInputOutputFormat/testReadWrite()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestSpecificInputOutputFormat/testReadWrite()#parquet/avro/TestSpecificInputOutputFormat/waitForJob(parquet.proto.utils.Job)
parquet/avro/TestSpecificInputOutputFormat/testReadWrite()#java/lang/String/equals(java.lang.Object)
parquet/avro/TestSpecificInputOutputFormat/testReadWrite()#parquet/hadoop/ParquetInputFormat/setUnboundRecordFilter(parquet.proto.utils.Job,java.lang.Class)
parquet/avro/TestSpecificInputOutputFormat/testReadWrite()#java/lang/Object/Object()
parquet/avro/TestSpecificInputOutputFormat/testReadWrite()#parquet/avro/AvroParquetOutputFormat/setSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)
parquet/avro/TestSpecificInputOutputFormat/testReadWrite()#parquet/avro/TestSpecificInputOutputFormat/nextRecord(int)
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#parquet/avro/AvroParquetInputFormat/setRequestedProjection(parquet.proto.utils.Job,parquet.pig.convert.Schema)
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#parquet/avro/AvroParquetReader/AvroParquetReader(parquet.hadoop.Path)
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#parquet/avro/TestSpecificInputOutputFormat/waitForJob(parquet.proto.utils.Job)
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#java/lang/String/equals(java.lang.Object)
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#parquet/hadoop/ParquetInputFormat/setUnboundRecordFilter(parquet.proto.utils.Job,java.lang.Class)
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#parquet/avro/AvroParquetInputFormat/setAvroReadSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#java/lang/Object/Object()
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#parquet/avro/AvroParquetOutputFormat/setSchema(parquet.proto.utils.Job,parquet.pig.convert.Schema)
parquet/avro/TestSpecificInputOutputFormat/testReadWriteChangedCar()#parquet/avro/TestSpecificInputOutputFormat/nextRecord(int)
parquet/Closeables/closeAndSwallowIOExceptions(java.io.Closeable)#parquet/Log/warn(java.lang.Object,java.lang.Throwable)
parquet/Closeables/closeAndSwallowIOExceptions(java.io.Closeable)#java/io/Closeable/close()
parquet/Closeables/close(java.io.Closeable)#java/io/Closeable/close()
parquet/pig/summary/StringSummaryData/add(java.lang.String)#parquet/pig/summary/EnumStat/add(java.lang.String)
parquet/pig/summary/StringSummaryData/add(java.lang.String)#parquet/pig/summary/SummaryData/add(java.lang.Object)
parquet/pig/summary/StringSummaryData/add(java.lang.String)#java/lang/String/length()
parquet/pig/summary/StringSummaryData/add(java.lang.String)#parquet/pig/summary/ValueStat/add(double)
parquet/pig/summary/StringSummaryData/setValues(java.util.Collection)#parquet/pig/summary/EnumStat/setValues(java.util.Collection)
parquet/pig/summary/StringSummaryData/getValues()#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/pig/summary/StringSummaryData/getValues()#java/util/Collections/sort(java.util.List,java.util.Comparator)
parquet/pig/summary/StringSummaryData/getValues()#parquet/pig/summary/StringSummaryData/getValues()/$anonymous1/()
parquet/pig/summary/StringSummaryData/getValues()#parquet/pig/summary/EnumStat/getValues()
parquet/pig/summary/StringSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/EnumStat/merge(parquet.pig.summary.EnumStat)
parquet/pig/summary/StringSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/SummaryData/merge(parquet.pig.summary.SummaryData)
parquet/pig/summary/StringSummaryData/merge(parquet.pig.summary.SummaryData)#parquet/pig/summary/ValueStat/merge(parquet.pig.summary.ValueStat)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/writeLongAction(java.util.List,long)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/struct/ThriftTypeID/getSerializedThriftType()
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/writeDoubleAction(java.util.List,double)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/writeBoolAction(java.util.List,boolean)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/writeByteAction(java.util.List,byte)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/typeName(byte)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/struct/ThriftType/getType()
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/writeStringAction(java.util.List,java.nio.ByteBuffer)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/readOneList(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.ListType)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/readOneSet(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.SetType)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.MapType)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/writeIntAction(java.util.List,int)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/writeShortAction(java.util.List,short)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/DecodingSchemaMismatchException/DecodingSchemaMismatchException(java.lang.String)
parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/checkEnum(parquet.thrift.struct.ThriftType,int)
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/ProtocolReadToWrite/ProtocolReadToWrite()
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/ProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,parquet.thrift.TProtocol,byte)
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet/thrift/TProtocol,java/util/List,parquet/thrift/struct/ThriftType/StructType)/$anonymous2/()
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet/thrift/TProtocol,java/util/List,parquet/thrift/struct/ThriftType/StructType)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/BufferedProtocolReadToWrite/notifyIgnoredFieldsOfRecord(parquet.thrift.TField)
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftType/StructType/getChildById(short)
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/BufferedProtocolReadToWrite/NullProtocol/NullProtocol()
parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/BufferedProtocolReadToWrite/writeLongAction(java.util.List,long)#parquet/thrift/BufferedProtocolReadToWrite/writeLongAction(java/util/List,long)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/writeLongAction(java.util.List,long)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/writeStringAction(java.util.List,java.nio.ByteBuffer)#parquet/thrift/BufferedProtocolReadToWrite/writeStringAction(java/util/List,java/nio/ByteBuffer)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/writeStringAction(java.util.List,java.nio.ByteBuffer)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/notifyRecordHasFieldIgnored()#parquet/thrift/FieldIgnoredHandler/handleRecordHasFieldIgnored()
parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/BufferedProtocolReadToWrite/readOneStruct(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.StructType)
parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/BufferedProtocolReadToWrite/Action/write(parquet.thrift.TProtocol)
parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/SkippableException/SkippableException(java.lang.String,java.lang.Throwable)
parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/BufferedProtocolReadToWrite/notifyRecordHasFieldIgnored()
parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#java/util/LinkedList/LinkedList()
parquet/thrift/BufferedProtocolReadToWrite/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)#parquet/thrift/BufferedProtocolReadToWrite/error(java.lang.String,java.util.List)
parquet/thrift/BufferedProtocolReadToWrite/writeBoolAction(java.util.List,boolean)#parquet/thrift/BufferedProtocolReadToWrite/writeBoolAction(java/util/List,boolean)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/writeBoolAction(java.util.List,boolean)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/writeByteAction(java.util.List,byte)#parquet/thrift/BufferedProtocolReadToWrite/writeByteAction(java/util/List,byte)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/writeByteAction(java.util.List,byte)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/typeName(byte)#java/lang/Enum/name()
parquet/thrift/BufferedProtocolReadToWrite/typeName(byte)#parquet/thrift/struct/ThriftTypeID/fromByte(byte)
parquet/thrift/BufferedProtocolReadToWrite/typeName(byte)#java/lang/String/valueOf(int)
parquet/thrift/BufferedProtocolReadToWrite/readOneList(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/BufferedProtocolReadToWrite/readOneList(parquet/thrift/TProtocol,java/util/List,parquet/thrift/struct/ThriftType/ListType)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/readOneList(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.ListType)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/readOneList(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/BufferedProtocolReadToWrite/readCollectionElements(parquet.thrift.TProtocol,int,byte,java.util.List,parquet.thrift.struct.ThriftType)
parquet/thrift/BufferedProtocolReadToWrite/readOneList(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/struct/ThriftType/ListType/getValues()
parquet/thrift/BufferedProtocolReadToWrite/readOneList(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.ListType)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/BufferedProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)
parquet/thrift/BufferedProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/BufferedProtocolReadToWrite/readOneMap(parquet/thrift/TProtocol,java/util/List,parquet/thrift/struct/ThriftType/MapType)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftType/MapType/getValue()
parquet/thrift/BufferedProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.MapType)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftType/MapType/getKey()
parquet/thrift/BufferedProtocolReadToWrite/readOneMap(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.MapType)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/BufferedProtocolReadToWrite/readOneSet(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/struct/ThriftType/SetType/getValues()
parquet/thrift/BufferedProtocolReadToWrite/readOneSet(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/BufferedProtocolReadToWrite/readOneSet(parquet/thrift/TProtocol,java/util/List,parquet/thrift/struct/ThriftType/SetType)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/readOneSet(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.SetType)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/readOneSet(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/BufferedProtocolReadToWrite/readCollectionElements(parquet.thrift.TProtocol,int,byte,java.util.List,parquet.thrift.struct.ThriftType)
parquet/thrift/BufferedProtocolReadToWrite/readOneSet(parquet.thrift.TProtocol,java.util.List,parquet.thrift.struct.ThriftType.SetType)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/BufferedProtocolReadToWrite/error(java.lang.String,java.util.List)#java/lang/StringBuilder/append(java.lang.String)
parquet/thrift/BufferedProtocolReadToWrite/error(java.lang.String,java.util.List)#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/thrift/BufferedProtocolReadToWrite/error(java.lang.String,java.util.List)#java/lang/StringBuilder/toString()
parquet/thrift/BufferedProtocolReadToWrite/error(java.lang.String,java.util.List)#parquet/thrift/BufferedProtocolReadToWrite/Action/toDebugString()
parquet/thrift/BufferedProtocolReadToWrite/notifyIgnoredFieldsOfRecord(parquet.thrift.TField)#parquet/thrift/FieldIgnoredHandler/handleFieldIgnored(parquet.thrift.TField)
parquet/thrift/BufferedProtocolReadToWrite/writeIntAction(java.util.List,int)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/writeIntAction(java.util.List,int)#parquet/thrift/BufferedProtocolReadToWrite/writeIntAction(java/util/List,int)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/writeShortAction(java.util.List,short)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/writeShortAction(java.util.List,short)#parquet/thrift/BufferedProtocolReadToWrite/writeShortAction(java/util/List,short)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/readCollectionElements(parquet.thrift.TProtocol,int,byte,java.util.List,parquet.thrift.struct.ThriftType)#parquet/thrift/BufferedProtocolReadToWrite/readOneValue(parquet.thrift.TProtocol,byte,java.util.List,parquet.thrift.struct.ThriftType)
parquet/thrift/BufferedProtocolReadToWrite/writeDoubleAction(java.util.List,double)#java/util/List/add(E)
parquet/thrift/BufferedProtocolReadToWrite/writeDoubleAction(java.util.List,double)#parquet/thrift/BufferedProtocolReadToWrite/writeDoubleAction(java/util/List,double)/$anonymous1/()
parquet/thrift/BufferedProtocolReadToWrite/checkEnum(parquet.thrift.struct.ThriftType,int)#parquet/thrift/struct/ThriftType/getType()
parquet/thrift/BufferedProtocolReadToWrite/checkEnum(parquet.thrift.struct.ThriftType,int)#parquet/thrift/struct/ThriftType/EnumType/getEnumValueById(int)
parquet/thrift/BufferedProtocolReadToWrite/checkEnum(parquet.thrift.struct.ThriftType,int)#parquet/thrift/DecodingSchemaMismatchException/DecodingSchemaMismatchException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getRecordWriter(parquet.hadoop.example.FileSystem,parquet.cascading.JobConf,java.lang.String,parquet.hadoop.mapred.Progressable)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)#java/util/ArrayList/ArrayList()
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)#java/lang/String/split(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)#java/lang/String/length()
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)#java/util/Arrays/asList(T[])
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)#org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getParquerRecordWriterWrapper(parquet.hadoop.ParquetOutputFormat,parquet.cascading.JobConf,java.lang.String,parquet.hadoop.mapred.Progressable)
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)#org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport/setSchema(parquet.schema.MessageType,org.apache.hadoop.hive.ql.io.parquet.Configuration)
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)#org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter/convert(java.util.List,java.util.List)
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getHiveRecordWriter(parquet.cascading.JobConf,parquet.hadoop.Path,java.lang.Class,boolean,java.util.Properties,parquet.hadoop.mapred.Progressable)#java/util/Properties/getProperty(java.lang.String)
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getParquerRecordWriterWrapper(parquet.hadoop.ParquetOutputFormat,parquet.cascading.JobConf,java.lang.String,parquet.hadoop.mapred.Progressable)#org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper/ParquetRecordWriterWrapper(parquet.hive.OutputFormat,parquet.cascading.JobConf,java.lang.String,parquet.hadoop.mapred.Progressable)
org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat/getParquerRecordWriterWrapper(parquet.hadoop.ParquetOutputFormat,parquet.cascading.JobConf,java.lang.String,parquet.hadoop.mapred.Progressable)#java/lang/String/toString()
parquet/filter2/predicate/FilterApi/binaryColumn(java.lang.String)#parquet/filter2/predicate/Operators/BinaryColumn/BinaryColumn(parquet.common.schema.ColumnPath)
parquet/filter2/predicate/FilterApi/binaryColumn(java.lang.String)#parquet/common/schema/ColumnPath/fromDotString(java.lang.String)
parquet/filter2/predicate/FilterApi/lt(C,T)#parquet/filter2/predicate/Operators/Lt/Lt(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/FilterApi/intColumn(java.lang.String)#parquet/common/schema/ColumnPath/fromDotString(java.lang.String)
parquet/filter2/predicate/FilterApi/intColumn(java.lang.String)#parquet/filter2/predicate/Operators/IntColumn/IntColumn(parquet.common.schema.ColumnPath)
parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)#parquet/filter2/predicate/Operators/Or/Or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/FilterApi/doubleColumn(java.lang.String)#parquet/filter2/predicate/Operators/DoubleColumn/DoubleColumn(parquet.common.schema.ColumnPath)
parquet/filter2/predicate/FilterApi/doubleColumn(java.lang.String)#parquet/common/schema/ColumnPath/fromDotString(java.lang.String)
parquet/filter2/predicate/FilterApi/not(parquet.filter2.predicate.FilterPredicate)#parquet/filter2/predicate/Operators/Not/Not(parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/FilterApi/floatColumn(java.lang.String)#parquet/filter2/predicate/Operators/FloatColumn/FloatColumn(parquet.common.schema.ColumnPath)
parquet/filter2/predicate/FilterApi/floatColumn(java.lang.String)#parquet/common/schema/ColumnPath/fromDotString(java.lang.String)
parquet/filter2/predicate/FilterApi/notEq(C,T)#parquet/filter2/predicate/Operators/NotEq/NotEq(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/FilterApi/ltEq(C,T)#parquet/filter2/predicate/Operators/LtEq/LtEq(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/FilterApi/longColumn(java.lang.String)#parquet/filter2/predicate/Operators/LongColumn/LongColumn(parquet.common.schema.ColumnPath)
parquet/filter2/predicate/FilterApi/longColumn(java.lang.String)#parquet/common/schema/ColumnPath/fromDotString(java.lang.String)
parquet/filter2/predicate/FilterApi/gt(C,T)#parquet/filter2/predicate/Operators/Gt/Gt(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/FilterApi/eq(C,T)#parquet/filter2/predicate/Operators/Eq/Eq(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)#parquet/filter2/predicate/Operators/And/And(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/filter2/predicate/FilterApi/booleanColumn(java.lang.String)#parquet/filter2/predicate/Operators/BooleanColumn/BooleanColumn(parquet.common.schema.ColumnPath)
parquet/filter2/predicate/FilterApi/booleanColumn(java.lang.String)#parquet/common/schema/ColumnPath/fromDotString(java.lang.String)
parquet/filter2/predicate/FilterApi/gtEq(C,T)#parquet/filter2/predicate/Operators/GtEq/GtEq(parquet.filter2.predicate.Operators.Column,T)
parquet/filter2/predicate/FilterApi/userDefined(parquet.filter2.predicate.Operators.Column,java.lang.Class)#parquet/filter2/predicate/Operators/UserDefined/UserDefined(parquet.filter2.predicate.Operators.Column,java.lang.Class)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#parquet/column/values/bitpacking/Packer/newIntPacker(int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#parquet/column/values/bitpacking/TestLemireBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#parquet/column/values/bitpacking/TestLemireBitPacking/generateValues(int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#parquet/column/values/bitpacking/TestLemireBitPacking/packUnpack(parquet.column.values.bitpacking.IntPacker,int[],int[])
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#java/lang/Enum/name()
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#parquet/column/values/bitpacking/Packer/values()
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#parquet/column/values/bitpacking/Packer/newBytePacker(int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPack()#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/column/values/bitpacking/TestLemireBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])#parquet/column/values/bitpacking/BytePacker/pack32Values(int[],int,byte[],int)
parquet/column/values/bitpacking/TestLemireBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])#parquet/column/values/bitpacking/BytePacker/getBitWidth()
parquet/column/values/bitpacking/TestLemireBitPacking/packUnpack(parquet.column.values.bitpacking.BytePacker,int[],int[])#parquet/column/values/bitpacking/BytePacker/unpack32Values(byte[],int,int[],int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/Packer/newIntPacker(int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BitPacking/createBitPackingReader(int,java.io.InputStream,long)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BitPacking/BitPackingWriter/write(int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/TestLemireBitPacking/generateValues(int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BitPacking/BitPackingReader/read()
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#java/io/ByteArrayOutputStream/write(int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/IntPacker/pack32Values(int[],int,int[],int)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#parquet/column/values/bitpacking/TestBitPacking/toString(byte[])
parquet/column/values/bitpacking/TestLemireBitPacking/testPackUnPackAgainstHandWritten()#java/io/ByteArrayOutputStream/toByteArray()
parquet/column/values/bitpacking/TestLemireBitPacking/packUnpack(parquet.column.values.bitpacking.IntPacker,int[],int[])#parquet/column/values/bitpacking/IntPacker/getBitWidth()
parquet/column/values/bitpacking/TestLemireBitPacking/packUnpack(parquet.column.values.bitpacking.IntPacker,int[],int[])#parquet/column/values/bitpacking/IntPacker/pack32Values(int[],int,int[],int)
parquet/column/values/bitpacking/TestLemireBitPacking/packUnpack(parquet.column.values.bitpacking.IntPacker,int[],int[])#parquet/column/values/bitpacking/IntPacker/unpack32Values(int[],int,int[],int)
parquet/column/values/bitpacking/TestLemireBitPacking/generateValues(int)#parquet/Log/debug(java.lang.Object)
parquet/column/values/bitpacking/TestLemireBitPacking/generateValues(int)#java/lang/Math/pow(double,double)
parquet/column/values/bitpacking/TestLemireBitPacking/generateValues(int)#java/lang/Math/random()
parquet/column/values/bitpacking/TestLemireBitPacking/generateValues(int)#parquet/column/values/bitpacking/TestBitPacking/toString(int[])
parquet/hadoop/thrift/ThriftBytesWriteSupport/write(parquet.hadoop.thrift.BytesWritable)#parquet/hadoop/thrift/ThriftBytesWriteSupport/protocol(parquet.hadoop.thrift.BytesWritable)
parquet/hadoop/thrift/ThriftBytesWriteSupport/write(parquet.hadoop.thrift.BytesWritable)#parquet/thrift/ProtocolPipe/readOne(parquet.thrift.TProtocol,parquet.thrift.TProtocol)
parquet/hadoop/thrift/ThriftBytesWriteSupport/write(parquet.hadoop.thrift.BytesWritable)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/hadoop/thrift/ThriftBytesWriteSupport/protocol(parquet.hadoop.thrift.BytesWritable)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/hadoop/thrift/ThriftBytesWriteSupport/setTProtocolClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/thrift/ThriftWriteSupport/setThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/thrift/ThriftWriteSupport/getThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/thrift/BufferedProtocolReadToWrite/BufferedProtocolReadToWrite(parquet.thrift.struct.ThriftType.StructType,parquet.thrift.FieldIgnoredHandler)
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/thrift/ThriftWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/thrift/ThriftBytesWriteSupport/getTProtocolFactoryClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/thrift/ThriftSchemaConverter/toStructType(java.lang.Class)
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/thrift/ThriftSchemaConverter/convert(java.lang.Class)
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/thrift/ProtocolReadToWrite/ProtocolReadToWrite()
parquet/hadoop/thrift/ThriftBytesWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/thrift/ThriftSchemaConverter/ThriftSchemaConverter()
parquet/hadoop/thrift/ThriftBytesWriteSupport/getTProtocolFactoryClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Class/forName(java.lang.String)
parquet/hadoop/thrift/ThriftBytesWriteSupport/getTProtocolFactoryClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String)
parquet/hadoop/thrift/ThriftBytesWriteSupport/getTProtocolFactoryClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/hadoop/thrift/ThriftBytesWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/hadoop/thrift/ThriftBytesWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/hadoop/thrift/ThriftWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)
parquet/hadoop/thrift/ThriftBytesWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/hadoop/thrift/ThriftBytesWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)#parquet/thrift/ParquetWriteProtocol/ParquetWriteProtocol(parquet.io.api.RecordConsumer,parquet.io.MessageColumnIO,parquet.thrift.struct.ThriftType.StructType)
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/schema/PrimitiveType/PrimitiveTypeName/values()
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/ParquetMetadataConverter()
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.format.converter.Encoding)
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/schema/OriginalType/values()
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/toParquetRepetition(parquet.schema.Type.Repetition)
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/getPrimitive(parquet.format.converter.Type)
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/getConvertedType(parquet.schema.OriginalType)
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/fromParquetRepetition(parquet.format.converter.FieldRepetitionType)
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/getOriginalType(parquet.format.converter.ConvertedType)
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/getEncoding(parquet.column.Encoding)
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/column/Encoding/values()
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/schema/Type/Repetition/values()
parquet/format/converter/TestParquetMetadataConverter/testEnumEquivalence()#parquet/format/converter/ParquetMetadataConverter/getType(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/format/converter/TestParquetMetadataConverter/testFilterMetaData()#parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)
parquet/format/converter/TestParquetMetadataConverter/testFilterMetaData()#parquet/format/converter/TestParquetMetadataConverter/metadata(long[])
parquet/format/converter/TestParquetMetadataConverter/testFilterMetaData()#parquet/format/converter/TestParquetMetadataConverter/filter(parquet.format.converter.FileMetaData,long,long)
parquet/format/converter/TestParquetMetadataConverter/testFilterMetaData()#parquet/format/converter/TestParquetMetadataConverter/verifyMD(parquet.format.converter.FileMetaData,long[])
parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)#parquet/format/converter/TestParquetMetadataConverter/fileSize(parquet.format.converter.FileMetaData)
parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)#java/util/Set/size()
parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)#parquet/format/converter/TestParquetMetadataConverter/filter(parquet.format.converter.FileMetaData,long,long)
parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)#java/util/Set/add(E)
parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)#java/util/Set/contains(java.lang.Object)
parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)#parquet/format/converter/ParquetMetadataConverter/getOffset(parquet.format.converter.RowGroup)
parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)#java/util/TreeSet/TreeSet()
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/format/converter/ParquetMetadataConverter/toParquetSchema(parquet.schema.MessageType)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/schema/Types/PrimitiveBuilder/scale(int)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/format/converter/ParquetMetadataConverter/ParquetMetadataConverter()
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/schema/Types/PrimitiveBuilder/length(int)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/schema/Types/PrimitiveBuilder/precision(int)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/schema/Types/Builder/named(java.lang.String)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/schema/Types/GroupBuilder/required(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/schema/Types/GroupBuilder/optional(parquet.schema.PrimitiveType.PrimitiveTypeName)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/schema/Types/Builder/as(parquet.schema.OriginalType)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverterDecimal()#parquet/schema/Types/buildMessage()
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverter()#parquet/format/converter/ParquetMetadataConverter/toParquetSchema(parquet.schema.MessageType)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverter()#parquet/format/converter/ParquetMetadataConverter/fromParquetSchema(java.util.List)
parquet/format/converter/TestParquetMetadataConverter/testSchemaConverter()#parquet/format/converter/ParquetMetadataConverter/ParquetMetadataConverter()
parquet/format/converter/TestParquetMetadataConverter/testPageHeader()#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
parquet/format/converter/TestParquetMetadataConverter/testPageHeader()#java/io/ByteArrayOutputStream/toByteArray()
parquet/format/converter/TestParquetMetadataConverter/testPageHeader()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/format/converter/TestParquetMetadataConverter/testPageHeader()#java/lang/Object/Object()
parquet/format/converter/TestParquetMetadataConverter/metadata(long[])#java/util/ArrayList/ArrayList()
parquet/format/converter/TestParquetMetadataConverter/metadata(long[])#java/util/Collections/emptyList()
parquet/format/converter/TestParquetMetadataConverter/metadata(long[])#java/util/Arrays/asList(T[])
parquet/format/converter/TestParquetMetadataConverter/metadata(long[])#java/lang/Object/Object()
parquet/format/converter/TestParquetMetadataConverter/filter(parquet.format.converter.FileMetaData,long,long)#parquet/format/converter/ParquetMetadataConverter/RangeMetadataFilter/RangeMetadataFilter(long,long)
parquet/format/converter/TestParquetMetadataConverter/filter(parquet.format.converter.FileMetaData,long,long)#parquet/format/converter/ParquetMetadataConverter/filterFileMetaData(parquet.format.converter.FileMetaData,parquet.format.converter.ParquetMetadataConverter.RangeMetadataFilter)
parquet/format/converter/TestParquetMetadataConverter/filter(parquet.format.converter.FileMetaData,long,long)#java/lang/Object/Object()
parquet/format/converter/TestParquetMetadataConverter/randomTestFilterMetaData()#java/util/Random/nextInt(int)
parquet/format/converter/TestParquetMetadataConverter/randomTestFilterMetaData()#parquet/format/converter/TestParquetMetadataConverter/verifyAllFilters(parquet.format.converter.FileMetaData,long)
parquet/format/converter/TestParquetMetadataConverter/randomTestFilterMetaData()#java/util/Random/Random(long)
parquet/format/converter/TestParquetMetadataConverter/randomTestFilterMetaData()#java/lang/AssertionError/AssertionError(java.lang.String,java.lang.Throwable)
parquet/format/converter/TestParquetMetadataConverter/randomTestFilterMetaData()#java/lang/System/currentTimeMillis()
parquet/format/converter/TestParquetMetadataConverter/randomTestFilterMetaData()#parquet/format/converter/TestParquetMetadataConverter/metadata(long[])
parquet/format/converter/TestParquetMetadataConverter/randomTestFilterMetaData()#java/util/Arrays/toString(long[])
parquet/format/converter/TestParquetMetadataConverter/verifyMD(parquet.format.converter.FileMetaData,long[])#parquet/format/converter/ParquetMetadataConverter/getOffset(parquet.format.converter.RowGroup)
parquet/io/api/Converter/asGroupConverter()#java/lang/Class/getName()
parquet/io/api/Converter/asGroupConverter()#java/lang/ClassCastException/ClassCastException(java.lang.String)
parquet/io/api/Converter/asGroupConverter()#java/lang/Object/getClass()
parquet/io/api/Converter/asPrimitiveConverter()#java/lang/Class/getName()
parquet/io/api/Converter/asPrimitiveConverter()#java/lang/ClassCastException/ClassCastException(java.lang.String)
parquet/io/api/Converter/asPrimitiveConverter()#java/lang/Object/getClass()
parquet/bytes/BytesInput/IntBytesInput/writeAllTo(java.io.OutputStream)#parquet/bytes/BytesUtils/writeIntLittleEndian(java.io.OutputStream,int)
parquet/proto/ProtoWriteSupport/StringWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/proto/ProtoWriteSupport/StringWriter/writeRawValue(java.lang.Object)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/schema/Type/ID/toString()#java/lang/String/valueOf(int)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/copy(parquet.bytes.BytesInput)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/size()
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/Log/debug(java.lang.Object)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#java/util/List/add(E)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/column/page/Page/Page(parquet.bytes.BytesInput,int,int,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/copy(parquet.bytes.BytesInput)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/bytes/BytesInput/size()
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/Log/debug(java.lang.Object)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#java/util/List/add(E)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/column/page/Page/Page(parquet.bytes.BytesInput,int,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)
parquet/column/page/mem/MemPageWriter/writePage(parquet.bytes.BytesInput,int,parquet.column.statistics.Statistics,parquet.column.Encoding,parquet.column.Encoding,parquet.column.Encoding)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/column/page/mem/MemPageWriter/memUsageString(java.lang.String)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/page/mem/MemPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/bytes/BytesInput/size()
parquet/column/page/mem/MemPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/Log/debug(java.lang.Object)
parquet/column/page/mem/MemPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String)
parquet/column/page/mem/MemPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getDictionarySize()
parquet/column/page/mem/MemPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/getBytes()
parquet/column/page/mem/MemPageWriter/writeDictionaryPage(parquet.column.page.DictionaryPage)#parquet/column/page/DictionaryPage/copy()
parquet/pig/convert/TupleConverter/FieldIntegerConverter/addFloat(float)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldIntegerConverter/addBinary(parquet.io.api.Binary)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldIntegerConverter/addBinary(parquet.io.api.Binary)#java/lang/Integer/parseInt(java.lang.String)
parquet/pig/convert/TupleConverter/FieldIntegerConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/pig/convert/TupleConverter/FieldIntegerConverter/addInt(int)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldIntegerConverter/addDouble(double)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldIntegerConverter/addLong(long)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldIntegerConverter/addBoolean(boolean)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#parquet/column/values/bitpacking/BitPacking/BitPackingWriter/finish()
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#parquet/column/values/bitpacking/BitPackingPerfTest/manual(byte[],int[])
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#java/io/PrintStream/println(int)
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#java/io/PrintStream/println()
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#parquet/column/values/bitpacking/BitPacking/BitPackingWriter/write(int)
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#parquet/column/values/bitpacking/BitPacking/getBitPackingWriter(int,java.io.OutputStream)
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#java/io/ByteArrayOutputStream/toByteArray()
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#java/lang/System/currentTimeMillis()
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#parquet/column/values/bitpacking/BitPackingPerfTest/generated(byte[],int[])
parquet/column/values/bitpacking/BitPackingPerfTest/main(java.lang.String[])#java/io/PrintStream/println(java.lang.String)
parquet/column/values/bitpacking/BitPackingPerfTest/manual(byte[],int[])#parquet/column/values/bitpacking/BitPackingValuesReader/BitPackingValuesReader(int)
parquet/column/values/bitpacking/BitPackingPerfTest/manual(byte[],int[])#parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)
parquet/column/values/bitpacking/BitPackingPerfTest/generated(byte[],int[])#parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)
parquet/column/values/bitpacking/BitPackingPerfTest/generated(byte[],int[])#parquet/column/values/bitpacking/ByteBitPackingValuesReader/ByteBitPackingValuesReader(int,parquet.column.values.bitpacking.Packer)
parquet/column/values/bitpacking/BitPackingPerfTest/verify(int[])#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#java/io/PrintStream/print(java.lang.String)
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#parquet/column/values/ValuesReader/readInteger()
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#java/io/PrintStream/println(java.lang.String)
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#java/lang/System/nanoTime()
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#java/io/PrintStream/println()
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#parquet/column/values/bitpacking/BitPackingPerfTest/verify(int[])
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#java/lang/Object/getClass()
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#java/lang/Class/getSimpleName()
parquet/column/values/bitpacking/BitPackingPerfTest/readNTimes(byte[],int[],parquet.column.values.ValuesReader)#java/lang/System/gc()
parquet/pig/PerfTest2/main(java.lang.String[])#java/lang/StringBuilder/append(java.lang.String)
parquet/pig/PerfTest2/main(java.lang.String[])#java/io/File/exists()
parquet/pig/PerfTest2/main(java.lang.String[])#java/io/File/File(java.lang.String)
parquet/pig/PerfTest2/main(java.lang.String[])#java/lang/StringBuilder/StringBuilder()
parquet/pig/PerfTest2/main(java.lang.String[])#parquet/pig/PerfTest2/clean(java.io.File)
parquet/pig/PerfTest2/main(java.lang.String[])#java/io/PrintStream/println(java.lang.Object)
parquet/pig/PerfTest2/main(java.lang.String[])#parquet/pig/PerfTest2/write(java.lang.String)
parquet/pig/PerfTest2/main(java.lang.String[])#parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)
parquet/pig/PerfTest2/clean(java.io.File)#java/io/File/isDirectory()
parquet/pig/PerfTest2/clean(java.io.File)#parquet/pig/PerfTest2/clean(java.io.File)
parquet/pig/PerfTest2/clean(java.io.File)#java/io/File/listFiles()
parquet/pig/PerfTest2/clean(java.io.File)#java/io/File/delete()
parquet/pig/PerfTest2/write(java.lang.String)#parquet/pig/ParquetStorer/ParquetStorer()
parquet/pig/PerfTest2/write(java.lang.String)#java/lang/StringBuilder/append(java.lang.String)
parquet/pig/PerfTest2/write(java.lang.String)#java/io/File/getAbsoluteFile()
parquet/pig/PerfTest2/write(java.lang.String)#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/pig/PerfTest2/write(java.lang.String)#java/io/File/toURI()
parquet/pig/PerfTest2/write(java.lang.String)#java/lang/Object/Object()
parquet/pig/PerfTest2/write(java.lang.String)#java/lang/StringBuilder/toString()
parquet/pig/PerfTest2/write(java.lang.String)#parquet/hadoop/util/ContextUtil/newJobContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.JobID)
parquet/pig/PerfTest2/write(java.lang.String)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/pig/PerfTest2/write(java.lang.String)#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/pig/PerfTest2/write(java.lang.String)#java/io/File/File(java.lang.String)
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#parquet/pig/ParquetLoader/ParquetLoader(java.lang.String)
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/lang/StringBuilder/append(java.lang.String)
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/io/File/getAbsoluteFile()
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/io/File/toURI()
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/io/PrintStream/println(char[])
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/lang/System/currentTimeMillis()
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/lang/Object/Object()
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/lang/StringBuilder/toString()
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#parquet/hadoop/util/ContextUtil/newJobContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.JobID)
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/pig/PerfTest2/load(java.lang.String,int,java.lang.StringBuilder)#java/io/File/File(java.lang.String)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/writeData(int[],int)#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadMaxMinValue()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndReadWhenDeltasAreSame()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/randomDataTest()#java/util/Random/nextInt()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/randomDataTest()#java/util/Random/nextInt(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/randomDataTest()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/randomDataTest()#parquet/column/values/ValuesWriter/reset()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndReadWhenAMiniBlockIsNotFullyWritten()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndReadWhenAMiniBlockIsNotFullyWritten()#java/util/Random/nextInt()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReturnCorrectOffsetAfterInitialization()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/getNextOffset()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReturnCorrectOffsetAfterInitialization()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/writeData(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReturnCorrectOffsetAfterInitialization()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/DeltaBinaryPackingValuesReader()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReturnCorrectOffsetAfterInitialization()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/readInteger()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReturnCorrectOffsetAfterInitialization()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReturnCorrectOffsetAfterInitialization()#java/lang/System/arraycopy(java.lang.Object,int,java.lang.Object,int,int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReturnCorrectOffsetAfterInitialization()#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReturnCorrectOffsetAfterInitialization()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/writeData(int[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)#java/lang/Math/ceil(double)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)#parquet/column/values/delta/DeltaBinaryPackingValuesReader/DeltaBinaryPackingValuesReader()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)#parquet/column/values/delta/DeltaBinaryPackingValuesReader/readInteger()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)#parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadAndWrite(int[],int)#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldThrowExceptionWhenReadMoreThanWritten()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldThrowExceptionWhenReadMoreThanWritten()#java/lang/Throwable/getMessage()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldThrowExceptionWhenReadMoreThanWritten()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/readInteger()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteWhenDeltaIs0ForEachBlock()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldSkip()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/writeData(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldSkip()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/DeltaBinaryPackingValuesReader()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldSkip()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/readInteger()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldSkip()#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldSkip()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldSkip()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/skip()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldSkip()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/initFromPage(int,byte[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadWriteWhenDataIsNotAlignedWithBlock()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadWriteWhenDataIsNotAlignedWithBlock()#java/util/Random/nextInt(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReset()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReadWriteWhenDataIsNotAlignedWithBlock()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReset()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldReset()#parquet/column/values/ValuesWriter/reset()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/writeData(int[])#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/writeData(int[],int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteNegativeDeltas()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteNegativeDeltas()#java/util/Random/nextInt(int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/setUp()#java/util/Random/Random()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/setUp()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/DeltaBinaryPackingValuesWriter(int,int,int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteWhenDataIsAlignedWithBlock()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteWhenDataIsAlignedWithBlock()#java/util/Random/nextInt()
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndReadWhenValuesAreSame()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/miniBlockSizeShouldBeMultipleOf8()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/DeltaBinaryPackingValuesWriter(int,int,int)
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndReadWhenBlockIsNotFullyWritten()#parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndRead(int[])
parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest/shouldWriteAndReadWhenBlockIsNotFullyWritten()#java/util/Random/nextInt()
parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()#parquet/thrift/ParquetWriteProtocol/Events/end()
parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()#parquet/thrift/ParquetWriteProtocol/Events/start()
parquet/hadoop/ParquetOutputFormat/getCompression(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/codec/CodecConfig/getParquetCompressionCodec(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetOutputFormat/isCompressionSet(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetOutputFormat/isCompressionSet(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/isCompressionSet(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getCompression(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getCompression(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetOutputFormat/getCompression(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/api/WriteSupport/WriteContext/getSchema()
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetRecordWriter/ParquetRecordWriter(parquet.hadoop.ParquetFileWriter,parquet.hadoop.api.WriteSupport,parquet.schema.MessageType,java.util.Map,int,int,parquet.hadoop.CodecFactory.BytesCompressor,int,boolean,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetOutputFormat/getWriteSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetOutputFormat/getDictionaryPageSize(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetOutputFormat/getBlockSize(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/Log/info(java.lang.Object)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/CodecFactory/getCompressor(parquet.hadoop.metadata.CompressionCodecName,int)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetOutputFormat/getPageSize(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetFileWriter/start()
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetOutputFormat/getWriterVersion(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetFileWriter/ParquetFileWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.schema.MessageType,parquet.hadoop.Path)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/CodecFactory/CodecFactory(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetOutputFormat/getEnableDictionary(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/ParquetOutputFormat/getValidation(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/api/WriteSupport/WriteContext/getExtraMetaData()
parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/api/WriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetOutputFormat/setDictionaryPageSize(parquet.proto.utils.Job,int)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getDictionaryPageSize(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getDictionaryPageSize(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetOutputFormat/getDictionaryPageSize(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getBlockSize(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getBlockSize(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetOutputFormat/getBlockSize(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(parquet.pig.TaskAttemptContext,parquet.hadoop.Path)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(parquet.pig.TaskAttemptContext,parquet.hadoop.Path)#parquet/hadoop/ParquetOutputFormat/getCodec(parquet.pig.TaskAttemptContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(parquet.pig.TaskAttemptContext,parquet.hadoop.Path)#parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/ParquetOutputFormat/setWriteSupportClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/setWriteSupportClass(parquet.proto.utils.Job,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/ParquetOutputFormat/getOutputCommitter(parquet.pig.TaskAttemptContext)#parquet/hadoop/ParquetOutputCommitter/ParquetOutputCommitter(parquet.hadoop.Path,parquet.pig.TaskAttemptContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(parquet.pig.TaskAttemptContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(parquet.pig.TaskAttemptContext)#parquet/hadoop/metadata/CompressionCodecName/getExtension()
parquet/hadoop/ParquetOutputFormat/getRecordWriter(parquet.pig.TaskAttemptContext)#parquet/hadoop/ParquetOutputFormat/getCodec(parquet.pig.TaskAttemptContext)
parquet/hadoop/ParquetOutputFormat/getRecordWriter(parquet.pig.TaskAttemptContext)#parquet/hadoop/ParquetOutputFormat/getRecordWriter(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.Path,parquet.hadoop.metadata.CompressionCodecName)
parquet/hadoop/ParquetOutputFormat/getWriterVersion(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Enum/toString()
parquet/hadoop/ParquetOutputFormat/getWriterVersion(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/column/ParquetProperties/WriterVersion/fromString(java.lang.String)
parquet/hadoop/ParquetOutputFormat/getWriteSupportClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/util/ConfigurationUtil/getClassFromConfig(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String,java.lang.Class)
parquet/hadoop/ParquetOutputFormat/setEnableDictionary(parquet.proto.utils.Job,boolean)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getEnableDictionary(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getEnableDictionary(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetOutputFormat/getEnableDictionary(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getValidation(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getValidation(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetOutputFormat/getValidation(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/setPageSize(parquet.proto.utils.Job,int)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/setBlockSize(parquet.proto.utils.Job,int)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getCodec(parquet.pig.TaskAttemptContext)#parquet/hadoop/codec/CodecConfig/from(parquet.cascading.JobConf)
parquet/hadoop/ParquetOutputFormat/setWriteSupportClass(parquet.cascading.JobConf,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/ParquetOutputFormat/getWriteSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetOutputFormat/getWriteSupportClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetOutputFormat/getWriteSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Class/newInstance()
parquet/hadoop/ParquetOutputFormat/getWriteSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/hadoop/ParquetOutputFormat/getWriteSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/hadoop/ParquetOutputFormat/isCompressionSet(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/codec/CodecConfig/isParquetCompressionSet(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetOutputFormat/setValidation(parquet.hadoop.util.JobContext,boolean)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/setValidation(parquet.hadoop.util.JobContext,boolean)#parquet/hadoop/ParquetOutputFormat/setValidation(parquet.hadoop.util.JobContext,boolean)
parquet/hadoop/ParquetOutputFormat/setCompression(parquet.proto.utils.Job,parquet.hadoop.metadata.CompressionCodecName)#java/lang/Enum/name()
parquet/hadoop/ParquetOutputFormat/setCompression(parquet.proto.utils.Job,parquet.hadoop.metadata.CompressionCodecName)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getPageSize(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetOutputFormat/getPageSize(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetOutputFormat/getPageSize(parquet.hadoop.util.JobContext)
parquet/proto/ProtoWriteSupport/DoubleWriter/writeRawValue(java.lang.Object)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/tools/read/SimpleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/InitContext/getFileSchema()
parquet/tools/read/SimpleReadSupport/init(parquet.hadoop.api.InitContext)#parquet/hadoop/api/ReadSupport/ReadContext/ReadContext(parquet.schema.MessageType)
parquet/tools/read/SimpleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)#parquet/tools/read/SimpleRecordMaterializer/SimpleRecordMaterializer(parquet.schema.MessageType)
parquet/example/data/simple/Int96Value/toString()#java/lang/String/valueOf(java.lang.Object)
parquet/example/data/simple/Int96Value/writeValue(parquet.io.api.RecordConsumer)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/column/values/bitpacking/SixBitPackingReader/read()#java/io/InputStream/read()
parquet/column/values/bitpacking/SixBitPackingReader/read()#parquet/column/values/bitpacking/BaseBitPackingReader/alignToBytes(int)
parquet/column/values/plain/PlainValuesReader/initFromPage(int,byte[],int)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[],int,int)
parquet/column/values/plain/PlainValuesReader/initFromPage(int,byte[],int)#parquet/bytes/LittleEndianDataInputStream/LittleEndianDataInputStream(java.io.InputStream)
parquet/column/values/plain/PlainValuesReader/initFromPage(int,byte[],int)#parquet/Log/debug(java.lang.Object)
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testTwiceDeclaredColumn()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testTwiceDeclaredColumn()#java/lang/Throwable/getMessage()
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testTwiceDeclaredColumn()#parquet/filter2/predicate/SchemaCompatibilityValidator/validate(parquet.filter2.predicate.FilterPredicate,parquet.schema.MessageType)
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testTwiceDeclaredColumn()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testFindsInvalidTypes()#java/lang/Throwable/getMessage()
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testFindsInvalidTypes()#parquet/filter2/predicate/SchemaCompatibilityValidator/validate(parquet.filter2.predicate.FilterPredicate,parquet.schema.MessageType)
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testValidType()#parquet/filter2/predicate/SchemaCompatibilityValidator/validate(parquet.filter2.predicate.FilterPredicate,parquet.schema.MessageType)
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testRepeatedNotSupported()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testRepeatedNotSupported()#java/lang/Throwable/getMessage()
parquet/filter2/predicate/TestSchemaCompatibilityValidator/testRepeatedNotSupported()#parquet/filter2/predicate/SchemaCompatibilityValidator/validate(parquet.filter2.predicate.FilterPredicate,parquet.schema.MessageType)
parquet/hadoop/thrift/ParquetThriftBytesOutputFormat/setThriftClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/thrift/ThriftWriteSupport/setThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)
parquet/hadoop/thrift/ParquetThriftBytesOutputFormat/setThriftClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/thrift/ParquetThriftBytesOutputFormat/getThriftClass(parquet.proto.utils.Job)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/thrift/ParquetThriftBytesOutputFormat/getThriftClass(parquet.proto.utils.Job)#parquet/hadoop/thrift/ThriftWriteSupport/getThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/thrift/ParquetThriftBytesOutputFormat/setTProtocolClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/thrift/ThriftBytesWriteSupport/setTProtocolClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)
parquet/hadoop/thrift/ParquetThriftBytesOutputFormat/setTProtocolClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/readInteger()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.Throwable)
parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/readInteger()#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/readInt()
parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/initFromPage(int,byte[],int)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[],int,int)
parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/initFromPage(int,byte[],int)#parquet/column/values/rle/RunLengthBitPackingHybridDecoder/RunLengthBitPackingHybridDecoder(int,java.io.ByteArrayInputStream)
parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/initFromPage(int,byte[],int)#parquet/bytes/BytesUtils/readIntLittleEndian(java.io.InputStream)
parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/skip()#parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/readInteger()
parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/readBoolean()#parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/readInteger()
parquet/io/TestFiltered/StringEndsWithAPredicate/functionToApply(java.lang.String)#java/lang/String/endsWith(java.lang.String)
parquet/filter/ColumnRecordFilter/isMatch()#parquet/filter/ColumnPredicates/Predicate/apply(parquet.column.ColumnReader)
parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)#parquet/filter/ColumnRecordFilter/column(java/lang/String,parquet/filter/ColumnPredicates/Predicate)/$anonymous1/()
parquet/filter/ColumnRecordFilter/column(java.lang.String,parquet.filter.ColumnPredicates.Predicate)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/copy(parquet.io.api.Binary)#parquet/io/api/Binary/length()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/copy(parquet.io.api.Binary)#parquet/io/api/Binary/fromByteArray(byte[])
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/copy(parquet.io.api.Binary)#java/util/Arrays/copyOf(byte[],int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/copy(parquet.io.api.Binary)#parquet/io/api/Binary/getBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/hasNext()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/IntIterator/next()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/IntList/iterator()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/fallBackDictionaryEncodedData()#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/getDictionarySize()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/copy(parquet.io.api.Binary)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/dictionary/IntList/add(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/io/api/Binary/length()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/ValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/writeBytes(parquet.io.api.Binary)#parquet/column/values/dictionary/DictionaryValuesWriter/checkAndFallbackIfNeeded()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/PlainValuesWriter(int)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/ValuesWriter/createDictionaryPage()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/createDictionaryPage()#parquet/column/page/DictionaryPage/DictionaryPage(parquet.bytes.BytesInput,int,parquet.column.Encoding)
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/createDictionaryPage()#java/util/Iterator/next()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/getBytes()
parquet/column/values/dictionary/DictionaryValuesWriter/PlainBinaryDictionaryValuesWriter/createDictionaryPage()#parquet/column/values/plain/PlainValuesWriter/writeBytes(parquet.io.api.Binary)
parquet/proto/ProtoMessageConverter/ProtoFloatConverter/addFloat(float)#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetShortInspector/getPrimitiveWritableObject(java.lang.Object)#org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetShortInspector/get(java.lang.Object)
parquet/pig/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/HashMap/HashMap()
parquet/pig/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/pig/PigMetaData/addToMetaData(java.util.Map)
parquet/pig/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/WriteSupport/WriteContext/WriteContext(parquet.schema.MessageType,java.util.Map)
parquet/pig/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/pig/PigMetaData/PigMetaData(parquet.pig.convert.Schema)
parquet/pig/TupleWriteSupport/fromPigSchema(java.lang.String)#parquet/pig/TupleWriteSupport/TupleWriteSupport(parquet.pig.convert.Schema)
parquet/pig/TupleWriteSupport/write(parquet.pig.convert.Tuple)#parquet/io/api/RecordConsumer/startMessage()
parquet/pig/TupleWriteSupport/write(parquet.pig.convert.Tuple)#parquet/io/api/RecordConsumer/endMessage()
parquet/pig/TupleWriteSupport/write(parquet.pig.convert.Tuple)#parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)
parquet/pig/TupleWriteSupport/write(parquet.pig.convert.Tuple)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/schema/GroupType/getFields()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/schema/Type/asGroupType()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/io/api/RecordConsumer/endGroup()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/Map/Entry/getValue()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/Map/Entry/getKey()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/schema/Type/isPrimitive()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/List/get(int)
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/schema/Type/getName()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/io/api/RecordConsumer/startGroup()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/Map/entrySet()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/lang/Object/Object()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/List/size()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/Map/size()
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#java/util/Arrays/asList(T[])
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)#parquet/schema/GroupType/getType(int)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#java/lang/Number/doubleValue()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/schema/Type/asPrimitiveType()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/pig/TupleWriteSupport/writeTuple(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.convert.Tuple)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/Binary/fromByteArray(byte[])
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#java/lang/String/getBytes(java.lang.String)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/schema/Type/isPrimitive()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/RecordConsumer/startGroup()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/schema/Type/asGroupType()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#java/lang/Enum/name()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#java/lang/Number/floatValue()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/RecordConsumer/endGroup()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#java/lang/Number/intValue()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/RecordConsumer/addFloat(float)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/RecordConsumer/addLong(long)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/RecordConsumer/addBoolean(boolean)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#java/lang/Number/longValue()
parquet/pig/TupleWriteSupport/writeValue(parquet.schema.Type,parquet.pig.convert.FieldSchema,parquet.pig.convert.Tuple,int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.String,java.lang.Throwable)
parquet/io/TestColumnIO/testSchema()#parquet/schema/Type/toString()
parquet/io/TestColumnIO/testRequiredOfRequired()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/io/TestColumnIO/testRequiredOfRequired()#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/io/TestColumnIO/testRequiredOfRequired()#java/util/Arrays/asList(T[])
parquet/io/TestColumnIO/testRequiredOfRequired()#parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)
parquet/io/TestColumnIO/testRequiredOfRequired()#parquet/example/data/Group/addGroup(java.lang.String)
parquet/io/TestColumnIO/testRequiredOfRequired()#parquet/example/data/GroupFactory/newGroup()
parquet/io/TestColumnIO/testRequiredOfRequired()#parquet/example/data/Group/append(java.lang.String,long)
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/simple/NanoTime/NanoTime(int,long)
parquet/io/TestColumnIO/testOneOfEach()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/Group/append(java.lang.String,float)
parquet/io/TestColumnIO/testOneOfEach()#java/lang/System/currentTimeMillis()
parquet/io/TestColumnIO/testOneOfEach()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/Group/append(java.lang.String,parquet.example.data.simple.NanoTime)
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/Group/append(java.lang.String,int)
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/Group/append(java.lang.String,double)
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/Group/append(java.lang.String,boolean)
parquet/io/TestColumnIO/testOneOfEach()#parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/Group/append(java.lang.String,parquet.io.api.Binary)
parquet/io/TestColumnIO/testOneOfEach()#java/util/Arrays/asList(T[])
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/GroupFactory/newGroup()
parquet/io/TestColumnIO/testOneOfEach()#parquet/example/data/Group/append(java.lang.String,long)
parquet/io/TestColumnIO/data()#java/util/Arrays/asList(T[])
parquet/io/TestColumnIO/testPushParser()#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/io/TestColumnIO/testPushParser()#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/io/TestColumnIO/testPushParser()#parquet/io/TestColumnIO/newColumnWriteStore(parquet.column.page.mem.MemPageStore)
parquet/io/TestColumnIO/testPushParser()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestColumnIO/testPushParser()#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer)
parquet/io/TestColumnIO/testPushParser()#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/io/TestColumnIO/testPushParser()#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/io/TestColumnIO/testPushParser()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestColumnIO/testPushParser()#parquet/io/RecordReader/read()
parquet/io/TestColumnIO/testPushParser()#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/TestColumnIO/testPushParser()#parquet/io/ExpectationValidatingConverter/ExpectationValidatingConverter(java.lang.String[],parquet.schema.MessageType)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#java/util/ArrayList/ArrayList()
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/example/data/Group/append(java.lang.String,int)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#java/util/List/addAll(java.util.Collection)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/example/data/simple/SimpleGroupFactory/newGroup()
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/io/TestColumnIO/validateGroups(java.util.List,java.lang.Object[][])
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithExtraFields()#parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])
parquet/io/TestColumnIO/log(java.lang.Object)#parquet/Log/info(java.lang.Object)
parquet/io/TestColumnIO/testColumnIO()#parquet/example/data/simple/SimpleGroup/toString()
parquet/io/TestColumnIO/testColumnIO()#java/util/ArrayList/ArrayList()
parquet/io/TestColumnIO/testColumnIO()#java/lang/Object/toString()
parquet/io/TestColumnIO/testColumnIO()#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/io/TestColumnIO/testColumnIO()#parquet/io/TestColumnIO/newColumnWriteStore(parquet.column.page.mem.MemPageStore)
parquet/io/TestColumnIO/testColumnIO()#parquet/io/RecordReaderImplementation/read()
parquet/io/TestColumnIO/testColumnIO()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestColumnIO/testColumnIO()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestColumnIO/testColumnIO()#parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)
parquet/io/TestColumnIO/testColumnIO()#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/io/TestColumnIO/testColumnIO()#java/util/List/add(E)
parquet/io/TestColumnIO/testColumnIO()#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/TestColumnIO/testColumnIO()#parquet/io/TestColumnIO/getRecordReader(parquet.io.MessageColumnIO,parquet.schema.MessageType,parquet.column.page.PageReadStore)
parquet/io/TestColumnIO/testColumnIO()#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/io/TestColumnIO/testColumnIO()#java/util/List/get(int)
parquet/io/TestColumnIO/testColumnIO()#parquet/io/TestColumnIO/log(java.lang.Object)
parquet/io/TestColumnIO/testColumnIO()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)#java/util/ArrayList/ArrayList()
parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)#parquet/io/RecordReaderImplementation/read()
parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)#java/util/List/add(E)
parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType,parquet.schema.MessageType)
parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)#parquet/io/TestColumnIO/getRecordReader(parquet.io.MessageColumnIO,parquet.schema.MessageType,parquet.column.page.PageReadStore)
parquet/io/TestColumnIO/getRecordReader(parquet.io.MessageColumnIO,parquet.schema.MessageType,parquet.column.page.PageReadStore)#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestColumnIO/getRecordReader(parquet.io.MessageColumnIO,parquet.schema.MessageType,parquet.column.page.PageReadStore)#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer)
parquet/io/TestColumnIO/testGroupWriter()#parquet/example/data/simple/SimpleGroup/toString()
parquet/io/TestColumnIO/testGroupWriter()#java/util/ArrayList/ArrayList()
parquet/io/TestColumnIO/testGroupWriter()#java/lang/Object/toString()
parquet/io/TestColumnIO/testGroupWriter()#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/io/TestColumnIO/testGroupWriter()#parquet/io/RecordConsumerLoggingWrapper/RecordConsumerLoggingWrapper(parquet.io.api.RecordConsumer)
parquet/io/TestColumnIO/testGroupWriter()#parquet/example/data/simple/convert/GroupRecordConverter/getRootConverter()
parquet/io/TestColumnIO/testGroupWriter()#parquet/example/data/simple/convert/GroupRecordConverter/GroupRecordConverter(parquet.schema.MessageType)
parquet/io/TestColumnIO/testGroupWriter()#java/util/List/add(E)
parquet/io/TestColumnIO/testGroupWriter()#java/util/List/get(int)
parquet/io/TestColumnIO/testGroupWriter()#parquet/io/ConverterConsumer/ConverterConsumer(parquet.io.api.GroupConverter,parquet.schema.MessageType)
parquet/io/TestColumnIO/testGroupWriter()#parquet/example/data/simple/convert/GroupRecordConverter/getCurrentRecord()
parquet/io/TestColumnIO/testGroupWriter()#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/TestColumnIO/validateGroups(java.util.List,java.lang.Object[][])#java/util/Iterator/next()
parquet/io/TestColumnIO/validateGroups(java.util.List,java.lang.Object[][])#parquet/example/data/GroupValueSource/getInteger(int,int)
parquet/io/TestColumnIO/validateGroups(java.util.List,java.lang.Object[][])#java/util/List/iterator()
parquet/io/TestColumnIO/validateGroups(java.util.List,java.lang.Object[][])#parquet/example/data/GroupValueSource/getFieldRepetitionCount(int)
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#java/util/ArrayList/ArrayList()
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/example/data/Group/append(java.lang.String,int)
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#java/util/List/addAll(java.util.Collection)
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/example/data/simple/SimpleGroupFactory/newGroup()
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/io/TestColumnIO/validateGroups(java.util.List,java.lang.Object[][])
parquet/io/TestColumnIO/testReadUsingProjectedSchema()#parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#java/lang/Object/toString()
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/io/TestColumnIO/newColumnWriteStore(parquet.column.page.mem.MemPageStore)
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/io/RecordReaderImplementation/read()
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#java/util/List/size()
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/io/TestColumnIO/getRecordReader(parquet.io.MessageColumnIO,parquet.schema.MessageType,parquet.column.page.PageReadStore)
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/io/TestColumnIO/log(java.lang.Object)
parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])#parquet/io/TestColumnIO/newColumnWriteStore(parquet.column.page.mem.MemPageStore)
parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type[])
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#java/util/ArrayList/ArrayList()
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/example/data/Group/addGroup(int)
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/io/TestColumnIO/testSchema(parquet.schema.MessageType,java.util.List)
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#java/util/List/add(E)
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/example/data/GroupFactory/newGroup()
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/example/data/Group/add(int,parquet.io.api.Binary)
parquet/io/TestColumnIO/testOptionalRequiredInteraction()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/io/TestColumnIO/newColumnWriteStore(parquet.column.page.mem.MemPageStore)#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/io/TestColumnIO/testEmptyField()#parquet/io/api/RecordConsumer/startMessage()
parquet/io/TestColumnIO/testEmptyField()#parquet/io/TestColumnIO/newColumnWriteStore(parquet.column.page.mem.MemPageStore)
parquet/io/TestColumnIO/testEmptyField()#parquet/io/ColumnIOFactory/ColumnIOFactory(boolean)
parquet/io/TestColumnIO/testEmptyField()#java/lang/Throwable/getMessage()
parquet/io/TestColumnIO/testEmptyField()#parquet/io/api/RecordConsumer/addLong(long)
parquet/io/TestColumnIO/testEmptyField()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestColumnIO/testEmptyField()#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/io/TestColumnIO/testEmptyField()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestColumnIO/testEmptyField()#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/io/TestColumnIO/testEmptyField()#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/io/TestColumnIO/testWriteWithGroupWriter()#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/io/TestColumnIO/testWriteWithGroupWriter()#parquet/io/TestColumnIO/testWriteWithGroupWriter()/$anonymous1/()
parquet/io/TestColumnIO/testWriteWithGroupWriter()#parquet/column/ColumnWriteStore/flush()
parquet/io/TestColumnIO/testWriteWithGroupWriter()#parquet/example/data/GroupWriter/GroupWriter(parquet.io.api.RecordConsumer,parquet.schema.GroupType)
parquet/io/TestColumnIO/testWriteWithGroupWriter()#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/io/TestColumnIO/testWriteWithGroupWriter()#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/io/TestColumnIO/testWriteWithGroupWriter()#parquet/example/data/GroupWriter/write(parquet.example.data.Group)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#parquet/example/data/Group/append(java.lang.String,int)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#java/lang/Throwable/getMessage()
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#parquet/example/data/simple/SimpleGroupFactory/newGroup()
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestColumnIO/testReadUsingRequestedSchemaWithIncompatibleField()#parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)
parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)#parquet/io/RecordReaderImplementation/getNextLevel(int,int)
parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)#parquet/io/RecordReaderImplementation/getNextReader(int,int)
parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)#java/util/List/size()
parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)#parquet/io/MessageColumnIO/getLeaves()
parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)#java/util/List/get(int)
parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)#parquet/io/TestColumnIO/log(java.lang.Object)
parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)#java/util/Arrays/toString(java.lang.Object[])
parquet/io/TestColumnIO/validateFSA(int[][],parquet.io.MessageColumnIO,parquet.io.RecordReaderImplementation)#parquet/io/ColumnIO/getFieldPath()
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#parquet/example/data/Group/append(java.lang.String,int)
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#parquet/io/TestColumnIO/writeGroups(parquet.schema.MessageType,parquet.column.page.mem.MemPageStore,parquet.example.data.Group[])
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#parquet/example/data/simple/SimpleGroupFactory/SimpleGroupFactory(parquet.schema.MessageType)
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#java/lang/Throwable/getMessage()
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#parquet/example/data/simple/SimpleGroupFactory/newGroup()
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/io/TestColumnIO/testReadUsingSchemaWithRequiredFieldThatWasOptional()#parquet/io/TestColumnIO/readGroups(parquet.column.page.mem.MemPageStore,parquet.schema.MessageType,parquet.schema.MessageType,int)
parquet/hadoop/SplitStrategy/getSplitStrategy(boolean)#parquet/hadoop/TaskSideMetadataSplitStrategy/TaskSideMetadataSplitStrategy()
parquet/hadoop/SplitStrategy/getSplitStrategy(boolean)#parquet/Log/info(java.lang.Object)
parquet/hadoop/SplitStrategy/getSplitStrategy(boolean)#parquet/hadoop/ClientSideMetadataSplitStrategy/ClientSideMetadataSplitStrategy()
parquet/filter2/predicate/Operators/Column/hashCode()#parquet/common/schema/ColumnPath/hashCode()
parquet/filter2/predicate/Operators/Column/hashCode()#java/lang/Object/hashCode()
parquet/filter2/predicate/Operators/Column/equals(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
parquet/filter2/predicate/Operators/Column/equals(java.lang.Object)#parquet/common/schema/ColumnPath/equals(java.lang.Object)
parquet/filter2/predicate/Operators/Column/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/filter2/predicate/Operators/Column/toString()#parquet/common/schema/ColumnPath/toDotString()
parquet/bytes/TestBytesUtil/testWidth()#parquet/bytes/BytesUtils/getWidthFromMaxInt(int)
parquet/bytes/BytesInput/SequenceBytesIn/writeAllTo(java.io.OutputStream)#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/bytes/BytesInput/SequenceBytesIn/writeAllTo(java.io.OutputStream)#parquet/bytes/BytesInput/size()
parquet/bytes/BytesInput/SequenceBytesIn/writeAllTo(java.io.OutputStream)#parquet/Log/debug(java.lang.Object)
parquet/pig/PigSchemaConverter/ColumnIndexAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/schema/GroupType/getFields()
parquet/pig/PigSchemaConverter/ColumnIndexAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#java/util/ArrayList/ArrayList()
parquet/pig/PigSchemaConverter/ColumnIndexAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/pig/PigSchemaConverter/filter(parquet.schema.Type,parquet.pig.convert.FieldSchema)
parquet/pig/PigSchemaConverter/ColumnIndexAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#java/util/List/add(E)
parquet/pig/PigSchemaConverter/ColumnIndexAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#java/util/List/get(int)
parquet/pig/PigSchemaConverter/ColumnIndexAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
parquet/pig/PigSchemaConverter/ColumnIndexAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#parquet/schema/GroupType/getFieldCount()
parquet/pig/PigSchemaConverter/ColumnIndexAccess/filterTupleSchema(parquet.schema.GroupType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)#java/lang/Object/Object()
parquet/io/api/PrimitiveConverter/addFloat(float)#java/lang/Class/getName()
parquet/io/api/PrimitiveConverter/addFloat(float)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/io/api/PrimitiveConverter/addFloat(float)#java/lang/Object/getClass()
parquet/io/api/PrimitiveConverter/setDictionary(parquet.column.Dictionary)#java/lang/Class/getName()
parquet/io/api/PrimitiveConverter/setDictionary(parquet.column.Dictionary)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/io/api/PrimitiveConverter/setDictionary(parquet.column.Dictionary)#java/lang/Object/getClass()
parquet/io/api/PrimitiveConverter/addValueFromDictionary(int)#java/lang/Class/getName()
parquet/io/api/PrimitiveConverter/addValueFromDictionary(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/io/api/PrimitiveConverter/addValueFromDictionary(int)#java/lang/Object/getClass()
parquet/io/api/PrimitiveConverter/addInt(int)#java/lang/Class/getName()
parquet/io/api/PrimitiveConverter/addInt(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/io/api/PrimitiveConverter/addInt(int)#java/lang/Object/getClass()
parquet/io/api/PrimitiveConverter/addDouble(double)#java/lang/Class/getName()
parquet/io/api/PrimitiveConverter/addDouble(double)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/io/api/PrimitiveConverter/addDouble(double)#java/lang/Object/getClass()
parquet/io/api/PrimitiveConverter/addBoolean(boolean)#java/lang/Class/getName()
parquet/io/api/PrimitiveConverter/addBoolean(boolean)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/io/api/PrimitiveConverter/addBoolean(boolean)#java/lang/Object/getClass()
parquet/io/api/PrimitiveConverter/addLong(long)#java/lang/Class/getName()
parquet/io/api/PrimitiveConverter/addLong(long)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/io/api/PrimitiveConverter/addLong(long)#java/lang/Object/getClass()
parquet/io/api/PrimitiveConverter/addBinary(parquet.io.api.Binary)#java/lang/Class/getName()
parquet/io/api/PrimitiveConverter/addBinary(parquet.io.api.Binary)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/io/api/PrimitiveConverter/addBinary(parquet.io.api.Binary)#java/lang/Object/getClass()
parquet/thrift/projection/FieldProjectionFilter/isMatched(parquet.thrift.projection.FieldsPath)#java/util/List/size()
parquet/thrift/projection/FieldProjectionFilter/isMatched(parquet.thrift.projection.FieldsPath)#parquet/thrift/projection/FieldProjectionFilter/matchPattern(parquet.thrift.projection.FieldsPath,parquet.thrift.projection.PathGlobPattern)
parquet/thrift/projection/FieldProjectionFilter/isMatched(parquet.thrift.projection.FieldsPath)#java/util/List/get(int)
parquet/thrift/projection/FieldProjectionFilter/matchPattern(parquet.thrift.projection.FieldsPath,parquet.thrift.projection.PathGlobPattern)#parquet/thrift/projection/PathGlobPattern/matches(java.lang.CharSequence)
parquet/thrift/projection/FieldProjectionFilter/matchPattern(parquet.thrift.projection.FieldsPath,parquet.thrift.projection.PathGlobPattern)#parquet/thrift/projection/FieldsPath/toString()
parquet/bytes/BytesInput/copy(parquet.bytes.BytesInput)#parquet/bytes/BytesInput/from(byte[])
parquet/bytes/BytesInput/copy(parquet.bytes.BytesInput)#parquet/bytes/BytesInput/toByteArray()
parquet/bytes/BytesInput/from(byte[],int,int)#parquet/bytes/BytesInput/ByteArrayBytesInput/ByteArrayBytesInput(byte[],int,int)
parquet/bytes/BytesInput/from(byte[],int,int)#parquet/Log/debug(java.lang.Object)
parquet/bytes/BytesInput/fromInt(int)#parquet/bytes/BytesInput/IntBytesInput/IntBytesInput(int)
parquet/bytes/BytesInput/from(java.io.InputStream,int)#parquet/bytes/BytesInput/StreamBytesInput/StreamBytesInput(java.io.InputStream,int)
parquet/bytes/BytesInput/toByteArray()#parquet/bytes/BytesInput/BAOS/BAOS(int)
parquet/bytes/BytesInput/toByteArray()#parquet/bytes/BytesInput/writeAllTo(java.io.OutputStream)
parquet/bytes/BytesInput/toByteArray()#parquet/bytes/BytesInput/size()
parquet/bytes/BytesInput/toByteArray()#parquet/bytes/BytesInput/BAOS/getBuf()
parquet/bytes/BytesInput/toByteArray()#java/io/ByteArrayOutputStream/size()
parquet/bytes/BytesInput/toByteArray()#parquet/Log/debug(java.lang.Object)
parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])#parquet/bytes/BytesInput/SequenceBytesIn/SequenceBytesIn(java.util.List)
parquet/bytes/BytesInput/concat(parquet.bytes.BytesInput[])#java/util/Arrays/asList(T[])
parquet/bytes/BytesInput/fromUnsignedVarInt(int)#parquet/bytes/BytesInput/UnsignedVarIntBytesInput/UnsignedVarIntBytesInput(int)
parquet/bytes/BytesInput/concat(java.util.List)#parquet/bytes/BytesInput/SequenceBytesIn/SequenceBytesIn(java.util.List)
parquet/bytes/BytesInput/from(byte[])#parquet/bytes/BytesInput/ByteArrayBytesInput/ByteArrayBytesInput(byte[],int,int)
parquet/bytes/BytesInput/from(byte[])#parquet/Log/debug(java.lang.Object)
parquet/bytes/BytesInput/fromZigZagVarInt(int)#parquet/bytes/BytesInput/UnsignedVarIntBytesInput/UnsignedVarIntBytesInput(int)
parquet/bytes/BytesInput/from(parquet.bytes.CapacityByteArrayOutputStream)#parquet/bytes/BytesInput/CapacityBAOSBytesInput/CapacityBAOSBytesInput(parquet.bytes.CapacityByteArrayOutputStream)
parquet/bytes/BytesInput/from(java.io.ByteArrayOutputStream)#parquet/bytes/BytesInput/BAOSBytesInput/BAOSBytesInput(java.io.ByteArrayOutputStream)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateUnpack(java.io.FileWriter,int,int,boolean)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)#java/io/Writer/append(java.lang.CharSequence)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generatePack(java.io.FileWriter,int,int,boolean)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/align(int,int)#java/lang/StringBuilder/append(java.lang.String)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/align(int,int)#java/lang/String/length()
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/align(int,int)#java/lang/StringBuilder/StringBuilder()
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/align(int,int)#java/lang/StringBuilder/toString()
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/align(int,int)#java/lang/String/valueOf(int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateUnpack(java.io.FileWriter,int,int,boolean)#parquet/bytes/BytesUtils/paddedByteCountFromBits(int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateUnpack(java.io.FileWriter,int,int,boolean)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/align(int,int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateUnpack(java.io.FileWriter,int,int,boolean)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/getShift(java.io.FileWriter,int,boolean,int,int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateUnpack(java.io.FileWriter,int,int,boolean)#java/io/Writer/append(java.lang.CharSequence)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateUnpack(java.io.FileWriter,int,int,boolean)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/genMask(int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateClass(java.io.FileWriter,int,boolean)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/Writer/append(java.lang.CharSequence)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/getAbsoluteFile()
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/exists()
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/File(java.lang.String)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/OutputStreamWriter/close()
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/mkdirs()
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/FileWriter/FileWriter(java.io.File)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)#java/io/File/getParentFile()
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/visualizeAlignment(java.io.FileWriter,int,int,int,int,int,int,int)#java/lang/Math/max(int,int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/visualizeAlignment(java.io.FileWriter,int,int,int,int,int,int,int)#java/io/Writer/append(java.lang.CharSequence)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/visualizeAlignment(java.io.FileWriter,int,int,int,int,int,int,int)#java/lang/String/valueOf(int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/main(java.lang.String[])#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generateScheme(java.lang.String,boolean,java.lang.String)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/getShift(java.io.FileWriter,int,boolean,int,int)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/visualizeAlignment(java.io.FileWriter,int,int,int,int,int,int,int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generatePack(java.io.FileWriter,int,int,boolean)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/align(int,int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generatePack(java.io.FileWriter,int,int,boolean)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/getShift(java.io.FileWriter,int,boolean,int,int)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generatePack(java.io.FileWriter,int,int,boolean)#java/io/Writer/append(java.lang.CharSequence)
parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/generatePack(java.io.FileWriter,int,int,boolean)#parquet/encoding/bitpacking/ByteBasedBitPackingGenerator/genMask(int)
parquet/proto/ProtoRecordMaterializer/getCurrentRecord()#parquet/proto/ProtoRecordConverter/getCurrentRecord()
parquet/hadoop/ParquetInputFormat/pickOneFileFromEachFolder(java.util.List)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetInputFormat/pickOneFileFromEachFolder(java.util.List)#java/util/HashSet/HashSet()
parquet/hadoop/ParquetInputFormat/createRecordReader(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/createRecordReader(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/hadoop/ParquetInputFormat/getReadSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/createRecordReader(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/hadoop/ParquetInputFormat/getFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/createRecordReader(org.apache.hadoop.hive.ql.io.parquet.read.InputSplit,parquet.pig.TaskAttemptContext)#parquet/hadoop/ParquetRecordReader/ParquetRecordReader(parquet.hadoop.api.ReadSupport,parquet.filter2.compat.FilterCompat.Filter)
parquet/hadoop/ParquetInputFormat/listStatus(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/listStatus(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/getAllFileRecursively(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/setUnboundRecordFilter(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/setUnboundRecordFilter(parquet.proto.utils.Job,java.lang.Class)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/hadoop/ParquetInputFormat/setUnboundRecordFilter(parquet.proto.utils.Job,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/ParquetInputFormat/setUnboundRecordFilter(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/ParquetInputFormat/getFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetInputFormat/isTaskSideMetaData(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetFileWriter/getGlobalMetaData(java.util.List,boolean)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetInputFormat/getReadSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetInputFormat/samplingFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/metadata/GlobalMetaData/getKeyValueMetaData()
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/metadata/GlobalMetaData/getSchema()
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetInputFormat/pickOneFileFromEachFolder(java.util.List)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#java/lang/Math/max(int,int)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetInputFormat/getFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/api/InitContext/InitContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/SplitStrategy/getSplitStrategy(boolean)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/SplitStrategy/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List,long,long,java.util.List,parquet.hadoop.api.ReadSupport.ReadContext)
parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String)
parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)#java/lang/Object/toString()
parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)#parquet/hadoop/util/SerializationUtil/writeObjectToConfAsBase64(java.lang.String,java.lang.Object,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)#parquet/hadoop/ParquetInputFormat/getUnboundRecordFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#java/util/HashMap/HashMap(java.util.Map)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/FileStatusWrapper/FileStatusWrapper(parquet.hadoop.FileStatus)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#java/util/Collections/emptyList()
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#java/util/List/addAll(java.util.Collection)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/FootersCacheValue/getFooter()
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/LruCache/put(K,V)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/FootersCacheValue/FootersCacheValue(parquet.hadoop.ParquetInputFormat.FileStatusWrapper,parquet.hadoop.Footer)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#java/util/List/add(E)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#java/util/HashSet/HashSet()
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/LruCache/getCurrentValue(K)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/LruCache/LruCache(int)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#java/lang/Math/max(int,int)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/getFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/Footer/getFile()
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#java/util/List/size()
parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/listStatus(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/getGlobalMetaData(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/getFooters(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/getGlobalMetaData(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetFileWriter/getGlobalMetaData(java.util.List)
parquet/hadoop/ParquetInputFormat/getReadSupportClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/util/ConfigurationUtil/getClassFromConfig(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String,java.lang.Class)
parquet/hadoop/ParquetInputFormat/setReadSupportClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/setReadSupportClass(parquet.proto.utils.Job,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/ParquetInputFormat/getSplits(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/getSplits(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)
parquet/hadoop/ParquetInputFormat/getSplits(parquet.hadoop.util.JobContext)#java/util/ArrayList/ArrayList(java.util.Collection)
parquet/hadoop/ParquetInputFormat/getSplits(parquet.hadoop.util.JobContext)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/getSplits(parquet.hadoop.util.JobContext)#parquet/hadoop/ParquetInputFormat/listStatus(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/getUnboundRecordFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/util/ConfigurationUtil/getClassFromConfig(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String,java.lang.Class)
parquet/hadoop/ParquetInputFormat/getFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection)#parquet/hadoop/ParquetInputFormat/isTaskSideMetaData(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection)#parquet/hadoop/ParquetFileReader/readAllFootersInParallelUsingSummaryFiles(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection,boolean)
parquet/hadoop/ParquetInputFormat/getFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Collection)#parquet/Log/debug(java.lang.Object)
parquet/hadoop/ParquetInputFormat/getFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)#parquet/hadoop/ParquetInputFormat/getFooters(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.List)
parquet/hadoop/ParquetInputFormat/getReadSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputFormat/getReadSupportClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getReadSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Class/newInstance()
parquet/hadoop/ParquetInputFormat/getReadSupport(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/hadoop/ParquetInputFormat/staticAddInputPathRecursively(java.util.List,parquet.hadoop.example.FileSystem,parquet.hadoop.Path,parquet.hadoop.PathFilter)#parquet/hadoop/ParquetInputFormat/staticAddInputPathRecursively(java.util.List,parquet.hadoop.example.FileSystem,parquet.hadoop.Path,parquet.hadoop.PathFilter)
parquet/hadoop/ParquetInputFormat/setTaskSideMetaData(parquet.proto.utils.Job,boolean)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/ParquetInputFormat/setReadSupportClass(parquet.cascading.JobConf,java.lang.Class)#java/lang/Class/getName()
parquet/hadoop/ParquetInputFormat/getFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
parquet/hadoop/ParquetInputFormat/getFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/util/SerializationUtil/readObjectFromConfAsBase64(java.lang.String,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getAllFileRecursively(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/ArrayList/ArrayList()
parquet/hadoop/ParquetInputFormat/getAllFileRecursively(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputFormat/staticAddInputPathRecursively(java.util.List,parquet.hadoop.example.FileSystem,parquet.hadoop.Path,parquet.hadoop.PathFilter)
parquet/hadoop/ParquetInputFormat/getAllFileRecursively(java.util.List,org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/Log/info(java.lang.Object)
parquet/hadoop/ParquetInputFormat/getFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/filter2/compat/FilterCompat/get(parquet.filter2.predicate.FilterPredicate,parquet.filter.UnboundRecordFilter)
parquet/hadoop/ParquetInputFormat/getFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputFormat/getFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/ParquetInputFormat/getUnboundRecordFilterInstance(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/ParquetInputFormat/getUnboundRecordFilterInstance(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/lang/Class/newInstance()
parquet/hadoop/ParquetInputFormat/getUnboundRecordFilterInstance(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/BadConfigurationException/BadConfigurationException(java.lang.String,java.lang.Throwable)
parquet/hadoop/ParquetInputFormat/getUnboundRecordFilterInstance(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/util/ConfigurationUtil/getClassFromConfig(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.String,java.lang.Class)
parquet/pig/TestPigSchemaConverter/testMapOfList()#parquet/pig/TestPigSchemaConverter/testPigConversion(java.lang.String)
parquet/pig/TestPigSchemaConverter/testMapTuple()#parquet/pig/TestPigSchemaConverter/testPigConversion(java.lang.String)
parquet/pig/TestPigSchemaConverter/testMultiBag()#parquet/pig/TestPigSchemaConverter/testPigConversion(java.lang.String)
parquet/pig/TestPigSchemaConverter/testSimpleBag()#parquet/pig/TestPigSchemaConverter/testPigConversion(java.lang.String)
parquet/pig/TestPigSchemaConverter/testMapWithFixed()#parquet/pig/TestPigSchemaConverter/testFixedConversion(java.lang.String,java.lang.String)
parquet/pig/TestPigSchemaConverter/testSchemaEvolution()#java/util/Arrays/asList(T[])
parquet/pig/TestPigSchemaConverter/testSchemaEvolution()#java/util/HashMap/HashMap()
parquet/pig/TestPigSchemaConverter/testSchemaEvolution()#parquet/pig/PigSchemaConverter/pigSchemaToString(parquet.pig.convert.Schema)
parquet/pig/TestPigSchemaConverter/testSchemaEvolution()#parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
parquet/pig/TestPigSchemaConverter/testSchemaEvolution()#java/util/Map/put(K,V)
parquet/pig/TestPigSchemaConverter/testSchemaEvolution()#java/util/HashSet/HashSet(java.util.Collection)
parquet/pig/TestPigSchemaConverter/testSchemaEvolution()#parquet/pig/TupleReadSupport/getPigSchemaFromMultipleFiles(parquet.schema.MessageType,java.util.Map)
parquet/pig/TestPigSchemaConverter/testMap3()#parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)
parquet/pig/TestPigSchemaConverter/testMap4()#parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)
parquet/pig/TestPigSchemaConverter/testPigConversion(java.lang.String)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TestPigSchemaConverter/testFixedConversion(java.lang.String,java.lang.String)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/pig/TestPigSchemaConverter/testFixedConversion(java.lang.String,java.lang.String)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TestPigSchemaConverter/testAnnonymousField()#parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)
parquet/pig/TestPigSchemaConverter/testTupleBag()#parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)
parquet/pig/TestPigSchemaConverter/testTupleBagWithAnonymousInnerField()#parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)
parquet/pig/TestPigSchemaConverter/testMapSimple()#parquet/pig/TestPigSchemaConverter/testPigConversion(java.lang.String)
parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)#parquet/schema/Type/toString()
parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)#parquet/pig/PigSchemaConverter/filter(parquet.schema.MessageType,parquet.pig.convert.Schema,parquet.pig.RequiredFieldList)
parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TestPigSchemaConverter/testMap2()#parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)
parquet/pig/TestPigSchemaConverter/testMap()#parquet/pig/TestPigSchemaConverter/testConversion(java.lang.String,java.lang.String)
parquet/hadoop/codec/SnappyUtil/validateBuffer(byte[],int,int)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/hadoop/codec/SnappyUtil/validateBuffer(byte[],int,int)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/pig/convert/TupleConverter/FieldFloatConverter/addFloat(float)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldFloatConverter/addBinary(parquet.io.api.Binary)#java/lang/Float/parseFloat(java.lang.String)
parquet/pig/convert/TupleConverter/FieldFloatConverter/addBinary(parquet.io.api.Binary)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldFloatConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/pig/convert/TupleConverter/FieldFloatConverter/addInt(int)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldFloatConverter/addLong(long)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldFloatConverter/addDouble(double)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/pig/convert/TupleConverter/FieldFloatConverter/addBoolean(boolean)#parquet/pig/convert/ParentValueContainer/add(java.lang.Object)
parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/hashCode()#java/lang/Object/hashCode()
parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/hashCode()#java/lang/Object/getClass()
parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/equals(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
parquet/filter2/predicate/Operators/BinaryLogicalFilterPredicate/equals(java.lang.Object)#java/lang/Object/getClass()
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/readingRLE()#parquet/column/values/rle/RunLengthBitPackingHybridValuesReader/RunLengthBitPackingHybridValuesReader(int)
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/readingRLE()#parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/readData(parquet.column.values.ValuesReader,byte[])
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/prepare()#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/RunLengthBitPackingHybridValuesWriter(int,int)
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/prepare()#java/util/Random/nextInt(int)
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/prepare()#parquet/column/values/ValuesWriter/writeInteger(int)
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/prepare()#java/util/Random/Random()
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/prepare()#parquet/column/values/delta/DeltaBinaryPackingValuesWriter/DeltaBinaryPackingValuesWriter(int,int,int)
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/prepare()#parquet/column/values/ValuesWriter/getBytes()
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/prepare()#parquet/bytes/BytesInput/toByteArray()
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/readData(parquet.column.values.ValuesReader,byte[])#parquet/column/values/ValuesReader/readInteger()
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/readData(parquet.column.values.ValuesReader,byte[])#parquet/column/values/ValuesReader/initFromPage(int,byte[],int)
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/readingDelta()#parquet/column/values/delta/DeltaBinaryPackingValuesReader/DeltaBinaryPackingValuesReader()
parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/readingDelta()#parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers/readData(parquet.column.values.ValuesReader,byte[])
parquet/cascading/convert/TupleConverter/TuplePrimitiveConverter/addFloat(float)#parquet/cascading/convert/TupleConverter/getCurrentTuple()
parquet/cascading/convert/TupleConverter/TuplePrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/io/api/Binary/toStringUsingUTF8()
parquet/cascading/convert/TupleConverter/TuplePrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/cascading/convert/TupleConverter/getCurrentTuple()
parquet/cascading/convert/TupleConverter/TuplePrimitiveConverter/addInt(int)#parquet/cascading/convert/TupleConverter/getCurrentTuple()
parquet/cascading/convert/TupleConverter/TuplePrimitiveConverter/addBoolean(boolean)#parquet/cascading/convert/TupleConverter/getCurrentTuple()
parquet/cascading/convert/TupleConverter/TuplePrimitiveConverter/addLong(long)#parquet/cascading/convert/TupleConverter/getCurrentTuple()
parquet/cascading/convert/TupleConverter/TuplePrimitiveConverter/addDouble(double)#parquet/cascading/convert/TupleConverter/getCurrentTuple()
parquet/column/statistics/BooleanStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/BooleanStatistics/setMinMaxFromBytes(byte[],byte[])#parquet/bytes/BytesUtils/bytesToBool(byte[])
parquet/column/statistics/BooleanStatistics/setMinMax(boolean,boolean)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/BooleanStatistics/initializeStats(boolean,boolean)#parquet/column/statistics/Statistics/markAsNotEmpty()
parquet/column/statistics/BooleanStatistics/toString()#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/column/statistics/BooleanStatistics/toString()#parquet/column/statistics/Statistics/getNumNulls()
parquet/column/statistics/BooleanStatistics/toString()#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/BooleanStatistics/getMinBytes()#parquet/bytes/BytesUtils/booleanToBytes(boolean)
parquet/column/statistics/BooleanStatistics/updateStats(boolean)#parquet/column/statistics/BooleanStatistics/updateStats(boolean,boolean)
parquet/column/statistics/BooleanStatistics/updateStats(boolean)#parquet/column/statistics/BooleanStatistics/initializeStats(boolean,boolean)
parquet/column/statistics/BooleanStatistics/updateStats(boolean)#parquet/column/statistics/Statistics/isEmpty()
parquet/column/statistics/BooleanStatistics/getMaxBytes()#parquet/bytes/BytesUtils/booleanToBytes(boolean)
parquet/column/statistics/BooleanStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/BooleanStatistics/updateStats(boolean,boolean)
parquet/column/statistics/BooleanStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/BooleanStatistics/getMin()
parquet/column/statistics/BooleanStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/BooleanStatistics/initializeStats(boolean,boolean)
parquet/column/statistics/BooleanStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/BooleanStatistics/getMax()
parquet/column/statistics/BooleanStatistics/mergeStatisticsMinMax(parquet.column.statistics.Statistics)#parquet/column/statistics/Statistics/isEmpty()
parquet/example/data/simple/LongValue/toString()#java/lang/String/valueOf(long)
parquet/example/data/simple/LongValue/writeValue(parquet.io.api.RecordConsumer)#parquet/io/api/RecordConsumer/addLong(long)
parquet/format/converter/ParquetMetadataConverter/NoFilter/accept(parquet.format.converter.ParquetMetadataConverter.MetadataFilterVisitor)#parquet/format/converter/ParquetMetadataConverter/MetadataFilterVisitor/visit(parquet.format.converter.ParquetMetadataConverter.NoFilter)
parquet/Ints/checkedCast(long)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/Ints/checkedCast(long)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
parquet/example/data/simple/convert/SimplePrimitiveConverter/addFloat(float)#parquet/example/data/Group/add(int,float)
parquet/example/data/simple/convert/SimplePrimitiveConverter/addFloat(float)#parquet/example/data/simple/convert/SimpleGroupConverter/getCurrentRecord()
parquet/example/data/simple/convert/SimplePrimitiveConverter/addInt(int)#parquet/example/data/Group/add(int,int)
parquet/example/data/simple/convert/SimplePrimitiveConverter/addInt(int)#parquet/example/data/simple/convert/SimpleGroupConverter/getCurrentRecord()
parquet/example/data/simple/convert/SimplePrimitiveConverter/addBoolean(boolean)#parquet/example/data/Group/add(int,boolean)
parquet/example/data/simple/convert/SimplePrimitiveConverter/addBoolean(boolean)#parquet/example/data/simple/convert/SimpleGroupConverter/getCurrentRecord()
parquet/example/data/simple/convert/SimplePrimitiveConverter/addLong(long)#parquet/example/data/Group/add(int,long)
parquet/example/data/simple/convert/SimplePrimitiveConverter/addLong(long)#parquet/example/data/simple/convert/SimpleGroupConverter/getCurrentRecord()
parquet/example/data/simple/convert/SimplePrimitiveConverter/addDouble(double)#parquet/example/data/Group/add(int,double)
parquet/example/data/simple/convert/SimplePrimitiveConverter/addDouble(double)#parquet/example/data/simple/convert/SimpleGroupConverter/getCurrentRecord()
parquet/example/data/simple/convert/SimplePrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/example/data/simple/convert/SimpleGroupConverter/getCurrentRecord()
parquet/example/data/simple/convert/SimplePrimitiveConverter/addBinary(parquet.io.api.Binary)#parquet/example/data/Group/add(int,parquet.io.api.Binary)
parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)#java/net/URL/getProtocol()
parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)#java/lang/String/equals(java.lang.Object)
parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)#java/net/URL/getPath()
parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)#java/lang/String/startsWith(java.lang.String)
parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)#java/lang/ClassLoader/getResources(java.lang.String)
parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)#java/util/Enumeration/nextElement()
parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)#java/lang/Class/getClassLoader()
parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)#java/util/Enumeration/hasMoreElements()
parquet/Version/readVersionNumber()#parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)
parquet/Version/readVersionNumber()#java/util/Properties/getProperty(java.lang.String)
parquet/Version/readVersionNumber()#java/net/URL/openStream()
parquet/Version/readVersionNumber()#java/util/Properties/Properties()
parquet/Version/readVersionNumber()#parquet/Log/warn(java.lang.Object,java.lang.Throwable)
parquet/Version/readVersionNumber()#parquet/Version/getJarPath()
parquet/Version/readVersionNumber()#java/util/Properties/load(java.io.InputStream)
parquet/Version/getJarPath()#java/net/URL/getProtocol()
parquet/Version/getJarPath()#java/lang/Class/getResource(java.lang.String)
parquet/Version/getJarPath()#java/lang/String/equals(java.lang.Object)
parquet/Version/getJarPath()#java/lang/String/substring(int,int)
parquet/Version/getJarPath()#java/lang/String/indexOf(java.lang.String)
parquet/Version/getJarPath()#java/net/URL/getPath()
parquet/Version/readFullVersion()#parquet/Version/getResourceFromJar(java.lang.String,java.lang.String)
parquet/Version/readFullVersion()#java/net/URL/openStream()
parquet/Version/readFullVersion()#java/util/jar/Manifest/Manifest(java.io.InputStream)
parquet/Version/readFullVersion()#parquet/Log/warn(java.lang.Object,java.lang.Throwable)
parquet/Version/readFullVersion()#java/util/jar/Manifest/getMainAttributes()
parquet/Version/readFullVersion()#parquet/Version/getJarPath()
parquet/Version/readFullVersion()#java/util/jar/Attributes/getValue(java.lang.String)
parquet/Version/main(java.lang.String[])#java/io/PrintStream/println(java.lang.String)
parquet/column/values/bitpacking/ByteBitPackingValuesWriter/getBufferedSize()#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/getBufferSize()
parquet/column/values/bitpacking/ByteBitPackingValuesWriter/getBytes()#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.Throwable)
parquet/column/values/bitpacking/ByteBitPackingValuesWriter/getBytes()#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/toBytes()
parquet/column/values/bitpacking/ByteBitPackingValuesWriter/memUsageString(java.lang.String)#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/memUsageString(java.lang.String)
parquet/column/values/bitpacking/ByteBitPackingValuesWriter/reset()#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/ByteBasedBitPackingEncoder(int,parquet.column.values.bitpacking.Packer)
parquet/column/values/bitpacking/ByteBitPackingValuesWriter/getAllocatedSize()#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/getAllocatedSize()
parquet/column/values/bitpacking/ByteBitPackingValuesWriter/writeInteger(int)#parquet/io/ParquetEncodingException/ParquetEncodingException(java.lang.Throwable)
parquet/column/values/bitpacking/ByteBitPackingValuesWriter/writeInteger(int)#parquet/column/values/bitpacking/ByteBasedBitPackingEncoder/writeInt(int)
parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addFloat(float)#parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addFloat(float)/$anonymous1/(java.lang.String)
parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addInt(int)#parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addInt(int)/$anonymous3/(java.lang.String)
parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addInt(int)#parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addInt(int)/$anonymous2/(java.lang.String)
parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addInt(int)#parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addInt(int)/$anonymous1/(java.lang.String)
parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addInt(int)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addBoolean(boolean)#parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addBoolean(boolean)/$anonymous1/(java.lang.String)
parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addLong(long)#parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addLong(long)/$anonymous1/(java.lang.String)
parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addDouble(double)#parquet/thrift/ThriftRecordConverter/FieldPrimitiveConverter/addDouble(double)/$anonymous1/(java.lang.String)
parquet/pig/TupleConsumerPerfTest/pigMetaData(java.lang.String)#parquet/pig/PigMetaData/PigMetaData(java.lang.String)
parquet/pig/TupleConsumerPerfTest/pigMetaData(java.lang.String)#java/util/HashMap/HashMap()
parquet/pig/TupleConsumerPerfTest/pigMetaData(java.lang.String)#parquet/pig/PigMetaData/addToMetaData(java.util.Map)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String,java.lang.String)#parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)
parquet/pig/TupleConsumerPerfTest/tuple()#java/lang/Integer/Integer(int)
parquet/pig/TupleConsumerPerfTest/read(parquet.io.RecordReader,int,java.lang.String)#java/io/PrintStream/printf(java.lang.String,java.lang.Object[])
parquet/pig/TupleConsumerPerfTest/read(parquet.io.RecordReader,int,java.lang.String)#java/lang/System/currentTimeMillis()
parquet/pig/TupleConsumerPerfTest/read(parquet.io.RecordReader,int,java.lang.String)#java/lang/RuntimeException/RuntimeException()
parquet/pig/TupleConsumerPerfTest/newColumnFactory(java.lang.String)#parquet/io/ColumnIOFactory/ColumnIOFactory()
parquet/pig/TupleConsumerPerfTest/newColumnFactory(java.lang.String)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)
parquet/pig/TupleConsumerPerfTest/newColumnFactory(java.lang.String)#parquet/pig/PigSchemaConverter/PigSchemaConverter()
parquet/pig/TupleConsumerPerfTest/newColumnFactory(java.lang.String)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.pig.TupleWriteSupport,int)#parquet/pig/TupleWriteSupport/write(parquet.pig.convert.Tuple)
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.pig.TupleWriteSupport,int)#parquet/pig/TupleConsumerPerfTest/tuple()
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.pig.TupleWriteSupport,int)#java/io/PrintStream/printf(java.lang.String,java.lang.Object[])
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.pig.TupleWriteSupport,int)#java/lang/System/currentTimeMillis()
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.pig.TupleWriteSupport,int)#parquet/column/page/mem/MemPageStore/addRowCount(long)
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#java/io/PrintStream/println(java.lang.String)
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/memSize()
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String,java.lang.String)
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/maxColMemSize()
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/pig/PigSchemaConverter/PigSchemaConverter()
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/flush()
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.column.impl.ColumnWriteStoreImpl,parquet.schema.MessageType,java.lang.String)
parquet/pig/TupleConsumerPerfTest/main(java.lang.String[])#parquet/pig/TupleConsumerPerfTest/pigSchema(boolean,boolean)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/pig/TupleConsumerPerfTest/pigMetaData(java.lang.String)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#java/io/PrintStream/println(java.lang.String)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#java/io/PrintStream/println()
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/hadoop/api/ReadSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/io/MessageColumnIO/getRecordReader(parquet.column.page.PageReadStore,parquet.io.api.RecordMaterializer)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/pig/TupleReadSupport/prepareForRead(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.util.Map,parquet.schema.MessageType,parquet.hadoop.api.ReadSupport.ReadContext)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/pig/TupleConsumerPerfTest/newColumnFactory(java.lang.String)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/pig/PigSchemaConverter/convert(parquet.schema.MessageType)
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/pig/TupleReadSupport/TupleReadSupport()
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/pig/PigSchemaConverter/PigSchemaConverter()
parquet/pig/TupleConsumerPerfTest/read(parquet.column.page.PageReadStore,java.lang.String,java.lang.String)#parquet/pig/TupleConsumerPerfTest/read(parquet.io.RecordReader,int,java.lang.String)
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.column.impl.ColumnWriteStoreImpl,parquet.schema.MessageType,java.lang.String)#parquet/pig/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.column.impl.ColumnWriteStoreImpl,parquet.schema.MessageType,java.lang.String)#parquet/pig/TupleWriteSupport/fromPigSchema(java.lang.String)
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.column.impl.ColumnWriteStoreImpl,parquet.schema.MessageType,java.lang.String)#java/io/PrintStream/println()
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.column.impl.ColumnWriteStoreImpl,parquet.schema.MessageType,java.lang.String)#parquet/io/MessageColumnIO/getRecordWriter(parquet.column.ColumnWriteStore)
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.column.impl.ColumnWriteStoreImpl,parquet.schema.MessageType,java.lang.String)#parquet/pig/TupleWriteSupport/prepareForWrite(parquet.io.api.RecordConsumer)
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.column.impl.ColumnWriteStoreImpl,parquet.schema.MessageType,java.lang.String)#parquet/pig/TupleConsumerPerfTest/newColumnFactory(java.lang.String)
parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.column.impl.ColumnWriteStoreImpl,parquet.schema.MessageType,java.lang.String)#parquet/pig/TupleConsumerPerfTest/write(parquet.column.page.mem.MemPageStore,parquet.pig.TupleWriteSupport,int)
parquet/pig/TupleConsumerPerfTest/pigSchema(boolean,boolean)#java/lang/StringBuilder/append(java.lang.String)
parquet/pig/TupleConsumerPerfTest/pigSchema(boolean,boolean)#java/lang/StringBuilder/StringBuilder()
parquet/pig/TupleConsumerPerfTest/pigSchema(boolean,boolean)#java/lang/StringBuilder/toString()
parquet/proto/TestUtils/writeMessages(parquet.proto.MessageOrBuilder[])#parquet/proto/TestUtils/writeMessages(java.lang.Class,parquet.proto.MessageOrBuilder[])
parquet/proto/TestUtils/writeMessages(parquet.proto.MessageOrBuilder[])#parquet/proto/TestUtils/inferRecordsClass(parquet.proto.MessageOrBuilder[])
parquet/proto/TestUtils/readMessages(parquet.hadoop.Path)#java/util/ArrayList/ArrayList()
parquet/proto/TestUtils/readMessages(parquet.hadoop.Path)#parquet/hadoop/ParquetReader/close()
parquet/proto/TestUtils/readMessages(parquet.hadoop.Path)#parquet/proto/ProtoParquetReader/ProtoParquetReader(parquet.hadoop.Path)
parquet/proto/TestUtils/readMessages(parquet.hadoop.Path)#parquet/proto/TestUtils/asMessage(parquet.proto.utils.MessageOrBuilder)
parquet/proto/TestUtils/readMessages(parquet.hadoop.Path)#java/util/List/add(E)
parquet/proto/TestUtils/readMessages(parquet.hadoop.Path)#parquet/hadoop/ParquetReader/read()
parquet/proto/TestUtils/asMessages(java.util.List)#java/util/ArrayList/ArrayList()
parquet/proto/TestUtils/asMessages(java.util.List)#parquet/proto/TestUtils/asMessage(parquet.proto.utils.MessageOrBuilder)
parquet/proto/TestUtils/cloneList(parquet.proto.MessageOrBuilder[])#java/util/ArrayList/ArrayList()
parquet/proto/TestUtils/cloneList(parquet.proto.MessageOrBuilder[])#parquet/proto/TestUtils/asMessage(parquet.proto.utils.MessageOrBuilder)
parquet/proto/TestUtils/writeAndRead(T[])#parquet/proto/TestUtils/readMessages(parquet.hadoop.Path)
parquet/proto/TestUtils/writeAndRead(T[])#parquet/proto/TestUtils/writeMessages(java.lang.Class,parquet.proto.MessageOrBuilder[])
parquet/proto/TestUtils/writeAndRead(T[])#parquet/proto/TestUtils/inferRecordsClass(parquet.proto.MessageOrBuilder[])
parquet/proto/TestUtils/writeMessages(java.lang.Class,parquet.proto.MessageOrBuilder[])#parquet/proto/TestUtils/someTemporaryFilePath()
parquet/proto/TestUtils/writeMessages(java.lang.Class,parquet.proto.MessageOrBuilder[])#parquet/proto/ProtoParquetWriter/ProtoParquetWriter(parquet.hadoop.Path,java.lang.Class)
parquet/proto/TestUtils/someTemporaryFilePath()#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/proto/TestUtils/someTemporaryFilePath()#java/io/File/deleteOnExit()
parquet/proto/TestUtils/someTemporaryFilePath()#java/io/File/delete()
parquet/proto/TestUtils/someTemporaryFilePath()#java/io/File/getPath()
parquet/proto/TestUtils/testData(T[])#parquet/proto/TestUtils/asMessages(java.util.List)
parquet/proto/TestUtils/testData(T[])#parquet/proto/TestUtils/cloneList(parquet.proto.MessageOrBuilder[])
parquet/proto/TestUtils/testData(T[])#parquet/proto/TestUtils/writeAndRead(T[])
parquet/proto/TestUtils/testData(T[])#parquet/proto/TestUtils/checkSameBuilderInstance(parquet.proto.MessageOrBuilder[])
parquet/proto/TestUtils/inferRecordsClass(parquet.proto.MessageOrBuilder[])#java/lang/Object/equals(java.lang.Object)
parquet/proto/TestUtils/inferRecordsClass(parquet.proto.MessageOrBuilder[])#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/proto/TestUtils/inferRecordsClass(parquet.proto.MessageOrBuilder[])#java/lang/Object/getClass()
parquet/bytes/BytesInput/ByteArrayBytesInput/writeAllTo(java.io.OutputStream)#java/io/OutputStream/write(byte[],int,int)
parquet/schema/Types/PrimitiveBuilder/decimalMetadata()#parquet/schema/DecimalMetadata/DecimalMetadata(int,int)
parquet/schema/Types/PrimitiveBuilder/decimalMetadata()#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/schema/Types/PrimitiveBuilder/maxPrecision(int)#java/lang/Math/floor(double)
parquet/schema/Types/PrimitiveBuilder/maxPrecision(int)#java/lang/Math/round(double)
parquet/schema/Types/PrimitiveBuilder/maxPrecision(int)#java/lang/Math/log10(double)
parquet/schema/Types/PrimitiveBuilder/maxPrecision(int)#java/lang/Math/pow(double,double)
parquet/schema/Types/PrimitiveBuilder/build(java.lang.String)#java/lang/Enum/toString()
parquet/schema/Types/PrimitiveBuilder/build(java.lang.String)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
parquet/schema/Types/PrimitiveBuilder/build(java.lang.String)#parquet/schema/DecimalMetadata/getPrecision()
parquet/schema/Types/PrimitiveBuilder/build(java.lang.String)#parquet/schema/Types/PrimitiveBuilder/decimalMetadata()
parquet/schema/Types/PrimitiveBuilder/build(java.lang.String)#parquet/schema/Types/PrimitiveBuilder/maxPrecision(int)
parquet/schema/Types/PrimitiveBuilder/build(java.lang.String)#parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,int,java.lang.String,parquet.schema.OriginalType,parquet.schema.DecimalMetadata,parquet.schema.Type.ID)
parquet/schema/Types/PrimitiveBuilder/build(java.lang.String)#parquet/Preconditions/checkState(boolean,java.lang.String)
parquet/schema/Types/PrimitiveBuilder/build(java.lang.String)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/thrift/struct/ThriftType/SetType/hashCode()#parquet/thrift/struct/ThriftField/hashCode()
parquet/thrift/struct/ThriftType/SetType/hashCode()#parquet/thrift/struct/ThriftType/hashCode()
parquet/thrift/struct/ThriftType/SetType/equals(java.lang.Object)#parquet/thrift/struct/ThriftType/equals(java.lang.Object)
parquet/thrift/struct/ThriftType/SetType/equals(java.lang.Object)#parquet/thrift/struct/ThriftField/equals(java.lang.Object)
parquet/thrift/struct/ThriftType/SetType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.SetType)
parquet/filter/NotRecordFilter/isMatch()#parquet/filter/RecordFilter/isMatch()
parquet/filter/NotRecordFilter/not(parquet.filter.UnboundRecordFilter)#parquet/filter/NotRecordFilter/not(parquet/filter/UnboundRecordFilter)/$anonymous1/()
parquet/filter/NotRecordFilter/not(parquet.filter.UnboundRecordFilter)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/hadoop/thrift/ParquetThriftOutputFormat/setThriftClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/thrift/ThriftWriteSupport/setThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration,java.lang.Class)
parquet/hadoop/thrift/ParquetThriftOutputFormat/setThriftClass(parquet.proto.utils.Job,java.lang.Class)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/thrift/ParquetThriftOutputFormat/getThriftClass(parquet.proto.utils.Job)#parquet/hadoop/util/ContextUtil/getConfiguration(parquet.hadoop.util.JobContext)
parquet/hadoop/thrift/ParquetThriftOutputFormat/getThriftClass(parquet.proto.utils.Job)#parquet/hadoop/thrift/ThriftWriteSupport/getThriftClass(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/tools/command/DumpCommand/DumpGroupConverter/getConverter(int)#parquet/tools/command/DumpCommand/DumpConverter/DumpConverter()
parquet/thrift/ParquetWriteProtocol/writeBinary(java.nio.ByteBuffer)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeI16(short)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeString(java.lang.String)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeI64(long)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeMessageEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeListBegin(parquet.thrift.TList)#parquet/thrift/ParquetWriteProtocol/toString(parquet.thrift.TStruct)
parquet/thrift/ParquetWriteProtocol/writeListBegin(parquet.thrift.TList)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeI32(int)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeSetEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/struct/ThriftType/SetType/getValues()
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/ParquetWriteProtocol/MapWriteProtocol/MapWriteProtocol(parquet.io.GroupColumnIO,parquet.thrift.struct.ThriftType.MapType,parquet.thrift.ParquetWriteProtocol.Events)
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/ParquetWriteProtocol/StructWriteProtocol/StructWriteProtocol(parquet.io.GroupColumnIO,parquet.thrift.struct.ThriftType.StructType,parquet.thrift.ParquetWriteProtocol.Events)
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/struct/ThriftType/getType()
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/ParquetWriteProtocol/ListWriteProtocol/ListWriteProtocol(parquet.io.GroupColumnIO,parquet.thrift.struct.ThriftField,parquet.thrift.ParquetWriteProtocol.Events)
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/ParquetWriteProtocol/EnumWriteProtocol/EnumWriteProtocol(parquet.io.PrimitiveColumnIO,parquet.thrift.struct.ThriftType.EnumType,parquet.thrift.ParquetWriteProtocol.Events)
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/PrimitiveWriteProtocol(parquet.io.PrimitiveColumnIO,parquet.thrift.ParquetWriteProtocol.Events)
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/struct/ThriftType/ListType/getValues()
parquet/thrift/ParquetWriteProtocol/getProtocol(parquet.thrift.struct.ThriftField,parquet.io.ColumnIO,parquet.thrift.ParquetWriteProtocol.Events)#parquet/thrift/struct/ThriftField/getType()
parquet/thrift/ParquetWriteProtocol/writeFieldStop()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeListEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeMapEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeByte(byte)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeDouble(double)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeBool(boolean)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeBinaryToRecordConsumer(java.nio.ByteBuffer)#parquet/io/api/Binary/fromByteArray(byte[],int,int)
parquet/thrift/ParquetWriteProtocol/writeBinaryToRecordConsumer(java.nio.ByteBuffer)#java/nio/Buffer/limit()
parquet/thrift/ParquetWriteProtocol/writeBinaryToRecordConsumer(java.nio.ByteBuffer)#java/nio/ByteBuffer/array()
parquet/thrift/ParquetWriteProtocol/writeBinaryToRecordConsumer(java.nio.ByteBuffer)#java/nio/Buffer/position()
parquet/thrift/ParquetWriteProtocol/writeBinaryToRecordConsumer(java.nio.ByteBuffer)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/thrift/ParquetWriteProtocol/writeFieldEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeMapBegin(parquet.thrift.TMap)#parquet/thrift/ParquetWriteProtocol/toString(parquet.thrift.TStruct)
parquet/thrift/ParquetWriteProtocol/writeMapBegin(parquet.thrift.TMap)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeMessageBegin(parquet.thrift.TMessage)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeSetBegin(parquet.thrift.TSet)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeFieldBegin(parquet.thrift.TField)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeStructEnd()#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeStructBegin(parquet.thrift.TStruct)#parquet/thrift/ParquetWriteProtocol/toString(parquet.thrift.TStruct)
parquet/thrift/ParquetWriteProtocol/writeStructBegin(parquet.thrift.TStruct)#parquet/Log/debug(java.lang.Object)
parquet/thrift/ParquetWriteProtocol/writeStringToRecordConsumer(java.lang.String)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/thrift/ParquetWriteProtocol/writeStringToRecordConsumer(java.lang.String)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/hadoop/TestInputFormat/testGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/setUp()#parquet/hadoop/metadata/FileMetaData/FileMetaData(parquet.schema.MessageType,java.util.Map,java.lang.String)
parquet/hadoop/TestInputFormat/setUp()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/hadoop/TestInputFormat/setUp()#java/util/HashMap/HashMap()
parquet/hadoop/TestInputFormat/setUp()#java/util/List/add(E)
parquet/hadoop/TestInputFormat/setUp()#parquet/hadoop/TestInputFormat/newBlock(long,long)
parquet/hadoop/TestInputFormat/setUp()#java/util/ArrayList/ArrayList()
parquet/hadoop/TestInputFormat/testRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testOnlyOneKindOfFilterSupported()#parquet/filter2/predicate/FilterApi/intColumn(java.lang.String)
parquet/hadoop/TestInputFormat/testOnlyOneKindOfFilterSupported()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/hadoop/TestInputFormat/testOnlyOneKindOfFilterSupported()#java/lang/Throwable/getMessage()
parquet/hadoop/TestInputFormat/testOnlyOneKindOfFilterSupported()#parquet/hadoop/ParquetInputFormat/setUnboundRecordFilter(parquet.proto.utils.Job,java.lang.Class)
parquet/hadoop/TestInputFormat/testOnlyOneKindOfFilterSupported()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/hadoop/TestInputFormat/testOnlyOneKindOfFilterSupported()#parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)
parquet/hadoop/TestInputFormat/testThrowExceptionWhenMaxSplitSizeIsSmallerThanMinSplitSizeTaskSide()#java/lang/Throwable/getMessage()
parquet/hadoop/TestInputFormat/testThrowExceptionWhenMaxSplitSizeIsSmallerThanMinSplitSizeTaskSide()#parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testThrowExceptionWhenMaxSplitSizeIsSmallerThanMinSplitSize()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testThrowExceptionWhenMaxSplitSizeIsSmallerThanMinSplitSize()#java/lang/Throwable/getMessage()
parquet/hadoop/TestInputFormat/message(java.util.List)#java/lang/String/valueOf(java.lang.Object)
parquet/hadoop/TestInputFormat/message(java.util.List)#java/util/Arrays/toString(long[])
parquet/hadoop/TestInputFormat/testThrowExceptionWhenMaxSplitSizeIsNegative()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testThrowExceptionWhenMaxSplitSizeIsNegative()#java/lang/Throwable/getMessage()
parquet/hadoop/TestInputFormat/testTSGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)#parquet/schema/Type/toString()
parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)#parquet/hadoop/ClientSideMetadataSplitStrategy/generateSplits(java.util.List,parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)
parquet/hadoop/TestInputFormat/testMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/newBlock(long,long)#parquet/hadoop/metadata/BlockMetaData/addColumn(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/hadoop/TestInputFormat/newBlock(long,long)#parquet/column/statistics/BinaryStatistics/BinaryStatistics()
parquet/hadoop/TestInputFormat/newBlock(long,long)#parquet/hadoop/metadata/BlockMetaData/setTotalByteSize(long)
parquet/hadoop/TestInputFormat/newBlock(long,long)#java/util/Arrays/asList(T[])
parquet/hadoop/TestInputFormat/newBlock(long,long)#parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/hadoop/TestInputFormat/newBlock(long,long)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/hadoop/TestInputFormat/newBlock(long,long)#parquet/hadoop/metadata/BlockMetaData/BlockMetaData()
parquet/hadoop/TestInputFormat/newBlock(long,long)#java/util/HashSet/HashSet(java.util.Collection)
parquet/hadoop/TestInputFormat/getDummyCacheValue(java.io.File,parquet.hadoop.example.FileSystem)#parquet/hadoop/ParquetInputFormat/FootersCacheValue/isCurrent(parquet.hadoop.ParquetInputFormat.FileStatusWrapper)
parquet/hadoop/TestInputFormat/getDummyCacheValue(java.io.File,parquet.hadoop.example.FileSystem)#parquet/hadoop/ParquetInputFormat/FileStatusWrapper/FileStatusWrapper(parquet.hadoop.FileStatus)
parquet/hadoop/TestInputFormat/getDummyCacheValue(java.io.File,parquet.hadoop.example.FileSystem)#parquet/hadoop/ParquetInputFormat/FootersCacheValue/FootersCacheValue(parquet.hadoop.ParquetInputFormat.FileStatusWrapper,parquet.hadoop.Footer)
parquet/hadoop/TestInputFormat/getDummyCacheValue(java.io.File,parquet.hadoop.example.FileSystem)#parquet/hadoop/Footer/Footer(parquet.hadoop.Path,parquet.hadoop.metadata.ParquetMetadata)
parquet/hadoop/TestInputFormat/getDummyCacheValue(java.io.File,parquet.hadoop.example.FileSystem)#java/io/File/getPath()
parquet/hadoop/TestInputFormat/testTSMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testTSMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])
parquet/hadoop/TestInputFormat/testTSMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSMultipleRowGroupsInABlockToAlignHDFSBlock()#parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testTSGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testTSGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/filter2/predicate/FilterApi/intColumn(java.lang.String)
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/filter2/compat/FilterCompat/FilterPredicateCompat/getFilterPredicate()
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/filter2/predicate/FilterApi/or(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/filter2/predicate/FilterApi/not(parquet.filter2.predicate.FilterPredicate)
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/filter2/predicate/FilterApi/notEq(C,T)
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/hadoop/ParquetInputFormat/getFilter(org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/filter2/predicate/FilterApi/eq(C,T)
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/hadoop/ParquetInputFormat/setFilterPredicate(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.filter2.predicate.FilterPredicate)
parquet/hadoop/TestInputFormat/testGetFilter()#parquet/filter2/predicate/FilterApi/and(parquet.filter2.predicate.FilterPredicate,parquet.filter2.predicate.FilterPredicate)
parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])#parquet/hadoop/ParquetInputSplit/getReadSupportMetadata()
parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])#java/util/Map/get(java.lang.Object)
parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])#java/util/List/size()
parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])#parquet/hadoop/TestInputFormat/message(java.util.List)
parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])#java/util/List/get(int)
parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])#java/util/Arrays/toString(long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS()#parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testTSRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testTSRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])
parquet/hadoop/TestInputFormat/testTSRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testTSRowGroupNotAlignToHDFSBlock()#parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])#java/lang/Object/Object()
parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])#java/util/List/size()
parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])#parquet/hadoop/TestInputFormat/message(java.util.List)
parquet/hadoop/TestInputFormat/shouldSplitStartBe(java.util.List,long[])#java/util/List/get(int)
parquet/hadoop/TestInputFormat/getTempFile()#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/hadoop/TestInputFormat/getTempFile()#java/io/File/deleteOnExit()
parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])#java/util/List/size()
parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])#parquet/hadoop/TestInputFormat/message(java.util.List)
parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])#java/util/List/get(int)
parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])#parquet/hadoop/ParquetInputSplit/getRowGroupOffsets()
parquet/hadoop/TestInputFormat/testFooterCacheValueIsNewer()#parquet/hadoop/TestInputFormat/getDummyCacheValue(java.io.File,parquet.hadoop.example.FileSystem)
parquet/hadoop/TestInputFormat/testFooterCacheValueIsNewer()#java/io/File/setLastModified(long)
parquet/hadoop/TestInputFormat/testFooterCacheValueIsNewer()#parquet/hadoop/ParquetInputFormat/FootersCacheValue/isNewerThan(parquet.hadoop.ParquetInputFormat.FootersCacheValue)
parquet/hadoop/TestInputFormat/testFooterCacheValueIsNewer()#parquet/hadoop/TestInputFormat/getTempFile()
parquet/hadoop/TestInputFormat/testFooterCacheValueIsNewer()#java/io/File/lastModified()
parquet/hadoop/TestInputFormat/testTSThrowExceptionWhenMaxSplitSizeIsNegative()#java/lang/Throwable/getMessage()
parquet/hadoop/TestInputFormat/testTSThrowExceptionWhenMaxSplitSizeIsNegative()#parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/generateSplitByMinMaxSize(long,long)
parquet/hadoop/TestInputFormat/testGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLocationBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/withHDFSBlockSize(long[])
parquet/hadoop/TestInputFormat/testGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitBlockSizeBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/testGenerateSplitsNotAlignedWithHDFSBlock()#parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])
parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])#java/util/List/size()
parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])#parquet/hadoop/TestInputFormat/message(java.util.List)
parquet/hadoop/TestInputFormat/shouldSplitLengthBe(java.util.List,int[])#java/util/List/get(int)
parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)#parquet/hadoop/metadata/BlockMetaData/addColumn(parquet.hadoop.metadata.ColumnChunkMetaData)
parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)#parquet/hadoop/metadata/BlockMetaData/setTotalByteSize(long)
parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)#java/util/Arrays/asList(T[])
parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)#parquet/hadoop/metadata/BlockMetaData/setRowCount(long)
parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)#parquet/hadoop/metadata/ColumnChunkMetaData/get(parquet.common.schema.ColumnPath,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.hadoop.metadata.CompressionCodecName,java.util.Set,parquet.column.statistics.Statistics,long,long,long,long,long)
parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)#parquet/hadoop/metadata/BlockMetaData/BlockMetaData()
parquet/hadoop/TestInputFormat/makeBlockFromStats(parquet.column.statistics.IntStatistics,long)#java/util/HashSet/HashSet(java.util.Collection)
parquet/hadoop/TestInputFormat/testFooterCacheValueIsCurrent()#parquet/hadoop/TestInputFormat/getDummyCacheValue(java.io.File,parquet.hadoop.example.FileSystem)
parquet/hadoop/TestInputFormat/testFooterCacheValueIsCurrent()#parquet/hadoop/ParquetInputFormat/FootersCacheValue/isCurrent(parquet.hadoop.ParquetInputFormat.FileStatusWrapper)
parquet/hadoop/TestInputFormat/testFooterCacheValueIsCurrent()#java/io/File/setLastModified(long)
parquet/hadoop/TestInputFormat/testFooterCacheValueIsCurrent()#parquet/hadoop/ParquetInputFormat/FileStatusWrapper/FileStatusWrapper(parquet.hadoop.FileStatus)
parquet/hadoop/TestInputFormat/testFooterCacheValueIsCurrent()#parquet/hadoop/TestInputFormat/getTempFile()
parquet/hadoop/TestInputFormat/testFooterCacheValueIsCurrent()#java/io/File/lastModified()
parquet/hadoop/TestInputFormat/testFooterCacheValueIsCurrent()#java/io/File/getAbsolutePath()
parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)#parquet/schema/Type/toString()
parquet/hadoop/TestInputFormat/generateTSSplitByMinMaxSize(long,long)#parquet/hadoop/TaskSideMetadataSplitStrategy/generateTaskSideMDSplits(parquet.hadoop.BlockLocation[],parquet.hadoop.FileStatus,java.lang.String,java.util.Map,long,long)
parquet/column/impl/ColumnReaderImpl/Binding/getBinary()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/impl/ColumnReaderImpl/Binding/getFloat()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/impl/ColumnReaderImpl/Binding/getInteger()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/impl/ColumnReaderImpl/Binding/getDictionaryId()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/impl/ColumnReaderImpl/Binding/getDouble()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/impl/ColumnReaderImpl/Binding/getBoolean()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/column/impl/ColumnReaderImpl/Binding/getLong()#java/lang/UnsupportedOperationException/UnsupportedOperationException()
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)#parquet/hadoop/example/GroupWriteSupport/setSchema(parquet.schema.MessageType,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)#parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)#parquet/hadoop/ParquetWriter/write(T)
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)#java/io/File/getAbsolutePath()
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)#parquet/hadoop/ParquetWriter/ParquetWriter(parquet.hadoop.Path,org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.api.WriteSupport)
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)#parquet/hadoop/ParquetWriter/close()
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)#parquet/hadoop/example/GroupWriteSupport/GroupWriteSupport()
parquet/filter2/recordlevel/PhoneBookWriter/main(java.lang.String[])#parquet/filter2/recordlevel/TestRecordLevelFilters/makeUsers()
parquet/filter2/recordlevel/PhoneBookWriter/main(java.lang.String[])#java/io/File/File(java.lang.String)
parquet/filter2/recordlevel/PhoneBookWriter/main(java.lang.String[])#parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.util.List)#java/io/IOException/IOException(java.lang.String)
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.util.List)#parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.io.File,java.util.List)
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.util.List)#java/io/File/delete()
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.util.List)#java/io/File/createTempFile(java.lang.String,java.lang.String)
parquet/filter2/recordlevel/PhoneBookWriter/writeToFile(java.util.List)#java/io/File/deleteOnExit()
parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)#java/util/ArrayList/ArrayList()
parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)#parquet/hadoop/example/GroupWriteSupport/setSchema(parquet.schema.MessageType,org.apache.hadoop.hive.ql.io.parquet.Configuration)
parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)#parquet/hadoop/ParquetReader/builder(parquet.hadoop.api.ReadSupport,parquet.hadoop.Path)
parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)#java/io/File/getAbsolutePath()
parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)#java/util/List/add(E)
parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)#parquet/hadoop/ParquetReader/read()
parquet/filter2/recordlevel/PhoneBookWriter/readFile(java.io.File,parquet.filter2.compat.FilterCompat.Filter)#parquet/hadoop/example/GroupReadSupport/GroupReadSupport()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/example/data/Group/append(java.lang.String,double)
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/filter2/recordlevel/PhoneBookWriter/User/getName()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/example/data/Group/addGroup(java.lang.String)
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/filter2/recordlevel/PhoneBookWriter/Location/getLat()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/example/data/Group/append(java.lang.String,java.lang.String)
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/example/data/simple/SimpleGroup/SimpleGroup(parquet.schema.GroupType)
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/filter2/recordlevel/PhoneBookWriter/User/getPhoneNumbers()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/filter2/recordlevel/PhoneBookWriter/Location/getLon()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/filter2/recordlevel/PhoneBookWriter/PhoneNumber/getKind()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/filter2/recordlevel/PhoneBookWriter/User/getLocation()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/filter2/recordlevel/PhoneBookWriter/PhoneNumber/getNumber()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/filter2/recordlevel/PhoneBookWriter/User/getId()
parquet/filter2/recordlevel/PhoneBookWriter/groupFromUser(parquet.filter2.recordlevel.PhoneBookWriter.User)#parquet/example/data/Group/append(java.lang.String,long)
parquet/filter2/predicate/TestValidTypeMap/testMismatchedTypes()#parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/filter2/predicate/TestValidTypeMap/testMismatchedTypes()#java/lang/Throwable/getMessage()
parquet/filter2/predicate/TestValidTypeMap/testValidTypes()#parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/filter2/predicate/TestValidTypeMap/testUnsupportedType()#parquet/filter2/predicate/ValidTypeMap/assertTypeValid(parquet.filter2.predicate.Operators.Column,parquet.schema.PrimitiveType.PrimitiveTypeName,parquet.schema.OriginalType)
parquet/filter2/predicate/TestValidTypeMap/testUnsupportedType()#java/lang/Throwable/getMessage()
parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType,parquet.schema.MessageType,boolean)#parquet/schema/MessageType/accept(parquet.schema.TypeVisitor)
parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType,parquet.schema.MessageType,boolean)#parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/getColumnIO()
parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType,parquet.schema.MessageType,boolean)#parquet/io/ColumnIOFactory/ColumnIOCreatorVisitor/ColumnIOCreatorVisitor(boolean,parquet.schema.MessageType,boolean)
parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType,parquet.schema.MessageType)
parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType,parquet.schema.MessageType)#parquet/io/ColumnIOFactory/getColumnIO(parquet.schema.MessageType,parquet.schema.MessageType,boolean)
parquet/format/converter/ParquetMetadataConverter/RangeMetadataFilter/accept(parquet.format.converter.ParquetMetadataConverter.MetadataFilterVisitor)#parquet/format/converter/ParquetMetadataConverter/MetadataFilterVisitor/visit(parquet.format.converter.ParquetMetadataConverter.RangeMetadataFilter)
parquet/avro/AvroIndexedRecordConverter/AvroUnionConverter/end()#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/common/schema/ColumnPath/toDotString()#java/util/Iterator/hasNext()
parquet/common/schema/ColumnPath/toDotString()#java/lang/StringBuilder/append(java.lang.String)
parquet/common/schema/ColumnPath/toDotString()#java/util/Arrays/asList(T[])
parquet/common/schema/ColumnPath/toDotString()#java/util/Iterator/next()
parquet/common/schema/ColumnPath/toDotString()#java/lang/StringBuilder/StringBuilder()
parquet/common/schema/ColumnPath/toDotString()#java/lang/StringBuilder/append(char)
parquet/common/schema/ColumnPath/toDotString()#java/util/List/iterator()
parquet/common/schema/ColumnPath/toDotString()#java/lang/StringBuilder/toString()
parquet/common/schema/ColumnPath/fromDotString(java.lang.String)#java/lang/String/split(java.lang.String)
parquet/common/schema/ColumnPath/fromDotString(java.lang.String)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/common/schema/ColumnPath/fromDotString(java.lang.String)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/common/schema/ColumnPath/iterator()#java/util/Arrays/asList(T[])
parquet/common/schema/ColumnPath/iterator()#java/util/List/iterator()
parquet/common/schema/ColumnPath/get(java.lang.String[])#parquet/common/schema/ColumnPath/ColumnPath(java.lang.String[])
parquet/common/schema/ColumnPath/get(java.lang.String[])#parquet/common/internal/Canonicalizer/canonicalize(T)
parquet/common/schema/ColumnPath/hashCode()#java/util/Arrays/hashCode(java.lang.Object[])
parquet/common/schema/ColumnPath/toString()#java/util/Arrays/toString(java.lang.Object[])
parquet/common/schema/ColumnPath/equals(java.lang.Object)#java/util/Arrays/equals(java.lang.Object[],java.lang.Object[])
parquet/avro/AvroIndexedRecordConverter/MapConverter/end()#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/avro/AvroIndexedRecordConverter/MapConverter/start()#java/util/HashMap/HashMap()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI32(int)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI32(int)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI32(int)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeBool(boolean)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeBool(boolean)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeBool(boolean)#parquet/io/api/RecordConsumer/addBoolean(boolean)
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeBinary(java.nio.ByteBuffer)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeBinary(java.nio.ByteBuffer)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeBinary(java.nio.ByteBuffer)#parquet/thrift/ParquetWriteProtocol/writeBinaryToRecordConsumer(java.nio.ByteBuffer)
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI16(short)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI16(short)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI16(short)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI64(long)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI64(long)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeI64(long)#parquet/io/api/RecordConsumer/addLong(long)
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeString(java.lang.String)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeString(java.lang.String)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeString(java.lang.String)#parquet/thrift/ParquetWriteProtocol/writeStringToRecordConsumer(java.lang.String)
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeByte(byte)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeByte(byte)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeByte(byte)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeDouble(double)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/end()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeDouble(double)#parquet/thrift/ParquetWriteProtocol/FieldBaseWriteProtocol/start()
parquet/thrift/ParquetWriteProtocol/PrimitiveWriteProtocol/writeDouble(double)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/column/values/bitpacking/OneBitPackingReader/read()#java/io/InputStream/read()
parquet/io/ExpectationValidatingConverter/path(java.util.List,parquet.schema.Type)#java/util/List/size()
parquet/io/ExpectationValidatingConverter/path(java.util.List,parquet.schema.Type)#java/util/List/get(int)
parquet/io/ExpectationValidatingConverter/path(java.util.List,parquet.schema.Type)#parquet/schema/Type/getName()
parquet/io/ExpectationValidatingConverter/validate(java.lang.String)#java/util/Deque/pop()
parquet/example/data/simple/BooleanValue/writeValue(parquet.io.api.RecordConsumer)#parquet/io/api/RecordConsumer/addBoolean(boolean)
parquet/example/data/simple/BooleanValue/toString()#java/lang/String/valueOf(boolean)
parquet/avro/AvroIndexedRecordConverter/FieldIntegerConverter/addInt(int)#parquet/avro/AvroIndexedRecordConverter/ParentValueContainer/add(java.lang.Object)
parquet/filter2/recordlevel/FilteringGroupConverter/getColumnIO(java.util.List)#parquet/Preconditions/checkArgument(boolean,java.lang.String)
parquet/filter2/recordlevel/FilteringGroupConverter/getColumnIO(java.util.List)#java/util/Map/get(java.lang.Object)
parquet/filter2/recordlevel/FilteringGroupConverter/getValueInspectors(parquet.common.schema.ColumnPath)#java/util/List/toArray(T[])
parquet/filter2/recordlevel/FilteringGroupConverter/getValueInspectors(parquet.common.schema.ColumnPath)#java/util/Map/get(java.lang.Object)
parquet/filter2/recordlevel/FilteringGroupConverter/getValueInspectors(parquet.common.schema.ColumnPath)#java/util/List/size()
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/filter2/recordlevel/FilteringGroupConverter/getColumnIO(java.util.List)
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/io/api/Converter/asGroupConverter()
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/filter2/recordlevel/FilteringGroupConverter/getValueInspectors(parquet.common.schema.ColumnPath)
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#java/util/ArrayList/ArrayList(int)
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/io/api/Converter/isPrimitive()
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/io/api/GroupConverter/getConverter(int)
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/filter2/recordlevel/FilteringPrimitiveConverter/FilteringPrimitiveConverter(parquet.io.api.PrimitiveConverter,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate.ValueInspector[])
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/column/ColumnDescriptor/getPath()
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#java/util/List/size()
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#java/util/List/addAll(java.util.Collection)
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/io/api/Converter/asPrimitiveConverter()
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/common/schema/ColumnPath/get(java.lang.String[])
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/io/PrimitiveColumnIO/getColumnDescriptor()
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/Preconditions/checkNotNull(T,java.lang.String)
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#parquet/filter2/recordlevel/FilteringGroupConverter/FilteringGroupConverter(parquet.io.api.GroupConverter,java.util.List,java.util.Map,java.util.Map)
parquet/filter2/recordlevel/FilteringGroupConverter/getConverter(int)#java/util/List/add(E)
parquet/filter2/recordlevel/FilteringGroupConverter/end()#parquet/io/api/GroupConverter/end()
parquet/filter2/recordlevel/FilteringGroupConverter/start()#parquet/io/api/GroupConverter/start()
parquet/proto/ProtoMessageConverter/end()#parquet/proto/ProtoMessageConverter/ParentValueContainer/add(java.lang.Object)
parquet/proto/ProtoMessageConverter/newMessageConverter(Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/newMessageConverter(Message/Builder,Descriptors/FieldDescriptor,parquet/schema/Type)/$anonymous2/()
parquet/proto/ProtoMessageConverter/newMessageConverter(Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/newMessageConverter(Message/Builder,Descriptors/FieldDescriptor,parquet/schema/Type)/$anonymous1/()
parquet/proto/ProtoMessageConverter/newMessageConverter(Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/schema/Type/asGroupType()
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoEnumConverter/ProtoEnumConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Descriptors.FieldDescriptor)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoIntConverter/ProtoIntConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoBooleanConverter/ProtoBooleanConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoMessageConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,java.lang.Class,parquet.schema.GroupType)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#java/lang/String/format(java.lang.String,java.lang.Object[])
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoFloatConverter/ProtoFloatConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoLongConverter/ProtoLongConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoBinaryConverter/ProtoBinaryConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoStringConverter/ProtoStringConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer)
parquet/proto/ProtoMessageConverter/newScalarConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer,Message.Builder,Descriptors.FieldDescriptor,parquet.schema.Type)#parquet/proto/ProtoMessageConverter/ProtoDoubleConverter/ProtoDoubleConverter(parquet.proto.ProtoMessageConverter.ParentValueContainer)
parquet/proto/ProtoRecordConverter/SkipParentValueContainer/add(java.lang.Object)#java/lang/RuntimeException/RuntimeException(java.lang.String)
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/ColumnReader/consume()
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/mem/TestMemColumn/getColumnWriter(parquet.column.ColumnDescriptor,parquet.column.page.mem.MemPageStore)
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/ColumnWriter/write(long,int,int)
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/ColumnReader/getCurrentDefinitionLevel()
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/ColumnReader/getCurrentRepetitionLevel()
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/ColumnReader/getLong()
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/ColumnWriter/flush()
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/ColumnReader/getTotalValueCount()
parquet/column/mem/TestMemColumn/testMemColumn()#parquet/column/mem/TestMemColumn/getColumnReader(parquet.column.page.mem.MemPageStore,parquet.column.ColumnDescriptor,parquet.schema.MessageType)
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/ColumnReader/consume()
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/ColumnWriter/write(parquet.io.api.Binary,int,int)
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/mem/TestMemColumn/newColumnWriteStoreImpl(parquet.column.page.mem.MemPageStore)
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/impl/ColumnWriteStoreImpl/getColumnWriter(parquet.column.ColumnDescriptor)
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/ColumnReader/getCurrentDefinitionLevel()
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/ColumnReader/getCurrentRepetitionLevel()
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/ColumnWriter/flush()
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/ColumnReader/getTotalValueCount()
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/mem/TestMemColumn/getColumnReader(parquet.column.page.mem.MemPageStore,parquet.column.ColumnDescriptor,parquet.schema.MessageType)
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/io/api/Binary/toStringUsingUTF8()
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/io/api/Binary/fromString(java.lang.String)
parquet/column/mem/TestMemColumn/testMemColumnBinary()#parquet/column/ColumnReader/getBinary()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/ColumnReader/consume()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/mem/TestMemColumn/newColumnWriteStoreImpl(parquet.column.page.mem.MemPageStore)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/impl/ColumnWriteStoreImpl/getColumnWriter(parquet.column.ColumnDescriptor)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/ColumnWriter/write(long,int,int)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/ColumnReader/getCurrentDefinitionLevel()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/ColumnReader/getCurrentRepetitionLevel()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/ColumnWriter/flush()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/ColumnReader/getTotalValueCount()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/mem/TestMemColumn/getColumnReader(parquet.column.page.mem.MemPageStore,parquet.column.ColumnDescriptor,parquet.schema.MessageType)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/ColumnReader/getLong()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/Log/debug(java.lang.Object)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPagesRepeated()#parquet/column/ColumnWriter/writeNull(int,int)
parquet/column/mem/TestMemColumn/getColumnWriter(parquet.column.ColumnDescriptor,parquet.column.page.mem.MemPageStore)#parquet/column/mem/TestMemColumn/newColumnWriteStoreImpl(parquet.column.page.mem.MemPageStore)
parquet/column/mem/TestMemColumn/getColumnWriter(parquet.column.ColumnDescriptor,parquet.column.page.mem.MemPageStore)#parquet/column/impl/ColumnWriteStoreImpl/getColumnWriter(parquet.column.ColumnDescriptor)
parquet/column/mem/TestMemColumn/getColumnReader(parquet.column.page.mem.MemPageStore,parquet.column.ColumnDescriptor,parquet.schema.MessageType)#parquet/column/impl/ColumnReadStoreImpl/getColumnReader(parquet.column.ColumnDescriptor)
parquet/column/mem/TestMemColumn/getColumnReader(parquet.column.page.mem.MemPageStore,parquet.column.ColumnDescriptor,parquet.schema.MessageType)#parquet/example/DummyRecordConverter/DummyRecordConverter(parquet.schema.MessageType)
parquet/column/mem/TestMemColumn/getColumnReader(parquet.column.page.mem.MemPageStore,parquet.column.ColumnDescriptor,parquet.schema.MessageType)#parquet/column/impl/ColumnReadStoreImpl/ColumnReadStoreImpl(parquet.column.page.PageReadStore,parquet.io.api.GroupConverter,parquet.schema.MessageType)
parquet/column/mem/TestMemColumn/getColumnReader(parquet.column.page.mem.MemPageStore,parquet.column.ColumnDescriptor,parquet.schema.MessageType)#parquet/example/DummyRecordConverter/getRootConverter()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/ColumnReader/consume()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/schema/MessageType/getColumnDescription(java.lang.String[])
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/mem/TestMemColumn/newColumnWriteStoreImpl(parquet.column.page.mem.MemPageStore)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/impl/ColumnWriteStoreImpl/getColumnWriter(parquet.column.ColumnDescriptor)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/ColumnWriter/write(long,int,int)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/ColumnReader/getCurrentDefinitionLevel()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/ColumnReader/getCurrentRepetitionLevel()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/ColumnReader/getLong()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/ColumnWriter/flush()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/page/mem/MemPageStore/MemPageStore(long)
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/ColumnReader/getTotalValueCount()
parquet/column/mem/TestMemColumn/testMemColumnSeveralPages()#parquet/column/mem/TestMemColumn/getColumnReader(parquet.column.page.mem.MemPageStore,parquet.column.ColumnDescriptor,parquet.schema.MessageType)
parquet/column/mem/TestMemColumn/newColumnWriteStoreImpl(parquet.column.page.mem.MemPageStore)#parquet/column/impl/ColumnWriteStoreImpl/ColumnWriteStoreImpl(parquet.column.page.PageWriteStore,int,int,int,boolean,parquet.column.ParquetProperties.WriterVersion)
parquet/column/values/dictionary/PlainValuesDictionary/PlainFloatDictionary/toString()#java/lang/StringBuilder/append(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainFloatDictionary/toString()#java/lang/StringBuilder/append(int)
parquet/column/values/dictionary/PlainValuesDictionary/PlainFloatDictionary/toString()#java/lang/StringBuilder/StringBuilder(java.lang.String)
parquet/column/values/dictionary/PlainValuesDictionary/PlainFloatDictionary/toString()#java/lang/StringBuilder/append(float)
parquet/column/values/dictionary/PlainValuesDictionary/PlainFloatDictionary/toString()#java/lang/StringBuilder/toString()
parquet/thrift/ParquetWriteProtocol/MessageWriteProtocol/writeStructBegin(parquet.thrift.TStruct)#parquet/io/api/RecordConsumer/startMessage()
parquet/thrift/ParquetWriteProtocol/MessageWriteProtocol/writeStructEnd()#parquet/io/api/RecordConsumer/endMessage()
parquet/cascading/TestParquetTBaseScheme/testReadWithoutClass()#parquet/cascading/TestParquetTBaseScheme/doRead(parquet.cascading.Scheme)
parquet/cascading/TestParquetTBaseScheme/testReadWithoutClass()#parquet/cascading/ParquetTBaseScheme/ParquetTBaseScheme()
parquet/cascading/TestParquetTBaseScheme/testRead()#parquet/cascading/TestParquetTBaseScheme/doRead(parquet.cascading.Scheme)
parquet/cascading/TestParquetTBaseScheme/testRead()#parquet/cascading/ParquetTBaseScheme/ParquetTBaseScheme(java.lang.Class)
parquet/cascading/TestParquetTBaseScheme/createFileForRead()#parquet/hadoop/util/ContextUtil/newTaskAttemptContext(org.apache.hadoop.hive.ql.io.parquet.Configuration,parquet.hadoop.util.TaskAttemptID)
parquet/cascading/TestParquetTBaseScheme/createFileForRead()#java/io/ByteArrayOutputStream/reset()
parquet/cascading/TestParquetTBaseScheme/createFileForRead()#java/io/ByteArrayOutputStream/toByteArray()
parquet/cascading/TestParquetTBaseScheme/createFileForRead()#parquet/hadoop/thrift/ThriftToParquetFileWriter/ThriftToParquetFileWriter(parquet.hadoop.Path,parquet.pig.TaskAttemptContext,parquet.hadoop.thrift.TProtocolFactory,java.lang.Class)
parquet/cascading/TestParquetTBaseScheme/createFileForRead()#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
parquet/cascading/TestParquetTBaseScheme/createFileForRead()#parquet/hadoop/thrift/ThriftToParquetFileWriter/write(parquet.hadoop.thrift.BytesWritable)
parquet/cascading/TestParquetTBaseScheme/createFileForRead()#parquet/hadoop/thrift/ThriftToParquetFileWriter/close()
parquet/cascading/TestParquetTBaseScheme/testWrite()#parquet/cascading/TestParquetTBaseScheme/PackThriftFunction/PackThriftFunction()
parquet/cascading/TestParquetTBaseScheme/testWrite()#parquet/cascading/ParquetTBaseScheme/ParquetTBaseScheme(java.lang.Class)
parquet/cascading/TestParquetTBaseScheme/testWrite()#java/lang/Object/Object()
parquet/cascading/TestParquetTBaseScheme/doRead(parquet.cascading.Scheme)#parquet/cascading/TestParquetTBaseScheme/UnpackThriftFunction/UnpackThriftFunction()
parquet/cascading/TestParquetTBaseScheme/doRead(parquet.cascading.Scheme)#java/io/File/File(java.lang.String)
parquet/cascading/TestParquetTBaseScheme/doRead(parquet.cascading.Scheme)#parquet/cascading/TestParquetTBaseScheme/createFileForRead()
parquet/cascading/TestParquetTBaseScheme/doRead(parquet.cascading.Scheme)#java/lang/Object/Object()
parquet/column/values/plain/PlainValuesReader/LongPlainValuesReader/skip()#parquet/bytes/LittleEndianDataInputStream/skipBytes(int)
parquet/column/values/plain/PlainValuesReader/LongPlainValuesReader/skip()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/column/values/plain/PlainValuesReader/LongPlainValuesReader/readLong()#parquet/bytes/LittleEndianDataInputStream/readLong()
parquet/column/values/plain/PlainValuesReader/LongPlainValuesReader/readLong()#parquet/io/ParquetDecodingException/ParquetDecodingException(java.lang.String,java.lang.Throwable)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsEven()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/updateNull()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/And/And(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/doubleMoreThan10()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter/reset(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(int)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator/intIsNull()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/update(double)
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/ValueInspector/isKnown()
parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter/testReset()#parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate/Or/Or(parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate,parquet.filter2.recordlevel.IncrementallyUpdatedFilterPredicate)
parquet/column/values/RandomStr/alphanumeric()#java/lang/StringBuffer/StringBuffer(int)
parquet/column/values/RandomStr/alphanumeric()#java/lang/StringBuffer/append(char)
parquet/column/values/RandomStr/alphanumeric()#java/lang/StringBuffer/toString()
parquet/column/values/RandomStr/alphanumeric()#java/lang/String/toCharArray()
parquet/column/values/RandomStr/get(int)#java/lang/StringBuffer/length()
parquet/column/values/RandomStr/get(int)#java/lang/StringBuffer/toString()
parquet/column/values/RandomStr/get(int)#java/lang/StringBuffer/append(char)
parquet/column/values/RandomStr/get(int)#java/util/Random/nextInt()
parquet/column/values/RandomStr/get(int)#java/lang/Math/abs(int)
parquet/column/values/RandomStr/get(int)#java/lang/StringBuffer/StringBuffer()
parquet/filter2/predicate/Operators/GtEq/accept(parquet.filter2.predicate.FilterPredicate.Visitor)#parquet/filter2/predicate/FilterPredicate/Visitor/visit(parquet.filter2.predicate.Operators.GtEq)
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/io/api/RecordConsumer/addBinary(parquet.io.api.Binary)
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/io/api/RecordConsumer/addFloat(float)
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/schema/PrimitiveType/getPrimitiveTypeName()
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/io/api/RecordConsumer/addLong(long)
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/io/api/RecordConsumer/addBoolean(boolean)
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/io/api/RecordConsumer/addDouble(double)
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/io/api/RecordConsumer/addInteger(int)
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/schema/Type/getName()
parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)#parquet/io/api/Binary/fromString(java.lang.String)
parquet/cascading/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
parquet/cascading/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#java/util/HashMap/HashMap()
parquet/cascading/TupleWriteSupport/init(org.apache.hadoop.hive.ql.io.parquet.Configuration)#parquet/hadoop/api/WriteSupport/WriteContext/WriteContext(parquet.schema.MessageType,java.util.Map)
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/schema/GroupType/getFields()
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/io/api/RecordConsumer/startMessage()
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/schema/Type/asPrimitiveType()
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/io/api/RecordConsumer/endMessage()
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#java/util/List/size()
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/io/api/RecordConsumer/startField(java.lang.String,int)
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/io/api/RecordConsumer/endField(java.lang.String,int)
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/schema/Type/isPrimitive()
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#java/util/List/get(int)
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/cascading/TupleWriteSupport/writePrimitive(parquet.cascading.TupleEntry,parquet.schema.PrimitiveType)
parquet/cascading/TupleWriteSupport/write(parquet.cascading.TupleEntry)#parquet/schema/Type/getName()
parquet/thrift/struct/ThriftType/ByteType/accept(parquet.thrift.struct.ThriftType.TypeVisitor)#parquet/thrift/struct/ThriftType/TypeVisitor/visit(parquet.thrift.struct.ThriftType.ByteType)
parquet/thrift/projection/amend/DefaultEventsVisitor/StringProtocol/readBinary()#java/nio/ByteBuffer/wrap(byte[])
parquet/thrift/projection/amend/DefaultEventsVisitor/StringProtocol/readBinary()#java/lang/String/getBytes()
parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest/writeRLEWithSmallBitWidthTest()#parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter/RunLengthBitPackingHybridValuesWriter(int,int)
parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest/writeRLEWithSmallBitWidthTest()#parquet/column/values/delta/benchmark/BenchMarkTest/runWriteTest(parquet.column.values.ValuesWriter)
parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest/prepare()#java/util/Random/nextInt(int)
parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest/prepare()#java/util/Random/Random()
