org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#java/lang/Class/isAssignableFrom(java.lang.Class)
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$ByteWritableConverter/ByteWritableConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#java/lang/Class/getName()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$TextConverter/TextConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$LongWritableConverter/LongWritableConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#java/lang/StringBuilder/toString()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$NullWritableConverter/NullWritableConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$AvroWrapperConverter/AvroWrapperConverter(org.apache.avro.Schema)
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory/getConf()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$FloatWritableConverter/FloatWritableConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$BooleanWritableConverter/BooleanWritableConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$BytesWritableConverter/BytesWritableConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$DoubleWritableConverter/DoubleWritableConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/avro/hadoop/io/AvroDatumConverterFactory$IntWritableConverter/IntWritableConverter()
org/apache/avro/hadoop/io/AvroDatumConverterFactory/create(java.lang.Class)#org/apache/hadoop/mapred/JobConf/getNumReduceTasks()
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setOutputKeyClass(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/getBoolean(java.lang.String,boolean)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setOutputFormat(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/getStringCollection(java.lang.String)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setStrings(java.lang.String,java.lang.String[])
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setMapOutputValueClass(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setOutputKeyComparatorClass(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#java/util/Collection/add(java.lang.Object)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setMapRunnerClass(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setReducerClass(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#java/util/Collection/toArray(java.lang.Object[])
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#java/lang/Class/getName()
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setInputFormat(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setPartitionerClass(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#java/util/Collection/contains(java.lang.Object)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setMapOutputKeyClass(java.lang.Class)
org/apache/avro/mapred/tether/TetherJob/setupTetherJob(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/filecache/DistributedCache/addCacheFile(java.net.URI,org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/lang/Boolean/toString()
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/util/Iterator/hasNext()
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/util/Iterator/next()
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/lang/StringBuilder/append(char)
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/util/List/iterator()
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/lang/Boolean/Boolean(boolean)
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/lang/StringBuilder/toString()
org/apache/avro/mapred/tether/TetherJob/setExecutable(org.apache.hadoop.mapred.JobConf,java.io.File,java.util.List,boolean)#java/io/File/toString()
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/Schema/parse(java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/JobConf/setOutputFormat(java.lang.Class)
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/JobConf/JobConf(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/mapred/AvroMultipleOutputs$InternalFileOutputFormat/getUniqueName(org.apache.hadoop.mapred.JobConf,java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/JobConf/getOutputFormat()
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/JobConf/get(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/JobConf/getNumReduceTasks()
org/apache/avro/mapred/AvroMultipleOutputs/InternalFileOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/toString()
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#org/apache/avro/generic/GenericData/deepCopy(org.apache.avro.Schema,java.lang.Object)
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#java/lang/Long/valueOf(long)
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#org/apache/avro/generic/GenericData$Record/Record(org.apache.avro.Schema)
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#org/apache/avro/generic/GenericData/compare(java.lang.Object,java.lang.Object,org.apache.avro.Schema)
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#java/lang/StringBuilder/append(java.lang.Object)
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#org/apache/avro/file/DataFileWriter/append(java.lang.Object)
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#java/lang/StringBuilder/toString()
org/apache/avro/hadoop/file/SortedKeyValueFile/Writer/append(java.lang.Object,java.lang.Object)#org/apache/avro/file/DataFileWriter/sync()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Map$Entry/getKey()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/List/size()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#org/apache/hadoop/mapred/JobConf/JobConf(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#org/apache/hadoop/mapred/JobConf/getMapperClass()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Set/iterator()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Map/containsKey(java.lang.Object)
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Map/entrySet()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Map/put(java.lang.Object,java.lang.Object)
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/ArrayList/ArrayList()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Iterator/hasNext()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#org/apache/hadoop/util/ReflectionUtils/newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#org/apache/hadoop/mapred/FileInputFormat/setInputPaths(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path[])
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Map/get(java.lang.Object)
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Iterator/next()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/HashMap/HashMap()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/List/toArray(java.lang.Object[])
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/LinkedList/LinkedList()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#org/apache/hadoop/mapred/InputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/List/add(java.lang.Object)
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/lang/Object/getClass()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/Map$Entry/getValue()
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/io/PrintStream/println(java.lang.Object)
org/apache/avro/mapred/DelegatingInputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)#java/util/List/iterator()
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/mapred/AvroTextOutputFormat$AvroTextRecordWriter/AvroTextRecordWriter(org.apache.avro.mapred.AvroTextOutputFormat,org.apache.avro.file.DataFileWriter,byte[])
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/Schema/create(org.apache.avro.Schema$Type)
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/String/getBytes(java.lang.String)
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/reflect/ReflectDatumWriter/ReflectDatumWriter()
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/JobConf/get(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/toString()
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/file/DataFileWriter/DataFileWriter(org.apache.avro.io.DatumWriter)
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/file/DataFileWriter/create(org.apache.avro.Schema,java.io.OutputStream)
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path)
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/AvroTextOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/FileOutputFormat/getTaskOutputPath(org.apache.hadoop.mapred.JobConf,java.lang.String)
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#org/apache/avro/Schema/parse(java.lang.String)
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#org/apache/hadoop/io/SequenceFile$Metadata/get(org.apache.hadoop.io.Text)
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#org/apache/hadoop/io/Text/toString()
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#java/lang/StringBuilder/StringBuilder()
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/getInputPath()
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/getFileSystem()
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/getConfiguration()
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#java/lang/StringBuilder/toString()
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#org/slf4j/Logger/debug(java.lang.String)
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/hadoop/io/AvroSequenceFile/Reader/Options/getConfigurationWithAvroSerialization()#org/apache/hadoop/conf/Configuration/Configuration(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/getCompressOutput(org.apache.hadoop.mapreduce.JobContext)
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#java/lang/String/equals(java.lang.Object)
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/conf/Configuration/get(java.lang.String)
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/file/CodecFactory/nullCodec()
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/file/CodecFactory/fromString(java.lang.String)
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/file/CodecFactory/deflateCodec(int)
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/TaskAttemptContext/getConfiguration()
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/file/CodecFactory/xzCodec(int)
org/apache/avro/mapreduce/AvroOutputFormatBase/getCompressionCodec(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/conf/Configuration/getInt(java.lang.String,int)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#org/apache/avro/Schema/toString()
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#org/apache/hadoop/mapred/Reporter/getCounter(java.lang.String,java.lang.String)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#org/apache/hadoop/mapred/JobConf/get(java.lang.String)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#org/apache/hadoop/mapred/RecordReader/next(java.lang.Object,java.lang.Object)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#java/lang/StringBuilder/append(java.lang.Object)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#org/apache/hadoop/mapred/JobConf/getNumReduceTasks()
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#java/io/IOException/IOException(java.lang.String)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#org/slf4j/Logger/warn(java.lang.String,java.lang.Throwable)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#java/io/IOException/IOException(java.lang.String,java.lang.Throwable)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#org/apache/hadoop/mapred/Counters$Counter/increment(long)
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#java/lang/StringBuilder/toString()
org/apache/avro/mapred/tether/TetherMapRunner/run(org.apache.hadoop.mapred.RecordReader,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter)#org/apache/hadoop/io/NullWritable/get()
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/JobConf/getInt(java.lang.String,int)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/file/CodecFactory/deflateCodec(int)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/FileOutputFormat/getCompressOutput(org.apache.hadoop.mapred.JobConf)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/file/DataFileWriter/setCodec(org.apache.avro.file.CodecFactory)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/generic/GenericDatumWriter/GenericDatumWriter()
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/mapred/tether/TetherOutputFormat$1/1(org.apache.avro.mapred.tether.TetherOutputFormat,org.apache.avro.file.DataFileWriter)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/toString()
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/file/DataFileWriter/DataFileWriter(org.apache.avro.io.DatumWriter)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/file/DataFileWriter/create(org.apache.avro.Schema,java.io.OutputStream)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/tether/TetherOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/FileOutputFormat/getTaskOutputPath(org.apache.hadoop.mapred.JobConf,java.lang.String)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Reader/Reader(org.apache.avro.hadoop.io.AvroSequenceFile$Reader$Options)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/lib/input/FileSplit/getStart()
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/withConfiguration(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/withKeySchema(org.apache.avro.Schema)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/io/SequenceFile$Reader/sync(long)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/lib/input/FileSplit/getPath()
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/lib/input/FileSplit/getLength()
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/TaskAttemptContext/getConfiguration()
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/withInputPath(org.apache.hadoop.fs.Path)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/withValueSchema(org.apache.avro.Schema)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/Options()
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Reader$Options/withFileSystem(org.apache.hadoop.fs.FileSystem)
org/apache/avro/mapreduce/AvroSequenceFileInputFormat/AvroSequenceFileRecordReader/initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/io/SequenceFile$Reader/getPosition()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getOutputPath()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getFileSystem()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getCompressionCodec()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getReplicationFactor()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getCompressionType()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getKeyClass()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getBlockSizeBytes()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getConfigurationWithAvroSerialization()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getBufferSizeBytes()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getValueClass()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/getProgressable()
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/hadoop/io/SequenceFile/createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,int,short,long,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)
org/apache/avro/hadoop/io/AvroSequenceFile/createWriter(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/access$000(org.apache.avro.hadoop.io.AvroSequenceFile$Writer$Options)
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/mapred/SequenceFileReader$10/10()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#java/util/Map/put(java.lang.Object,java.lang.Object)
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/mapred/SequenceFileReader$3/3()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/mapred/SequenceFileReader$4/4()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/mapred/SequenceFileReader$5/5()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/mapred/SequenceFileReader$6/6()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/mapred/SequenceFileReader$7/7()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/mapred/SequenceFileReader$8/8()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/mapred/SequenceFileReader$9/9()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#java/util/HashMap/HashMap()
org/apache/avro/mapred/SequenceFileReader/<clinit>()#org/apache/avro/Schema/create(org.apache.avro.Schema$Type)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/ProcessBuilder/ProcessBuilder(java.util.List)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/getBoolean(java.lang.String,boolean)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/fs/FileUtil/chmod(java.lang.String,java.lang.String)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/String/split(java.lang.String)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/TaskLog/getTaskLogLength(org.apache.hadoop.mapred.JobConf)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/String/trim()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/net/URI/toString()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/util/Map/putAll(java.util.Map)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/ProcessBuilder/start()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/util/HashMap/HashMap()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/String/toString()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/System/getProperty(java.lang.String)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/System/setProperty(java.lang.String,java.lang.String)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/TaskLog/getTaskLogFile(org.apache.hadoop.mapred.TaskAttemptID,boolean,org.apache.hadoop.mapred.TaskLog$LogName)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/fs/Path/Path(java.lang.String)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/ProcessBuilder/environment()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/fs/Path/toString()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/util/Map/put(java.lang.Object,java.lang.Object)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/util/ArrayList/ArrayList()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/Integer/toString(int)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/String/length()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/TaskLog/captureOutAndError(java.util.List,java.util.List,java.io.File,java.io.File,long,boolean)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/filecache/DistributedCache/getCacheFiles(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/util/List/add(java.lang.Object)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/io/File/mkdirs()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/get(java.lang.String)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/io/PrintStream/println(java.lang.Object)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/lang/System/getenv(java.lang.String)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/filecache/DistributedCache/getLocalCacheFiles(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#org/apache/avro/ipc/Server/getPort()
org/apache/avro/mapred/tether/TetheredProcess/startSubprocess(org.apache.hadoop.mapred.JobConf)#java/io/File/getParentFile()
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/getStringCollection(java.lang.String)
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setStrings(java.lang.String,java.lang.String[])
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setMapOutputValueClass(java.lang.Class)
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setOutputKeyComparatorClass(java.lang.Class)
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#java/util/Collection/add(java.lang.Object)
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#java/util/Collection/contains(java.lang.Object)
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/setMapOutputKeyClass(java.lang.Class)
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#java/util/Collection/toArray(java.lang.Object[])
org/apache/avro/mapred/AvroJob/configureAvroShuffle(org.apache.hadoop.mapred.JobConf)#java/lang/Class/getName()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/util/Iterator/hasNext()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#org/apache/avro/hadoop/file/SortedKeyValueFile$Reader/iterator()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#org/apache/avro/generic/GenericData/compare(java.lang.Object,java.lang.Object,org.apache.avro.Schema)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/util/NavigableMap/floorEntry(java.lang.Object)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/lang/StringBuilder/toString()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#org/slf4j/Logger/debug(java.lang.String)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/util/Iterator/next()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/lang/Long/longValue()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#org/apache/avro/file/DataFileReader/seek(long)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/lang/StringBuilder/append(java.lang.Object)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/get(java.lang.Object)#java/util/Map$Entry/getValue()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#org/apache/avro/file/DataFileReader/DataFileReader(org.apache.avro.file.SeekableInput,org.apache.avro.io.DatumReader)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#org/apache/avro/file/DataFileReader/iterator()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#java/util/Iterator/hasNext()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#org/apache/avro/Schema/equals(java.lang.Object)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#org/apache/avro/generic/GenericData/createDatumReader(org.apache.avro.Schema)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#java/util/NavigableMap/put(java.lang.Object,java.lang.Object)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#java/util/TreeMap/TreeMap()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#java/util/Iterator/next()
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#org/apache/avro/Schema/create(org.apache.avro.Schema$Type)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#java/util/TreeMap/TreeMap(java.util.Comparator)
org/apache/avro/hadoop/file/SortedKeyValueFile/Reader/loadIndexFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.avro.Schema)#org/apache/avro/file/DataFileReader/close()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#org/apache/avro/generic/GenericData/toString(java.lang.Object)
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#org/apache/hadoop/io/Text/set(byte[],int,int)
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#java/nio/ByteBuffer/position()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#org/apache/hadoop/io/Text/set(byte[])
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#java/nio/ByteBuffer/duplicate()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#org/apache/hadoop/io/Text/set(java.lang.String)
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#org/apache/avro/file/FileReader/pastSync(long)
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#java/nio/ByteBuffer/remaining()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#java/nio/ByteBuffer/array()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#java/nio/ByteBuffer/hasArray()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#org/apache/avro/file/FileReader/next(java.lang.Object)
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#org/apache/avro/file/FileReader/hasNext()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#org/apache/avro/generic/GenericData/get()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#java/nio/ByteBuffer/arrayOffset()
org/apache/avro/mapred/AvroAsTextRecordReader/next(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)#java/nio/ByteBuffer/get(byte[])
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/util/ReflectionUtils/newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withValueClass(java.lang.Class)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withProgressable(org.apache.hadoop.util.Progressable)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withFileSystem(org.apache.hadoop.fs.FileSystem)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getDefaultWorkFile(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withCompressionType(org.apache.hadoop.io.SequenceFile$CompressionType)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withKeyClass(java.lang.Class)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/TaskAttemptContext/getOutputKeyClass()
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getOutputCompressorClass(org.apache.hadoop.mapreduce.JobContext,java.lang.Class)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/TaskAttemptContext/getConfiguration()
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withValueSchema(org.apache.avro.Schema)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/Options()
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getCompressOutput(org.apache.hadoop.mapreduce.JobContext)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/mapreduce/AvroSequenceFileOutputFormat$1/1(org.apache.avro.mapreduce.AvroSequenceFileOutputFormat,org.apache.hadoop.io.SequenceFile$Writer)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/hadoop/mapreduce/TaskAttemptContext/getOutputValueClass()
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withConfiguration(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withOutputPath(org.apache.hadoop.fs.Path)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withKeySchema(org.apache.avro.Schema)
org/apache/avro/mapreduce/AvroSequenceFileOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)#org/apache/avro/hadoop/io/AvroSequenceFile$Writer$Options/withCompressionCodec(org.apache.hadoop.io.compress.CompressionCodec)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#java/util/Map/put(java.lang.Object,java.lang.Object)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#java/util/Map/get(java.lang.Object)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#org/apache/avro/mapred/AvroMultipleOutputs$RecordWriterWithCounter/RecordWriterWithCounter(org.apache.hadoop.mapred.RecordWriter,java.lang.String,org.apache.hadoop.mapred.Reporter)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#org/apache/hadoop/fs/FileSystem/get(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#java/lang/StringBuilder/toString()
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/JobConf(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/AvroMultipleOutputs/getRecordWriter(java.lang.String,java.lang.String,org.apache.hadoop.mapred.Reporter,org.apache.avro.Schema)#org/apache/avro/Schema/toString()
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#org/apache/avro/Schema/toString()
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/setClass(java.lang.String,java.lang.Class,java.lang.Class)
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/setBoolean(java.lang.String,boolean)
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#java/lang/StringBuilder/toString()
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/get(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroMultipleOutputs/addNamedOutput(org.apache.hadoop.mapred.JobConf,java.lang.String,boolean,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/getNumReduceTasks()
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#java/util/Map/put(java.lang.Object,java.lang.Object)
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#java/util/Map/get(java.lang.Object)
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#org/apache/hadoop/mapreduce/Job/getConfiguration()
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#org/apache/hadoop/mapreduce/Job/setOutputFormatClass(java.lang.Class)
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#org/apache/hadoop/conf/Configuration/get(java.lang.String,java.lang.String)
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#org/apache/hadoop/conf/Configuration/get(java.lang.String)
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#java/lang/StringBuilder/toString()
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#org/apache/hadoop/mapreduce/TaskInputOutputContext/getConfiguration()
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#org/apache/avro/Schema/parse(java.lang.String)
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapreduce/AvroMultipleOutputs/getContext(java.lang.String)#org/apache/hadoop/mapreduce/TaskInputOutputContext/getTaskAttemptID()
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#java/util/Map/put(java.lang.Object,java.lang.Object)
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#org/apache/hadoop/mapreduce/TaskAttemptContext/getConfiguration()
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#org/apache/hadoop/util/ReflectionUtils/newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#org/apache/avro/mapreduce/AvroMultipleOutputs$RecordWriterWithCounter/RecordWriterWithCounter(org.apache.hadoop.mapreduce.RecordWriter,java.lang.String,org.apache.hadoop.mapreduce.TaskInputOutputContext)
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#java/util/Map/get(java.lang.Object)
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#org/apache/hadoop/mapreduce/TaskAttemptContext/getOutputFormatClass()
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#org/apache/hadoop/mapreduce/OutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)
org/apache/avro/mapreduce/AvroMultipleOutputs/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)#java/io/IOException/IOException(java.lang.Throwable)
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/generic/GenericData/createDatumWriter(org.apache.avro.Schema)
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/mapred/AvroOutputFormat$1/1(org.apache.avro.mapred.AvroOutputFormat,org.apache.avro.file.DataFileWriter)
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/JobConf/getNumReduceTasks()
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/toString()
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/file/DataFileWriter/DataFileWriter(org.apache.avro.io.DatumWriter)
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/avro/file/DataFileWriter/create(org.apache.avro.Schema,java.io.OutputStream)
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path)
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)#org/apache/hadoop/mapred/FileOutputFormat/getTaskOutputPath(org.apache.hadoop.mapred.JobConf,java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#org/apache/avro/file/DataFileWriter/setSyncInterval(int)
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/util/Iterator/hasNext()
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/util/Map$Entry/getKey()
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/lang/String/length()
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#org/apache/avro/file/DataFileWriter/setCodec(org.apache.avro.file.CodecFactory)
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/util/Iterator/next()
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/net/URLDecoder/decode(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/lang/String/startsWith(java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/util/Map$Entry/getValue()
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#org/apache/avro/file/DataFileWriter/setMeta(java.lang.String,byte[])
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/iterator()
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#org/apache/avro/file/DataFileWriter/setMeta(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/getInt(java.lang.String,int)
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/lang/String/getBytes(java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/configureDataFileWriter(org.apache.avro.file.DataFileWriter,org.apache.hadoop.mapred.JobConf)#java/lang/String/substring(int)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/getInt(java.lang.String,int)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#org/apache/avro/file/CodecFactory/deflateCodec(int)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/FileOutputFormat/getCompressOutput(org.apache.hadoop.mapred.JobConf)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/get(java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/get(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#org/apache/avro/file/CodecFactory/fromString(java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#java/lang/String/equals(java.lang.Object)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroOutputFormat/getCodecFactory(org.apache.hadoop.mapred.JobConf)#org/apache/avro/file/CodecFactory/xzCodec(int)
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#java/util/Map/put(java.lang.Object,java.lang.Object)
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#java/util/Collections/emptyMap()
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#java/lang/String/split(java.lang.String)
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#java/lang/RuntimeException/RuntimeException(java.lang.Throwable)
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#java/util/HashMap/HashMap()
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#org/apache/avro/Schema$Parser/Parser()
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#org/apache/avro/Schema$Parser/parse(java.lang.String)
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/mapred/JobConf/get(java.lang.String)
org/apache/avro/mapred/AvroMultipleInputs/getInputSchemaMap(org.apache.hadoop.mapred.JobConf)#org/apache/hadoop/fs/Path/Path(java.lang.String)
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/fs/Path/toString()
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#java/lang/StringBuilder/StringBuilder()
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/get(java.lang.String)
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/setMapperClass(java.lang.Class)
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#java/lang/StringBuilder/toString()
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#java/lang/StringBuilder/append(java.lang.String)
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#java/io/PrintStream/println(java.lang.String)
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)
org/apache/avro/mapred/AvroMultipleInputs/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,org.apache.avro.Schema)#java/lang/Class/getName()
