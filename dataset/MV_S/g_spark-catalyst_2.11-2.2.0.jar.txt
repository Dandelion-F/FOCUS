org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#org/apache/spark/sql/catalyst/CatalystTypeConverters$/org$apache$spark$sql$catalyst$CatalystTypeConverters$$isPrimitive(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#org/apache/spark/sql/catalyst/CatalystTypeConverters$MapConverter$$anonfun$4/4(org.apache.spark.sql.catalyst.CatalystTypeConverters$MapConverter)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#org/apache/spark/sql/catalyst/CatalystTypeConverters$MapConverter$$anonfun$3/3(org.apache.spark.sql.catalyst.CatalystTypeConverters$MapConverter)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#org/apache/spark/sql/catalyst/CatalystTypeConverters$MapConverter/keyType()
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/CatalystTypeConverters/MapConverter/toScala(org.apache.spark.sql.catalyst.util.MapData)#org/apache/spark/sql/catalyst/CatalystTypeConverters$MapConverter/valueType()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitSimpleCase$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitSimpleCase$1$$anonfun$44/44(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitSimpleCase$1,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitSimpleCase$1$$anonfun$apply$38/38(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitSimpleCase$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSimpleCase/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SimpleCaseContext/whenClause()
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParserUtils$/unescapeSQLString(java.lang.String)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/Predef$/char2Character(char)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#java/lang/String/length()
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParserUtils$$anonfun$1/1(java.lang.String,int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder(int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/collection/immutable/Range/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/collection/mutable/StringBuilder/append(char)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/RichInt$/until$extension0(int,int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/Predef$/intWrapper(int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#java/lang/String/charAt(int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParserUtils$/appendEscapedChar$1(char,scala.collection.mutable.StringBuilder)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Join/constraints()
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Set/$minus$minus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Filter/constraints()
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Set/reduceOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Set/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Some/x()
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Set/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints$$anonfun$inferFilters$1$$anonfun$23/23(org.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints$$anonfun$inferFilters$1,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraints/anonfun/inferFilters/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/constraints()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/types/StructField$/apply$default$4()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/4/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/ExtractValue$/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$31/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/31/anonfun/apply/50/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/delta()
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/g()
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile$PercentileDigestSerializer/length(org.apache.spark.sql.catalyst.util.QuantileSummaries)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile$PercentileDigest/quantileSummaries()
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#java/nio/ByteBuffer/array()
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/value()
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#java/nio/ByteBuffer/putInt(int)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#java/nio/ByteBuffer/putLong(long)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#java/nio/ByteBuffer/putDouble(double)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/PercentileDigestSerializer/serialize(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile$PercentileDigest)#java/nio/ByteBuffer/wrap(byte[])
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal$/double2bigDecimal(double)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/ceil(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Sample$$anonfun$25/25(org.apache.spark.sql.catalyst.plans.logical.Sample,double)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal/$times(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/Sample/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$minus(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$plus(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$div(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#org/apache/spark/sql/catalyst/dsl/package$expressions$/intToLiteral(int)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#org/apache/spark/sql/catalyst/dsl/package$expressions$/longToLiteral(long)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#org/apache/spark/sql/catalyst/dsl/package$expressions$/DslExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/anonfun/99/apply(int)#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$times(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/Encoders/TIMESTAMP()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/TIMESTAMP()#org/apache/spark/sql/Encoders$$typecreator11$1/1()
org/apache/spark/sql/Encoders/TIMESTAMP()#org/apache/spark/sql/Encoders$/TIMESTAMP()
org/apache/spark/sql/Encoders/TIMESTAMP()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/TIMESTAMP()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/TIMESTAMP()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/TIMESTAMP()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/TIMESTAMP()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/TIMESTAMP()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/BINARY()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/BINARY()#org/apache/spark/sql/Encoders$$typecreator12$1/1()
org/apache/spark/sql/Encoders/BINARY()#org/apache/spark/sql/Encoders$/BINARY()
org/apache/spark/sql/Encoders/BINARY()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/BINARY()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/BINARY()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/BINARY()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/BINARY()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/BINARY()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/BYTE()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/BYTE()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/BYTE()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/BYTE()#org/apache/spark/sql/Encoders$/BYTE()
org/apache/spark/sql/Encoders/BYTE()#org/apache/spark/sql/Encoders$$typecreator2$1/1()
org/apache/spark/sql/Encoders/BYTE()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/BYTE()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/BYTE()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/BYTE()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/BOOLEAN()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/BOOLEAN()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/BOOLEAN()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/BOOLEAN()#org/apache/spark/sql/Encoders$$typecreator1$1/1()
org/apache/spark/sql/Encoders/BOOLEAN()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/BOOLEAN()#org/apache/spark/sql/Encoders$/BOOLEAN()
org/apache/spark/sql/Encoders/BOOLEAN()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/BOOLEAN()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/BOOLEAN()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/DATE()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/DATE()#org/apache/spark/sql/Encoders$$typecreator10$1/1()
org/apache/spark/sql/Encoders/DATE()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/DATE()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/DATE()#org/apache/spark/sql/Encoders$/DATE()
org/apache/spark/sql/Encoders/DATE()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/DATE()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/DATE()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/DATE()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/DECIMAL()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/DECIMAL()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/DECIMAL()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/DECIMAL()#org/apache/spark/sql/Encoders$$typecreator9$1/1()
org/apache/spark/sql/Encoders/DECIMAL()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/DECIMAL()#org/apache/spark/sql/Encoders$/DECIMAL()
org/apache/spark/sql/Encoders/DECIMAL()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/DECIMAL()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/DECIMAL()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/LONG()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/LONG()#org/apache/spark/sql/Encoders$/LONG()
org/apache/spark/sql/Encoders/LONG()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/LONG()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/LONG()#org/apache/spark/sql/Encoders$$typecreator5$1/1()
org/apache/spark/sql/Encoders/LONG()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/LONG()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/LONG()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/LONG()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/FLOAT()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/FLOAT()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/FLOAT()#org/apache/spark/sql/Encoders$/FLOAT()
org/apache/spark/sql/Encoders/FLOAT()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/FLOAT()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/FLOAT()#org/apache/spark/sql/Encoders$$typecreator6$1/1()
org/apache/spark/sql/Encoders/FLOAT()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/FLOAT()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/FLOAT()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/SHORT()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/SHORT()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/SHORT()#org/apache/spark/sql/Encoders$/SHORT()
org/apache/spark/sql/Encoders/SHORT()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/SHORT()#org/apache/spark/sql/Encoders$$typecreator3$1/1()
org/apache/spark/sql/Encoders/SHORT()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/SHORT()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/SHORT()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/SHORT()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/DOUBLE()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/DOUBLE()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/DOUBLE()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/DOUBLE()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/DOUBLE()#org/apache/spark/sql/Encoders$$typecreator7$1/1()
org/apache/spark/sql/Encoders/DOUBLE()#org/apache/spark/sql/Encoders$/DOUBLE()
org/apache/spark/sql/Encoders/DOUBLE()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/DOUBLE()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/DOUBLE()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/STRING()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/STRING()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/STRING()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/STRING()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/STRING()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/STRING()#org/apache/spark/sql/Encoders$/STRING()
org/apache/spark/sql/Encoders/STRING()#org/apache/spark/sql/Encoders$$typecreator8$1/1()
org/apache/spark/sql/Encoders/STRING()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/STRING()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/INT()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/INT()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/INT()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/INT()#org/apache/spark/sql/Encoders$$typecreator4$1/1()
org/apache/spark/sql/Encoders/INT()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/INT()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/INT()#org/apache/spark/sql/Encoders$/INT()
org/apache/spark/sql/Encoders/INT()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/INT()#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#org/apache/hadoop/fs/FileSystem/mkdirs(org.apache.hadoop.fs.Path)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$createPartitions$1$$anonfun$5/5(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog$$anonfun$createPartitions$1,org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$createPartitions$1$$anonfun$4/4(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog$$anonfun$createPartitions$1)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#org/apache/hadoop/fs/Path/toUri()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/createPartitions/1/apply(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation$/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/math/BigInt$/apply(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/math/BigInt/min(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/rowCountsExist(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputMap(org.apache.spark.sql.catalyst.expressions.AttributeMap,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation$$anonfun$1/1(org.apache.spark.sql.catalyst.plans.logical.Statistics)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation$$anonfun$2/2(org.apache.spark.sql.catalyst.plans.logical.Statistics)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/package$/BigInt()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#org/apache/spark/sql/catalyst/plans/LeftExistence$/unapply(org.apache.spark.sql.catalyst.plans.JoinType)
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#scala/collection/immutable/Set$/empty()
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/constraints()
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#scala/Predef$/Set()
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#scala/Option/isDefined()
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#scala/collection/Seq/toSet()
org/apache/spark/sql/catalyst/plans/logical/Join/validConstraints()#scala/collection/Set/union(scala.collection.GenSet)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#org/apache/spark/sql/catalyst/plans/LeftExistence$/unapply(org.apache.spark.sql.catalyst.plans.JoinType)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/Join/output()#org/apache/spark/sql/catalyst/plans/logical/Join$$anonfun$output$7/7(org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#scala/collection/Seq/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/Join/output()#org/apache/spark/sql/catalyst/plans/logical/Join$$anonfun$output$5/5(org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#org/apache/spark/sql/catalyst/plans/logical/Join$$anonfun$output$6/6(org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/plans/logical/Join/output()#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Join/output()#org/apache/spark/sql/catalyst/plans/logical/Join$$anonfun$output$8/8(org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/Some/get()
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/anonfun/10/apply(scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#org/apache/spark/sql/types/Decimal$$anonfun$ceil$1/apply()
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/types/Decimal/anonfun/ceil/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Expression/transformDown(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Expression/fastEquals(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32$$anonfun$apply$51$$anonfun$2/2(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32$$anonfun$apply$51)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32$$anonfun$apply$51$$anonfun$1/1(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32$$anonfun$apply$51)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$rowToColumnStat$2/2()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$rowToColumnStat$4/4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/package$/BigInt()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/math/BigInt$/apply(long)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$rowToColumnStat$3/3(org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$rowToColumnStat$1/1(org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Option/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/aggregate/Count$/apply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/fixedLenTypeStruct$1(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Least,org.apache.spark.sql.catalyst.expressions.Subtract,org.apache.spark.sql.catalyst.expressions.Literal)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/Attribute/nullable()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus$/apply$default$4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/struct$1(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#scala/Option/foreach(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/KEY_VERSION()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#scala/math/BigInt/toString()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_DISTINCT_COUNT()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_MAX_LEN()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$toMap$2/2(org.apache.spark.sql.catalyst.plans.logical.ColumnStat,java.lang.String,org.apache.spark.sql.types.DataType,scala.collection.mutable.HashMap)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/HashMap/HashMap()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/HashMap/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_AVG_LEN()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_NULL_COUNT()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/toMap(java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$toMap$1/1(org.apache.spark.sql.catalyst.plans.logical.ColumnStat,java.lang.String,org.apache.spark.sql.types.DataType,scala.collection.mutable.HashMap)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_AVG_LEN()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$7/7(java.lang.String,org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$1/1(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Option/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_DISTINCT_COUNT()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_MAX_VALUE()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/math/BigInt$/apply(long)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_MIN_VALUE()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/util/control/NonFatal$/unapply(java.lang.Throwable)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$3/3(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/Map/apply(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$5/5(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_MAX_LEN()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$6/6(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/package$/BigInt()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$2/2()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/Map/get(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_NULL_COUNT()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/StringOps/toLong()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/logWarning(scala.Function0,java.lang.Throwable)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$4/4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaDate(int)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaTimestamp(long)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$toExternalString(java.lang.Object,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/Token/getInputStream()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/ParserRuleContext/getParent()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/Token/getStopIndex()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/Token/getTokenSource()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/Token/getChannel()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/misc/Pair/Pair(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/ParserRuleContext/getChild(int)
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/tree/ParseTree/getPayload()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/ParserRuleContext/removeLastChild()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/CommonToken/CommonToken(org.antlr.v4.runtime.misc.Pair,int,int,int,int)
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/Token/getStartIndex()
org/apache/spark/sql/catalyst/parser/PostProcessor/replaceTokenByIdentifier(org.antlr.v4.runtime.ParserRuleContext,int,scala.Function1)#org/antlr/v4/runtime/ParserRuleContext/addChild(org.antlr.v4.runtime.Token)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#java/lang/Class/isMemberClass()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/collection/LinearSeqOptimized/apply(int)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#org/apache/spark/sql/catalyst/encoders/OuterScopes$$anonfun$getOuterScope$2/2(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#org/apache/spark/sql/catalyst/encoders/OuterScopes$/getOuterScope(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/collection/LinearSeqOptimized/lengthCompare(int)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#java/lang/Class/getDeclaringClass()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#java/util/concurrent/ConcurrentMap/get(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#org/apache/spark/sql/catalyst/encoders/OuterScopes$/outerScopes()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/Option/get()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/util/matching/Regex/unapplySeq(java.lang.CharSequence)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#org/apache/spark/sql/catalyst/encoders/OuterScopes$$anonfun$getOuterScope$1/1(java.lang.Class,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes$class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.ExpectsInputTypes)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/collection/mutable/ArrayOps/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/Predef$/doubleArrayOps(double[])
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile$$anonfun$checkInputDataTypes$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/collection/mutable/ArrayOps/exists(scala.Function1)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/ApproximatePercentile/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Set/$plus(java.lang.Object)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/Set()
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/diff(scala.collection.GenSeq)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Set$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Set/nonEmpty()
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Set/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/plans/QueryPlan$$anonfun$generateEquivalentConstraintClasses$1$$anonfun$3/3(org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$generateEquivalentConstraintClasses$1,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/SeqLike/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/plans/QueryPlan$$anonfun$generateEquivalentConstraintClasses$1$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$generateEquivalentConstraintClasses$1,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/QueryPlan/anonfun/generateEquivalentConstraintClasses/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/take(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/findGroupingExprs/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/VirtualColumn$/groupingIdName()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke$/apply$default$5()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#java/lang/Class/getAnnotation(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/ScalaReflection$/isNativeType(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$$anonfun$org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor$1/1(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/UDTRegistration$/getUDTFor(java.lang.String)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Predef$DummyImplicit$/dummyImplicit()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply$default$4()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$4()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$5()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$$anonfun$1/1(org.apache.spark.sql.types.UserDefinedType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/encoders/RowEncoder/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#java/lang/Class/getAnnotation(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$$anonfun$5/5()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/ScalaReflection$/isNativeType(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$$anonfun$4/4(org.apache.spark.sql.types.UserDefinedType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/UDTRegistration$/getUDTFor(java.lang.String)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$/externalDataTypeFor(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke$/apply$default$5()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply$default$4()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$4()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$5()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/encoders/RowEncoder$/org$apache$spark$sql$catalyst$encoders$RowEncoder$$deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/encoders/RowEncoder/deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$org$apache$spark$sql$catalyst$catalog$SessionCatalog$$requirePartialMatchedPartitionSpec$1$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.catalog.SessionCatalog$$anonfun$org$apache$spark$sql$catalyst$catalog$SessionCatalog$$requirePartialMatchedPartitionSpec$1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/Iterable/forall(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/immutable/Map/keys()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/Iterable/mkString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requirePartialMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$5$$anonfun$6/6(org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$$anonfun$5,org.apache.spark.sql.catalyst.expressions.BoundReference,org.apache.spark.sql.catalyst.expressions.objects.Invoke)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/fromObject(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$5$$anonfun$1/1(org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$$anonfun$5)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/CreateStruct$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/anonfun/5/apply(scala.Tuple2)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#org/apache/spark/sql/catalyst/util/CompressionCodecs$/shortCompressionCodecNames()
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#org/apache/spark/util/Utils$/classForName(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/immutable/Map/keys()
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#org/apache/spark/sql/catalyst/util/CompressionCodecs$$anonfun$1/1(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#org/apache/spark/sql/catalyst/util/CompressionCodecs$/getCodecClassName(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/Iterable/mkString(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/collection/immutable/Map/nonEmpty()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InsertIntoContext/tableIdentifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/collection/immutable/Map/keys()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InsertIntoContext/EXISTS()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InsertIntoContext/partitionSpec()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withInsertInto$1$$anonfun$4/4(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withInsertInto$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withInsertInto$1$$anonfun$5/5(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withInsertInto$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withInsertInto$1$$anonfun$6/6(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withInsertInto$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InsertIntoContext/OVERWRITE()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/collection/immutable/Map/filter(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/collection/Iterable/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withInsertInto$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withInsertInto/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/catalyst/catalog/FunctionResourceType$/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/5/apply(scala.Tuple2)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/anonfun/doGenCode/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/IntRef/create(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/ArrayBuffer/length()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback$$anonfun$doGenCode$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,scala.runtime.IntRef,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenFallback/class/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/SeqLike/length()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$/logWarning(scala.Function0)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/distinct()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$$anonfun$checkColumnNameDuplication$1/1(java.lang.String,scala.collection.immutable.Iterable)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$$anonfun$1/1()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$$anonfun$2/2()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/length()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$$anonfun$3/3()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/groupBy(scala.Function1)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/immutable/Map/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#scala/Option/orElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveRelations$$anonfun$34/34(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$,scala.Option)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/FunctionUtils$/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/util/Utils$/classForName(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/FunctionUtils$/getMethodType(org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#java/lang/String/length()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/logInfo(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/metrics/source/CodegenMetrics$/METRIC_SOURCE_CODE_SIZE()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#com/codahale/metrics/Histogram/update(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anon$1$$anonfun$load$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1,long,long)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#com/codahale/metrics/Histogram/update(long)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/metrics/source/CodegenMetrics$/METRIC_COMPILATION_TIME()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#java/lang/System/nanoTime()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anon/1/load(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anon$1/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$anon$$timeMs$1(long,long)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$isDefinedAt$3/3(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$isDefinedAt$2/2(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/GroupingSets/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$isDefinedAt$6/6(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/IterableLike/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$isDefinedAt$1/1(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$isDefinedAt$5/5(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/get()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/hasGroupingFunction(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$isDefinedAt$4/4(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/VirtualColumn$/hiveGroupingIdName()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/VirtualColumn$/groupingIdAttribute()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/cubeExprs(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/IterableLike/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$23/23(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6,scala.collection.Seq,org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$findGroupingExprs(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/rollupExprs(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$applyOrElse$27/27(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$applyOrElse$26/26(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$applyOrElse$25/25(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$applyOrElse$24/24(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$applyOrElse$23/23(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6$$anonfun$applyOrElse$22/22(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/GroupingSets/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$replaceGroupingFunc(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Some/get()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/hasGroupingFunction(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/children()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$$anonfun$apply$33/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Expression/transformDown(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$$anonfun$apply$33$$anonfun$applyOrElse$13$$anonfun$92/92(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer$$anonfun$apply$33$$anonfun$applyOrElse$13)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$$anonfun$apply$33$$anonfun$applyOrElse$13$$anonfun$11/11(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer$$anonfun$apply$33$$anonfun$applyOrElse$13)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateNestedTupleFields(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LocalRelation$/apply$default$2()
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion$$anonfun$apply$6$$anonfun$12/12(org.apache.spark.sql.catalyst.optimizer.PushProjectionThroughUnion$$anonfun$apply$6,scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion$$anonfun$apply$6$$anonfun$applyOrElse$5/5(org.apache.spark.sql.catalyst.optimizer.PushProjectionThroughUnion$$anonfun$apply$6)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#scala/Some/x()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#scala/collection/mutable/Map/get(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#scala/collection/mutable/Map/update(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/searchLevel/1/anonfun/apply/mcVI/sp/1/apply(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/itemIds()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#scala/util/parsing/combinator/Parsers$Parser/$tilde$greater(scala.Function0)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$subscript$2/2()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$subscript$3/3()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/accept(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#scala/util/parsing/combinator/Parsers$Parser/$less$tilde(scala.Function0)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$subscript$1/1()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/subscript()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#scala/util/parsing/combinator/Parsers$Parser/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/util/parsing/combinator/Parsers$Success/result()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/NoSuccess()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/expression()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/parseAll(scala.util.parsing.combinator.Parsers$Parser,java.lang.CharSequence)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/parse(java.lang.String)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/util/parsing/combinator/Parsers$NoSuccess$/unapply(scala.util.parsing.combinator.Parsers$ParseResult)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#scala/util/parsing/combinator/Parsers$Parser/$tilde$greater(scala.Function0)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/accept(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$named$1/1()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$named$3/3()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#scala/util/parsing/combinator/Parsers$Parser/$bar(scala.Function0)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/named()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$named$2/2()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#scala/util/parsing/combinator/Parsers$Parser/map(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/util/package$/toPrettySQL(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/expressions/Cast/eval(org.apache.spark.sql.catalyst.InternalRow)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$25/25(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$24/24(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$outputName$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/expressions/package$/EmptyRow()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Pivot/childrenResolved()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32/32(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7,org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,boolean)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$28/28(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7,org.apache.spark.sql.catalyst.expressions.NamedExpression,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$applyOrElse$30/30(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$applyOrElse$29/29(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$applyOrElse$28/28(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$31/31(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7,scala.collection.Seq,boolean,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$26/26(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$30/30(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$29/29(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$27/27(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/collection/mutable/ArrayBuffer/ArrayBuffer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$65/65(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$66/66(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$,scala.collection.Seq,scala.collection.mutable.ArrayBuffer,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$71/71(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/ArrayBuffer/groupBy(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/ArrayBuffer/ArrayBuffer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/immutable/Map/toSeq()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$73/73(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$72/72(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/collection/mutable/ArrayBuffer/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#org/apache/spark/sql/catalyst/expressions/AttributeSet$/apply(scala.collection.Iterable)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$7$$anonfun$11/apply()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/anonfun/11/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/Seq/sorted(scala.math.Ordering)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/immutable/Map/keys()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/Iterable/mkString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/requireExactMatchedPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/Analyzer$CTESubstitution$$anonfun$apply$1/org$apache$spark$sql$catalyst$analysis$Analyzer$CTESubstitution$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/Analyzer/execute(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/Analyzer$CTESubstitution$/substituteCTE(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/Analyzer$CTESubstitution$/org$apache$spark$sql$catalyst$analysis$Analyzer$CTESubstitution$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#scala/collection/Seq/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/CTESubstitution/anonfun/apply/1/anonfun/applyOrElse/18/apply(scala.collection.Seq,scala.Tuple2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#org/apache/spark/sql/types/StructType$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#scala/collection/Seq/transpose(scala.Function1)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#scala/collection/IterableLike/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#org/apache/spark/sql/catalyst/analysis/ResolveInlineTables$$anonfun$4/4(org.apache.spark.sql.catalyst.analysis.ResolveInlineTables,org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#org/apache/spark/sql/catalyst/analysis/ResolveInlineTables$$anonfun$1/1(org.apache.spark.sql.catalyst.analysis.ResolveInlineTables,org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/convert(org.apache.spark.sql.catalyst.analysis.UnresolvedInlineTable)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Limit$/unapply(org.apache.spark.sql.catalyst.plans.logical.GlobalLimit)
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/CombineLimits/anonfun/apply/19/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Limit$/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$subexpressionElimination$2$$anonfun$apply$3/3(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext$$anonfun$subexpressionElimination$2,org.apache.spark.sql.catalyst.expressions.codegen.SubExprEliminationState)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/anonfun/subexpressionElimination/2/apply(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$/org$apache$spark$sql$catalyst$expressions$codegen$GenerateSafeProjection$$convertToSafe(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderJoin$$anonfun$apply$1$$anonfun$5/5(org.apache.spark.sql.catalyst.optimizer.ReorderJoin$$anonfun$apply$1,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#java/util/Iterator/hasNext()
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$ArrayConverter$$anonfun$toCatalystImpl$2/2(org.apache.spark.sql.catalyst.CatalystTypeConverters$ArrayConverter)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$ArrayConverter$$anonfun$toCatalystImpl$1/1(org.apache.spark.sql.catalyst.CatalystTypeConverters$ArrayConverter)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$ArrayConverter/toCatalystImpl(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#java/lang/Iterable/iterator()
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/runtime/ScalaRunTime$/isArray(java.lang.Object,int)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#java/util/Iterator/next()
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$CatalystTypeConverter/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/CatalystTypeConverters/ArrayConverter/toCatalystImpl(java.lang.Object)#scala/collection/mutable/ArrayBuffer$/empty()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/util/Try/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/util/Try$/apply(scala.Function0)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$9$$anonfun$apply$11$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.json.JacksonParser$$anonfun$makeConverter$9$$anonfun$apply$11,java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$9$$anonfun$apply$11$$anonfun$applyOrElse$2/2(org.apache.spark.sql.catalyst.json.JacksonParser$$anonfun$makeConverter$9$$anonfun$apply$11,java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getText()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getLongValue()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/9/anonfun/apply/11/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Predef$/long2Long(long)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/clear()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/immutable/StringOps$/apply$extension(java.lang.String,int)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#java/lang/String/length()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/mkString()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer$/empty()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/toSeq()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/nonEmpty()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute$/e$1(java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute$/parseAttributeName(java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/CaseWhen/valueTypesEqual()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/CaseWhen/valueTypes()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$$findWiderCommonType(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/CaseWhen/childrenResolved()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$CaseWhenCoercion$$anonfun$apply$8$$anonfun$applyOrElse$11/11(org.apache.spark.sql.catalyst.analysis.TypeCoercion$CaseWhenCoercion$$anonfun$apply$8,org.apache.spark.sql.catalyst.expressions.CaseWhen)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/CaseWhenCoercion/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$CaseWhenCoercion$$anonfun$apply$8$$anonfun$applyOrElse$12/12(org.apache.spark.sql.catalyst.analysis.TypeCoercion$CaseWhenCoercion$$anonfun$apply$8,org.apache.spark.sql.catalyst.expressions.CaseWhen)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#org/apache/hadoop/fs/Path/toUri()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#scala/collection/mutable/HashMap/remove(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/renamePartitions/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$/generatePartitionPath(scala.collection.immutable.Map,scala.collection.Seq,org.apache.hadoop.fs.Path)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$23/23(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/string(org.antlr.v4.runtime.Token)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuerySpecificationContext/aggregation()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuerySpecificationContext/windows()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/IterableLike/foldRight(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetQuantifierContext/DISTINCT()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$7(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuerySpecificationContext/identifierSeq()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/EnhancedLogicalPlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuerySpecificationContext/namedExpressionSeq()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuerySpecificationContext/colTypeList()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuerySpecificationContext/setQuantifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$18/18(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$19/19(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$20/20(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$21/21(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$22/22(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$24/24(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$15/15(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$16/16(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$17/17(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuerySpecificationContext/lateralView()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/TraversableOnce/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$1/1(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$EnhancedLogicalPlan$/optionalMap$extension(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1$$anonfun$apply$11/11(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQuerySpecification$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$3()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$EnhancedLogicalPlan$/optional$extension(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,java.lang.Object,scala.Function0)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQuerySpecification/1/apply()#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/Some/x()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNonOptionalPartitionSpec/1/anonfun/apply/9/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/collection/Seq/toSet()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#org/apache/spark/util/Utils$/truncatedString(scala.collection.Seq,java.lang.String,java.lang.String,java.lang.String,int)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/runtime/ScalaRunTime$/isArray(java.lang.Object,int)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/collection/mutable/ArrayOps/isEmpty()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/Some/x()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#org/apache/spark/util/Utils$/truncatedString$default$5()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$argString$1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/collection/Iterable/isEmpty()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/collection/immutable/Set/contains(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/collection/immutable/Set/subsetOf(scala.collection.GenSet)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/argString/1/apply(java.lang.Object)#scala/collection/immutable/Set/toSeq()
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$$anonfun$equalsStructurally$1/1()
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/forall(scala.Function1)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getDayOfWeekFromString(org.apache.spark.unsafe.types.UTF8String)
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/NextDay/anonfun/doGenCode/16/apply(java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$8$$anonfun$apply$10$$anonfun$applyOrElse$6/6(org.apache.spark.sql.catalyst.json.JacksonParser$$anonfun$makeConverter$8$$anonfun$apply$10)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/io/ByteArrayOutputStream/toByteArray()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/util/Utils$/tryWithResource(scala.Function0,scala.Function1)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/unsafe/types/UTF8String/fromBytes(byte[])
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$8$$anonfun$apply$10$$anonfun$applyOrElse$5/5(org.apache.spark.sql.catalyst.json.JacksonParser$$anonfun$makeConverter$8$$anonfun$apply$10,java.io.ByteArrayOutputStream)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getText()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/8/anonfun/apply/10/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/math/package$/floor(double)
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/Predef$/doubleArrayOps(double[])
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/collection/mutable/ArrayOps/sorted(scala.math.Ordering)
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/Stats(double,int,int)
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/value()
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/collection/mutable/ArrayBuffer/ArrayBuffer()
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/reflect/ClassTag$/Double()
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/QuantileSummaries/withHeadBufferInserted()#scala/collection/mutable/ArrayBuffer/isEmpty()
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/math/package$/ceil(double)
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/delta()
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/Predef$/require(boolean,scala.Function0)
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/g()
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/collection/mutable/ArrayOps/last()
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/collection/mutable/ArrayOps/isEmpty()
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/value()
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/collection/mutable/ArrayBuffer/isEmpty()
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$$anonfun$query$1/1(org.apache.spark.sql.catalyst.util.QuantileSummaries)
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$$anonfun$query$2/2(org.apache.spark.sql.catalyst.util.QuantileSummaries)
org/apache/spark/sql/catalyst/util/QuantileSummaries/query(double)#scala/collection/mutable/ArrayOps/head()
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#scala/collection/mutable/ArrayOps/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#org/apache/spark/sql/catalyst/util/QuantileSummaries$$anonfun$merge$1/1(org.apache.spark.sql.catalyst.util.QuantileSummaries)
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#org/apache/spark/sql/catalyst/util/QuantileSummaries$/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#scala/collection/mutable/ArrayOps/sortBy(scala.Function1,scala.math.Ordering)
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#org/apache/spark/sql/catalyst/util/QuantileSummaries$$anonfun$merge$2/2(org.apache.spark.sql.catalyst.util.QuantileSummaries)
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#scala/Predef$/require(boolean,scala.Function0)
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#scala/collection/mutable/ArrayBuffer/isEmpty()
org/apache/spark/sql/catalyst/util/QuantileSummaries/merge(org.apache.spark.sql.catalyst.util.QuantileSummaries)#org/apache/spark/sql/catalyst/util/QuantileSummaries$$anonfun$1/1(org.apache.spark.sql.catalyst.util.QuantileSummaries)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$schemaFor$1$$typecreator43$1/1(org.apache.spark.sql.catalyst.ScalaReflection$$anonfun$schemaFor$1)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/Annotations$AnnotationApi/tpe()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/Types$TypeApi/$eq$colon$eq(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags/typeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/runtime/BooleanRef/create(boolean)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/FoldablePropagation$$anonfun$16/16()
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/FoldablePropagation$$anonfun$apply$10/10(scala.PartialFunction,scala.runtime.BooleanRef)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformUp(scala.PartialFunction)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/FoldablePropagation$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/FoldablePropagation$/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters$/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters$$anonfun$9/9(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/TraversableOnce/toSet()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/immutable/Set/toSeq()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Some/x()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$$anonfun$apply$1)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$2/2(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$$anonfun$apply$1,scala.collection.immutable.Map,org.apache.spark.sql.catalyst.analysis.UnresolvedTableValuedFunction)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$/org$apache$spark$sql$catalyst$analysis$ResolveTableValuedFunctions$$builtinFunctions()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Iterable/headOption()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Map/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Map/get(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$6/6(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$$anonfun$apply$1,org.apache.spark.sql.catalyst.analysis.UnresolvedTableValuedFunction)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableOnce/reduceLeftOption(scala.Function2)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/ScalaReflection$/getParameterTypes(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableLike/filter(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10$$anonfun$77/77(org.apache.spark.sql.catalyst.analysis.Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10$$anonfun$78/78(org.apache.spark.sql.catalyst.analysis.Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10$$anonfun$79/79(org.apache.spark.sql.catalyst.analysis.Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10$$anonfun$applyOrElse$73/73(org.apache.spark.sql.catalyst.analysis.Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10,org.apache.spark.sql.catalyst.expressions.ScalaUDF)
org/apache/spark/sql/catalyst/analysis/Analyzer/HandleNullInputsForUDF/anonfun/apply/29/anonfun/applyOrElse/10/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10$$anonfun$applyOrElse$72/72(org.apache.spark.sql.catalyst.analysis.Analyzer$HandleNullInputsForUDF$$anonfun$apply$29$$anonfun$applyOrElse$10,org.apache.spark.sql.catalyst.expressions.ScalaUDF)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetOperationContext/setQuantifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitSetOperation$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#scala/Option/exists(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#org/antlr/v4/runtime/Token/getType()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#org/apache/spark/sql/catalyst/plans/logical/Union$/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSetOperation/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitSetOperation$1$$anonfun$27/27(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitSetOperation$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntervalContext/intervalField()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitInterval$1$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitInterval$1,scala.collection.mutable.Buffer)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#scala/collection/mutable/Buffer/reduce(scala.Function2)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/validate(scala.Function0,java.lang.String,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitInterval$1$$anonfun$47/47(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitInterval$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitInterval$1$$anonfun$apply$40/40(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitInterval$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInterval/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitInterval$1/apply()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Iterator/hasNext()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Map$Entry/getKey()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/apply(java.util.Map,scala.Function1,scala.Function1)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Map/size()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Iterator/next()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Set/iterator()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Map$Entry/getValue()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Map/entrySet()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/collection/JavaConverters$/mapAsJavaMapConverter(scala.collection.Map)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/toJavaMap(java.lang.Object[],java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/collection/convert/Decorators$AsJava/asJava()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/toScalaMap(java.lang.Object[],java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1/org$apache$spark$sql$catalyst$rules$RuleExecutor$$anonfun$$$outer()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1$$anonfun$apply$1$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1,org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule,org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#java/lang/System/nanoTime()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#org/apache/spark/sql/catalyst/rules/RuleExecutor$/timeMap()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#org/spark_project/guava/util/concurrent/AtomicLongMap/addAndGet(java.lang.Object,long)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/apply(org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.Rule)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#scala/Some/get()
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/ResolveCreateNamedStruct/anonfun/apply/42/anonfun/101/apply(scala.collection.Seq)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/math/BigInt/$greater(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/math/BigInt$/long2bigInt(long)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/collection/TraversableOnce/sum(scala.math.Numeric)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/math/BigInt/$times(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$$anonfun$create$1/1(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/compile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Array$/empty(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$$anonfun$1/1(int,java.lang.String,java.lang.String,int,int,int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Predef$/Map()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$$anonfun$2/2(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,int,java.lang.String,java.lang.String,int,int,int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/Seq$/tabulate(int,scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/immutable/Map$/empty()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/anonfun/3/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$/org$apache$spark$sql$catalyst$expressions$codegen$GenerateSafeProjection$$convertToSafe(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extract(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$hasWindowFunction(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$addWindow(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$apply$27$$anonfun$74/74(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$apply$27)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$apply$27$$anonfun$75/75(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$apply$27)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$apply$27$$anonfun$76/76(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$apply$27)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$apply$27$$anonfun$applyOrElse$65/65(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$apply$27)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Project/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$apply$27$$anonfun$applyOrElse$63/63(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$apply$27)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$apply$27$$anonfun$applyOrElse$64/64(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$apply$27)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/apply/27/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$$anonfun$8/8(scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$$anonfun$6/6()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$$anonfun$7/7()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/Seq/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$$anonfun$unapply$4/4()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#scala/Function1/apply$mcDD$sp(double)
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#org/apache/spark/sql/catalyst/expressions/Ceil/f()
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/Ceil/nullSafeEval(java.lang.Object)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Ceil/defineCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function1)
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Ceil$$anonfun$doGenCode$5/5(org.apache.spark.sql.catalyst.expressions.Ceil)
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Ceil$$anonfun$doGenCode$6/6(org.apache.spark.sql.catalyst.expressions.Ceil)
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Ceil$$anonfun$doGenCode$7/7(org.apache.spark.sql.catalyst.expressions.Ceil)
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/Ceil/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Ceil$$anonfun$doGenCode$4/4(org.apache.spark.sql.catalyst.expressions.Ceil)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$$anonfun$prunePartitionsByFilter$1/1(java.lang.String,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.InterpretedPredicate)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/toSet()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$$anonfun$1/1(org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/expressions/InterpretedPredicate$/create(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$$anonfun$5/5(scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/In$$anonfun$checkInputDataTypes$3/3(org.apache.spark.sql.catalyst.expressions.In)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/In$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.In)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/In$$anonfun$checkInputDataTypes$1/1(org.apache.spark.sql.catalyst.expressions.In)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/immutable/$colon$colon/tl$1()
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/In$$anonfun$checkInputDataTypes$2/2(org.apache.spark.sql.catalyst.expressions.In)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/collection/immutable/$colon$colon/head()
org/apache/spark/sql/catalyst/expressions/In/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/sql()#org/apache/spark/sql/catalyst/expressions/In$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.In)
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/expressions/In/sql()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/In$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.In,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/In$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.In,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/In/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$2$$anonfun$applyOrElse$6/6(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$2)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$2$$anonfun$applyOrElse$5/5(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$2)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$2$$anonfun$applyOrElse$3/3(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$2)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$2$$anonfun$applyOrElse$2/2(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$2)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$2$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$2)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$2$$anonfun$applyOrElse$8/8(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$2,org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$2$$anonfun$applyOrElse$7/7(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$2)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/2/applyOrElse(org.apache.spark.sql.types.DataType,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$2$$anonfun$applyOrElse$4/4(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$2)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/inputSet()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$PropagateTypes$$anonfun$apply$1$$anonfun$4/4(org.apache.spark.sql.catalyst.analysis.TypeCoercion$PropagateTypes$$anonfun$apply$1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/children()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$PropagateTypes$$anonfun$apply$1$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.analysis.TypeCoercion$PropagateTypes$$anonfun$apply$1,scala.collection.immutable.Map,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PropagateTypes/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformExpressions(scala.PartialFunction)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassNameFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/immutable/Set/$plus(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/immutable/Set/contains(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/reflect/api/Symbols$ClassSymbolApi/isPrimitive()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$javaKeywords()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/reflect/api/Types$TypeApi/typeSymbol()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/reflect/api/Symbols$SymbolApi/asClass()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/10/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TypeConstructorContext/STRING()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitTypeConstructor$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#java/lang/String/toUpperCase(java.util.Locale)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/string(org.antlr.v4.runtime.tree.TerminalNode)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#javax/xml/bind/DatatypeConverter/parseHexBinary(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#java/sql/Timestamp/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TypeConstructorContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#java/lang/String/length()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#java/lang/IllegalArgumentException/getMessage()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#java/sql/Date/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitTypeConstructor$1$$anonfun$46/46(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitTypeConstructor$1,java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTypeConstructor/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/types/StructField/jsonValue()#org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/StructField/jsonValue()#org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/StructField/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)
org/apache/spark/sql/types/StructField/jsonValue()#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/StructField/jsonValue()#scala/Predef$/$conforms()
org/apache/spark/sql/types/StructField/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/StructField/jsonValue()#org/apache/spark/sql/types/StructField$$anonfun$jsonValue$1/1(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/types/StructField/jsonValue()#org/apache/spark/sql/types/StructField$$anonfun$jsonValue$2/2(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/types/StructField/jsonValue()#org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/StructField/jsonValue()#org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/StructField/jsonValue()#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/types/StructField/jsonValue()#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$$anonfun$flattenJoin$1/1()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$/flattenJoin$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$51/51(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/IterableLike/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$6/6(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21,scala.collection.Seq,scala.collection.mutable.ArrayBuffer,org.apache.spark.sql.catalyst.plans.logical.Aggregate)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/ArrayBuffer/nonEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer/execute(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$54/54(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveAggregateFunctions$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/ArrayBuffer$/empty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$50/50(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$49/49(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$53/53(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$48/48(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/boolean2Boolean(boolean)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21/resolvedAggregateFilter$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$$anonfun$unapply$1/1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/Map()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/collectAliases(scala.collection.Seq)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$$anonfun$1/1(scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_4()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/immutable/Map$/empty()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$$anonfun$collectProjectsAndFilters$1/1()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/org$apache$spark$sql$catalyst$planning$PhysicalOperation$$substitute(scala.collection.immutable.Map,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/EncodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/FractionalType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/IntegralType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$$haveSameType(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$applyOrElse$6/6(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$$findWiderCommonType(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/immutable/IndexedSeq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$applyOrElse$10/10(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/x()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$applyOrElse$7/7(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$15/15(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$13/13(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/findWiderTypeWithoutStringPromotion(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$applyOrElse$9/9(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$applyOrElse$8/8(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/immutable/IndexedSeq/length()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/CreateMap/values()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/immutable/IndexedSeq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$14/14(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$12/12(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$11/11(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$18/18(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$17/17(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6$$anonfun$16/16(org.apache.spark.sql.catalyst.analysis.TypeCoercion$FunctionArgumentConversion$$anonfun$apply$6)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/immutable/IndexedSeq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/FunctionArgumentConversion/anonfun/apply/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/TimestampType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#org/apache/spark/sql/util/SchemaUtils$$anonfun$checkColumnNameDuplication$1/apply()
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#scala/collection/immutable/Iterable/mkString(java.lang.String)
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/util/SchemaUtils/anonfun/checkColumnNameDuplication/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/Float2float(java.lang.Float)
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/math/Integral/rem(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Remainder/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/Double2double(java.lang.Double)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#org/apache/spark/sql/types/StructField$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/dataType()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/schemaFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/schemaFor/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/nullable()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$$anonfun$1$$anonfun$2/2(org.apache.spark.sql.catalyst.analysis.TypeCoercion$$anonfun$1,org.apache.spark.sql.types.NumericType,org.apache.spark.sql.types.NumericType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/IndexedSeq/apply(int)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/numericPrecedence()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/IndexedSeq/lastIndexWhere(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/anonfun/1/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Iterator/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Iterator/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Seq/grouped(int)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/mutable/ArrayOps/toSeq()
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/CaseWhen$/createFromParser(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/CaseWhen$$anonfun$9/9()
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$9/9(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/collection/TraversableLike/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$10/10(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$11/11(org.apache.spark.sql.catalyst.catalog.SessionCatalog,org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTableSchema(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.types.StructType)#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$reset$2/2(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$reset$4/4(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$reset$5/5(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#scala/collection/IterableLike/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$reset$6/6(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/spark_project/guava/cache/Cache/invalidateAll()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$reset$1/1(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/apache/spark/sql/catalyst/catalog/SessionCatalog$/DEFAULT_DATABASE()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$reset$3/3(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/reset()#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$/builtin()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/collection/immutable/StringOps/r()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#java/util/regex/Pattern/matcher(java.lang.CharSequence)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#java/util/regex/Matcher/matches()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/util/matching/Regex/pattern()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/validateName(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$39/39(org.apache.spark.sql.catalyst.catalog.SessionCatalog,org.apache.spark.sql.catalyst.catalog.CatalogFunction,org.apache.spark.sql.catalyst.FunctionIdentifier)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#scala/Option/orNull(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/registerFunction(org.apache.spark.sql.catalyst.catalog.CatalogFunction,boolean,scala.Option)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/VIEW()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$lookupRelation$1/1(org.apache.spark.sql.catalyst.catalog.SessionCatalog,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$20/20(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$21/21(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$lookupRelation$2/2(org.apache.spark.sql.catalyst.catalog.SessionCatalog,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/lookupRelation(org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/HashMap/contains(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/HashMap/get(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#org/spark_project/guava/cache/Cache/invalidate(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$refreshTable$1/1(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$25/25(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/refreshTable(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$refreshTable$2/2(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$getTempViewOrPermanentTableMetadata$4/4(org.apache.spark.sql.catalyst.catalog.SessionCatalog,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$getTempViewOrPermanentTableMetadata$3/3(org.apache.spark.sql.catalyst.catalog.SessionCatalog,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$getTempViewOrPermanentTableMetadata$1/1(org.apache.spark.sql.catalyst.catalog.SessionCatalog,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/get()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$getTempViewOrPermanentTableMetadata$2/2(org.apache.spark.sql.catalyst.catalog.SessionCatalog,org.apache.spark.sql.catalyst.TableIdentifier)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTempViewOrPermanentTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$/DEFAULT_DATABASE()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/dropDatabase(java.lang.String,boolean,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#scala/collection/mutable/HashMap/keys()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/util/StringUtils$/filterPattern(scala.collection.Seq,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$23/23(org.apache.spark.sql.catalyst.catalog.SessionCatalog,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$22/22(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/listTables(java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$24/24(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/setCurrentDatabase(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$5/5(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/immutable/Iterable/mkString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$1/1(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/Seq/groupBy(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$4/4(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/SeqLike/length()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$6/6(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/Seq/distinct()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/checkDuplication(scala.collection.Seq)#scala/collection/immutable/Map/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/createDatabase(org.apache.spark.sql.catalyst.catalog.CatalogDatabase,boolean)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$renameTable$2/2(org.apache.spark.sql.catalyst.catalog.SessionCatalog,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$renameTable$1/1(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$18/18(org.apache.spark.sql.catalyst.catalog.SessionCatalog)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/HashMap/contains(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/collection/mutable/HashMap/remove(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/renameTable(org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.TableIdentifier)#scala/Option/get()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/collection/immutable/List/isEmpty()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/json4s/JsonAST$JDouble/num()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/Array$/empty(scala.reflect.ClassTag)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/apache/spark/sql/types/Metadata$$anonfun$fromJObject$1$$anonfun$apply$4/4(org.apache.spark.sql.types.Metadata$$anonfun$fromJObject$1)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/reflect/ClassTag$/Boolean()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/json4s/JsonAST$JInt/num()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/collection/immutable/List$/canBuildFrom()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/json4s/JsonAST$JArray/arr()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/json4s/JsonAST$JBool/value()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/apache/spark/sql/types/Metadata$$anonfun$fromJObject$1$$anonfun$apply$1/1(org.apache.spark.sql.types.Metadata$$anonfun$fromJObject$1)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/json4s/JsonAST$JString/s()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/math/BigInt/toLong()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/reflect/ClassTag$/Double()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/apache/spark/sql/types/Metadata$$anonfun$fromJObject$1$$anonfun$apply$2/2(org.apache.spark.sql.types.Metadata$$anonfun$fromJObject$1)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/collection/immutable/List/head()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/apache/spark/sql/types/Metadata$$anonfun$fromJObject$1$$anonfun$apply$3/3(org.apache.spark.sql.types.Metadata$$anonfun$fromJObject$1)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/json4s/package$/JNull()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#java/lang/Object/getClass()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/apache/spark/sql/types/Metadata$$anonfun$fromJObject$1$$anonfun$apply$5/5(org.apache.spark.sql.types.Metadata$$anonfun$fromJObject$1)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/reflect/ClassTag$/Long()
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/Metadata/anonfun/fromJObject/1/apply(scala.Tuple2)#org/apache/spark/sql/types/Metadata$/fromJObject(org.json4s.JsonAST$JObject)
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/BinaryOperator/right()
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/BinaryOperator/left()
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/BinaryOperator/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/Predef$/println(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#java/lang/System/nanoTime()
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/Function0/apply()
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#org/apache/spark/sql/catalyst/util/package$/benchmark(scala.Function0)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/ByteArrayOutputStream/flush()
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/FileInputStream/read()
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/lang/String/String(byte[],java.lang.String)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/ByteArrayOutputStream/write(int)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/FileInputStream/close()
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/ByteArrayOutputStream/toByteArray()
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#org/apache/spark/sql/catalyst/util/package$/fileToString(java.io.File,java.lang.String)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/FileInputStream/FileInputStream(java.io.File)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$$anonfun$2/2()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$$anonfun$3/3()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/math/package$/max(int,int)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$/sideBySide(scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/fill(int,scala.Function0)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$$anonfun$sideBySide$1/1(int)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/TraversableOnce/max(scala.math.Ordering)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$$anonfun$1/1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/Some/x()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/collection/mutable/Queue/toSeq()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$$findWiderCommonType(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$WidenSetOperationTypes$$anonfun$5/5(int)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)#scala/collection/mutable/Queue/enqueue(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$WidenSetOperationTypes$/getWidestTypes(scala.collection.Seq,int,scala.collection.mutable.Queue)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#scala/collection/mutable/Queue$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$WidenSetOperationTypes$$anonfun$org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes$1/1(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$WidenSetOperationTypes$$anonfun$org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes$2/2(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#scala/Predef$/require(boolean)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#java/security/MessageDigest/digest()
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#org/apache/commons/codec/digest/DigestUtils/sha512Hex(byte[])
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#org/apache/commons/codec/digest/DigestUtils/sha256Hex(byte[])
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#org/apache/commons/codec/digest/DigestUtils/sha384Hex(byte[])
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#java/security/MessageDigest/getInstance(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#java/security/MessageDigest/update(byte[])
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/fromBytes(byte[])
org/apache/spark/sql/catalyst/expressions/Sha2/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1$1/1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#org/json4s/JsonAST$JString/JString(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#org/json4s/JsonAST$JInt/JInt(scala.math.BigInt)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#org/json4s/JsonAST$JObject/JObject(scala.collection.immutable.List)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$collectJsonValue$1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.ArrayBuffer)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$jsonFields$1/1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#scala/collection/Iterator/toSeq()
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#scala/collection/TraversableOnce/toList()
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$jsonFields$2/2(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#scala/Predef$/assert(boolean,scala.Function0)
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#org/apache/spark/sql/catalyst/ScalaReflection$/getConstructorParameterNames(java.lang.Class)
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/trees/TreeNode/jsonFields()#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$generateTreeString$3/3(org.apache.spark.sql.catalyst.trees.TreeNode,int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/IterableLike/foreach(scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/SeqLike/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/Seq/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/Seq/init()
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/mutable/StringBuilder/append(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$generateTreeString$2/2(org.apache.spark.sql.catalyst.trees.TreeNode,int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,boolean)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$generateTreeString$1/1(org.apache.spark.sql.catalyst.trees.TreeNode,scala.collection.mutable.StringBuilder)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/generateTreeString(int,scala.collection.Seq,scala.collection.mutable.StringBuilder,boolean,java.lang.String,boolean)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$1/1(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$3/3(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/math/BigInt$/long2bigInt(long)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/storage/StorageLevel/useDisk()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/storage/StorageLevel/useOffHeap()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#java/lang/String/endsWith(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonDSL$/list2jvalue(scala.collection.immutable.List)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/util/Utils$/truncatedString$default$5()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$2/2(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/Iterator/toSeq()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$4/4(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/storage/StorageLevel/deserialized()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$5/5(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$6/6(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/types/Metadata$/empty()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$7/7(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonAST$JDouble/JDouble(double)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/Product/productIterator()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$8/8(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$9/9(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/ScalaReflection$/getConstructorParameterNames(java.lang.Class)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/util/Utils$/truncatedString(scala.collection.Seq,java.lang.String,java.lang.String,java.lang.String,int)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonAST$JBool/JBool(boolean)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonAST$JArray/JArray(scala.collection.immutable.List)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/storage/StorageLevel/useMemory()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonDSL$/option2jvalue(scala.Option,scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#java/util/UUID/toString()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonAST$JString/JString(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$10/10(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$11/11(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$12/12(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/json4s/JsonAST$JInt/JInt(scala.math.BigInt)
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#org/apache/spark/storage/StorageLevel/replication()
org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)#scala/collection/TraversableOnce/toList()
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/HashExpression$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.HashExpression,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/HashExpression/children()
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/HashExpression/dataType()
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HashExpression/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Map/values()
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode/transformExpressions(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$PullOutNondeterministic$$anonfun$apply$28$$anonfun$9/9(org.apache.spark.sql.catalyst.analysis.Analyzer$PullOutNondeterministic$$anonfun$apply$28,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/transformExpressions(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$PullOutNondeterministic$$anonfun$apply$28$$anonfun$applyOrElse$69/69(org.apache.spark.sql.catalyst.analysis.Analyzer$PullOutNondeterministic$$anonfun$apply$28)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$PullOutNondeterministic$$anonfun$apply$28$$anonfun$applyOrElse$66/66(org.apache.spark.sql.catalyst.analysis.Analyzer$PullOutNondeterministic$$anonfun$apply$28)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$PullOutNondeterministic$$anonfun$apply$28$$anonfun$8/8(org.apache.spark.sql.catalyst.analysis.Analyzer$PullOutNondeterministic$$anonfun$apply$28,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/analysis/Analyzer/PullOutNondeterministic/anonfun/apply/28/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$PullOutNondeterministic$/org$apache$spark$sql$catalyst$analysis$Analyzer$PullOutNondeterministic$$getNondeterToAttr(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveFunctions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveFunctions$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveFunctions$$anonfun$apply$16$$anonfun$applyOrElse$7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveFunctions$$anonfun$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#java/lang/Class/getCanonicalName()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveFunctions$$anonfun$apply$16$$anonfun$applyOrElse$7$$anonfun$applyOrElse$52/apply()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveFunctions$$anonfun$apply$16/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveFunctions$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/52/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$2/apply()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/immutable/Map/keys()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$2$$anonfun$apply$4/4(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/Seq/sorted(scala.math.Ordering)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$2$$anonfun$7/7(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/TraversableOnce/toSeq()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$2$$anonfun$apply$3/3(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/applyOrElse/2/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Iterator/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/CaseKeyWhen$/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Iterator/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/grouped(int)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/mutable/ArrayOps/toSeq()
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/CaseKeyWhen$$anonfun$10/10(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/drop(int)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Coalesce$$anonfun$doGenCode$1/1(org.apache.spark.sql.catalyst.expressions.Coalesce,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Coalesce/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputMap(org.apache.spark.sql.catalyst.expressions.AttributeMap,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/Project/expressions()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/rowCountsExist(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation$/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/ImplicitCastInputTypes/inputTypes()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryOperator$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryOperator)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/findTightestCommonType()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function2/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$ImplicitTypeCasts$$anonfun$apply$11$$anonfun$applyOrElse$15/15(org.apache.spark.sql.catalyst.analysis.TypeCoercion$ImplicitTypeCasts$$anonfun$apply$11,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.BinaryOperator)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$ImplicitTypeCasts$$anonfun$apply$11$$anonfun$applyOrElse$16/16(org.apache.spark.sql.catalyst.analysis.TypeCoercion$ImplicitTypeCasts$$anonfun$apply$11,org.apache.spark.sql.catalyst.expressions.BinaryOperator)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$ImplicitTypeCasts$$anonfun$apply$11$$anonfun$22/22(org.apache.spark.sql.catalyst.analysis.TypeCoercion$ImplicitTypeCasts$$anonfun$apply$11)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$ImplicitTypeCasts$$anonfun$apply$11$$anonfun$21/21(org.apache.spark.sql.catalyst.analysis.TypeCoercion$ImplicitTypeCasts$$anonfun$apply$11)
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/BucketSpec$$anonfun$toLinkedHashMap$7/7(org.apache.spark.sql.catalyst.catalog.BucketSpec)
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/BucketSpec$$anonfun$toLinkedHashMap$8/8(org.apache.spark.sql.catalyst.catalog.BucketSpec)
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#java/lang/Object/toString()
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/BucketSpec/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/Annotations$AnnotationApi/tpe()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor$1$$typecreator22$1/1(org.apache.spark.sql.catalyst.ScalaReflection$$anonfun$org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor$1)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/Types$TypeApi/$eq$colon$eq(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags/typeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/deserializerFor/1/apply(scala.reflect.api.Annotations$AnnotationApi)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$$anonfun$4$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.aggregate.PivotFirst$$anonfun$4)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$7(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$3()
org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/anonfun/4/apply(scala.Tuple2)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/Cast/anonfun/3/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#org/apache/spark/sql/catalyst/analysis/EliminateView$$anonfun$apply$2$$anonfun$applyOrElse$1/apply()
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/analysis/EliminateView/anonfun/apply/2/anonfun/applyOrElse/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/apache/spark/sql/catalyst/parser/AbstractSqlParser$$anonfun$parse$1/1(org.apache.spark.sql.catalyst.parser.AbstractSqlParser,java.lang.String)
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/removeErrorListeners()
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/antlr/v4/runtime/CommonTokenStream/CommonTokenStream(org.antlr.v4.runtime.TokenSource)
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/addParseListener(org.antlr.v4.runtime.tree.ParseTreeListener)
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/apache/spark/sql/catalyst/parser/SqlBaseLexer/addErrorListener(org.antlr.v4.runtime.ANTLRErrorListener)
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/antlr/v4/runtime/CommonTokenStream/reset()
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/antlr/v4/runtime/atn/ParserATNSimulator/setPredictionMode(org.antlr.v4.runtime.atn.PredictionMode)
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/addErrorListener(org.antlr.v4.runtime.ANTLRErrorListener)
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/apache/spark/sql/catalyst/parser/SqlBaseLexer/removeErrorListeners()
org/apache/spark/sql/catalyst/parser/AbstractSqlParser/parse(java.lang.String,scala.Function1)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/reset()
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/Encoders/typecreator12/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/children()
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction$$anonfun$sql$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateFunction)
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/sql(boolean)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/prettyName()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/children()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32$$anonfun$apply$51$$anonfun$1$$anonfun$applyOrElse$31/31(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32$$anonfun$apply$51$$anonfun$1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$anonfun$$ifExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Literal)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolvePivot$$anonfun$apply$7$$anonfun$32$$anonfun$apply$51/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolvePivot$$anonfun$$anonfun$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/32/anonfun/apply/51/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectType(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/SingleType(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/RootClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/thisPrefix(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator30/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectType(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/SingleType(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/RootClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/thisPrefix(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator52/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveFunctions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveFunctions$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateExpression$/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateFunction,org.apache.spark.sql.catalyst.expressions.aggregate.AggregateMode,boolean)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveFunctions$$anonfun$apply$16$$anonfun$applyOrElse$7$$anonfun$applyOrElse$53/apply()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveFunctions$$anonfun$apply$16$$anonfun$applyOrElse$7/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveFunctions$$anonfun$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#org/apache/spark/sql/catalyst/expressions/AggregateWindowFunction/prettyName()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveFunctions/anonfun/apply/16/anonfun/applyOrElse/7/anonfun/applyOrElse/53/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveFunctions$$anonfun$apply$16/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveFunctions$$anonfun$$$outer()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$resolve$1/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$anonfun$$$outer()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$resolve$1$$anonfun$apply$5/apply()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$resolve$1$$anonfun$apply$5$$anonfun$apply$6/6(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolve$1$$anonfun$apply$5)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/anonfun/resolve/1/anonfun/apply/5/apply()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Range$/apply(long,long,long,scala.Option)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/Some/get()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/4/applyOrElse(scala.collection.Seq,scala.Function1)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputMap(org.apache.spark.sql.catalyst.expressions.AttributeMap,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/Project/expressions()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/rowCountsExist(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation$/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ProjectEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Project)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/EqualNullSafe$$anonfun$checkInputDataTypes$5/5(org.apache.spark.sql.catalyst.expressions.EqualNullSafe)
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/EqualNullSafe/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$constructLeftJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/ArrayBuffer/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$extractCorrelatedScalarSubqueries(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/ArrayBuffer$/empty()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$$anonfun$apply$5$$anonfun$20/20(org.apache.spark.sql.catalyst.optimizer.RewriteCorrelatedScalarSubquery$$anonfun$apply$5,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$$anonfun$apply$5$$anonfun$19/19(org.apache.spark.sql.catalyst.optimizer.RewriteCorrelatedScalarSubquery$$anonfun$apply$5,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$$anonfun$apply$5$$anonfun$18/18(org.apache.spark.sql.catalyst.optimizer.RewriteCorrelatedScalarSubquery$$anonfun$apply$5,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#java/util/List/isEmpty()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1$$anonfun$9/9(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$EnhancedLogicalPlan$/optional$extension(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,java.lang.Object,scala.Function0)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1$$anonfun$apply$10/10(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1$$anonfun$12/12(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1$$anonfun$13/13(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1$$anonfun$10/10(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1$$anonfun$11/11(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withQueryResultClauses$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryOrganizationContext/windows()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/EnhancedLogicalPlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withQueryResultClauses/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$EnhancedLogicalPlan$/optionalMap$extension(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#java/lang/Class/getSimpleName()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$jsonFields$1$$anonfun$apply$17/17(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$jsonFields$1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/1/apply()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$jsonFields$1/apply()
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/FormatString$$anonfun$14/14(org.apache.spark.sql.catalyst.expressions.FormatString,org.apache.spark.sql.catalyst.InternalRow)
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#java/util/Formatter/Formatter(java.lang.Appendable,java.util.Locale)
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/StringBuffer/toString()
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#java/util/Formatter/format(java.lang.String,java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/reflect/ClassTag$/AnyRef()
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/expressions/FormatString/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/StringBuffer/StringBuffer()
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/FormatString$$anonfun$16/16(org.apache.spark.sql.catalyst.expressions.FormatString)
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/FormatString$$anonfun$17/17(org.apache.spark.sql.catalyst.expressions.FormatString,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/FormatString$$anonfun$15/15(org.apache.spark.sql.catalyst.expressions.FormatString,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/mkString()
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/FormatString/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Stack$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.Stack)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/take(int)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/tabulate(int,scala.Function1)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Stack$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.Stack,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/runtime/NonLocalReturnControl/key()
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/Predef$/intWrapper(int)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/runtime/RichInt$/until$extension0(int,int)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Stack/prettyName()
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/runtime/NonLocalReturnControl/value()
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Stack$$anonfun$checkInputDataTypes$1/1(org.apache.spark.sql.catalyst.expressions.Stack,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/checkInputDataTypes()#java/lang/Object/Object()
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/immutable/IndexedSeq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/RichInt$/until$extension0(int,int)
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/intWrapper(int)
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/Stack$$anonfun$eval$1/1(org.apache.spark.sql.catalyst.expressions.Stack,java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Stack/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/Stack$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.Stack,org.apache.spark.sql.catalyst.InternalRow)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/RootClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectType(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/SingleType(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/thisPrefix(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator20/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects/transformUp(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$$anonfun$apply$33$$anonfun$applyOrElse$13$$anonfun$11$$anonfun$12/12(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer$$anonfun$apply$33$$anonfun$applyOrElse$13$$anonfun$11)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/anonfun/apply/33/anonfun/applyOrElse/13/anonfun/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator42/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectTerm(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/util/Failure/exception()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$7$$anonfun$11/11(org.apache.spark.sql.catalyst.analysis.FunctionRegistry$$anonfun$7)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#java/lang/Throwable/getCause()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$7$$anonfun$12/12(org.apache.spark.sql.catalyst.analysis.FunctionRegistry$$anonfun$7,java.lang.reflect.Constructor,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/collection/Seq$/fill(int,scala.Function0)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$7$$anonfun$10/10(org.apache.spark.sql.catalyst.analysis.FunctionRegistry$$anonfun$7,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#java/lang/Throwable/getMessage()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/util/Try$/apply(scala.Function0)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$7$$anonfun$8/8(org.apache.spark.sql.catalyst.analysis.FunctionRegistry$$anonfun$7,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/util/Success/value()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/collection/mutable/ArrayOps/find(scala.Function1)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$7$$anonfun$9/9(org.apache.spark.sql.catalyst.analysis.FunctionRegistry$$anonfun$7)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/7/apply(scala.collection.Seq)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$9/9()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#scala/collection/Seq/flatten(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#scala/collection/TraversableOnce/reduceOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/collect(scala.PartialFunction)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$10/10()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$11/11()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/mutable/Map/values()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/TraversableOnce/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Traversable$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/TraversableOnce/toSeq()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformUp(scala.PartialFunction)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Iterable/flatten(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$2/2(scala.collection.mutable.Map)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/mutable/Map$/empty()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/SubExprUtils$/stripOuterReferences(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$16/16(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$17/17(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$13/13()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$14/14()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$pullOutCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$15/15()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#org/apache/spark/sql/catalyst/rules/RuleExecutor$Batch/name()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#org/apache/spark/sql/catalyst/util/package$/sideBySide(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1$$anonfun$apply$5/apply()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/5/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Multiply/deterministic()
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator$/org$apache$spark$sql$catalyst$optimizer$ReorderAssociativeOperator$$flattenAdd(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.ExpressionSet)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2$$anonfun$3/3(org.apache.spark.sql.catalyst.optimizer.ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2$$anonfun$4/4(org.apache.spark.sql.catalyst.optimizer.ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/package$/EmptyRow()
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2$$anonfun$applyOrElse$9/9(org.apache.spark.sql.catalyst.optimizer.ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator$/org$apache$spark$sql$catalyst$optimizer$ReorderAssociativeOperator$$flattenMultiply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.ExpressionSet)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Multiply/dataType()
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2$$anonfun$2/2(org.apache.spark.sql.catalyst.optimizer.ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Add/dataType()
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2$$anonfun$applyOrElse$10/10(org.apache.spark.sql.catalyst.optimizer.ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2$$anonfun$5/5(org.apache.spark.sql.catalyst.optimizer.ReorderAssociativeOperator$$anonfun$apply$2$$anonfun$applyOrElse$2)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ReorderAssociativeOperator/anonfun/apply/2/anonfun/applyOrElse/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Add/deterministic()
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/FormatString/anonfun/17/apply(java.lang.String,scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#org/apache/spark/sql/catalyst/plans/logical/Filter/getConstraints(boolean)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#scala/runtime/BooleanRef/zero()
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin$$anonfun$7/7(org.apache.spark.sql.catalyst.optimizer.EliminateOuterJoin,org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin$$anonfun$6/6(org.apache.spark.sql.catalyst.optimizer.EliminateOuterJoin,org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#scala/runtime/VolatileByteRef/create(byte)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$buildNewJoinType(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.Join)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/BindReferences$/bindReference$default$3()
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Expression/find(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/BindReferences$/bindReference(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.package$AttributeSeq,boolean)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/SubqueryExpression$/hasCorrelatedSubquery(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/package$/AttributeSeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin$$anonfun$org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull$1/1(org.apache.spark.sql.catalyst.optimizer.EliminateOuterJoin)
org/apache/spark/sql/catalyst/optimizer/EliminateOuterJoin/org$apache$spark$sql$catalyst$optimizer$EliminateOuterJoin$$canFilterOutNull(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/length()
org/apache/spark/sql/AnalysisException/getSimpleMessage()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/AnalysisException/getSimpleMessage()#org/apache/spark/sql/AnalysisException$$anonfun$3/3(org.apache.spark.sql.AnalysisException)
org/apache/spark/sql/AnalysisException/getSimpleMessage()#org/apache/spark/sql/AnalysisException$$anonfun$5/5(org.apache.spark.sql.AnalysisException)
org/apache/spark/sql/AnalysisException/getSimpleMessage()#org/apache/spark/sql/AnalysisException$$anonfun$6/6(org.apache.spark.sql.AnalysisException)
org/apache/spark/sql/AnalysisException/getSimpleMessage()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/AnalysisException/getSimpleMessage()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/AnalysisException/getSimpleMessage()#scala/Option/map(scala.Function1)
org/apache/spark/sql/AnalysisException/getSimpleMessage()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/AnalysisException/getSimpleMessage()#org/apache/spark/sql/AnalysisException$$anonfun$4/4(org.apache.spark.sql.AnalysisException)
org/apache/spark/sql/AnalysisException/getSimpleMessage()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/AnalysisException/getMessage()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/AnalysisException/getMessage()#org/apache/spark/sql/AnalysisException$$anonfun$1/1(org.apache.spark.sql.AnalysisException)
org/apache/spark/sql/AnalysisException/getMessage()#scala/Option/map(scala.Function1)
org/apache/spark/sql/AnalysisException/getMessage()#org/apache/spark/sql/AnalysisException$$anonfun$2/2(org.apache.spark.sql.AnalysisException)
org/apache/spark/sql/AnalysisException/getMessage()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/AnalysisException/getMessage()#scala/Predef$/$conforms()
org/apache/spark/sql/AnalysisException/getMessage()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/AnalysisException/getMessage()#scala/Option/flatten(scala.Predef$$less$colon$less)
org/apache/spark/sql/AnalysisException/getMessage()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/AnalysisException/getMessage()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#org/apache/spark/sql/types/StructField$/apply$default$4()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/ResolveInlineTables$$anonfun$1$$anonfun$2/2(org.apache.spark.sql.catalyst.analysis.ResolveInlineTables$$anonfun$1)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/ResolveInlineTables$$anonfun$1$$anonfun$3/3(org.apache.spark.sql.catalyst.analysis.ResolveInlineTables$$anonfun$1,java.lang.String)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/findWiderTypeWithoutStringPromotion(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/ResolveInlineTables$$anonfun$1$$anonfun$apply$3/3(org.apache.spark.sql.catalyst.analysis.ResolveInlineTables$$anonfun$1)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Iterator/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/CaseKeyWhen$/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Iterator/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/grouped(int)
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/mutable/ArrayOps/toSeq()
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CaseKeyWhen/apply(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/CaseKeyWhen$$anonfun$10/10(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/collection/immutable/Set/apply(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/collection/Seq/indexOf(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#org/json4s/JsonAST$JArray/JArray(scala.collection.immutable.List)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$jsonFields$2$$anonfun$apply$18/18(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$jsonFields$2)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#org/json4s/JsonAST$JInt/JInt(scala.math.BigInt)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/jsonFields/2/apply(scala.Tuple2)#scala/collection/TraversableOnce/toList()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#org/apache/spark/sql/catalyst/analysis/AliasViewChild$$anonfun$org$apache$spark$sql$catalyst$analysis$AliasViewChild$$findAttributeByName$2$$anonfun$apply$3/3(org.apache.spark.sql.catalyst.analysis.AliasViewChild$$anonfun$org$apache$spark$sql$catalyst$analysis$AliasViewChild$$findAttributeByName$2)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#org/apache/spark/sql/catalyst/analysis/AliasViewChild$$anonfun$org$apache$spark$sql$catalyst$analysis$AliasViewChild$$findAttributeByName$2/apply()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/org/apache/spark/sql/catalyst/analysis/AliasViewChild/findAttributeByName/2/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator21/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Least$$anonfun$doGenCode$19/19(org.apache.spark.sql.catalyst.expressions.Least,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/drop(int)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Least$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.Least,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Least/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Least/prettyName()
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Least$$anonfun$checkInputDataTypes$2/2(org.apache.spark.sql.catalyst.expressions.Least)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Least$$anonfun$checkInputDataTypes$1/1(org.apache.spark.sql.catalyst.expressions.Least)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Least$$anonfun$checkInputDataTypes$3/3(org.apache.spark.sql.catalyst.expressions.Least)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/TraversableOnce/count(scala.Function1)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#org/apache/spark/sql/catalyst/util/TypeUtils$/checkForOrderingExpr(org.apache.spark.sql.types.DataType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Least/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/RLike/dataType()
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/RLike$$anonfun$doGenCode$2/2(org.apache.spark.sql.catalyst.expressions.RLike,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/RLike/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/commons/lang3/StringEscapeUtils/escapeJava(java.lang.String)
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/RLike/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$$anonfun$8/8(scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$$anonfun$6/6()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$$anonfun$7/7()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/collection/Seq/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#org/apache/spark/sql/catalyst/planning/PhysicalAggregation$$anonfun$unapply$4/4()
org/apache/spark/sql/catalyst/planning/PhysicalAggregation/unapply(java.lang.Object)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/collection/Seq/reduceOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$$anonfun$org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$constructLeftJoins$1$$anonfun$apply$7/7(org.apache.spark.sql.catalyst.optimizer.RewriteCorrelatedScalarSubquery$$anonfun$org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$constructLeftJoins$1,scala.runtime.ObjectRef,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/NamedExpression$/newExprId()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/collection/Seq/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/Literal$/TrueLiteral()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/collection/Seq/reverse()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/CaseWhen$/apply(scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$7(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$evalSubqueryOnZeroTups(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/collection/IterableLike/foreach(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode/output()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$/ALWAYS_TRUE_COLNAME()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$3()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#org/apache/spark/sql/catalyst/expressions/Attribute/exprId()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/anonfun/org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/constructLeftJoins/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.ScalarSubquery)#scala/Option/get()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/VIEW_QUERY_OUTPUT_COLUMN_NAME_PREFIX()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$viewQueryColumnNames$1$$anonfun$apply$1$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.catalog.CatalogTable$$anonfun$viewQueryColumnNames$1$$anonfun$apply$1,int)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/apply(int)#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$viewQueryColumnNames$1/org$apache$spark$sql$catalyst$catalog$CatalogTable$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/types/DecimalType$/SYSTEM_DEFAULT()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/types/NumericType$/defaultConcreteType()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$ImplicitTypeCasts$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/types/DecimalType$/forType(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$ImplicitTypeCasts$$anonfun$23/23(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/collection/TraversableLike/headOption()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$ImplicitTypeCasts$$anonfun$25/25()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Option/orNull(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$ImplicitTypeCasts$$anonfun$24/24()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/catalyst/expressions/Cast$/forceNullable(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#org/apache/spark/sql/types/TypeCollection$/unapply(org.apache.spark.sql.types.AbstractDataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/ImplicitTypeCasts/org$apache$spark$sql$catalyst$analysis$TypeCoercion$ImplicitTypeCasts$$implicitCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.AbstractDataType)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/math/package$/ceil(double)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/expressions()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$greater$eq(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$7(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TimeWindowing$$anonfun$apply$40$$anonfun$99/99(org.apache.spark.sql.catalyst.analysis.TimeWindowing$$anonfun$apply$40,org.apache.spark.sql.catalyst.expressions.TimeWindow,int)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/getField(java.lang.String)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableOnce/toList()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$less(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/dsl/package$expressions$/DslExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/children()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/types/Metadata$/empty()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/tabulate(int,scala.Function1)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TimeWindowing$$anonfun$apply$40$$anonfun$100/100(org.apache.spark.sql.catalyst.analysis.TimeWindowing$$anonfun$apply$40,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/List/head()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$amp$amp(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/List/size()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformExpressions(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TimeWindowing$$anonfun$apply$40$$anonfun$98/98(org.apache.spark.sql.catalyst.analysis.TimeWindowing$$anonfun$apply$40)
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/TimeWindowing/anonfun/apply/40/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TimeWindowing$$anonfun$apply$40$$anonfun$15/15(org.apache.spark.sql.catalyst.analysis.TimeWindowing$$anonfun$apply$40,org.apache.spark.sql.catalyst.expressions.AttributeReference)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/Predef$/println(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#java/lang/System/nanoTime()
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/Function0/apply()
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#org/apache/spark/sql/catalyst/util/package$/benchmark(scala.Function0)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/package/benchmark(scala.Function0)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/ByteArrayOutputStream/flush()
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/FileInputStream/read()
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/lang/String/String(byte[],java.lang.String)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/ByteArrayOutputStream/write(int)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/FileInputStream/close()
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/ByteArrayOutputStream/toByteArray()
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#org/apache/spark/sql/catalyst/util/package$/fileToString(java.io.File,java.lang.String)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/FileInputStream/FileInputStream(java.io.File)
org/apache/spark/sql/catalyst/util/package/fileToString(java.io.File,java.lang.String)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$$anonfun$2/2()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$$anonfun$3/3()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/math/package$/max(int,int)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$/sideBySide(scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/fill(int,scala.Function0)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$$anonfun$sideBySide$1/1(int)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#scala/collection/TraversableOnce/max(scala.math.Ordering)
org/apache/spark/sql/catalyst/util/package/sideBySide(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/util/package$$anonfun$1/1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$$anonfun$create$1/1(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/compile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Array$/empty(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$$anonfun$1/1(int,java.lang.String,java.lang.String,int,int,int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Predef$/Map()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$$anonfun$2/2(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,int,java.lang.String,java.lang.String,int,int,int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/Seq$/tabulate(int,scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/immutable/Map$/empty()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/create(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType)#scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/math/BigInt/$greater(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/math/BigInt$/long2bigInt(long)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/collection/TraversableOnce/sum(scala.math.Numeric)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/math/BigInt/$times(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils/fromDecimal(org.apache.spark.sql.types.Decimal,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/sql/internal/SQLConf$/org$apache$spark$sql$internal$SQLConf$$sqlConfEntries()
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#java/util/Map/get(java.lang.Object)
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/internal/config/ConfigEntry/valueConverter()
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#scala/Predef$/require(boolean,scala.Function0)
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#scala/Option/map(scala.Function1)
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/internal/config/ConfigEntry/key()
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/sql/internal/SQLConf$$anonfun$getConf$1/1(org.apache.spark.sql.internal.SQLConf,org.apache.spark.internal.config.ConfigEntry)
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/sql/internal/SQLConf$$anonfun$getConf$2/2(org.apache.spark.sql.internal.SQLConf,java.lang.Object)
org/apache/spark/sql/internal/SQLConf/getConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#org/apache/spark/sql/internal/SQLConf$/org$apache$spark$sql$internal$SQLConf$$sqlConfEntries()
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#scala/collection/Iterable$/canBuildFrom()
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#scala/collection/TraversableLike/filter(scala.Function1)
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#scala/collection/TraversableOnce/toSeq()
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#scala/collection/JavaConverters$/collectionAsScalaIterableConverter(java.util.Collection)
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#org/apache/spark/sql/internal/SQLConf$$anonfun$getAllDefinedConfs$2/2(org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#org/apache/spark/sql/internal/SQLConf$$anonfun$getAllDefinedConfs$1/1(org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/internal/SQLConf/getAllDefinedConfs()#java/util/Map/values()
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/sql/internal/SQLConf$/org$apache$spark$sql$internal$SQLConf$$sqlConfEntries()
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/internal/config/ConfigEntry/stringConverter()
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#java/util/Map/get(java.lang.Object)
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#scala/Predef$/require(boolean,scala.Function0)
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/sql/internal/SQLConf$$anonfun$setConf$4/4(org.apache.spark.sql.internal.SQLConf,org.apache.spark.internal.config.ConfigEntry)
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/internal/config/ConfigEntry/key()
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/sql/internal/SQLConf$$anonfun$setConf$3/3(org.apache.spark.sql.internal.SQLConf,org.apache.spark.internal.config.ConfigEntry)
org/apache/spark/sql/internal/SQLConf/setConf(org.apache.spark.internal.config.ConfigEntry,java.lang.Object)#org/apache/spark/sql/internal/SQLConf$$anonfun$setConf$2/2(org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Iterator/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Iterator/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Seq/grouped(int)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/mutable/ArrayOps/toSeq()
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/CaseWhen$/createFromParser(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/CaseWhen$$anonfun$9/9()
org/apache/spark/sql/catalyst/expressions/CaseWhen/createFromParser(scala.collection.Seq)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#scala/collection/IterableLike/exists(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts$$anonfun$isCartesianProduct$1/1(org.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts$$anonfun$isCartesianProduct$2/2(org.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts,org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts$$anonfun$58/58(org.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/isCartesianProduct(org.apache.spark.sql.catalyst.plans.logical.Join)#org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts$$anonfun$59/59(org.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema$$anonfun$1/1(org.apache.spark.sql.catalyst.plans.logical.ScriptInputOutputSchema,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.logical.ScriptInputOutputSchema)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema$$anonfun$3/3(org.apache.spark.sql.catalyst.plans.logical.ScriptInputOutputSchema)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema$$anonfun$2/2(org.apache.spark.sql.catalyst.plans.logical.ScriptInputOutputSchema)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/immutable/StringOps/nonEmpty()
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/Option/nonEmpty()
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/runtime/NonLocalReturnControl/value()
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/runtime/NonLocalReturnControl/key()
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#java/lang/Object/Object()
org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema/getRowFormatSQL(scala.collection.Seq,scala.Option,scala.collection.Seq)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitPartitionSpec$1$$anonfun$7/7(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitPartitionSpec$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#scala/collection/mutable/Buffer/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitPartitionSpec$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PartitionSpecContext/partitionVal()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/checkDuplicateKeys(scala.collection.Seq,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPartitionSpec/1/apply()#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator44/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/inputSet()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/catalyst/analysis/UnresolvedStar$$anonfun$1/1(org.apache.spark.sql.catalyst.analysis.UnresolvedStar,scala.Function2)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/Traversable$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/catalyst/analysis/UnresolvedStar$$anonfun$expand$1/1(org.apache.spark.sql.catalyst.analysis.UnresolvedStar,scala.Option)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/catalyst/analysis/UnresolvedStar$$anonfun$2/2(org.apache.spark.sql.catalyst.analysis.UnresolvedStar)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/expand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)#scala/collection/SeqLike/size()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#org/apache/spark/sql/catalyst/util/package$/sideBySide(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1$$anonfun$apply$1$$anonfun$apply$2/apply()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/collection/mutable/Buffer/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/collection/mutable/Set/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/ExpressionSet/toDebugString()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/localTypeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeApi/$less$colon$less(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator64$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator65$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/definedByConstructorParams(scala.reflect.api.Types$TypeApi)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/definedByConstructorParams(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/StandardDefinitions/definitions()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator13$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/StandardDefinitions$DefinitionsApi/BooleanTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator14$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator15$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassNameFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator16$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/StandardDefinitions$DefinitionsApi/LongTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/immutable/List/exists(scala.Function1)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator17$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/getConstructorParameters(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator18$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/UnresolvedMapObjects$/apply$default$3()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#java/lang/Class/newInstance()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator19$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/types/UDTRegistration$/getUDTFor(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$9/9(scala.Option,scala.collection.Seq,java.lang.Class)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/arrayClassFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/mirror()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/ClassTag/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/schemaFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/localTypeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/nullable()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke$/apply$default$5()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#java/lang/Class/getAnnotation(java.lang.Class)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Types$TypeRefExtractor/unapply(scala.reflect.api.Types$TypeRefApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/StandardDefinitions$DefinitionsApi/FloatTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/StandardDefinitions$DefinitionsApi/ShortTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Option/nonEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/dataType()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/StandardDefinitions$DefinitionsApi/DoubleTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Types/TypeRef()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/getPath$1(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Symbols$SymbolApi/typeSignature()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Types$TypeApi/declaration(scala.reflect.api.Names$NameApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Types$TypeApi/$less$colon$less(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Types$TypeApi/typeSymbol()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Symbols/NoSymbol()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Names/newTermName(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/StandardDefinitions$DefinitionsApi/ByteTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$7/7(scala.collection.Seq,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator4$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$5()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator5$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/StandardDefinitions$DefinitionsApi/IntTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Symbols$SymbolApi/annotations()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$8/8(scala.collection.Seq,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Symbols$SymbolApi/companionSymbol()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator6$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/JavaUniverse$JavaMirror/runtimeClass(scala.reflect.api.Symbols$ClassSymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator7$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/types/UDTRegistration$/exists(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/types/ArrayType$/apply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator8$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$5/5(scala.reflect.api.Types$TypeApi,org.apache.spark.sql.types.DataType,boolean,scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Symbols$SymbolApi/asClass()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator20$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator9$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator10$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator21$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator11$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/ImplicitTags/TypeRefTag()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Some/get()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$6/6(scala.reflect.api.Types$TypeApi,org.apache.spark.sql.types.DataType,boolean,scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/reflect/api/Types$TypeApi/normalize()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator12$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)#scala/Option/get()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions/definitions()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/BooleanTpe()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/LongTpe()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#java/lang/reflect/Array/newInstance(java.lang.Class,int)
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/DoubleTpe()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeApi/$less$colon$less(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/ByteTpe()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/FloatTpe()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/ShortTpe()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/arrayClassFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/IntTpe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/definedByConstructorParams(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/ByteTpe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator54$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions/definitions()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator46$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator57$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/BooleanTpe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator47$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator58$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator48$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator59$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassNameFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/types/DecimalType$/SYSTEM_DEFAULT()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/LongTpe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/collection/immutable/List/exists(scala.Function1)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$schemaFor$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator49$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$schemaFor$2/2()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/getConstructorParameters(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#java/lang/Class/newInstance()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/Schema(org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/types/UDTRegistration$/getUDTFor(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/types/DecimalType$/BigIntDecimal()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/ClassTag/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/schemaFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/localTypeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/nullable()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#java/lang/Class/getAnnotation(java.lang.Class)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeRefExtractor/unapply(scala.reflect.api.Types$TypeRefApi)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/FloatTpe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/ShortTpe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/dataType()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/DoubleTpe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types/TypeRef()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeApi/$less$colon$less(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeApi/typeSymbol()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator60$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/types/StructType$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator50$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator61$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/IntTpe()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Symbols$SymbolApi/annotations()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator51$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator62$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/types/UDTRegistration$/exists(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator52$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator63$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator53$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator55$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Some/get()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/ImplicitTags/TypeRefTag()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator44$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator56$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator45$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/schemaFor(scala.reflect.api.Types$TypeApi)#scala/Option/get()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions/definitions()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/BooleanTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/LongTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/arrayClassFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/ClassTag/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassNameFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/types/DecimalType$/SYSTEM_DEFAULT()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/localTypeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeRefExtractor/unapply(scala.reflect.api.Types$TypeRefApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/FloatTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/ShortTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/DoubleTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types/TypeRef()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeApi/$less$colon$less(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator1$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator2$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator3$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/ByteTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardDefinitions$DefinitionsApi/IntTpe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/reflect/api/ImplicitTags/TypeRefTag()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/Some/get()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)#scala/Option/get()
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassNameFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/serializerFor$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/definedByConstructorParams(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/localTypeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/reflect/ClassTag/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeRefExtractor/unapply(scala.reflect.api.Types$TypeRefApi)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/definedByConstructorParams(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeApi/$less$colon$less(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator42$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/localTypeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types/TypeRef()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/reflect/api/ImplicitTags/TypeRefTag()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/Some/get()
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/ScalaReflection/optionOfProductType(scala.reflect.api.Types$TypeApi)#scala/Option/get()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/Class/isArray()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassNameFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/Class/getComponentType()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$5()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/schemaFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke$/apply$default$5()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/nullable()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/Class/isPrimitive()
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$toCatalystArray$1$1/1(scala.collection.immutable.Set,scala.reflect.api.Types$TypeApi,scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)
org/apache/spark/sql/catalyst/ScalaReflection/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/Class/newInstance()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor$3/3()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/definedByConstructorParams(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor$2/2(scala.collection.immutable.Set,scala.reflect.api.Types$TypeApi,scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator24$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator35$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator25$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator36$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator26$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator37$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassNameFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/types/DecimalType$/SYSTEM_DEFAULT()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator27$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator38$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/immutable/List/exists(scala.Function1)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator28$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator39$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/getConstructorParameters(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator29$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$dataTypeFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/types/UDTRegistration$/getUDTFor(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/types/DecimalType$/BigIntDecimal()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/ClassTag/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/immutable/Set/contains(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/localTypeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/Symbols$ClassSymbolApi/isPrimitive()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke$/apply$default$5()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/Class/getAnnotation(java.lang.Class)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/Types$TypeRefExtractor/unapply(scala.reflect.api.Types$TypeRefApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst$/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.Function1,org.apache.spark.sql.types.DataType,scala.Function1,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$10/10(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.immutable.Set,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/Types/TypeRef()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/Types$TypeApi/$less$colon$less(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/Types$TypeApi/typeSymbol()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor$1/1(scala.collection.immutable.Set,scala.reflect.api.Types$TypeApi,scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/Symbols$SymbolApi/annotations()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator40$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/types/UDTRegistration$/exists(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator30$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/Symbols$SymbolApi/asClass()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator31$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator32$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator33$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/reflect/api/ImplicitTags/TypeRefTag()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Some/get()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator23$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/ScalaReflection$$typecreator34$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.Types$TypeApi,scala.collection.Seq,scala.collection.immutable.Set)#scala/Option/get()
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$getConstructorParameterNames$1/1()
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#scala/reflect/api/Symbols$ClassSymbolApi/selfType()
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#org/apache/spark/sql/catalyst/ScalaReflection$/constructParams(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/getConstructorParameterNames(java.lang.Class)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#org/apache/spark/sql/catalyst/ScalaReflection$/universe()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/Annotations$AnnotationApi/tpe()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/Types$TypeApi/$eq$colon$eq(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/TypeTags/typeOf(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor$3$$typecreator41$1/1(org.apache.spark.sql.catalyst.ScalaReflection$$anonfun$org$apache$spark$sql$catalyst$ScalaReflection$$serializerFor$3)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/org/apache/spark/sql/catalyst/ScalaReflection/serializerFor/3/apply(scala.reflect.api.Annotations$AnnotationApi)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$makeCopy$1/apply()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/mutable/ArrayOps/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#java/lang/IllegalArgumentException/getMessage()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$makeCopy$1$$anonfun$8/8(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$makeCopy$1,java.lang.reflect.Constructor[])
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#java/lang/Class/getConstructors()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/reflect/ClassTag$/AnyRef()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/mutable/ArrayOps/mkString(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#org/apache/spark/sql/catalyst/errors/package$TreeNodeException/TreeNodeException(org.apache.spark.sql.catalyst.trees.TreeNode,java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$makeCopy$1$$anonfun$apply$13/13(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$makeCopy$1,java.lang.Object[],java.lang.reflect.Constructor)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$makeCopy$1$$anonfun$6/6(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$makeCopy$1,java.lang.Object[])
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/mutable/ArrayOps/isEmpty()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#org/apache/spark/sql/catalyst/trees/CurrentOrigin$/withOrigin(org.apache.spark.sql.catalyst.trees.Origin,scala.Function0)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$makeCopy$1$$anonfun$apply$14/14(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$makeCopy$1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/mutable/ArrayOps/find(scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$makeCopy$1$$anonfun$5/5(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$makeCopy$1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/makeCopy/1/apply()#scala/collection/mutable/ArrayOps/filter(scala.Function1)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$$anonfun$unapply$1/1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/collectProjectsAndFilters(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/PhysicalOperation/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$$anonfun$flattenJoin$1/1()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins/flattenJoin(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.InnerLike)#org/apache/spark/sql/catalyst/planning/ExtractFiltersAndInnerJoins$/flattenJoin$default$2()
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/isAssignableFrom(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/IntegerLiteral$/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps$$anonfun$apply$2$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.optimizer.SimplifyCreateArrayOps$$anonfun$apply$2,org.apache.spark.sql.types.StructField,int)
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/SimplifyCreateArrayOps/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$$anonfun$prunePartitionsByFilter$1/1(java.lang.String,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.InterpretedPredicate)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/toSet()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$$anonfun$1/1(org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/expressions/InterpretedPredicate$/create(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils/prunePartitionsByFilter(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.Seq,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/catalog/ExternalCatalogUtils$$anonfun$5/5(scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveUpCast/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveUpCast$$fail(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.collection.Seq)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/util/TypeUtils$$anonfun$checkForSameTypeInputExpr$1$$anonfun$apply$1/1(org.apache.spark.sql.catalyst.util.TypeUtils$$anonfun$checkForSameTypeInputExpr$1)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/runtime/NonLocalReturnControl/NonLocalReturnControl(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/TypeUtils/anonfun/checkForSameTypeInputExpr/1/apply(org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#org/apache/spark/sql/catalyst/expressions/package$AttributeSeq/indexOf(org.apache.spark.sql.catalyst.expressions.ExprId)
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#org/apache/spark/sql/catalyst/expressions/BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1/apply()
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#org/apache/spark/sql/catalyst/expressions/package$AttributeSeq/apply(int)
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#org/apache/spark/sql/catalyst/expressions/Attribute/nullable()
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#org/apache/spark/sql/catalyst/expressions/package$AttributeSeq/attrs()
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/BindReferences/anonfun/bindReference/1/anonfun/applyOrElse/1/apply()#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#scala/collection/immutable/$colon$colon/tl$1()
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#org/apache/spark/sql/catalyst/plans/logical/Pivot$$anonfun$output$12/12(org.apache.spark.sql.catalyst.plans.logical.Pivot,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#org/apache/spark/sql/catalyst/plans/logical/Pivot$$anonfun$22/22(org.apache.spark.sql.catalyst.plans.logical.Pivot)
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#scala/collection/immutable/$colon$colon/head()
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#org/apache/spark/sql/catalyst/plans/logical/Pivot$$anonfun$output$13/13(org.apache.spark.sql.catalyst.plans.logical.Pivot)
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Pivot/output()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters$/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters$$anonfun$9/9(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/TraversableOnce/toSet()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/immutable/Set/toSeq()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation$$anonfun$apply$1$$anonfun$applyOrElse$3/3(org.apache.spark.sql.catalyst.optimizer.PropagateEmptyRelation$$anonfun$apply$1)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Join/children()
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation$/org$apache$spark$sql$catalyst$optimizer$PropagateEmptyRelation$$empty(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation$$anonfun$apply$1$$anonfun$applyOrElse$4/4(org.apache.spark.sql.catalyst.optimizer.PropagateEmptyRelation$$anonfun$apply$1)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation$$anonfun$apply$1$$anonfun$applyOrElse$2/2(org.apache.spark.sql.catalyst.optimizer.PropagateEmptyRelation$$anonfun$apply$1)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation$$anonfun$apply$1$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.optimizer.PropagateEmptyRelation$$anonfun$apply$1)
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PropagateEmptyRelation$/org$apache$spark$sql$catalyst$optimizer$PropagateEmptyRelation$$isEmptyLocalRelation(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/delta()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/copy$default$1()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/copy$default$3()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/mutable/ListBuffer$/empty()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/Array$/empty(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/g()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/IndexedSeq/size()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/IndexedSeq/length()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/value()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/mutable/ListBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/IndexedSeq/apply(int)
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/IndexedSeq/isEmpty()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/IndexedSeq/last()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#org/apache/spark/sql/catalyst/util/QuantileSummaries$Stats/copy(double,int,int)
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/IndexedSeq/head()
org/apache/spark/sql/catalyst/util/QuantileSummaries/org$apache$spark$sql$catalyst$util$QuantileSummaries$$compressImmut(scala.collection.IndexedSeq,double)#scala/collection/mutable/ListBuffer/prepend(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/planCost()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal$/double2bigDecimal(double)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal$/int2bigDecimal(int)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal/$div(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal/$times(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal/$plus(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/JoinPlan/betterThan(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf)#scala/math/BigDecimal/$less(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Matcher/appendReplacement(java.lang.StringBuffer,java.lang.String)
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/lang/StringBuffer/length()
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/lang/StringBuffer/toString()
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Matcher/find()
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/clone()
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Pattern/compile(java.lang.String)
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/lang/StringBuffer/delete(int,int)
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Matcher/appendTail(java.lang.StringBuffer)
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/RegExpReplace/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Pattern/matcher(java.lang.CharSequence)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/collection/JavaConverters$/mapAsJavaMapConverter(scala.collection.Map)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/toJavaMap(java.lang.Object[],java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/collection/convert/Decorators$AsJava/asJava()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toJavaMap(java.lang.Object[],java.lang.Object[])#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Iterator/hasNext()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Map$Entry/getKey()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/apply(java.util.Map,scala.Function1,scala.Function1)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Map/size()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Iterator/next()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Set/iterator()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Map$Entry/getValue()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/apply(java.util.Map,scala.Function1,scala.Function1)#java/util/Map/entrySet()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/toScalaMap(java.lang.Object[],java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/util/ArrayBasedMapData/toScalaMap(java.lang.Object[],java.lang.Object[])#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$$anonfun$equalsIgnoreCompatibleNullability$1/1()
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/forall(scala.Function1)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/types/DataType/equalsIgnoreCompatibleNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/json4s/jackson/JsonMethods$/render$default$2(org.json4s.JsonAST$JValue)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/DataType$JSortedObject$/unapplySeq(org.json4s.JsonAST$JValue)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/StructField$/apply$default$4()
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/collection/LinearSeqOptimized/apply(int)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/Tuple2/_1()
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/Option/isEmpty()
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/json4s/jackson/JsonMethods$/render(org.json4s.JsonAST$JValue,org.json4s.Formats)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/json4s/JsonAST$JString/s()
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/collection/LinearSeqOptimized/lengthCompare(int)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/Option/get()
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/json4s/JsonAST$JBool/value()
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/Tuple2/_2()
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/DataType$/parseDataType(org.json4s.JsonAST$JValue)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/json4s/jackson/JsonMethods$/compact(org.json4s.JsonAST$JValue)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/DataType/org$apache$spark$sql$types$DataType$$parseStructField(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/Metadata$/fromJObject(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$$anonfun$equalsIgnoreCaseAndNullability$1/1()
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/forall(scala.Function1)
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/types/DataType/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$/equalsIgnoreCaseAndNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#org/apache/spark/sql/types/DataType$$anonfun$nameToType$1/1(java.lang.String)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/collection/LinearSeqOptimized/apply(int)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/collection/immutable/StringOps/r()
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/collection/immutable/StringOps/toInt()
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/Option/isEmpty()
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#org/apache/spark/sql/types/DataType$/nonDecimalNameToType()
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/util/matching/Regex/unapplySeq(java.lang.CharSequence)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/collection/LinearSeqOptimized/lengthCompare(int)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#org/apache/spark/sql/types/DecimalType$/USER_DEFAULT()
org/apache/spark/sql/types/DataType/nameToType(java.lang.String)#scala/Option/get()
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$$anonfun$equalsStructurally$1/1()
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/forall(scala.Function1)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/DataType/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$$anonfun$equalsIgnoreNullability$1/1()
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/forall(scala.Function1)
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/types/DataType/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$/equalsIgnoreNullability(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/json4s/jackson/JsonMethods$/render$default$2(org.json4s.JsonAST$JValue)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#java/lang/Class/newInstance()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/collection/LinearSeqOptimized/apply(int)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/Option/isEmpty()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/json4s/jackson/JsonMethods$/render(org.json4s.JsonAST$JValue,org.json4s.Formats)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/json4s/JsonAST$JString/s()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/DataType$$anonfun$parseDataType$1/1()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/collection/LinearSeqOptimized/lengthCompare(int)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/StructType$/apply(scala.collection.Seq)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/collection/immutable/List$/canBuildFrom()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/DataType$JSortedObject$/unapplySeq(org.json4s.JsonAST$JValue)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/json4s/JsonAST$JArray/arr()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/DataType$/nameToType(java.lang.String)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/json4s/JsonAST$JBool/value()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/Tuple2/_1()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/apache/spark/util/Utils$/classForName(java.lang.String)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/Tuple2/_2()
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/DataType$/parseDataType(org.json4s.JsonAST$JValue)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#org/json4s/jackson/JsonMethods$/compact(org.json4s.JsonAST$JValue)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/DataType/parseDataType(org.json4s.JsonAST$JValue)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveMissingReferences$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveMissingReferences$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr$1/1(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveMissingReferences$,org.apache.spark.sql.catalyst.plans.logical.Aggregate)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator23/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator45/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/runtime/BooleanRef/create(boolean)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/FoldablePropagation$$anonfun$16/16()
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/FoldablePropagation$$anonfun$apply$10/10(scala.PartialFunction,scala.runtime.BooleanRef)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformUp(scala.PartialFunction)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/FoldablePropagation$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/optimizer/FoldablePropagation/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/FoldablePropagation$/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator1/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/plans/logical/FunctionUtils$/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/TypedFilter/typedCondition(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$ArgumentList/args()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$ArgumentList$$anonfun$5/5(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$ArgumentList)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$ArgumentList$$anonfun$implicitCast$2/2(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$ArgumentList)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$ArgumentList$$anonfun$implicitCast$1/1(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$ArgumentList)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/ArgumentList/implicitCast(scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/clear()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/immutable/StringOps$/apply$extension(java.lang.String,int)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#java/lang/String/length()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/mkString()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer$/empty()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/toSeq()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/collection/mutable/ArrayBuffer/nonEmpty()
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute$/e$1(java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute$/parseAttributeName(java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedAttribute/parseAttributeName(java.lang.String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveMissingReferences$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$resolveExpressionRecursively(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveMissingReferences$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeSet$/apply(scala.collection.Iterable)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveMissingReferences$$anonfun$apply$14$$anonfun$42/42(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveMissingReferences$$anonfun$apply$14,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveMissingReferences$$anonfun$apply$14$$anonfun$43/43(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveMissingReferences$$anonfun$apply$14)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveMissingReferences$$anonfun$apply$14$$anonfun$44/44(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveMissingReferences$$anonfun$apply$14)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/apply/14/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Floor$$anonfun$doGenCode$9/9(org.apache.spark.sql.catalyst.expressions.Floor)
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Floor$$anonfun$doGenCode$12/12(org.apache.spark.sql.catalyst.expressions.Floor)
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Floor$$anonfun$doGenCode$11/11(org.apache.spark.sql.catalyst.expressions.Floor)
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Floor$$anonfun$doGenCode$10/10(org.apache.spark.sql.catalyst.expressions.Floor)
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/Floor/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Floor/defineCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function1)
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#scala/Function1/apply$mcDD$sp(double)
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#org/apache/spark/sql/catalyst/expressions/Floor/f()
org/apache/spark/sql/catalyst/expressions/Floor/nullSafeEval(java.lang.Object)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/runtime/NonLocalReturnControl/NonLocalReturnControl(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/checkInputDataTypes/1/apply$mcVI$sp(int)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery$/org$apache$spark$sql$catalyst$optimizer$RewritePredicateSubquery$$getValueExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$7(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableOnce/reduceLeftOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/EqualTo$/tupled()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/get()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/reduceLeftOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/8/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/RootClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectType(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/SingleType(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/thisPrefix(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator24/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/math/Ordering/reverse()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/math/Ordering$/Option(scala.math.Ordering)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$8/8(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/Predef$/implicitly(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$1/1(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$2/2(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$9/9(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/$colon$colon/head()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/isEmpty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/$colon$colon/tl$1()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$6/6(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$5/5(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/TraversableLike/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$4/4(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$TableAccessCardinality/size()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/size()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$7/7(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/SeqLike/sortBy(scala.Function1,scala.math.Ordering)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/math/ScalaNumericAnyConversions/toDouble()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$TableAccessCardinality/plan()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/math/Ordering$/Option(scala.math.Ordering)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/SeqLike/sortBy(scala.Function1,scala.math.Ordering)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$3/3(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$16/16(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$15/15(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$14/14(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$reorderStarJoins$1/1(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/reorderStarJoins(scala.collection.Seq,scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/x()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LeafNode/stats(org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$hasStatistics(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LeafNode/outputSet()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LeafNode/outputSet()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$10/10(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Project/outputSet()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$findLeafNodeCol$1/1(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/findLeafNodeCol(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/math/BigInt/$greater(scala.math.BigInt)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/math/BigInt/toDouble()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LeafNode/stats(org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/x()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LeafNode/outputSet()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/math/BigInt/$greater$eq(scala.math.BigInt)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/org$apache$spark$sql$catalyst$optimizer$StarSchemaDetection$$isUnique(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/math/package$/abs(double)
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/Unhex/anonfun/doGenCode/17/apply(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator46/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/math/BigInt/$plus(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Tuple6/_1()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/rowCountsExist(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$1/1(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/ceil(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Tuple6/_2()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Tuple6/_3()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$9/9(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$8/8(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$7/7(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$2/2(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$4()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/math/BigInt/$minus(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$5/5(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$3/3(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$6/6(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/math/BigInt/$times(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/math/BigInt/max(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/math/BigDecimal/$times(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation$$anonfun$10/10(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.InnerOuterEstimation,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/doEstimate()#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/math/BigInt/$less(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/apply(scala.Option,scala.Option,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/math/BigDecimal$/int2bigDecimal(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/math/BigDecimal/$div(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/math/BigInt/max(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/math/BigInt/$greater(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/isIntersected(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.Range,org.apache.spark.sql.catalyst.plans.logical.statsEstimation.Range)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/joinSelectivity(scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/collection/Map$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/collection/IterableView/force(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/collection/immutable/Set/apply(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/collection/mutable/Buffer/remove(int)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$1$$anonfun$apply$6/6(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$1$$anonfun$apply$5/5(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/collection/Map/mapValues(scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/collection/Map/view()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/1/apply(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withJoinRelations$1$$anonfun$apply$19/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinCriteriaContext/booleanExpression()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinRelationContext/joinType()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinTypeContext/LEFT()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinTypeContext/FULL()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/Some/x()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinTypeContext/RIGHT()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinTypeContext/ANTI()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinCriteriaContext/USING()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinTypeContext/CROSS()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withJoinRelations$1/org$apache$spark$sql$catalyst$parser$AstBuilder$$anonfun$$$outer()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinRelationContext/joinCriteria()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinRelationContext/NATURAL()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinCriteriaContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withJoinRelations$1$$anonfun$apply$19$$anonfun$31/31(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withJoinRelations$1$$anonfun$apply$19)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withJoinRelations/1/anonfun/apply/19/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinTypeContext/SEMI()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Literal$/TrueLiteral()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$isDefinedAt$2/2(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/headOption()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$isDefinedAt$1/1(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Literal$/FalseLiteral()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$isDefinedAt$3/3(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/FalseLiteral()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/TrueLiteral()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/headOption()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$applyOrElse$12/12(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$13/13(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$14/14(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$applyOrElse$11/11(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$applyOrElse$13/13(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6$$anonfun$applyOrElse$14/14(org.apache.spark.sql.catalyst.optimizer.SimplifyConditionals$$anonfun$apply$6$$anonfun$applyOrElse$6)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/span(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/SimplifyConditionals/anonfun/apply/6/anonfun/applyOrElse/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$location$2/apply()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/location/2/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/util/parsing/combinator/Parsers$Success/result()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/NoSuccess()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/expression()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/parseAll(scala.util.parsing.combinator.Parsers$Parser,java.lang.CharSequence)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/parse(java.lang.String)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/util/parsing/combinator/Parsers$NoSuccess$/unapply(scala.util.parsing.combinator.Parsers$ParseResult)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/parse(java.lang.String)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#scala/util/parsing/combinator/Parsers$Parser/$tilde$greater(scala.Function0)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/accept(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$named$1/1()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$named$3/3()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#scala/util/parsing/combinator/Parsers$Parser/$bar(scala.Function0)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/named()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$named$2/2()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/named()#scala/util/parsing/combinator/Parsers$Parser/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#scala/util/parsing/combinator/Parsers$Parser/$tilde$greater(scala.Function0)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$subscript$2/2()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$subscript$3/3()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/accept(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#scala/util/parsing/combinator/Parsers$Parser/$less$tilde(scala.Function0)
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$$anonfun$subscript$1/1()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#org/apache/spark/sql/catalyst/expressions/JsonPathParser$/subscript()
org/apache/spark/sql/catalyst/expressions/JsonPathParser/subscript()#scala/util/parsing/combinator/Parsers$Parser/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/sql()
org/apache/spark/sql/catalyst/expressions/In/anonfun/2/apply(scala.Tuple2)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#java/lang/String/length()
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/anonfun/sideBySide/1/apply(scala.Tuple2)#scala/collection/immutable/StringOps/$times(int)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/FunctionUtils$/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/util/Utils$/classForName(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/FunctionUtils/getFunctionOneName(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/plans/logical/FunctionUtils$/getMethodType(org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#java/util/Arrays/hashCode(byte[])
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#java/lang/Double/doubleToLongBits(double)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#java/lang/Float/floatToIntBits(float)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#java/lang/Object/hashCode()
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/util/GenericArrayData/hashCode()#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$minus(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$div(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$expressions$/DslExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$bar$bar(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$times(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/aggregate/Covariance/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$plus(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Elt$$anonfun$11/11(org.apache.spark.sql.catalyst.expressions.Elt,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Elt$$anonfun$10/10(org.apache.spark.sql.catalyst.expressions.Elt,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/ArrayOps/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Elt$$anonfun$doGenCode$6/6(org.apache.spark.sql.catalyst.expressions.Elt)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Elt/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InputFileBlockLength/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/TraversableOnce/reduceOption(scala.Function2)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/plans/LeftExistence$/unapply(org.apache.spark.sql.catalyst.plans.JoinType)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$84/84(org.apache.spark.sql.catalyst.analysis.Analyzer,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$83/83(org.apache.spark.sql.catalyst.analysis.Analyzer,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/expressions/EqualTo$/tupled()
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/Iterable/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$91/91(org.apache.spark.sql.catalyst.analysis.Analyzer)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$90/90(org.apache.spark.sql.catalyst.analysis.Analyzer)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$89/89(org.apache.spark.sql.catalyst.analysis.Analyzer)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$88/88(org.apache.spark.sql.catalyst.analysis.Analyzer)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$87/87(org.apache.spark.sql.catalyst.analysis.Analyzer)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$86/86(org.apache.spark.sql.catalyst.analysis.Analyzer,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.JoinType,scala.collection.Seq,scala.Option)#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$85/85(org.apache.spark.sql.catalyst.analysis.Analyzer,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/typeCoercionRules()
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#org/apache/spark/sql/catalyst/analysis/Analyzer/Once()
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#scala/collection/immutable/List$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#org/apache/spark/sql/catalyst/rules/RuleExecutor$Batch/Batch(org.apache.spark.sql.catalyst.rules.RuleExecutor,java.lang.String,org.apache.spark.sql.catalyst.rules.RuleExecutor$Strategy,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#org/apache/spark/sql/catalyst/analysis/ResolveHints$ResolveBroadcastHints/ResolveBroadcastHints(org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#scala/collection/immutable/List/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/batches$lzycompute()#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp$$anonfun$doGenCode$22/22(org.apache.spark.sql.catalyst.expressions.ToUTCTimestamp,java.lang.String)
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ToUTCTimestamp/defineCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator25/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/RootClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectType(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/SingleType(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/thisPrefix(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator47/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$expressions$/DslExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#org/apache/spark/sql/types/DecimalType$/bounded(int,int)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#scala/Tuple2/_1$mcI$sp()
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/aggregate/Average/evaluateExpression$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$div(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$plus(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$expressions$/longToLiteral(long)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$expressions$/DslExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Average/updateExpressions$lzycompute()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/SeqLike/length()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$/logWarning(scala.Function0)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/distinct()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$$anonfun$checkColumnNameDuplication$1/1(java.lang.String,scala.collection.immutable.Iterable)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$$anonfun$1/1()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$$anonfun$2/2()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/length()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/util/SchemaUtils$$anonfun$3/3()
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/groupBy(scala.Function1)
org/apache/spark/sql/util/SchemaUtils/checkColumnNameDuplication(scala.collection.Seq,java.lang.String,boolean)#scala/collection/immutable/Map/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/Decimal$/MAX_LONG_DIGITS()
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/DecimalAggregates$$anonfun$apply$21/org$apache$spark$sql$catalyst$optimizer$DecimalAggregates$$anonfun$$$outer()
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/DecimalType$Expression$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_1$mcI$sp()
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/math/package$/pow(double,double)
org/apache/spark/sql/catalyst/optimizer/DecimalAggregates/anonfun/apply/21/anonfun/applyOrElse/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/FunctionResourceType/fromString(java.lang.String)#org/apache/spark/sql/catalyst/catalog/FunctionResourceType$/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/objects/DecodeUsingSerializer/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getUTF8String(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getBinary(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getInt(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/isNullAt(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getArray(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getDecimal(int,int,int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getInterval(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getLong(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getBoolean(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getStruct(int,int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/get(int,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getDouble(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getShort(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getMap(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getFloat(int)
org/apache/spark/sql/catalyst/expressions/BoundReference/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/InternalRow/getByte(int)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection$$anonfun$findMethod$1$$anonfun$apply$1/1(org.apache.spark.sql.catalyst.expressions.CallMethodViaReflection$$anonfun$findMethod$1)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#java/lang/reflect/Method/getModifiers()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#java/lang/reflect/Modifier/isStatic(int)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#java/lang/reflect/Method/getName()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#java/lang/reflect/Method/getParameterTypes()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#scala/collection/mutable/ArrayOps/forall(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/anonfun/findMethod/1/apply(java.lang.reflect.Method)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame/validate()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/sql/catalyst/expressions/aggregate/Percentile$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.aggregate.Percentile)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/sql/types/NumericType/ordering()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/sql/catalyst/expressions/aggregate/Percentile$$anonfun$getPercentiles$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.Percentile,scala.collection.Seq,long)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/collection/Seq/scanLeft(java.lang.Object,scala.Function2,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/util/collection/OpenHashMap/isEmpty()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/util/collection/OpenHashMap/toSeq()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/sql/catalyst/expressions/aggregate/Percentile$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.Percentile)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/Tuple2/_2$mcJ$sp()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/collection/TraversableLike/tail()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/getPercentiles(org.apache.spark.util.collection.OpenHashMap)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/runtime/RichDouble$/ceil$extension(double)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#org/apache/spark/sql/catalyst/expressions/aggregate/Percentile$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.aggregate.Percentile)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/Predef$/doubleWrapper(double)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/runtime/RichDouble$/floor$extension(double)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/org$apache$spark$sql$catalyst$expressions$aggregate$Percentile$$getPercentile(scala.collection.Seq,double)#scala/reflect/ClassTag$/Long()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#java/io/DataOutputStream/writeInt(int)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/util/collection/OpenHashMap/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/sql/catalyst/expressions/aggregate/Percentile$$anonfun$serialize$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.Percentile,byte[],java.io.DataOutputStream,org.apache.spark.sql.catalyst.expressions.UnsafeProjection)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#java/io/DataOutputStream/close()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#org/apache/spark/sql/catalyst/expressions/UnsafeProjection$/create(org.apache.spark.sql.types.DataType[])
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#java/io/ByteArrayOutputStream/close()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#java/io/DataOutputStream/flush()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#java/io/DataOutputStream/DataOutputStream(java.io.OutputStream)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/serialize(org.apache.spark.util.collection.OpenHashMap)#java/io/ByteArrayOutputStream/toByteArray()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes$class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.ExpectsInputTypes)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/aggregate/Percentile$$anonfun$checkInputDataTypes$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.Percentile)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/aggregate/Percentile$$anonfun$update$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.Percentile,long)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/SparkException/SparkException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/util/collection/OpenHashMap/changeValue$mcJ$sp(java.lang.Object,scala.Function0,scala.Function1)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#java/lang/Number/longValue()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/aggregate/Percentile$$anonfun$update$2/2(org.apache.spark.sql.catalyst.expressions.aggregate.Percentile,long)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/update(org.apache.spark.util.collection.OpenHashMap,org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#org/apache/spark/util/collection/OpenHashMap/update$mcJ$sp(java.lang.Object,long)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#org/apache/spark/util/collection/OpenHashMap$mcJ$sp/sp(scala.reflect.ClassTag,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#java/io/ByteArrayInputStream/close()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#java/io/DataInputStream/readFully(byte[])
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#java/io/DataInputStream/close()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#scala/reflect/ClassTag$/AnyRef()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#java/io/DataInputStream/readInt()
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#java/io/DataInputStream/DataInputStream(java.io.InputStream)
org/apache/spark/sql/catalyst/expressions/aggregate/Percentile/deserialize(byte[])#scala/reflect/ClassTag$/Long()
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#org/apache/spark/sql/catalyst/util/CompressionCodecs$/shortCompressionCodecNames()
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#org/apache/spark/util/Utils$/classForName(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/immutable/Map/keys()
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#org/apache/spark/sql/catalyst/util/CompressionCodecs$$anonfun$1/1(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#org/apache/spark/sql/catalyst/util/CompressionCodecs$/getCodecClassName(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/Iterable/mkString(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/CompressionCodecs/getCodecClassName(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/renameTable/2/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#org/apache/spark/sql/catalyst/expressions/Expression$$anonfun$genCode$2$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$genCode$2)
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/collection/immutable/StringOps/nonEmpty()
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#org/apache/spark/sql/catalyst/expressions/Expression$$anonfun$genCode$2/apply()
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Expression/anonfun/genCode/2/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#java/lang/Class/getMethods()
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$11/11(org.apache.spark.sql.catalyst.ScalaReflection)
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#java/lang/reflect/Method/getParameterTypes()
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#scala/collection/mutable/ArrayOps/filter(scala.Function1)
org/apache/spark/sql/catalyst/ScalaReflection/class/getParameterTypes(org.apache.spark.sql.catalyst.ScalaReflection,java.lang.Object)#scala/collection/mutable/ArrayOps/head()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Symbols$SymbolApi/isMethod()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/collection/immutable/List/flatten(scala.Function1)
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Symbols$TermSymbolApi/alternatives()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Symbols$SymbolApi/asMethod()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$12/12(org.apache.spark.sql.catalyst.ScalaReflection)
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Symbols$SymbolApi/asTerm()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/Option/get()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Symbols$MethodSymbolApi/paramss()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeApi/member(scala.reflect.api.Names$NameApi)
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/collection/immutable/List/find(scala.Function1)
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Universe/nme()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/StandardNames$TermNamesApi/CONSTRUCTOR()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/ScalaReflection/class/constructParams(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Symbols$ClassSymbolApi/typeParams()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeRefExtractor/unapply(scala.reflect.api.Types$TypeRefApi)
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Universe/TypeRefTag()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Universe/TypeRef()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$getConstructorParameters$2/2(org.apache.spark.sql.catalyst.ScalaReflection)
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/Option/get()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/ClassTag/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#org/apache/spark/sql/catalyst/ScalaReflection$$anonfun$getConstructorParameters$1/1(org.apache.spark.sql.catalyst.ScalaReflection,scala.collection.immutable.List,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Types$TypeApi/typeSymbol()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/collection/immutable/List/nonEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/reflect/api/Symbols$SymbolApi/asClass()
org/apache/spark/sql/catalyst/ScalaReflection/class/getConstructorParameters(org.apache.spark.sql.catalyst.ScalaReflection,scala.reflect.api.Types$TypeApi)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#org/apache/spark/sql/catalyst/plans/physical/RangePartitioning$$anonfun$satisfies$3/3(org.apache.spark.sql.catalyst.plans.physical.RangePartitioning,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#org/apache/spark/sql/catalyst/plans/physical/RangePartitioning$$anonfun$satisfies$2/2(org.apache.spark.sql.catalyst.plans.physical.RangePartitioning)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/collection/IterableLike/forall(scala.Function1)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/Predef$/wrapIntArray(int[])
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/collection/TraversableOnce/min(scala.math.Ordering)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/physical/RangePartitioning/satisfies(org.apache.spark.sql.catalyst.plans.physical.Distribution)#scala/collection/Seq/take(int)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_AVG_LEN()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$7/7(java.lang.String,org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$1/1(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Option/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_DISTINCT_COUNT()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_MAX_VALUE()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/math/BigInt$/apply(long)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_MIN_VALUE()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/util/control/NonFatal$/unapply(java.lang.Throwable)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$3/3(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/Map/apply(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$5/5(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_MAX_LEN()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$6/6(org.apache.spark.sql.types.StructField)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/package$/BigInt()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$2/2()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/Map/get(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$KEY_NULL_COUNT()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/collection/immutable/StringOps/toLong()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/logWarning(scala.Function0,java.lang.Throwable)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/fromMap(java.lang.String,org.apache.spark.sql.types.StructField,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$fromMap$4/4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/toByte()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#java/sql/Date/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/fromJavaTimestamp(java.sql.Timestamp)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/toBoolean()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/Decimal$/apply(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/toInt()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/toDouble()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/toLong()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#java/sql/Timestamp/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/fromJavaDate(java.sql.Date)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/toShort()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/toFloat()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/org$apache$spark$sql$catalyst$plans$logical$ColumnStat$$fromExternalString(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$rowToColumnStat$2/2()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$rowToColumnStat$4/4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/package$/BigInt()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/math/BigInt$/apply(long)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$rowToColumnStat$3/3(org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$$anonfun$rowToColumnStat$1/1(org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Option/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/rowToColumnStat(org.apache.spark.sql.Row,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/aggregate/Count$/apply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/fixedLenTypeStruct$1(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Least,org.apache.spark.sql.catalyst.expressions.Subtract,org.apache.spark.sql.catalyst.expressions.Literal)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/Attribute/nullable()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus$/apply$default$4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/struct$1(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/plans/logical/ColumnStat$/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/ColumnStat/statExprs(org.apache.spark.sql.catalyst.expressions.Attribute,double)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator26/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/Map/$plus$eq(scala.Tuple2)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$$anonfun$2$$anonfun$12/12(org.apache.spark.sql.catalyst.optimizer.PullupCorrelatedPredicates$$anonfun$2)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PullupCorrelatedPredicates$/org$apache$spark$sql$catalyst$optimizer$PullupCorrelatedPredicates$$missingReferences$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.mutable.Map)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator48/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParserUtils$/unescapeSQLString(java.lang.String)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/Predef$/char2Character(char)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#java/lang/String/length()
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParserUtils$$anonfun$1/1(java.lang.String,int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder(int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/collection/immutable/Range/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/collection/mutable/StringBuilder/append(char)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/runtime/RichInt$/until$extension0(int,int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#scala/Predef$/intWrapper(int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#java/lang/String/charAt(int)
org/apache/spark/sql/catalyst/parser/ParserUtils/unescapeSQLString(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParserUtils$/appendEscapedChar$1(char,scala.collection.mutable.StringBuilder)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator4/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$/apply$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst$/apply$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/expressions/aggregate/PivotFirst/toAggregateExpression()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolvePivot/anonfun/apply/7/anonfun/28/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/Encoders/TIMESTAMP()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/TIMESTAMP()#org/apache/spark/sql/Encoders$$typecreator11$1/1()
org/apache/spark/sql/Encoders/TIMESTAMP()#org/apache/spark/sql/Encoders$/TIMESTAMP()
org/apache/spark/sql/Encoders/TIMESTAMP()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/TIMESTAMP()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/TIMESTAMP()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/TIMESTAMP()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/TIMESTAMP()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/TIMESTAMP()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/BINARY()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/BINARY()#org/apache/spark/sql/Encoders$$typecreator12$1/1()
org/apache/spark/sql/Encoders/BINARY()#org/apache/spark/sql/Encoders$/BINARY()
org/apache/spark/sql/Encoders/BINARY()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/BINARY()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/BINARY()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/BINARY()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/BINARY()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/BINARY()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/DECIMAL()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/DECIMAL()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/DECIMAL()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/DECIMAL()#org/apache/spark/sql/Encoders$$typecreator9$1/1()
org/apache/spark/sql/Encoders/DECIMAL()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/DECIMAL()#org/apache/spark/sql/Encoders$/DECIMAL()
org/apache/spark/sql/Encoders/DECIMAL()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/DECIMAL()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/DECIMAL()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/LONG()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/LONG()#org/apache/spark/sql/Encoders$/LONG()
org/apache/spark/sql/Encoders/LONG()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/LONG()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/LONG()#org/apache/spark/sql/Encoders$$typecreator5$1/1()
org/apache/spark/sql/Encoders/LONG()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/LONG()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/LONG()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/LONG()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/FLOAT()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/FLOAT()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/FLOAT()#org/apache/spark/sql/Encoders$/FLOAT()
org/apache/spark/sql/Encoders/FLOAT()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/FLOAT()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/FLOAT()#org/apache/spark/sql/Encoders$$typecreator6$1/1()
org/apache/spark/sql/Encoders/FLOAT()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/FLOAT()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/FLOAT()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/SHORT()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/SHORT()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/SHORT()#org/apache/spark/sql/Encoders$/SHORT()
org/apache/spark/sql/Encoders/SHORT()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/SHORT()#org/apache/spark/sql/Encoders$$typecreator3$1/1()
org/apache/spark/sql/Encoders/SHORT()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/SHORT()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/SHORT()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/SHORT()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/reflect/ClassTag/runtimeClass()
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#java/lang/Class/getName()
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#java/lang/reflect/Modifier/isPublic(int)
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#java/lang/Class/getModifiers()
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/reflect/package$/classTag(scala.reflect.ClassTag)
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/Encoders/validatePublicClass(scala.reflect.ClassTag)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/Encoders/BYTE()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/BYTE()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/BYTE()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/BYTE()#org/apache/spark/sql/Encoders$/BYTE()
org/apache/spark/sql/Encoders/BYTE()#org/apache/spark/sql/Encoders$$typecreator2$1/1()
org/apache/spark/sql/Encoders/BYTE()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/BYTE()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/BYTE()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/BYTE()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/BOOLEAN()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/BOOLEAN()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/BOOLEAN()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/BOOLEAN()#org/apache/spark/sql/Encoders$$typecreator1$1/1()
org/apache/spark/sql/Encoders/BOOLEAN()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/BOOLEAN()#org/apache/spark/sql/Encoders$/BOOLEAN()
org/apache/spark/sql/Encoders/BOOLEAN()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/BOOLEAN()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/BOOLEAN()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/DATE()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/DATE()#org/apache/spark/sql/Encoders$$typecreator10$1/1()
org/apache/spark/sql/Encoders/DATE()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/DATE()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/DATE()#org/apache/spark/sql/Encoders$/DATE()
org/apache/spark/sql/Encoders/DATE()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/DATE()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/DATE()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/DATE()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/DOUBLE()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/DOUBLE()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/DOUBLE()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/DOUBLE()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/DOUBLE()#org/apache/spark/sql/Encoders$$typecreator7$1/1()
org/apache/spark/sql/Encoders/DOUBLE()#org/apache/spark/sql/Encoders$/DOUBLE()
org/apache/spark/sql/Encoders/DOUBLE()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/DOUBLE()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/DOUBLE()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/STRING()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/STRING()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/STRING()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/STRING()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/STRING()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/STRING()#org/apache/spark/sql/Encoders$/STRING()
org/apache/spark/sql/Encoders/STRING()#org/apache/spark/sql/Encoders$$typecreator8$1/1()
org/apache/spark/sql/Encoders/STRING()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/STRING()#java/lang/Class/getClassLoader()
org/apache/spark/sql/Encoders/INT()#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/Encoders/INT()#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/Encoders/INT()#scala/reflect/api/TypeTags/TypeTag()
org/apache/spark/sql/Encoders/INT()#org/apache/spark/sql/Encoders$$typecreator4$1/1()
org/apache/spark/sql/Encoders/INT()#scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
org/apache/spark/sql/Encoders/INT()#scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
org/apache/spark/sql/Encoders/INT()#org/apache/spark/sql/Encoders$/INT()
org/apache/spark/sql/Encoders/INT()#java/lang/Object/getClass()
org/apache/spark/sql/Encoders/INT()#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#java/lang/Class/isMemberClass()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/collection/LinearSeqOptimized/apply(int)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#org/apache/spark/sql/catalyst/encoders/OuterScopes$$anonfun$getOuterScope$2/2(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#org/apache/spark/sql/catalyst/encoders/OuterScopes$/getOuterScope(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/collection/LinearSeqOptimized/lengthCompare(int)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#java/lang/Class/getDeclaringClass()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#java/util/concurrent/ConcurrentMap/get(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#org/apache/spark/sql/catalyst/encoders/OuterScopes$/outerScopes()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/Option/get()
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#scala/util/matching/Regex/unapplySeq(java.lang.CharSequence)
org/apache/spark/sql/catalyst/encoders/OuterScopes/getOuterScope(java.lang.Class)#org/apache/spark/sql/catalyst/encoders/OuterScopes$$anonfun$getOuterScope$1/1(java.lang.Class,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#org/apache/spark/sql/catalyst/catalog/CatalogUtils$$anonfun$org$apache$spark$sql$catalyst$catalog$CatalogUtils$$normalizeColumnName$2/apply()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/anonfun/org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeColumnName/2/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation$/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/math/BigInt$/apply(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/math/BigInt/min(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/rowCountsExist(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputMap(org.apache.spark.sql.catalyst.expressions.AttributeMap,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation$$anonfun$1/1(org.apache.spark.sql.catalyst.plans.logical.Statistics)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation$$anonfun$2/2(org.apache.spark.sql.catalyst.plans.logical.Statistics)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/package$/BigInt()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/AggregateEstimation/estimate(org.apache.spark.sql.internal.SQLConf,org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#java/lang/String/replaceAll(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#org/apache/spark/sql/catalyst/util/StringUtils$$anonfun$filterPattern$1$$anonfun$apply$1/1(org.apache.spark.sql.catalyst.util.StringUtils$$anonfun$filterPattern$1,scala.util.matching.Regex)
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#scala/collection/mutable/SortedSet/$plus$plus$eq(scala.collection.TraversableOnce)
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/util/StringUtils/anonfun/filterPattern/1/apply(java.lang.String)#scala/collection/immutable/StringOps/r()
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#org/apache/spark/sql/catalyst/expressions/GetStructField$$anonfun$sql$1/1(org.apache.spark.sql.catalyst.expressions.GetStructField)
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#org/apache/spark/sql/catalyst/util/package$/quoteIdentifier(java.lang.String)
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GetStructField/sql()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/collection/mutable/ArrayBuffer$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/collection/mutable/ArrayBuffer/size()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitLogicalBinary$1/collectContexts$1(int,scala.collection.mutable.ArrayBuffer,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitLogicalBinary$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#org/antlr/v4/runtime/Token/getType()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/collection/mutable/ArrayBuffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/collection/mutable/ArrayBuffer/reverse()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitLogicalBinary$1$$anonfun$37/37(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitLogicalBinary$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitLogicalBinary$1$$anonfun$36/36(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitLogicalBinary$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitLogicalBinary$1$$anonfun$35/35(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitLogicalBinary$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitLogicalBinary/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitLogicalBinary$1/reduceToExpressionTree$1(int,int,scala.Function2,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectType(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/SingleType(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/RootClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/thisPrefix(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator16/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toByte()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/unsafe/types/CalendarInterval/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/sql/catalyst/expressions/Literal$/fromJSON(org.json4s.JsonAST$JValue)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/json4s/JsonAST$JString/s()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toBoolean()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/Decimal$/apply(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toInt()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toDouble()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#java/sql/Date/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/DataType$/parseDataType(org.json4s.JsonAST$JValue)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toLong()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#java/sql/Timestamp/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toShort()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/json4s/MonadicJValue/$bslash(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toFloat()
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Double/isNaN()
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Float/isNaN()
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/double2Double(double)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Double/isInfinite()
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/float2Float(float)
org/apache/spark/sql/catalyst/expressions/Literal/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Float/isInfinite()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#java/lang/Double/isNaN()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#java/lang/Float/isNaN()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Predef$/double2Double(double)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Predef$any2stringadd$/$plus$extension(java.lang.Object,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaDate(int)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#org/apache/spark/sql/types/DoubleType$/sql()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaTimestamp(long)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Predef$/any2stringadd(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/collection/mutable/StringBuilder/append(byte)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#org/apache/spark/sql/types/FloatType$/sql()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/collection/mutable/StringBuilder/append(long)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#javax/xml/bind/DatatypeConverter/printHexBinary(byte[])
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/collection/mutable/StringBuilder/append(double)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Predef$/float2Float(float)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/collection/mutable/StringBuilder/append(short)
org/apache/spark/sql/catalyst/expressions/Literal/sql()#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Array$/apply(scala.collection.Seq,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$$anonfun$default$1/1()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#java/lang/String/getBytes(java.nio.charset.Charset)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/collection/immutable/Map$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/Nothing()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/unsafe/types/CalendarInterval/CalendarInterval(int,long)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$/Map()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$/default(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$DummyImplicit$/dummyImplicit()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/Decimal$/apply(long,int,int)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/InternalRow$/fromSeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#java/sql/Timestamp/toString()
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaTimestamp(long)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#org/json4s/JsonAST$JString/JString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaDate(int)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#java/sql/Date/toString()
org/apache/spark/sql/catalyst/expressions/Literal/jsonFields()#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#org/apache/spark/SparkException/SparkException(java.lang.String)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#org/apache/spark/util/Utils$/classForName(java.lang.String)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#java/lang/Class/isAssignableFrom(java.lang.Class)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#org/apache/spark/util/Utils$/classIsLoadable(java.lang.String)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/UDTRegistration/anonfun/getUDTFor/1/apply(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/EqualTo$$anonfun$checkInputDataTypes$4/4(org.apache.spark.sql.catalyst.expressions.EqualTo)
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/EqualTo/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectType(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/SingleType(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator27/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/types/StructType/jsonValue()#org/apache/spark/sql/types/StructType/typeName()
org/apache/spark/sql/types/StructType/jsonValue()#org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/StructType/jsonValue()#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/types/StructType/jsonValue()#org/apache/spark/sql/types/StructType$$anonfun$jsonValue$3/3(org.apache.spark.sql.types.StructType)
org/apache/spark/sql/types/StructType/jsonValue()#org/apache/spark/sql/types/StructType$$anonfun$jsonValue$2/2(org.apache.spark.sql.types.StructType)
org/apache/spark/sql/types/StructType/jsonValue()#org/apache/spark/sql/types/StructType$$anonfun$jsonValue$1/1(org.apache.spark.sql.types.StructType)
org/apache/spark/sql/types/StructType/jsonValue()#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/StructType/jsonValue()#org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/StructType/jsonValue()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/types/StructType/catalogString()#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/StructType/catalogString()#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/types/StructType/catalogString()#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/StructType/catalogString()#scala/collection/mutable/ArrayOps/mkString(java.lang.String)
org/apache/spark/sql/types/StructType/catalogString()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/StructType/catalogString()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/StructType/catalogString()#org/apache/spark/sql/types/StructType$$anonfun$2/2(org.apache.spark.sql.types.StructType)
org/apache/spark/sql/types/StructType/catalogString()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/StructType/catalogString()#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/StructType/catalogString()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/StructType/sql()#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/StructType/sql()#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/types/StructType/sql()#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/StructType/sql()#scala/collection/mutable/ArrayOps/mkString(java.lang.String)
org/apache/spark/sql/types/StructType/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/StructType/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/StructType/sql()#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/StructType/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/StructType/sql()#org/apache/spark/sql/types/StructType$$anonfun$3/3(org.apache.spark.sql.types.StructType)
org/apache/spark/sql/types/StructType/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/StructType/simpleString(int)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/types/StructType/simpleString(int)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/types/StructType/simpleString(int)#scala/collection/mutable/ArrayOps/mkString(java.lang.String)
org/apache/spark/sql/types/StructType/simpleString(int)#org/apache/spark/sql/types/StructType$$anonfun$4/4(org.apache.spark.sql.types.StructType,int)
org/apache/spark/sql/types/StructType/simpleString(int)#scala/collection/mutable/ArrayOps/take(int)
org/apache/spark/sql/types/StructType/simpleString(int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/types/StructType/simpleString(int)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/types/StructType/simpleString(int)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/types/StructType/simpleString(int)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/StructType/simpleString(int)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/types/StructType/simpleString(int)#scala/collection/mutable/StringBuilder/append(java.lang.String)
org/apache/spark/sql/types/StructType/simpleString(int)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/collection/immutable/Set/mkString(java.lang.String)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/collection/immutable/Set/$minus$minus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#org/apache/spark/sql/types/StructType$$anonfun$apply$2/2(org.apache.spark.sql.types.StructType,scala.collection.immutable.Set)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/collection/mutable/ArrayOps/filter(scala.Function1)
org/apache/spark/sql/types/StructType/apply(scala.collection.immutable.Set)#scala/collection/immutable/Set/nonEmpty()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectType(scala.reflect.api.Symbols$SymbolApi,java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/SingleType(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator49/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#scala/collection/mutable/HashMap/contains(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#scala/collection/mutable/HashMap/remove(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/GlobalTempViewManager/rename(java.lang.String,java.lang.String)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Union/makeCopy(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/SetOperation/childrenResolved()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/SetOperation$/unapply(org.apache.spark.sql.catalyst.plans.logical.SetOperation)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$WidenSetOperationTypes$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$WidenSetOperationTypes$$buildNewChildrenWithWiderTypes(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/SetOperation/makeCopy(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$WidenSetOperationTypes$$anonfun$apply$2$$anonfun$applyOrElse$3/3(org.apache.spark.sql.catalyst.analysis.TypeCoercion$WidenSetOperationTypes$$anonfun$apply$2,org.apache.spark.sql.catalyst.plans.logical.Union)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Union/childrenResolved()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/SetOperation/childrenResolved()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/SetOperation$/unapply(org.apache.spark.sql.catalyst.plans.logical.SetOperation)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$WidenSetOperationTypes$$anonfun$apply$2$$anonfun$isDefinedAt$1/1(org.apache.spark.sql.catalyst.analysis.TypeCoercion$WidenSetOperationTypes$$anonfun$apply$2,org.apache.spark.sql.catalyst.plans.logical.Union)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Union/childrenResolved()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/apply/2/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#org/apache/spark/sql/catalyst/catalog/CatalogTablePartition$$anonfun$location$1/apply()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#org/apache/spark/sql/catalyst/catalog/CatalogTablePartition$$anonfun$location$1$$anonfun$2/2(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition$$anonfun$location$1)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/anonfun/location/1/apply()#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/Some/x()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/collection/Map$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/collection/IterableView/force(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/collection/Traversable/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/collection/Traversable$/canBuildFrom()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/collection/immutable/Set/apply(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/collection/Map/view()
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$4$$anonfun$apply$11/11(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$4$$anonfun$apply$10/10(org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/collection/Map/mapValues(scala.Function1)
org/apache/spark/sql/catalyst/trees/TreeNode/anonfun/4/apply(java.lang.Object)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/Some/x()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$ArgumentList/implicitCast(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$6$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.analysis.ResolveTableValuedFunctions$$anonfun$apply$1$$anonfun$6)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveTableValuedFunctions/anonfun/apply/1/anonfun/6/apply(scala.Tuple2)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#org/apache/spark/sql/catalyst/expressions/AttributeReference$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.AttributeReference)
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#org/apache/spark/sql/catalyst/util/package$/quoteIdentifier(java.lang.String)
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#org/apache/spark/sql/catalyst/expressions/AttributeReference$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.AttributeReference)
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/AttributeReference/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes/anonfun/1/applyOrElse(scala.Tuple2,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/json/JacksonGenerator/anonfun/org/apache/spark/sql/catalyst/json/JacksonGenerator/makeWriter/17/apply(org.apache.spark.sql.catalyst.expressions.SpecializedGetters,int)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveAggregateFunctions$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveAggregateFunctions$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$6$$anonfun$applyOrElse$58/58(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$6,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$6$$anonfun$applyOrElse$57/57(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions$$anonfun$apply$21$$anonfun$6,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggregateFunctions/anonfun/apply/21/anonfun/6/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/hasGroupingFunction(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/Iterator/next()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/immutable/StringOps/toIterator()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#java/util/regex/Pattern/quote(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#org/apache/spark/sql/catalyst/util/StringUtils$/escapeLikeRegex(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#java/lang/Character/toString(char)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#org/apache/spark/sql/catalyst/util/StringUtils$/fail$1(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/$plus$plus$eq(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/result()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/Iterator/hasNext()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/runtime/BoxesRunTime/unboxToChar(java.lang.Object)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ConcatWs$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.ConcatWs,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ConcatWs$$anonfun$9/9(org.apache.spark.sql.catalyst.expressions.ConcatWs,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/count(scala.Function1)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/IterableLike/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ConcatWs$$anonfun$7/7(org.apache.spark.sql.catalyst.expressions.ConcatWs)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/generic/GenericTraversableTemplate/unzip(scala.Function1)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ConcatWs$$anonfun$doGenCode$2/2(org.apache.spark.sql.catalyst.expressions.ConcatWs)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ConcatWs$$anonfun$doGenCode$3/3(org.apache.spark.sql.catalyst.expressions.ConcatWs)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ConcatWs$$anonfun$doGenCode$4/4(org.apache.spark.sql.catalyst.expressions.ConcatWs)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ConcatWs$$anonfun$doGenCode$5/5(org.apache.spark.sql.catalyst.expressions.ConcatWs)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ConcatWs/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ConcatWs$$anonfun$8/8(org.apache.spark.sql.catalyst.expressions.ConcatWs,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$/org$apache$spark$sql$catalyst$expressions$Cast$$resolvableNullability(boolean,boolean)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$canCast$1/1()
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/forall(scala.Function1)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$/forceNullable(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$needsTimeZone$1/1()
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/exists(scala.Function1)
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/needsTimeZone(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformExpressionsDown(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$$anonfun$apply$38$$anonfun$applyOrElse$76/76(org.apache.spark.sql.catalyst.analysis.CleanupAliases$$anonfun$apply$38)
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$$anonfun$apply$38$$anonfun$applyOrElse$75/75(org.apache.spark.sql.catalyst.analysis.CleanupAliases$$anonfun$apply$38)
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$$anonfun$apply$38$$anonfun$applyOrElse$74/74(org.apache.spark.sql.catalyst.analysis.CleanupAliases$$anonfun$apply$38)
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$$anonfun$apply$38$$anonfun$applyOrElse$16/16(org.apache.spark.sql.catalyst.analysis.CleanupAliases$$anonfun$apply$38)
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$$anonfun$apply$38$$anonfun$97/97(org.apache.spark.sql.catalyst.analysis.CleanupAliases$$anonfun$apply$38)
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$$anonfun$apply$38$$anonfun$96/96(org.apache.spark.sql.catalyst.analysis.CleanupAliases$$anonfun$apply$38)
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CleanupAliases$$anonfun$apply$38$$anonfun$95/95(org.apache.spark.sql.catalyst.analysis.CleanupAliases$$anonfun$apply$38)
org/apache/spark/sql/catalyst/analysis/CleanupAliases/anonfun/apply/38/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/types/Decimal$/MAX_LONG_DIGITS()
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/SortPrefix/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGenerate$$anonfun$makeGeneratorOutput$1/1(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGenerate$)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGenerate/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/immutable/List/mkString(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#org/antlr/v4/runtime/tree/TerminalNode/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PrimitiveDataTypeContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/immutable/$colon$colon/tl$1()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PrimitiveDataTypeContext/INTEGER_VALUE()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/immutable/StringOps/toInt()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitPrimitiveDataType$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/immutable/List/nonEmpty()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/immutable/$colon$colon/head()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#scala/collection/TraversableOnce/toList()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitPrimitiveDataType/1/apply()#org/apache/spark/sql/types/DecimalType$/USER_DEFAULT()
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/HiveHash/nullSafeElementHash(java.lang.String,java.lang.String,boolean,org.apache.spark.sql.types.DataType,java.lang.String,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/HiveHash/anonfun/genHashForStruct/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/children()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$66$$anonfun$apply$25$$anonfun$67/67(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$66$$anonfun$apply$25)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$66$$anonfun$apply$25$$anonfun$68/68(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$66$$anonfun$apply$25)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$66$$anonfun$apply$25$$anonfun$69/69(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$66$$anonfun$apply$25)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$66$$anonfun$apply$25$$anonfun$70/70(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$66$$anonfun$apply$25)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/ArrayBuffer/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$extractExpr$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/ArrayBuffer/contains(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$66/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/66/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$83$$anonfun$apply$63$$anonfun$apply$64/64(org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$83$$anonfun$apply$63)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$83$$anonfun$apply$63/apply()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/83/anonfun/apply/63/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/LocalRelation$$anonfun$computeStats$1/1(org.apache.spark.sql.catalyst.plans.logical.LocalRelation)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/TraversableOnce/sum(scala.math.Numeric)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$2()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$4()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigInt/$times(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#org/apache/spark/sql/catalyst/plans/logical/LocalRelation$$anonfun$toSQL$1/1(org.apache.spark.sql.catalyst.plans.logical.LocalRelation)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#org/apache/spark/sql/catalyst/plans/logical/LocalRelation$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.logical.LocalRelation,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#org/apache/spark/sql/catalyst/plans/logical/LocalRelation$$anonfun$3/3(org.apache.spark.sql.catalyst.plans.logical.LocalRelation)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/Predef$/require(boolean)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LocalRelation/toSQL(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/Alias/sql()#org/apache/spark/sql/catalyst/expressions/Alias$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.Alias)
org/apache/spark/sql/catalyst/expressions/Alias/sql()#org/apache/spark/sql/catalyst/expressions/Alias$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.Alias)
org/apache/spark/sql/catalyst/expressions/Alias/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Alias/sql()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/Alias/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Alias/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Alias/sql()#org/apache/spark/sql/catalyst/util/package$/quoteIdentifier(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Alias/sql()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/Alias/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#scala/collection/TraversableOnce/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#org/apache/spark/sql/catalyst/expressions/Alias$$anonfun$hashCode$2/2(org.apache.spark.sql.catalyst.expressions.Alias)
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Alias/hashCode()#org/apache/spark/sql/catalyst/expressions/Alias$$anonfun$hashCode$1/1(org.apache.spark.sql.catalyst.expressions.Alias)
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#java/text/BreakIterator/getWordInstance(java.util.Locale)
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#java/text/BreakIterator/next()
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#java/lang/Character/isLetterOrDigit(char)
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#java/text/BreakIterator/setText(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#java/text/BreakIterator/current()
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#java/lang/String/charAt(int)
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#scala/collection/mutable/ArrayBuffer/ArrayBuffer()
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#java/lang/String/substring(int,int)
org/apache/spark/sql/catalyst/expressions/Sentences/getSentences(java.lang.String,java.util.Locale)#java/text/BreakIterator/getSentenceInstance(java.util.Locale)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/Map()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$$anonfun$1/1()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$$anonfun$evalPlan$1$1/1(scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$evalExpr(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/immutable/Map/isEmpty()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery$$anonfun$evalPlan$1$2/2()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/immutable/Map$/empty()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/evalPlan$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/ArrayBuffer$/empty()
org/apache/spark/sql/catalyst/optimizer/RewriteCorrelatedScalarSubquery/org$apache$spark$sql$catalyst$optimizer$RewriteCorrelatedScalarSubquery$$splitSubquery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$viewQueryColumnNames$1$$anonfun$apply$1$$anonfun$apply$2/apply()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/viewQueryColumnNames/1/anonfun/apply/1/anonfun/apply/2/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#scala/collection/IterableLike/exists(scala.Function1)
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes$class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.ExpectsInputTypes)
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/StringToMap$$anonfun$checkInputDataTypes$6/6(org.apache.spark.sql.catalyst.expressions.StringToMap)
org/apache/spark/sql/catalyst/expressions/StringToMap/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntegerLiteralContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/math/BigDecimal$/apply(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/math/BigDecimal/isValidLong()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/math/BigDecimal/longValue()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntegerLiteral$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/math/BigDecimal/isValidInt()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/math/BigDecimal/underlying()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#scala/math/BigDecimal/intValue()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntegerLiteral/1/apply()#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#org/antlr/v4/runtime/Token/getType()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitWindowDef$1/org$apache$spark$sql$catalyst$parser$AstBuilder$$anonfun$$$outer()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitWindowDef$1$$anonfun$43$$anonfun$apply$35/35(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitWindowDef$1$$anonfun$43)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitWindowDef$1$$anonfun$43$$anonfun$apply$34/34(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitWindowDef$1$$anonfun$43)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/anonfun/43/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowFrameContext)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#org/apache/hadoop/fs/Path/toUri()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/requireDbExists(java.lang.String)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#org/apache/hadoop/fs/Path/Path(org.apache.hadoop.fs.Path,java.lang.String)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/db()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/TableDesc(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog,org.apache.spark.sql.catalyst.catalog.CatalogTable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/MANAGED()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doCreateTable(org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)#scala/Option/get()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#org/apache/hadoop/fs/FileSystem/delete(org.apache.hadoop.fs.Path,boolean)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree2$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#org/apache/hadoop/fs/FileSystem/mkdirs(org.apache.hadoop.fs.Path)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree1$1(org.apache.spark.sql.catalyst.catalog.CatalogDatabase)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#scala/Some/x()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/partitions()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#scala/collection/mutable/HashMap/toSeq()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/requireTableExists(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#scala/collection/mutable/HashMap/values()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/listPartitions(java.lang.String,java.lang.String,scala.Option)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$listPartitions$1/1(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/partitions()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$dropPartitions$1/1(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog,scala.collection.mutable.HashMap,boolean)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$2/2(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog,scala.collection.mutable.HashMap)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/requireTableExists(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/MANAGED()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/dropPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean,boolean,boolean)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#org/apache/hadoop/fs/FileSystem/mkdirs(org.apache.hadoop.fs.Path)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree3$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#org/apache/hadoop/fs/FileSystem/delete(org.apache.hadoop.fs.Path,boolean)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree4$1(java.lang.String,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/partitions()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$createPartitions$1/1(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog,scala.collection.mutable.HashMap,scala.collection.Seq,org.apache.hadoop.fs.Path)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$1/1(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog,scala.collection.mutable.HashMap)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/requireTableExists(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/createPartitions(java.lang.String,java.lang.String,scala.collection.Seq,boolean)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/functions()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/db()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#scala/collection/mutable/HashMap/nonEmpty()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#scala/collection/mutable/HashMap/contains(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropDatabase(java.lang.String,boolean,boolean)#scala/collection/mutable/HashMap/remove(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$doDropTable$1/1(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/partitions()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$3/3(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/requireDbExists(java.lang.String)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/Predef$/assert(boolean,scala.Function0)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/collection/mutable/HashMap/values()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/MANAGED()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#scala/collection/mutable/HashMap/remove(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doDropTable(java.lang.String,java.lang.String,boolean,boolean)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$doDropTable$2/2(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/liftedTree5$1(java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/partitions()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$renamePartitions$1/1(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#scala/collection/IterableLike/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#scala/Predef$/require(boolean,scala.Function0)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/MANAGED()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/renamePartitions(java.lang.String,java.lang.String,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$renamePartitions$2/2(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog,java.lang.String,java.lang.String,scala.collection.Seq,org.apache.hadoop.fs.Path,boolean,scala.collection.mutable.HashMap)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/table()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/db()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/hadoop/fs/Path/toUri()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/requireTableExists(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/hadoop/fs/Path/Path(org.apache.hadoop.fs.Path,java.lang.String)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#scala/Predef$/assert(boolean,scala.Function0)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$doRenameTable$1/1(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/MANAGED()
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#scala/collection/mutable/HashMap/remove(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/doRenameTable(java.lang.String,java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/table_$eq(org.apache.spark.sql.catalyst.catalog.CatalogTable)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/collection/mutable/ArrayBuffer/size()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/org$apache$spark$sql$catalyst$expressions$ScalaUDF$$genCodeForConverter(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,int)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$toString$1/1(org.apache.spark.sql.catalyst.expressions.ScalaUDF)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$toString$2/2(org.apache.spark.sql.catalyst.expressions.ScalaUDF)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#java/lang/Class/getSimpleName()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage$lzycompute()#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$28/28(org.apache.spark.sql.catalyst.expressions.ScalaUDF)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/indices()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/IndexedSeq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/IndexedSeq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/generic/GenericTraversableTemplate/unzip(scala.Function1)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/IndexedSeq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$24/24(org.apache.spark.sql.catalyst.expressions.ScalaUDF,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$25/25(org.apache.spark.sql.catalyst.expressions.ScalaUDF,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$26/26(org.apache.spark.sql.catalyst.expressions.ScalaUDF)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$27/27(org.apache.spark.sql.catalyst.expressions.ScalaUDF,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InputFileName/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/anonfun/13/apply(scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/IterableLike/exists(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/PhysicalOperation$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/get()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$isSelectiveStarJoin$1$$anonfun$13/13(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection$$anonfun$isSelectiveStarJoin$1)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$isSelectiveStarJoin$1$$anonfun$11/11(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection$$anonfun$isSelectiveStarJoin$1)
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection/anonfun/isSelectiveStarJoin/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/StarSchemaDetection$$anonfun$isSelectiveStarJoin$1$$anonfun$12/12(org.apache.spark.sql.catalyst.optimizer.StarSchemaDetection$$anonfun$isSelectiveStarJoin$1,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeRowJoiner/anonfun/2/apply(scala.Tuple2)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/util/package$/usePrettyExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/util/package$$anonfun$usePrettyExpression$1$$anonfun$4/4(org.apache.spark.sql.catalyst.util.package$$anonfun$usePrettyExpression$1,org.apache.spark.sql.catalyst.expressions.GetStructField)
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$any2stringadd$/$plus$extension(java.lang.Object,java.lang.String)
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/any2stringadd(java.lang.Object)
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/package/anonfun/usePrettyExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/genCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#org/apache/spark/sql/catalyst/expressions/Stack$$anonfun$4$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.Stack$$anonfun$4,int)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#org/apache/spark/sql/catalyst/expressions/CreateStruct$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/4/apply(int)#scala/collection/Seq$/tabulate(int,scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance/childrenResolved()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/encoders/OuterScopes$/getOuterScope(java.lang.Class)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveNewInstance/anonfun/apply/34/anonfun/applyOrElse/14/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/collection/Seq/splitAt(int)
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/expressions/JoinedRow/toSeq(scala.collection.Seq)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/atn/ATN/getNumberOfDecisions()
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/atn/PredictionContextCache/PredictionContextCache()
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/atn/ATNDeserializer/deserialize(char[])
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/VocabularyImpl/VocabularyImpl(java.lang.String[],java.lang.String[])
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/Vocabulary/getSymbolicName(int)
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#java/lang/String/toCharArray()
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/atn/ATN/getDecisionState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/dfa/DFA/DFA(org.antlr.v4.runtime.atn.DecisionState,int)
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/atn/ATNDeserializer/ATNDeserializer()
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/RuntimeMetaData/checkVersion(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/parser/SqlBaseLexer/<clinit>()#org/antlr/v4/runtime/Vocabulary/getLiteralName(int)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#org/apache/spark/sql/types/Decimal$/MAX_LONG_DIGITS()
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#org/apache/spark/sql/types/Decimal$/ROUND_HALF_EVEN()
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/math/package$/min(int,int)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/math/package$/abs(long)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/math/package$/max(int,int)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#org/apache/spark/sql/types/Decimal$/ROUND_CEILING()
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/math/BigDecimal$/apply(long,int)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#org/apache/spark/sql/types/Decimal$/org$apache$spark$sql$types$Decimal$$POW_10()
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#org/apache/spark/sql/types/Decimal$/ROUND_HALF_UP()
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/package$/BigDecimal()
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/math/BigDecimal/setScale(int,scala.Enumeration$Value)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#org/apache/spark/sql/types/Decimal$/ROUND_FLOOR()
org/apache/spark/sql/types/Decimal/changePrecision(int,int,scala.Enumeration$Value)#scala/math/BigDecimal/precision()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getText()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getFloatValue()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/6/anonfun/apply/8/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Predef$/float2Float(float)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$$anonfun$stripExtraNewLines$1/1(scala.collection.mutable.StringBuilder,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripExtraNewLines(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/mutable/StringBuilder/result()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/mutable/ArrayOps/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/immutable/StringOps/split(char)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/mutable/StringBuilder/result()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/immutable/StringOps/split(char)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$$anonfun$stripOverlappingComments$1/1(scala.collection.mutable.StringBuilder,scala.collection.Map,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/mutable/ArrayOps/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/collection/immutable/StringOps/count(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#java/lang/String/startsWith(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/math/package$/max(int,int)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.codegen.CodeFormatter)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#java/lang/String/length()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.codegen.CodeFormatter)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/collection/immutable/StringOps/$times(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#java/lang/String/endsWith(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/org$apache$spark$sql$catalyst$expressions$codegen$CodeFormatter$$addLine(java.lang.String)#scala/collection/immutable/StringOps/format(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/x()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/immutable/Set/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Set/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/immutable/Set$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/Set()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/toSet()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder$$anonfun$extractInnerJoins$1/1(org.apache.spark.sql.catalyst.optimizer.CostBasedJoinReorder)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/extractInnerJoins(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder$$anonfun$2/2(org.apache.spark.sql.catalyst.optimizer.CostBasedJoinReorder)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/immutable/Set/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/CostBasedJoinReorder/org$apache$spark$sql$catalyst$optimizer$CostBasedJoinReorder$$reorder(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$database$1/apply()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/CatalogTable/anonfun/database/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/lang/Package/getName()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/Predef$/println(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/tools/nsc/interpreter/AbstractFileClassLoader/classBytes(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/io/File/exists()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/sys/process/ProcessBuilder/$bang$bang()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/io/FileOutputStream/close()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/io/File/File(java.io.File,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/lang/String/split(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/io/File/mkdir()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/sys/process/package$/stringToProcess(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/collection/mutable/ArrayOps/last()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/lang/Class/getPackage()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#org/apache/spark/sql/catalyst/expressions/codegen/package$DumpByteCode$/dumpDirectory()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/io/File/getCanonicalPath()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/io/FileOutputStream/write(byte[])
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/lang/Class/getClassLoader()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/package/DumpByteCode/apply(java.lang.Object)#java/io/FileOutputStream/FileOutputStream(java.io.File)
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/Double/isNaN()
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/Float/isNaN()
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/double2Double(double)
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/float2Float(float)
org/apache/spark/sql/catalyst/expressions/IsNaN/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/IntegerLiteral$/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/x()
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/org$apache$spark$sql$catalyst$optimizer$LimitPushDown$$maybePushLimit(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/get()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPosition()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeBounds(scala.reflect.api.Types$TypeApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/asModule()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticPackage(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$InternalApi/reificationSupport()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ClassSymbolApi/asType()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$ModuleSymbolApi/moduleClass()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ExistentialType(scala.collection.immutable.List,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/TypeRef(scala.reflect.api.Types$TypeApi,scala.reflect.api.Symbols$SymbolApi,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/TypeName()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/FlagsRepr()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/universe()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Symbols$TypeSymbolApi/toTypeConstructor()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Names$TypeNameExtractor/apply(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/NoPrefix()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/setInfo(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticModule(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi$FlagsReprExtractor/apply(long)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/ThisType(scala.reflect.api.Symbols$SymbolApi)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/newNestedSymbol(scala.reflect.api.Symbols$SymbolApi,scala.reflect.api.Names$NameApi,scala.reflect.api.Position,java.lang.Object,boolean)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Universe/internal()
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/collection/immutable/List$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Mirror/staticClass(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/typecreator19/1/apply(scala.reflect.api.Mirror)#scala/reflect/api/Internals$ReificationSupportApi/selectOverloadedMethod(scala.reflect.api.Symbols$SymbolApi,java.lang.String,int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/compile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$$anonfun$4/4()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/collection/mutable/ArrayOps/$colon$plus(java.lang.Object,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$/newCodeGenContext()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$$anonfun$create$1/1(scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/create(scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$$anonfun$1/1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection/createCodeForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.StructType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#org/apache/spark/sql/catalyst/expressions/Pmod/dataType()
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/expressions/Pmod/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$84$$anonfun$apply$66$$anonfun$apply$67/67(org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$84$$anonfun$apply$66)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$$anonfun$84$$anonfun$apply$66/apply()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/84/anonfun/apply/66/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/Iterator/toList()
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/immutable/List/unzip(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike$$anonfun$8/8(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/Iterator/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/org$apache$spark$sql$catalyst$expressions$CreateNamedStructLike$$x$22(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/Seq/grouped(int)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/immutable/List/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/immutable/List/contains(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/immutable/List/nonEmpty()
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/immutable/List/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike$$anonfun$10/10(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateNamedStructLike/class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.CreateNamedStructLike)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/NullPropagation$$anonfun$apply$8$$anonfun$applyOrElse$7$$anonfun$15/15(org.apache.spark.sql.catalyst.optimizer.NullPropagation$$anonfun$apply$8$$anonfun$applyOrElse$7)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/NullPropagation$$anonfun$apply$8/org$apache$spark$sql$catalyst$optimizer$NullPropagation$$anonfun$$$outer()
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/aggregate/Count$/apply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/NullPropagation$$anonfun$apply$8$$anonfun$applyOrElse$7$$anonfun$applyOrElse$17/17(org.apache.spark.sql.catalyst.optimizer.NullPropagation$$anonfun$apply$8$$anonfun$applyOrElse$7)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/NullPropagation$$anonfun$apply$8$$anonfun$applyOrElse$7$$anonfun$applyOrElse$16/16(org.apache.spark.sql.catalyst.optimizer.NullPropagation$$anonfun$apply$8$$anonfun$applyOrElse$7)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/NullPropagation$$anonfun$apply$8$$anonfun$applyOrElse$7$$anonfun$applyOrElse$15/15(org.apache.spark.sql.catalyst.optimizer.NullPropagation$$anonfun$apply$8$$anonfun$applyOrElse$7)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/NullPropagation/anonfun/apply/8/anonfun/applyOrElse/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/math/BigDecimal$/apply(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#java/lang/String/length()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#java/lang/String/substring(int,int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$numericLiteral$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#java/lang/NumberFormatException/getMessage()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/math/BigDecimal/$greater(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NumberContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/numericLiteral/1/apply()#scala/math/BigDecimal/$less(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/List$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/CreateNamedStruct$$anonfun$doGenCode$1/1(org.apache.spark.sql.catalyst.expressions.CreateNamedStruct,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/List/size()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/List/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Hex/anonfun/doGenCode/16/apply(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/math/BigDecimal/scale()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$DecimalConverter/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$DecimalConverter/DecimalConverter(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$/convertToCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/InternalRow$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$2/2()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/math/BigDecimal/precision()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$5/5()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#java/math/BigDecimal/scale()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$TimestampConverter$/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$StringConverter$/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$DateConverter$/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#java/math/BigDecimal/precision()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/apply(scala.collection.Map,scala.Function1,scala.Function1)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$1/1()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$3/3()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$4/4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$fail(org.apache.spark.sql.types.StructType,int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/Expression/collect(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/indices()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/last()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/distinct()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/package$AttributeSeq/toStructType()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/package$/AttributeSeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveDeserializer$$anonfun$13/13(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer$)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/collection/SeqLike/sorted(scala.math.Ordering)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveDeserializer/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveDeserializer$$validateTopLevelTupleFields(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/IntegerLiteral$/unapply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/TimeWindow$/getIntervalInMicroSeconds(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/NonNullLiteral$/unapply(org.apache.spark.sql.catalyst.expressions.Literal)
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/StringOps/toLong()
org/apache/spark/sql/catalyst/expressions/TimeWindow/org$apache$spark$sql$catalyst$expressions$TimeWindow$$parseExpression(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#org/apache/commons/lang3/StringUtils/isBlank(java.lang.CharSequence)
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#org/apache/spark/unsafe/types/CalendarInterval/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#java/lang/String/startsWith(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/TimeWindow/getIntervalInMicroSeconds(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/StringTranslate$/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#scala/Predef$/char2Character(char)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/lang/String/charAt(int)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/lang/String/length()
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/util/HashMap/HashMap()
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/util/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/util/HashMap/get(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.InterpretedHashFunction)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/InternalRow/get(int,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/unsafe/types/UTF8String/numBytes()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#java/math/BigInteger/toByteArray()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/unsafe/types/UTF8String/getBaseOffset()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#java/lang/Double/doubleToLongBits(double)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/unsafe/types/UTF8String/getBaseObject()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#java/lang/Float/floatToIntBits(float)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/types/Decimal$/MAX_LONG_DIGITS()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.InterpretedHashFunction)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#java/math/BigDecimal/unscaledValue()
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/util/ArrayData/get(int,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/OptimizeIn$$anonfun$apply$3$$anonfun$applyOrElse$3$$anonfun$6/6(org.apache.spark.sql.catalyst.optimizer.OptimizeIn$$anonfun$apply$3$$anonfun$applyOrElse$3)
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/immutable/HashSet$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/ExpressionSet$/apply(scala.collection.TraversableOnce)
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/OptimizeIn$$anonfun$apply$3/org$apache$spark$sql$catalyst$optimizer$OptimizeIn$$anonfun$$$outer()
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/OptimizeIn/anonfun/apply/3/anonfun/applyOrElse/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/SetLike/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/apache/spark/sql/catalyst/expressions/ListQuery$/apply$default$2()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PredicateContext/expression()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withPredicate$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/apache/spark/sql/catalyst/expressions/ListQuery$/apply$default$3()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PredicateContext/NOT()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withPredicate$1/invertIfNotDefined$1(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withPredicate$1$$anonfun$apply$32/32(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withPredicate$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PredicateContext/query()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withPredicate/1/apply()#org/antlr/v4/runtime/Token/getType()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$addToPath$1(java.lang.String,org.apache.spark.sql.types.DataType,scala.collection.Seq,scala.Option)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/getClassNameFromType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/dataType()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#java/lang/String/startsWith(java.lang.String)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/schemaFor(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$Schema/nullable()
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$addToPathOrdinal$1(int,org.apache.spark.sql.types.DataType,scala.collection.Seq,scala.Option)
org/apache/spark/sql/catalyst/ScalaReflection/anonfun/9/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/ScalaReflection$/org$apache$spark$sql$catalyst$ScalaReflection$$deserializerFor(scala.reflect.api.Types$TypeApi,scala.Option,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/x()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$7/7(org.apache.spark.sql.catalyst.analysis.TypeCoercion$InConversion$$anonfun$apply$4)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/In/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/In/resolved()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/get()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$9/9(org.apache.spark.sql.catalyst.analysis.TypeCoercion$InConversion$$anonfun$apply$4)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$8/8(org.apache.spark.sql.catalyst.analysis.TypeCoercion$InConversion$$anonfun$apply$4)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$applyOrElse$4/4(org.apache.spark.sql.catalyst.analysis.TypeCoercion$InConversion$$anonfun$apply$4,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$$findWiderCommonType(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$applyOrElse$5/5(org.apache.spark.sql.catalyst.analysis.TypeCoercion$InConversion$$anonfun$apply$4,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/CreateStruct$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$10/10(org.apache.spark.sql.catalyst.analysis.TypeCoercion$InConversion$$anonfun$apply$4)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$InConversion$$flattenExpr(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$isDefinedAt$2/2(org.apache.spark.sql.catalyst.analysis.TypeCoercion$InConversion$$anonfun$apply$4,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$InConversion$$flattenExpr(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/In/resolved()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Some/get()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/types/ArrayType/jsonValue()#org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/ArrayType/jsonValue()#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/types/ArrayType/jsonValue()#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/types/ArrayType/jsonValue()#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/ArrayType/jsonValue()#scala/Predef$/$conforms()
org/apache/spark/sql/types/ArrayType/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/ArrayType/jsonValue()#org/apache/spark/sql/types/ArrayType/typeName()
org/apache/spark/sql/types/ArrayType/jsonValue()#org/apache/spark/sql/types/ArrayType$$anonfun$jsonValue$1/1(org.apache.spark.sql.types.ArrayType)
org/apache/spark/sql/types/ArrayType/jsonValue()#org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/ArrayType/jsonValue()#org/apache/spark/sql/types/ArrayType$$anonfun$jsonValue$2/2(org.apache.spark.sql.types.ArrayType)
org/apache/spark/sql/types/ArrayType/jsonValue()#org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/ArrayType/jsonValue()#org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getText()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getDoubleValue()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/7/anonfun/apply/9/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Predef$/double2Double(double)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/LikeSimplification$/org$apache$spark$sql$catalyst$optimizer$LikeSimplification$$startsAndEndsWith()
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/util/matching/Regex/unapplySeq(java.lang.CharSequence)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/LikeSimplification$/org$apache$spark$sql$catalyst$optimizer$LikeSimplification$$endsWith()
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/LinearSeqOptimized/apply(int)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/String/length()
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/LikeSimplification$/org$apache$spark$sql$catalyst$optimizer$LikeSimplification$$equalTo()
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/LikeSimplification$/org$apache$spark$sql$catalyst$optimizer$LikeSimplification$$startsWith()
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/LinearSeqOptimized/lengthCompare(int)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/LikeSimplification$/org$apache$spark$sql$catalyst$optimizer$LikeSimplification$$contains()
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/String/endsWith(java.lang.String)
org/apache/spark/sql/catalyst/optimizer/LikeSimplification/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#scala/collection/immutable/StringOps/toDouble()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SampleContext/ON()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withSample$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#org/apache/spark/sql/catalyst/plans/logical/Limit$/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SampleContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#org/antlr/v4/runtime/Token/getType()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withSample$1/sample$1(double)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SampleContext/expression()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/apply()#org/antlr/v4/runtime/Token/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#org/apache/spark/util/random/RandomSampler$/roundingEpsilon()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withSample$1$$anonfun$sample$1$1/1(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withSample$1,double,double)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#org/apache/spark/sql/catalyst/parser/ParserUtils$/validate(scala.Function0,java.lang.String,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#scala/Predef$/boolean2Boolean(boolean)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#scala/math/package$/random()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withSample/1/sample$1(double)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#java/lang/Class/getMethods()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#org/apache/spark/sql/catalyst/expressions/objects/Invoke$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.objects.Invoke)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#scala/collection/mutable/ArrayOps/find(scala.Function1)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/method$lzycompute()#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/isPrimitive()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/reflect/Method/getReturnType()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/reflect/Method/getExceptionTypes()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/ArrayOps/nonEmpty()
org/apache/spark/sql/catalyst/expressions/objects/Invoke/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$6/6()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$5/5(int)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/collection/mutable/ArrayOps/max(scala.math.Ordering)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$/expressionInfo(java.lang.String,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#java/lang/Class/getConstructors()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#java/lang/Class/isAssignableFrom(java.lang.Class)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/reflect/ClassTag$/Int()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/collection/mutable/ArrayOps/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/Predef$/intArrayOps(int[])
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$7/7(java.lang.String,java.lang.reflect.Constructor[],scala.Option)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#org/apache/spark/sql/catalyst/analysis/FunctionRegistry$$anonfun$4/4()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/reflect/ClassTag/runtimeClass()
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/collection/mutable/ArrayOps/find(scala.Function1)
org/apache/spark/sql/catalyst/analysis/FunctionRegistry/expression(java.lang.String,scala.reflect.ClassTag)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/SeqLike/reverseMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/math/Ordering$/ordered(scala.Function1)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$/timeMap()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$1/1()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/mutable/Map/keys()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/TraversableOnce/max(scala.math.Ordering)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$dumpTimeSpent$2/2(int)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/JavaConverters$/mapAsScalaMapConverter(java.util.Map)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$/dumpTimeSpent()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/spark_project/guava/util/concurrent/AtomicLongMap/asMap()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$dumpTimeSpent$1/1()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/mutable/Map/toSeq()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/immutable/Map/values()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$org$apache$spark$sql$catalyst$catalog$SessionCatalog$$requireNonEmptyValueInPartitionSpec$1$$anonfun$apply$1/1(org.apache.spark.sql.catalyst.catalog.SessionCatalog$$anonfun$org$apache$spark$sql$catalyst$catalog$SessionCatalog$$requireNonEmptyValueInPartitionSpec$1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/Iterable/exists(scala.Function1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/catalog/SessionCatalog$$anonfun$org$apache$spark$sql$catalyst$catalog$SessionCatalog$$requireNonEmptyValueInPartitionSpec$1$$anonfun$34/34(org.apache.spark.sql.catalyst.catalog.SessionCatalog$$anonfun$org$apache$spark$sql$catalyst$catalog$SessionCatalog$$requireNonEmptyValueInPartitionSpec$1)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/org/apache/spark/sql/catalyst/catalog/SessionCatalog/requireNonEmptyValueInPartitionSpec/1/apply(scala.collection.immutable.Map)#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/collection/immutable/Map/nonEmpty()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap/$plus$plus$eq(scala.collection.TraversableOnce)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap/LinkedHashMap()
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTablePartition$$anonfun$toLinkedHashMap$6/6(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)
org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTablePartition$$anonfun$1/1(org.apache.spark.sql.catalyst.catalog.CatalogTablePartition)
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat$/empty()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$11()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$14()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$15()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$5()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$10()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$12()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$13()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$8()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$16()
org/apache/spark/sql/catalyst/catalog/CatalogRelation/preCanonicalized()#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$17()
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/objects/InvokeLike$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/objects/InvokeLike$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/objects/InvokeLike$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/InvokeLike/class/prepareArguments(org.apache.spark.sql.catalyst.expressions.objects.InvokeLike,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$throwError(java.lang.String,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$2/2(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$1/1()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/foreachUp(scala.Function1)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$2/2()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$collectStreamingAggregates$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/collect(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$1/1()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$3/3()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/AliasViewChild$$anonfun$apply$1$$anonfun$2/2(org.apache.spark.sql.catalyst.analysis.AliasViewChild$$anonfun$apply$1)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/AliasViewChild$$anonfun$apply$1$$anonfun$1/1(org.apache.spark.sql.catalyst.analysis.AliasViewChild$$anonfun$apply$1,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/isPrimitive()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/takeWhile(scala.Function1)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/reverse()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/isAssignableFrom(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Some/x()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/isArray()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getComponentType()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$$anonfun$12/12(org.apache.spark.sql.catalyst.expressions.objects.MapObjects,java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$$anonfun$10/10(org.apache.spark.sql.catalyst.expressions.objects.MapObjects)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$$anonfun$11/11(org.apache.spark.sql.catalyst.expressions.objects.MapObjects)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$$anonfun$13/13(org.apache.spark.sql.catalyst.expressions.objects.MapObjects,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/String/contains(java.lang.CharSequence)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/GenArrayData$$anonfun$2/2(boolean,java.lang.String)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#org/apache/spark/unsafe/array/ByteArrayMethods/roundNumberOfBytesToNearestWord(int)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/GenArrayData$/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/GenArrayData$$anonfun$3/3(boolean,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#org/apache/spark/sql/catalyst/expressions/TernaryExpression/children()
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/Function3/apply(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#org/apache/spark/sql/catalyst/expressions/TernaryExpression/dataType()
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/TernaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function3)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/Predef$/Set()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/collection/immutable/Set$/empty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/40/apply(org.apache.spark.sql.catalyst.expressions.SortOrder)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$$anonfun$10/10()
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/collection/mutable/Buffer$/empty()
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$$anonfun$7/7(org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$$anonfun$9/9(org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/mapChildren(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/mapExpressions(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.collection.mutable.Buffer)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$$anonfun$org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases$1/1(org.apache.spark.sql.catalyst.expressions.AttributeMap,scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$$anonfun$8/8(org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$removeRedundantAliases(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)#org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAliases$/org$apache$spark$sql$catalyst$optimizer$RemoveRedundantAliases$$createAttributeMapping(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#org/apache/spark/sql/types/Decimal$$anonfun$floor$1/apply()
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/types/Decimal/anonfun/floor/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[],int,int)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/arrayOffset()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#com/fasterxml/jackson/core/JsonFactory/createParser(java.io.Reader)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/io/InputStreamReader/InputStreamReader(java.io.InputStream,java.lang.String)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/remaining()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/array()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/hasArray()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/json/CreateJacksonParser$/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/unsafe/types/UTF8String/getByteBuffer()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/position()
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#java/lang/Class/getMethod(java.lang.String,java.lang.Class[])
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#org/apache/spark/util/Utils$/classForName(java.lang.String)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#java/util/concurrent/ConcurrentMap/putIfAbsent(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#java/lang/Class/getField(java.lang.String)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#java/lang/reflect/Field/get(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#org/apache/spark/sql/catalyst/encoders/OuterScopes$/org$apache$spark$sql$catalyst$encoders$OuterScopes$$iwGetter(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#java/lang/reflect/Method/getReturnType()
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#java/lang/Class/getName()
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#org/apache/spark/sql/catalyst/encoders/OuterScopes$/outerScopes()
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/OuterScopes/anonfun/getOuterScope/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#org/apache/spark/SparkException/SparkException(java.lang.String)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#org/apache/spark/sql/catalyst/encoders/RowEncoder$$anonfun$1/apply()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#java/lang/Class/getName()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/ResolveHints$ResolveBroadcastHints$$anonfun$apply$1$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.analysis.ResolveHints$ResolveBroadcastHints$$anonfun$apply$1)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Set/contains(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/String/toUpperCase(java.util.Locale)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/ResolveHints$ResolveBroadcastHints/org$apache$spark$sql$catalyst$analysis$ResolveHints$ResolveBroadcastHints$$applyBroadcastHint(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/ResolveHints$ResolveBroadcastHints/org$apache$spark$sql$catalyst$analysis$ResolveHints$ResolveBroadcastHints$$BROADCAST_HINT_NAMES()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableOnce/toSet()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#org/apache/hadoop/fs/Path/Path(java.net.URI)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/HashMap/contains(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#org/apache/hadoop/fs/FileSystem/delete(org.apache.hadoop.fs.Path,boolean)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/HashMap/remove(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/anonfun/dropPartitions/1/apply(scala.collection.immutable.Map)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/Integer/valueOf(int)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/Double/valueOf(double)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/Long/valueOf(long)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/Byte/valueOf(byte)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/StringBuilder/append(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/Short/valueOf(short)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/Float/valueOf(float)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/Boolean/valueOf(boolean)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/get(int,org.apache.spark.sql.types.DataType)#java/lang/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#java/lang/StringBuilder/append(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#java/lang/StringBuilder/append(long)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#org/apache/spark/unsafe/Platform/putLong(java.lang.Object,long,long)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#java/math/BigInteger/toByteArray()
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#java/lang/AssertionError/AssertionError()
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#java/lang/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#java/lang/AssertionError/AssertionError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#java/lang/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/UnsafeRow/setDecimal(int,org.apache.spark.sql.types.Decimal,int)#java/math/BigDecimal/unscaledValue()
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Concat$$anonfun$doGenCode$1/1(org.apache.spark.sql.catalyst.expressions.Concat)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Concat$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.Concat,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Concat$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.Concat)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Concat/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/WidenSetOperationTypes/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/util/control/NonFatal$/unapply(java.lang.Throwable)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#java/lang/Throwable/getMessage()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/ResolveInlineTables$$anonfun$4/org$apache$spark$sql$catalyst$analysis$ResolveInlineTables$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/4/anonfun/apply/4/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$10$$anonfun$11/11(org.apache.spark.sql.catalyst.optimizer.RewriteDistinctAggregates$$anonfun$10,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/collection/SeqLike/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$10$$anonfun$12/12(org.apache.spark.sql.catalyst.optimizer.RewriteDistinctAggregates$$anonfun$10,org.apache.spark.sql.catalyst.expressions.Literal)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/10/apply(scala.Tuple2)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11$$anonfun$40/40(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11$$anonfun$41/41(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11$$anonfun$applyOrElse$43/43(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11$$anonfun$applyOrElse$42/42(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11$$anonfun$applyOrElse$41/41(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOrdinalInOrderByAndGroupBy$$anonfun$apply$11)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/JsonExprUtils$/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/JsonExprUtils$$anonfun$convertToMapData$1/1()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/CreateMap/eval$default$1()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Map$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/parser/CatalystSqlParser$/parseTableSchema(java.lang.String)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/JsonExprUtils$/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveOrdinalInOrderByAndGroupBy/anonfun/apply/11/anonfun/41/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#org/apache/spark/sql/catalyst/expressions/UnsafeProjection$/create(org.apache.spark.sql.types.DataType[])
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#org/apache/spark/sql/catalyst/expressions/UnsafeProjection$/create(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#org/apache/spark/sql/catalyst/expressions/UnsafeProjection$$anonfun$create$2/2()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$1/1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$2/2()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitQuery$1$$anonfun$apply$4/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CtesContext/namedQuery()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryContext/ctes()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitQuery$1$$anonfun$apply$4$$anonfun$2/2(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitQuery$1$$anonfun$apply$4)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/checkDuplicateKeys(scala.collection.Seq,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitQuery/1/anonfun/apply/4/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$2$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$$anonfun$checkForStreaming$2)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$collectStreamingAggregates$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$throwError(java.lang.String,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$2$$anonfun$apply$4/4(org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$$anonfun$checkForStreaming$2)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$2$$anonfun$apply$3/3(org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$$anonfun$checkForStreaming$2)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$2$$anonfun$6/6(org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$$anonfun$checkForStreaming$2)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$2$$anonfun$5/5(org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$$anonfun$checkForStreaming$2)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/CoGroup/children()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/children()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/FlatMapGroupsWithState/isStreaming()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$throwErrorIf(boolean,java.lang.String,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$containsCompleteData$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/anonfun/checkForStreaming/2/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/SeqLike/size()
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#org/apache/spark/sql/catalyst/expressions/RDG/child()
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/RDG/seed$lzycompute()#org/apache/spark/sql/catalyst/expressions/RDG/prettyName()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/encoders/RowEncoder$/org$apache$spark$sql$catalyst$encoders$RowEncoder$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry$$anonfun$2/apply()
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/SimpleFunctionRegistry/anonfun/2/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#org/apache/spark/sql/catalyst/analysis/ResolveHints$ResolveBroadcastHints$$anonfun$apply$1$$anonfun$applyOrElse$1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveHints/ResolveBroadcastHints/anonfun/apply/1/anonfun/applyOrElse/1/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/TRUNC_TO_YEAR()
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/TRUNC_TO_MONTH()
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getDayInYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getDayOfMonth(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/truncDate(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/immutable/StringOps/contains(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/lang/String/substring(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/lang/String/indexOf(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/util/Calendar/getTime()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/sql/Date/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#javax/xml/bind/DatatypeConverter/parseDateTime(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/stringToTime(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/lang/String/substring(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/sql/Timestamp/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/_4()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/isLeapYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/monthDays()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/splitDate(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/dateAddMonths(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/firstDayOfMonth(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/reflect/ClassTag$/Int()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getTimeZone(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#org/apache/spark/unsafe/types/UTF8String/getBytes()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Predef$/wrapIntArray(int[])
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#java/util/Calendar/getTimeInMillis()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#java/util/Calendar/set(int,int,int,int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Array$/apply(scala.collection.Seq,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#java/util/Calendar/set(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/isInvalidDate(int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#java/util/Calendar/getInstance(java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/collection/immutable/StringOps/format(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Option/get()
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getYearAndDayInYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/splitDate(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/Tuple2/_1$mcI$sp()
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/isLeapYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/Tuple2$mcII$sp/sp(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/reflect/ClassTag$/Int()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/threadLocalGmtCalendar()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/unsafe/types/UTF8String/getBytes()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/lang/ThreadLocal/get()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/Predef$/wrapIntArray(int[])
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/util/Calendar/getTimeInMillis()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/isInvalidDate(int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/Array$/apply(scala.collection.Seq,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/util/Calendar/set(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/util/Calendar/clear()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/util/Calendar/set(int,int,int,int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/stringToDate(org.apache.spark.unsafe.types.UTF8String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/timestampToString(long,java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/lang/String/length()
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/sql/Timestamp/toString()
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/lang/String/substring(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaTimestamp(long)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/text/DateFormat/format(java.util.Date)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getThreadLocalTimestampFormat(java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/math/package$/round(double)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/_4()
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/splitDate(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/monthsBetween(long,long,java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/daysToMillis(int,java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/millisToDays(long,java.util.TimeZone)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QualifiedNameContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FunctionCallContext/qualifiedName()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FunctionCallContext/windowSpec()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/Some/get()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/Option/exists(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FunctionCallContext/setQuantifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitFunctionCall$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitFunctionCall$1$$anonfun$38/38(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitFunctionCall$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitFunctionCall/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitFunctionCall$1$$anonfun$39/39(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitFunctionCall$1)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#java/lang/reflect/Field/get(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#java/lang/reflect/Field/setAccessible(boolean)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#scala/collection/mutable/Map/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$recordCompilationStats$1/1(java.lang.Class,java.lang.reflect.Field)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#scala/collection/JavaConverters$/mapAsScalaMapConverter(java.util.Map)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#java/lang/Class/getDeclaredField(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)#org/apache/spark/util/Utils$/classForName(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/janino/ClassBodyEvaluator/setDefaultImports(java.lang.String[])
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment,org.codehaus.janino.ClassBodyEvaluator,scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/util/ParentClassLoader/ParentClassLoader(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/runtime/VolatileByteRef/create(byte)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/janino/JaninoRuntimeException/JaninoRuntimeException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/janino/ClassBodyEvaluator/cook(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/commons/compiler/CompileException/getLocation()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/janino/ClassBodyEvaluator/getClazz()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile$3/3(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#java/lang/Class/newInstance()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/commons/compiler/CompileException/CompileException(java.lang.String,org.codehaus.commons.compiler.Location)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/janino/ClassBodyEvaluator/setExtendedClass(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/logError(scala.Function0,java.lang.Throwable)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$formatted$1(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment,scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/janino/ClassBodyEvaluator/ClassBodyEvaluator()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/janino/ClassBodyEvaluator/setClassName(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/codehaus/janino/ClassBodyEvaluator/setParentClassLoader(java.lang.ClassLoader)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile$2/2(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/recordCompilationStats(org.codehaus.janino.ClassBodyEvaluator)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/runtime/ObjectRef/zero()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/util/Utils$/getContextOrSparkClassLoader()
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#org/apache/spark/sql/catalyst/plans/JoinType$/apply(java.lang.String)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$MultiInsertQueryContext/multiInsertQueryBody()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$MultiInsertQueryContext/fromClause()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitMultiInsertQuery$1$$anonfun$3/3(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitMultiInsertQuery$1,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitMultiInsertQuery$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/apply()#scala/Some/get()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#org/apache/spark/sql/catalyst/catalog/CatalogUtils$/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#org/apache/spark/sql/catalyst/catalog/CatalogUtils$$anonfun$8/8(java.lang.String,scala.collection.Seq,scala.Function2)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#org/apache/spark/sql/catalyst/catalog/CatalogUtils$$anonfun$7/7(java.lang.String,scala.collection.Seq,scala.Function2)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/util/control/NonFatal$/unapply(java.lang.Throwable)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/newDateFormat(java.lang.String,java.util.TimeZone)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#java/text/DateFormat/parse(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#java/util/Date/getTime()
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/UnixTime/left()
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/daysToMillis(int,java.util.TimeZone)
org/apache/spark/sql/catalyst/expressions/UnixTime/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/UnixTime/right()
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/UnixTime$$anonfun$doGenCode$13/13(org.apache.spark.sql.catalyst.expressions.UnixTime,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/UnixTime/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/UnixTime/left()
org/apache/spark/sql/catalyst/expressions/UnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/UnixTime/right()
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#org/apache/spark/sql/catalyst/streaming/InternalOutputModes$/apply(java.lang.String)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateStruct/anonfun/apply/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$AliasedGenerator$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractGenerator$$AliasedGenerator()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGenerate$/makeGeneratorOutput(org.apache.spark.sql.catalyst.expressions.Generator,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Predef$/assert(boolean,scala.Function0)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractGenerator$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractGenerator$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/anonfun/58/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$58$$anonfun$apply$59/59(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$58)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/collection/mutable/ArrayOps/indexWhere(scala.Function1)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#java/util/Arrays/copyOfRange(byte[],int,int)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/Predef$/byteArrayOps(byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/Tuple2/_1$mcZ$sp()
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/char2byte(int,int,byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/unsafe/types/UTF8String/fromBytes(byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#java/lang/Math/abs(int)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/decode(long,int,byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/Tuple2$mcZI$sp/sp(boolean,int)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/encode(int,int,byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$$anonfun$1/1()
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/byte2char(int,int,byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/convert(byte[],int,int)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/anonfun/14/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#org/apache/spark/sql/catalyst/util/TypeUtils$$anonfun$compareBinary$1/1(byte[])
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/collection/generic/FilterMonadic/foreach(scala.Function1)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/collection/immutable/Range/withFilter(scala.Function1)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#org/apache/spark/sql/catalyst/util/TypeUtils$/compareBinary(byte[],byte[])
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#java/lang/Object/Object()
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#org/apache/spark/sql/catalyst/util/TypeUtils$$anonfun$compareBinary$2/2(byte[],byte[],java.lang.Object)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/runtime/RichInt$/until$extension0(int,int)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/Predef$/intWrapper(int)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/runtime/NonLocalReturnControl/key()
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/runtime/NonLocalReturnControl/value$mcI$sp()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggAliasInGroupBy$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveAggAliasInGroupBy$$mayResolveAttrByAggregateExprs(scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggAliasInGroupBy$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveAggAliasInGroupBy$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13$$anonfun$applyOrElse$50/50(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13$$anonfun$applyOrElse$46/46(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13$$anonfun$applyOrElse$47/47(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13$$anonfun$applyOrElse$48/48(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveAggAliasInGroupBy/anonfun/apply/13/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13$$anonfun$applyOrElse$49/49(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggAliasInGroupBy$$anonfun$apply$13)
org/apache/spark/sql/types/MapType/jsonValue()#org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/MapType/jsonValue()#org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/MapType/jsonValue()#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/types/MapType/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)
org/apache/spark/sql/types/MapType/jsonValue()#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/types/MapType/jsonValue()#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/MapType/jsonValue()#scala/Predef$/$conforms()
org/apache/spark/sql/types/MapType/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/MapType/jsonValue()#org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/MapType/jsonValue()#org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/MapType/jsonValue()#org/apache/spark/sql/types/MapType/typeName()
org/apache/spark/sql/types/MapType/jsonValue()#org/apache/spark/sql/types/MapType$$anonfun$jsonValue$1/1(org.apache.spark.sql.types.MapType)
org/apache/spark/sql/types/MapType/jsonValue()#org/apache/spark/sql/types/MapType$$anonfun$jsonValue$2/2(org.apache.spark.sql.types.MapType)
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/collection/mutable/StringBuilder/append(java.lang.String)
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#org/apache/spark/sql/types/DataType$/buildFormattedString(org.apache.spark.sql.types.DataType,java.lang.String,scala.collection.mutable.StringBuilder)
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/MapType/buildFormattedString(java.lang.String,scala.collection.mutable.StringBuilder)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/mutable/ArrayBuffer/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/Seq/count(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$7/7()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$8/8()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$/hashTimestamp(long)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/InternalRow/get(int,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$$anonfun$6/6()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$/hashCalendarInterval(org.apache.spark.unsafe.types.CalendarInterval)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$/normalizeDecimal(java.math.BigDecimal)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$$anonfun$5/5()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#java/math/BigDecimal/hashCode()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/util/ArrayData/get(int,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/reduceOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion$$anonfun$11/11()
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion$$anonfun$partitionByDeterministic$1/1()
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion/partitionByDeterministic(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/PushProjectionThroughUnion$$anonfun$partitionByDeterministic$2/2()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/immutable/Map/size()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$17/17(org.apache.spark.sql.catalyst.expressions.AttributeReference,org.apache.spark.sql.catalyst.expressions.Literal,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$26/26(scala.collection.Seq,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$21/21(org.apache.spark.sql.catalyst.plans.logical.Aggregate,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$3/3()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Predef$/boolean2Boolean(boolean)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/SetLike/toSeq()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/immutable/Map/keySet()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$10/10(org.apache.spark.sql.catalyst.expressions.AttributeReference,scala.collection.Seq,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$19/19()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$20/20()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$22/22()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$23/23()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$24/24()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$15/15()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$16/16()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$14/14()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$25/25()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$1/1()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/SeqLike/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/distinct()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$2/2()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$4/4()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/immutable/Map/toSeq()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$6/6()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/TraversableLike/groupBy(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/immutable/Set/flatten(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$8/8()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$9/9()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$unapply$2/2(scala.Option)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/reduceOption(scala.Function2)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$3/3()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$unapply$3/3(scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/unzip(scala.Function1)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$2/2()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$5/5(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple6/Tuple6(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Generate/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Project/outputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/outputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$/org$apache$spark$sql$catalyst$optimizer$ColumnPruning$$sameOutput(scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/LeftExistence$/unapply(org.apache.spark.sql.catalyst.plans.JoinType)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/DeserializeToObject/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Project/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/isDefinedAt(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Expand/outputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/children()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/outputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$$anonfun$apply$7$$anonfun$16/16(org.apache.spark.sql.catalyst.optimizer.ColumnPruning$$anonfun$apply$7,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.Expand)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$/org$apache$spark$sql$catalyst$optimizer$ColumnPruning$$sameOutput(scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Union/outputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/LeftExistence$/unapply(org.apache.spark.sql.catalyst.plans.JoinType)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Union/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Generate/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/inputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$$anonfun$apply$7$$anonfun$17/17(org.apache.spark.sql.catalyst.optimizer.ColumnPruning$$anonfun$apply$7,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$$anonfun$apply$7$$anonfun$15/15(org.apache.spark.sql.catalyst.optimizer.ColumnPruning$$anonfun$apply$7,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$$anonfun$apply$7$$anonfun$14/14(org.apache.spark.sql.catalyst.optimizer.ColumnPruning$$anonfun$apply$7,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$$anonfun$apply$7$$anonfun$13/13(org.apache.spark.sql.catalyst.optimizer.ColumnPruning$$anonfun$apply$7,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$$anonfun$apply$7$$anonfun$21/21(org.apache.spark.sql.catalyst.optimizer.ColumnPruning$$anonfun$apply$7,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$$anonfun$apply$7$$anonfun$20/20(org.apache.spark.sql.catalyst.optimizer.ColumnPruning$$anonfun$apply$7,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Project/outputSet()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/DeserializeToObject/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Project/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Join/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ColumnPruning$/org$apache$spark$sql$catalyst$optimizer$ColumnPruning$$prunedChild(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/references()
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ColumnPruning/anonfun/apply/7/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Expand/outputSet()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#java/lang/String/trim()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/collection/IterableLike/foreach(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$ordinalNumber$1(int)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$13$$anonfun$apply$14/14(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$13,int)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$dataTypes$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/nodeName()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/apply(scala.Tuple2)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/collection/immutable/$colon$colon/tl$1()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$$anonfun$cubeExprs$1/1(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics$,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/collection/Seq/toList()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/cubeExprs(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/collection/immutable/$colon$colon/head()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/cubeExprs(scala.collection.Seq)#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/constructExpand(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$7(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/constructAggregateExprs(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/drop(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/VirtualColumn$/groupingIdName()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveGroupingAnalytics$/constructGroupByAlias(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveGroupingAnalytics$$constructAggregate(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NamedExpressionContext/identifierList()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitNamedExpression$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NamedExpressionContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitNamedExpression/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NamedExpressionContext/expression()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Expression/foreach(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1$1$$anonfun$apply$7/7(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/org/apache/spark/sql/catalyst/analysis/CheckAnalysis/class/anonfun/checkValidAggregateExpression/1/1/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType$$anonfun$16/16(org.apache.spark.sql.catalyst.expressions.objects.ValidateExternalType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/ValidateExternalType/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SearchedCaseContext/whenClause()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitSearchedCase$1$$anonfun$apply$39/39(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitSearchedCase$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitSearchedCase$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitSearchedCase/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitSearchedCase$1$$anonfun$45/45(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitSearchedCase$1)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/dataType()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/parse(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/util/parsing/combinator/Parsers$Success/result()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/parseAll(scala.util.parsing.combinator.Parsers$Parser,java.lang.CharSequence)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#java/lang/System/nanoTime()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/mutable/Buffer/last()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/Project/outputSet()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$3/3()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/plan()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/IterableLike/head()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/mutable/Buffer/size()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$search$1/1(scala.collection.Seq,scala.collection.mutable.Buffer,long)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/TraversableOnce/size()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters$/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/AttributeSet$/apply(scala.collection.Iterable)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/mutable/Buffer$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/mutable/Buffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/ArrayBuffer/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/71/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#scala/collection/immutable/Set/$plus(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#org/spark_project/guava/reflect/Invokable/getReturnType()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#java/beans/PropertyDescriptor/getReadMethod()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/types/StructField$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#org/spark_project/guava/reflect/TypeToken/method(java.lang.reflect.Method)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/1/apply(java.beans.PropertyDescriptor)#java/beans/PropertyDescriptor/getName()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$4/4()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$5/5(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/util/Utils$/getContextOrSparkClassLoader()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/tuple(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$tuple$1/1()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#java/lang/ClassLoader/loadClass(java.lang.String)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$7/7()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/types/StructType$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/api/JavaUniverse$JavaMirror/runtimeClass(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#java/lang/Class/isPrimitive()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/api/TypeTags/typeTag(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/dataTypeFor(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/optionOfProductType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/api/TypeTags$TypeTag/in(scala.reflect.api.Mirror)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/deserializerFor(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/mirror()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/api/TypeTags$TypeTag/tpe()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/definedByConstructorParams(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#org/apache/spark/SparkException/SparkException(java.lang.String)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#org/apache/spark/sql/catalyst/encoders/RowEncoder$$anonfun$4/apply()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#java/lang/Class/getName()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/4/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReferenceInSubTree$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/ArrayBuffer/$plus$plus$eq(scala.collection.TraversableOnce)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$$anonfun$checkAndGetOuterReferences$1$$anonfun$apply$57/57(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery$$anonfun$checkAndGetOuterReferences$1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnNonEqualCorrelatedPredicate$1(boolean,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$$anonfun$checkAndGetOuterReferences$1$$anonfun$45/45(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery$$anonfun$checkAndGetOuterReferences$1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/checkAndGetOuterReferences/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/SubExprUtils$/getOuterReferences(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.AtLeastNNonNulls,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String)
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/AtLeastNNonNulls/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduceLeftOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin$$anonfun$apply$26$$anonfun$63/63(org.apache.spark.sql.catalyst.optimizer.ReplaceExceptWithAntiJoin$$anonfun$apply$26)
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/ReplaceExceptWithAntiJoin/anonfun/apply/26/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$36/36()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/span(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$38/38(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$37/37(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getCurrentName()
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#org/apache/spark/sql/catalyst/json/JacksonUtils$/nextUntil(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonToken)
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/json/JacksonParser/org$apache$spark$sql$catalyst$json$JacksonParser$$convertMap(com.fasterxml.jackson.core.JsonParser,scala.Function1)#scala/collection/mutable/ArrayBuffer$/empty()
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$2/2(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$12/12(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$4/4(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$8/8(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$9/9(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$13/13(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType,scala.Function1[],org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$14/14(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType,scala.Function1)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$15/15(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType,scala.Function1)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$16/16(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$10/10(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$11/11(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$1/1(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$3/3(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$5/5(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$3/3(org.apache.spark.sql.catalyst.json.JacksonParser)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$6/6(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$4/4(org.apache.spark.sql.catalyst.json.JacksonParser)
org/apache/spark/sql/catalyst/json/JacksonParser/makeConverter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$7/7(org.apache.spark.sql.catalyst.json.JacksonParser,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$3()
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/aggregate/HyperLogLogPlusPlus/anonfun/2/apply(int)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$7(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$toLinkedHashMap$9/9(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#java/util/Date/toString()
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap/$plus$plus$eq(scala.collection.TraversableOnce)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$5/5(org.apache.spark.sql.catalyst.catalog.CatalogTable)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/immutable/StringOps/nonEmpty()
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/Option/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/immutable/Map/nonEmpty()
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap/LinkedHashMap()
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#java/util/Date/Date(long)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$4/4(org.apache.spark.sql.catalyst.catalog.CatalogTable)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$toLinkedHashMap$15/15(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$toLinkedHashMap$14/14(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$toLinkedHashMap$13/13(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$toLinkedHashMap$12/12(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$toLinkedHashMap$11/11(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTable$$anonfun$toLinkedHashMap$10/10(org.apache.spark.sql.catalyst.catalog.CatalogTable,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/VIEW()
org/apache/spark/sql/catalyst/catalog/CatalogTable/toLinkedHashMap()#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/commons/lang3/StringEscapeUtils/escapeJava(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Like/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Like$$anonfun$doGenCode$1/1(org.apache.spark.sql.catalyst.expressions.Like,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Like/dataType()
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/Like/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/literal(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$1/1()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$2/2()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$up$up$up(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$3/3()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$4/4()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$5/5()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$6/6()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$7/7()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$8/8()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$9/9()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$bar(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$10/10()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$11/11()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$12/12()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/primitiveType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$primitiveType$13/13()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$tilde$greater(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$structType$1/1()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$structType$2/2()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$less$tilde(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#scala/collection/immutable/StringOps/r()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$up$up(scala.Function1)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$structType$3/3()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/structType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/regex(scala.util.matching.Regex)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$tilde$greater(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$mapType$2/2()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$mapType$4/4()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$mapType$5/5()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$mapType$7/7()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$mapType$8/8()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$tilde(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$less$tilde(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$mapType$1/1()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$mapType$3/3()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/literal(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$mapType$6/6()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/mapType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$up$up(scala.Function1)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$arrayType$4/4()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/literal(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$arrayType$5/5()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$arrayType$6/6()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$up$up(scala.Function1)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$tilde(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$less$tilde(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$arrayType$1/1()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$arrayType$2/2()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$$anonfun$arrayType$3/3()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/arrayType$lzycompute()#scala/util/parsing/combinator/Parsers$Parser/$tilde$greater(scala.Function0)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/dataType()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/parse(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#scala/util/parsing/combinator/Parsers$Success/result()
org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser/parse(java.lang.String)#org/apache/spark/sql/catalyst/parser/LegacyTypeStringParser$/parseAll(scala.util.parsing.combinator.Parsers$Parser,java.lang.CharSequence)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractGenerator$$trimAlias(org.apache.spark.sql.catalyst.expressions.NamedExpression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/simpleString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$58/58(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$applyOrElse$59/59(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$applyOrElse$60/60(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$applyOrElse$61/61(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$applyOrElse$62/62(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/count(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/find(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/util/package$/toPrettySQL(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$55/55(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$56/56(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractGenerator$$anonfun$apply$22$$anonfun$57/57(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$22)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractGenerator/anonfun/apply/22/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/Expand$/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#scala/collection/SeqLike/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/Expand/anonfun/20/apply(scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/Expand$$anonfun$20$$anonfun$apply$9/9(org.apache.spark.sql.catalyst.plans.logical.Expand$$anonfun$20,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Expression/find(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1$1/1(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/RowOrdering$/isOrderable(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidGroupingExprs$1(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$7/7(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1$2/2(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/Expression/children()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/Attribute/sql()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1$5/5(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1,scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateFunction/children()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1$1/1(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1$4/4(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1$3/3(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$checkValidAggregateExpression$1(org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq,scala.collection.Seq)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/x()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$8/8(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$5/5(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/expressions()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/inputSet()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$17/17(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$16/16(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$15/15(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$12/12(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$11/11(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$10/10(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/IterableLike/foreach(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/children()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$class/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$checkLimitClause(org.apache.spark.sql.catalyst.analysis.CheckAnalysis,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/simpleString()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/missingInput()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$dataTypes$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$13/13(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/SubExprUtils$/hasNullAwarePredicateWithinNot(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Intersect/duplicateResolved()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$9/9(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1,scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformExpressionsUp(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Except/duplicateResolved()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$6/6(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$toRow$1/1(org.apache.spark.sql.catalyst.encoders.ExpressionEncoder)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/toRow(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$4/4()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$5/5(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/util/Utils$/getContextOrSparkClassLoader()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/tuple(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$tuple$1/1()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#java/lang/ClassLoader/loadClass(java.lang.String)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$$anonfun$7/7()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/tuple(scala.collection.Seq)#org/apache/spark/sql/types/StructType$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/api/JavaUniverse$JavaMirror/runtimeClass(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#java/lang/Class/isPrimitive()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/api/TypeTags/typeTag(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/dataTypeFor(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/optionOfProductType(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/runtime/package$/universe()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/api/TypeTags$TypeTag/in(scala.reflect.api.Mirror)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/deserializerFor(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/encoders/ExpressionEncoder$/apply(scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/mirror()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#scala/reflect/api/TypeTags$TypeTag/tpe()
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/definedByConstructorParams(scala.reflect.api.Types$TypeApi)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#org/apache/spark/sql/catalyst/ScalaReflection$/serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,scala.reflect.api.TypeTags$TypeTag)
org/apache/spark/sql/catalyst/encoders/ExpressionEncoder/apply(scala.reflect.api.TypeTags$TypeTag)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#java/lang/System/nanoTime()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/mutable/Buffer/last()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/Project/outputSet()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$3/3()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/plan()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/IterableLike/head()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/mutable/Buffer/size()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$search$1/1(scala.collection.Seq,scala.collection.mutable.Buffer,long)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/TraversableOnce/size()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters$/buildJoinGraphInfo(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/AttributeSet$/apply(scala.collection.Iterable)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/mutable/Buffer$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/search(org.apache.spark.sql.internal.SQLConf,scala.collection.Seq,scala.collection.immutable.Set,scala.collection.Seq)#scala/collection/mutable/Buffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/MapLike/values()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/Seq/indices()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/mutable/Map/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/mutable/Map$/empty()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/runtime/IntRef/create(int)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$searchLevel$1/1(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option,scala.collection.mutable.Map,scala.runtime.IntRef,int,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/searchLevel(scala.collection.Seq,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/planCost()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/JoinPlan(scala.collection.immutable.Set,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.optimizer.Cost)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/Set/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/itemIds()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/intersect(scala.collection.GenSet)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$7/7()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$5/5(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/union(scala.collection.GenSet)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/rootCost(org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/TraversableOnce/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/$minus$minus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/plans/logical/Join/outputSet()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/TraversableLike/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/TraversableLike/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$6/6(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/plan()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/joinConds()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$8/8(org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/expressions/AttributeSet$/apply(scala.collection.Iterable)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/reduceOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/isEmpty()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDPFilters$/starJoinFilter(scala.collection.immutable.Set,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.optimizer.JoinGraphInfo)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/collection/immutable/Set/size()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/org$apache$spark$sql$catalyst$optimizer$JoinReorderDP$$buildJoin(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$JoinPlan,org.apache.spark.sql.internal.SQLConf,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.expressions.AttributeSet,scala.Option)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/Expression/sql()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Expression/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Expression/sql()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Expression/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Expression/sql()#org/apache/spark/sql/catalyst/expressions/Expression/children()
org/apache/spark/sql/catalyst/expressions/Expression/sql()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Expression/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Expression/sql()#org/apache/spark/sql/catalyst/expressions/Expression$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/Expression/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/collection/TraversableOnce/mkString()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/Predef$/fallbackStringCanBuildFrom()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/collection/immutable/StringOps/padTo(int,java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/dumpTimeSpent/2/apply(scala.Tuple2)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$IfCoercion$$anonfun$apply$9$$anonfun$applyOrElse$14/14(org.apache.spark.sql.catalyst.analysis.TypeCoercion$IfCoercion$$anonfun$apply$9,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/findWiderTypeForTwo(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$IfCoercion$$anonfun$apply$9$$anonfun$applyOrElse$13/13(org.apache.spark.sql.catalyst.analysis.TypeCoercion$IfCoercion$$anonfun$apply$9,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/IfCoercion/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/ArrayBuffer/head()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/ArrayBuffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$splitExpressions$2/2(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/ArrayBuffer/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$splitExpressions$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.mutable.ArrayBuffer,scala.collection.mutable.StringBuilder)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/ArrayBuffer/ArrayBuffer()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.Function1,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/ArrayBuffer/length()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/ArrayBuffer$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/splitExpressions(scala.collection.Seq,java.lang.String,scala.collection.Seq,java.lang.String,scala.Function1,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genComp(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/collection/mutable/ArrayBuffer/length()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceMinorObj(java.lang.Object,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/genEqual(org.apache.spark.sql.types.DataType,java.lang.String,java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#java/lang/String/split(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/Function0/apply()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#org/apache/spark/SparkEnv$/get()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/collection/mutable/HashMap/$plus$eq(scala.Tuple2)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#java/lang/String/contains(java.lang.CharSequence)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/collection/mutable/ArrayOps/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/registerComment(scala.Function0)#org/apache/spark/SparkEnv/conf()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/collection/mutable/HashMap/$plus$eq(scala.Tuple2)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/collection/mutable/HashMap/contains(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/collection/mutable/HashMap/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/freshName(java.lang.String)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/collection/mutable/ArrayBuffer/length()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/addReferenceObj(java.lang.String,java.lang.Object,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#scala/collection/mutable/HashMap$/empty()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$7/7(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.mutable.HashMap)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#scala/collection/Seq/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#scala/collection/mutable/HashMap/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/subexpressionEliminationForWholeStageCodegen(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext$$anonfun$subexpressionEliminationForWholeStageCodegen$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.EquivalentExpressions)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#java/lang/Class/getName()
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/apache/spark/sql/types/UserDefinedType$$anonfun$jsonValue$1/1(org.apache.spark.sql.types.UserDefinedType)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/apache/spark/sql/types/UserDefinedType$$anonfun$jsonValue$2/2(org.apache.spark.sql.types.UserDefinedType)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/apache/spark/sql/types/UserDefinedType$$anonfun$jsonValue$3/3(org.apache.spark.sql.types.UserDefinedType)
org/apache/spark/sql/types/UserDefinedType/jsonValue()#java/lang/Object/getClass()
org/apache/spark/sql/types/UserDefinedType/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow$$anonfun$14/14(org.apache.spark.sql.catalyst.expressions.objects.CreateExternalRow,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/CreateExternalRow/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/clone()
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Pattern/compile(java.lang.String)
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/MatchResult/group(int)
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Pattern/matcher(java.lang.CharSequence)
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Matcher/find()
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/expressions/RegExpExtract/nullSafeEval(java.lang.Object,java.lang.Object,java.lang.Object)#java/util/regex/Matcher/toMatchResult()
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/plans/logical/Union$$anonfun$9/9(org.apache.spark.sql.catalyst.plans.logical.Union)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#scala/collection/immutable/Map/keySet()
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#scala/collection/immutable/Set/diff(scala.collection.GenSet)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#scala/collection/Set/filter(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#scala/collection/immutable/Set/intersect(scala.collection.GenSet)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#scala/collection/TraversableLike/groupBy(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#scala/collection/immutable/Set$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/plans/logical/Union$$anonfun$8/8(org.apache.spark.sql.catalyst.plans.logical.Union)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#scala/collection/immutable/Set/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#scala/collection/SetLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/plans/logical/Union$$anonfun$11/11(org.apache.spark.sql.catalyst.plans.logical.Union)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/plans/logical/Union$$anonfun$10/10(org.apache.spark.sql.catalyst.plans.logical.Union)
org/apache/spark/sql/catalyst/plans/logical/Union/org$apache$spark$sql$catalyst$plans$logical$Union$$merge(scala.collection.immutable.Set,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/plans/logical/Union$$anonfun$12/12(org.apache.spark.sql.catalyst.plans.logical.Union,scala.collection.immutable.Map,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/immutable/Map/size()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$17/17(org.apache.spark.sql.catalyst.expressions.AttributeReference,org.apache.spark.sql.catalyst.expressions.Literal,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$26/26(scala.collection.Seq,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$21/21(org.apache.spark.sql.catalyst.plans.logical.Aggregate,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$3/3()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Predef$/boolean2Boolean(boolean)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/SetLike/toSeq()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/immutable/Map/keySet()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$10/10(org.apache.spark.sql.catalyst.expressions.AttributeReference,scala.collection.Seq,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$19/19()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$20/20()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$22/22()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$23/23()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$24/24()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$15/15()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$16/16()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$14/14()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$25/25()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$1/1()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/SeqLike/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/distinct()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$2/2()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$4/4()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/immutable/Map/toSeq()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$6/6()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/TraversableLike/groupBy(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/immutable/Set/flatten(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$8/8()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/rewrite(org.apache.spark.sql.catalyst.plans.logical.Aggregate)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$9/9()
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/$times(int)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen$$anonfun$doGenCode$1/1(org.apache.spark.sql.catalyst.expressions.CaseWhenCodegen,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen$$anonfun$8/8(org.apache.spark.sql.catalyst.expressions.CaseWhenCodegen,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/dataType()
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/CaseWhenCodegen/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$/hashTimestamp(long)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/InternalRow/get(int,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$$anonfun$6/6()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$/hashCalendarInterval(org.apache.spark.unsafe.types.CalendarInterval)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$/normalizeDecimal(java.math.BigDecimal)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$$anonfun$5/5()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/expressions/HiveHashFunction$/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#java/math/BigDecimal/hashCode()
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHashFunction/hash(java.lang.Object,org.apache.spark.sql.types.DataType,long)#org/apache/spark/sql/catalyst/util/ArrayData/get(int,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$unapply$2/2(scala.Option)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/reduceOption(scala.Function2)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$3/3()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$unapply$3/3(scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/unzip(scala.Function1)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$2/2()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$$anonfun$5/5(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple6/Tuple6(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys$/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/planning/ExtractEquiJoinKeys/unapply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/writeUnsafeData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#org/apache/spark/sql/types/Decimal$/MAX_LONG_DIGITS()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeMapToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$6/6()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/collection/IterableLike/forall(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$2/2()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$3/3()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/mutable/ArrayBuffer/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/Seq/count(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$7/7()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$8/8()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/writeExpressionsToBuffer$default$6()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/writeUnsafeData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/writeExpressionsToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,scala.collection.Seq,java.lang.String,boolean)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/newCodeGenContext()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$create$1/1(scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/compile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/createCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq,boolean)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/create(scala.collection.Seq,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Attribute/exprId()
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/optimizer/EliminateSerialization/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/StringType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/findCommonTypeForBinaryComparison()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryArithmetic/makeCopy(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryComparison$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryComparison)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/TimestampType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Equality$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryComparison)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryComparison/makeCopy(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryArithmetic$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryArithmetic)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function2/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$PromoteStrings$/org$apache$spark$sql$catalyst$analysis$TypeCoercion$PromoteStrings$$castExpr(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/Equality$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryComparison)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/types/StringType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/findCommonTypeForBinaryComparison()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/BinaryComparison$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryComparison)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/types/TimestampType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/BinaryArithmetic$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryArithmetic)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/PromoteStrings/anonfun/apply/3/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Function2/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/origin()
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals$$anonfun$apply$1$$anonfun$applyOrElse$4/4(org.apache.spark.sql.catalyst.analysis.SubstituteUnresolvedOrdinals$$anonfun$apply$1,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.Aggregate)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals$$anonfun$apply$1$$anonfun$1/1(org.apache.spark.sql.catalyst.analysis.SubstituteUnresolvedOrdinals$$anonfun$apply$1)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals$$anonfun$apply$1$$anonfun$3/3(org.apache.spark.sql.catalyst.analysis.SubstituteUnresolvedOrdinals$$anonfun$apply$1)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/trees/CurrentOrigin$/withOrigin(org.apache.spark.sql.catalyst.trees.Origin,scala.Function0)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Sort/origin()
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals$$anonfun$apply$1$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.analysis.SubstituteUnresolvedOrdinals$$anonfun$apply$1)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals$$anonfun$apply$1$$anonfun$applyOrElse$3/3(org.apache.spark.sql.catalyst.analysis.SubstituteUnresolvedOrdinals$$anonfun$apply$1)
org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/SubstituteUnresolvedOrdinals$$anonfun$apply$1$$anonfun$applyOrElse$2/2(org.apache.spark.sql.catalyst.analysis.SubstituteUnresolvedOrdinals$$anonfun$apply$1,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.Sort)
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#scala/Function2/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#org/apache/spark/sql/catalyst/expressions/BinaryExpression/dataType()
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/BinaryExpression/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/GetStructField$/apply$default$3()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/encoders/RowEncoder$/externalDataTypeFor(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/encoders/RowEncoder/anonfun/6/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/encoders/RowEncoder$/org$apache$spark$sql$catalyst$encoders$RowEncoder$$deserializerFor(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#org/apache/spark/sql/catalyst/util/TypeUtils$$anonfun$compareBinary$1/1(byte[])
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/collection/generic/FilterMonadic/foreach(scala.Function1)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/collection/immutable/Range/withFilter(scala.Function1)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#org/apache/spark/sql/catalyst/util/TypeUtils$/compareBinary(byte[],byte[])
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#java/lang/Object/Object()
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#org/apache/spark/sql/catalyst/util/TypeUtils$$anonfun$compareBinary$2/2(byte[],byte[],java.lang.Object)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/runtime/RichInt$/until$extension0(int,int)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/Predef$/intWrapper(int)
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/runtime/NonLocalReturnControl/key()
org/apache/spark/sql/catalyst/util/TypeUtils/compareBinary(byte[],byte[])#scala/runtime/NonLocalReturnControl/value$mcI$sp()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#java/lang/String/trim()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$13/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$anonfun$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$class$$anonfun$$ordinalNumber$1(int)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/nodeName()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/findWiderTypeForTwo(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/13/anonfun/apply/14/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/FalseLiteral()
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4$$anonfun$7/7(org.apache.spark.sql.catalyst.optimizer.BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4$$anonfun$9/9(org.apache.spark.sql.catalyst.optimizer.BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/TrueLiteral()
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Not/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableOnce/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4$$anonfun$8/8(org.apache.spark.sql.catalyst.optimizer.BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$/splitDisjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4$$anonfun$10/10(org.apache.spark.sql.catalyst.optimizer.BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4$$anonfun$11/11(org.apache.spark.sql.catalyst.optimizer.BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/BooleanSimplification/anonfun/apply/4/anonfun/applyOrElse/4/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4$$anonfun$12/12(org.apache.spark.sql.catalyst.optimizer.BooleanSimplification$$anonfun$apply$4$$anonfun$applyOrElse$4,scala.collection.Seq)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/collection/mutable/ArrayOps/indexWhere(scala.Function1)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#java/util/Arrays/copyOfRange(byte[],int,int)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/Predef$/byteArrayOps(byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/Tuple2/_1$mcZ$sp()
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/char2byte(int,int,byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/unsafe/types/UTF8String/fromBytes(byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#java/lang/Math/abs(int)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/decode(long,int,byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/Tuple2$mcZI$sp/sp(boolean,int)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/encode(int,int,byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$$anonfun$1/1()
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/byte2char(int,int,byte[])
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/util/NumberConverter/convert(byte[],int,int)#org/apache/spark/sql/catalyst/util/NumberConverter$/convert(byte[],int,int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#org/apache/spark/sql/types/MapType$/apply(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#scala/collection/Iterable/toSeq()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#org/apache/spark/sql/types/StructType$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#org/antlr/v4/runtime/Token/getType()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#org/apache/spark/sql/types/ArrayType$/apply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitComplexDataType$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitComplexDataType$1$$anonfun$apply$41/41(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitComplexDataType$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ComplexDataTypeContext/complexColTypeList()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ComplexDataTypeContext/dataType(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitComplexDataType/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveRelations$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(org.apache.spark.sql.catalyst.analysis.UnresolvedRelation,scala.Option)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/EliminateSubqueryAliases$/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveRelations$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveRelations$/resolveRelation(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/apply/8/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#org/apache/spark/sql/catalyst/streaming/InternalOutputModes$/apply(java.lang.String)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/streaming/InternalOutputModes/apply(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Greatest$$anonfun$doGenCode$20/20(org.apache.spark.sql.catalyst.expressions.Greatest,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/drop(int)
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Greatest/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/Greatest$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.Greatest,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Greatest$$anonfun$checkInputDataTypes$4/4(org.apache.spark.sql.catalyst.expressions.Greatest)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Greatest$$anonfun$checkInputDataTypes$5/5(org.apache.spark.sql.catalyst.expressions.Greatest)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Greatest/prettyName()
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/Greatest$$anonfun$checkInputDataTypes$6/6(org.apache.spark.sql.catalyst.expressions.Greatest)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/TraversableOnce/count(scala.Function1)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#org/apache/spark/sql/catalyst/util/TypeUtils$/checkForOrderingExpr(org.apache.spark.sql.types.DataType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Greatest/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate$/newCodeGenContext()
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/compile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate$$anonfun$create$1/1(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GeneratePredicate/create(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode$$anonfun$6/6(org.apache.spark.sql.catalyst.plans.logical.UnaryNode)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode$$anonfun$5/5(org.apache.spark.sql.catalyst.plans.logical.UnaryNode)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/TraversableOnce/sum(scala.math.Numeric)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$2()
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigInt/$div(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode/output()
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/math/BigInt/$times(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/UnaryNode/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/immutable/StringOps/contains(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/lang/String/substring(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/lang/String/indexOf(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/util/Calendar/getTime()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/sql/Date/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#javax/xml/bind/DatatypeConverter/parseDateTime(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/stringToTime(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/lang/String/substring(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#java/sql/Timestamp/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTime(java.lang.String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#java/lang/Math/floor(double)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#java/util/TimeZone/getOffset(long)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getMonth(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getDayOfMonth(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#java/util/Calendar/getInstance(java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#java/util/Calendar/set(int,int,int,int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#java/util/Calendar/set(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#java/util/TimeZone/getRawOffset()
org/apache/spark/sql/catalyst/util/DateTimeUtils/getOffsetFromLocalMillis(long,java.util.TimeZone)#java/util/Calendar/getTimeInMillis()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/_4()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/isLeapYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/monthDays()
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/splitDate(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/dateAddMonths(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/dateAddMonths(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/firstDayOfMonth(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/reflect/ClassTag$/Int()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getTimeZone(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#org/apache/spark/unsafe/types/UTF8String/getBytes()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Predef$/wrapIntArray(int[])
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#java/util/Calendar/getTimeInMillis()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#java/util/Calendar/set(int,int,int,int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Array$/apply(scala.collection.Seq,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#java/util/Calendar/set(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/isInvalidDate(int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#java/util/Calendar/getInstance(java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/collection/immutable/StringOps/format(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToTimestamp(org.apache.spark.unsafe.types.UTF8String,java.util.TimeZone)#scala/Option/get()
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getYearAndDayInYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/splitDate(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/Tuple2/_1$mcI$sp()
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/isLeapYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/splitDate(int)#scala/Tuple2$mcII$sp/sp(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/reflect/ClassTag$/Int()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/threadLocalGmtCalendar()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/unsafe/types/UTF8String/getBytes()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/lang/ThreadLocal/get()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/Predef$/wrapIntArray(int[])
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/util/Calendar/getTimeInMillis()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/isInvalidDate(int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/Array$/apply(scala.collection.Seq,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/util/Calendar/set(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/util/Calendar/clear()
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#java/util/Calendar/set(int,int,int,int,int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/stringToDate(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/stringToDate(org.apache.spark.unsafe.types.UTF8String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/TRUNC_TO_YEAR()
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/TRUNC_TO_MONTH()
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getDayInYear(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getDayOfMonth(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/DateTimeUtils/truncDate(int,int)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/truncDate(int,int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/timestampToString(long,java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/lang/String/length()
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/sql/Timestamp/toString()
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/lang/String/substring(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaTimestamp(long)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/text/DateFormat/format(java.util.Date)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/getThreadLocalTimestampFormat(java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/timestampToString(long,java.util.TimeZone)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/math/package$/round(double)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/_4()
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/splitDate(int)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/monthsBetween(long,long,java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/daysToMillis(int,java.util.TimeZone)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/util/DateTimeUtils/monthsBetween(long,long,java.util.TimeZone)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/millisToDays(long,java.util.TimeZone)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/AliasViewChild$$anonfun$apply$1/org$apache$spark$sql$catalyst$analysis$AliasViewChild$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/simpleString()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/qualifier()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/sql()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Cast$/mayTruncate(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/exprId()
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/AliasViewChild/anonfun/apply/1/anonfun/2/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/collection/Seq/slice(int,int)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/collection/IterableLike/exists(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/collection/IterableLike/forall(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection$$anonfun$checkInputDataTypes$2/2(org.apache.spark.sql.catalyst.expressions.CallMethodViaReflection)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection$$anonfun$checkInputDataTypes$1/1(org.apache.spark.sql.catalyst.expressions.CallMethodViaReflection)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/collection/Seq/take(int)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/checkInputDataTypes()#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection$/findMethod(java.lang.String,java.lang.String,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#scala/Predef$DummyImplicit$/dummyImplicit()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#scala/Option/orNull(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection$$anonfun$method$1/1(org.apache.spark.sql.catalyst.expressions.CallMethodViaReflection)
org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection/method$lzycompute()#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/math/BigInt/$greater$eq(scala.math.BigInt)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/LimitPushDown$$anonfun$apply$5$$anonfun$applyOrElse$4/4(org.apache.spark.sql.catalyst.optimizer.LimitPushDown$$anonfun$apply$5,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/LimitPushDown/anonfun/apply/5/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/util/package$/toPrettySQL(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/indexOf(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveGroupingAnalytics/replaceGroupingFunc/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/2/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PruneFilters$$anonfun$apply$16$$anonfun$25/25(org.apache.spark.sql.catalyst.optimizer.PruneFilters$$anonfun$apply$16,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PruneFilters/anonfun/apply/16/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$34/34(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduceLeft(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/span(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$33/33()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ColTypeContext/ColTypeContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colType()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PartitionSpecLocationContext/PartitionSpecLocationContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpecLocation()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LocationSpecContext/LocationSpecContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/locationSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PredicateOperatorContext/PredicateOperatorContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicateOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SortItemContext/SortItemContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sortItem()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FrameBoundContext/FrameBoundContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/frameBound()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuotedIdentifierContext/QuotedIdentifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/quotedIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#java/util/List/add(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryOrganizationContext/QueryOrganizationContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryOrganization()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$StrictIdentifierContext/StrictIdentifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuotedIdentifierAlternativeContext/QuotedIdentifierAlternativeContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StrictIdentifierContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$UnquotedIdentifierContext/UnquotedIdentifierContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StrictIdentifierContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/strictIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#java/util/List/add(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LateralViewContext/LateralViewContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/lateralView()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WindowFrameContext/WindowFrameContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowFrame()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FileFormatContext/FileFormatContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableFileFormatContext/TableFileFormatContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$FileFormatContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$GenericFileFormatContext/GenericFileFormatContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$FileFormatContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fileFormat()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$GroupingSetContext/GroupingSetContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/groupingSet()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableProviderContext/TableProviderContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProvider()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateTableHeaderContext/CreateTableHeaderContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createTableHeader()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DescribeColNameContext/DescribeColNameContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeColName()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PartitionValContext/PartitionValContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionVal()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TablePropertyListContext/TablePropertyListContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyList()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ArithmeticUnaryContext/ArithmeticUnaryContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ValueExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ComparisonContext/ComparisonContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ValueExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/pushNewRecursionContext(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/antlr/v4/runtime/FailedPredicateException/FailedPredicateException(org.antlr.v4.runtime.Parser,java.lang.String)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ValueExpressionContext/ValueExpressionContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ValueExpressionDefaultContext/ValueExpressionDefaultContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ValueExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRecursionRule(org.antlr.v4.runtime.ParserRuleContext,int,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/precpred(org.antlr.v4.runtime.RuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ArithmeticBinaryContext/ArithmeticBinaryContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ValueExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/triggerExitRuleEvent()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/valueExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/unrollRecursionContexts(org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#java/util/List/add(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AggregationContext/AggregationContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/aggregation()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$MultiInsertQueryBodyContext/MultiInsertQueryBodyContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/multiInsertQueryBody()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InsertIntoContext/InsertIntoContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/insertInto()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FromClauseContext/FromClauseContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/fromClause()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NestedConstantListContext/NestedConstantListContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nestedConstantList()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TablePropertyContext/TablePropertyContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableProperty()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WindowsContext/WindowsContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windows()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SubqueryContext/SubqueryContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryPrimaryContext/QueryPrimaryContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableContext/TableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InlineTableDefault1Context/InlineTableDefault1Context(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryPrimaryDefaultContext/QueryPrimaryDefaultContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryPrimary()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DescribeFuncNameContext/DescribeFuncNameContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/describeFuncName()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$UnsupportedHiveNativeCommandsContext/UnsupportedHiveNativeCommandsContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/unsupportedHiveNativeCommands()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QuerySpecificationContext/QuerySpecificationContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#java/util/List/add(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/querySpecification()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PartitionSpecContext/PartitionSpecContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/partitionSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AliasedQueryContext/AliasedQueryContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$RelationPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RelationPrimaryContext/RelationPrimaryContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableNameContext/TableNameContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$RelationPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InlineTableDefault2Context/InlineTableDefault2Context(org.apache.spark.sql.catalyst.parser.SqlBaseParser$RelationPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableValuedFunctionContext/TableValuedFunctionContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$RelationPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relationPrimary()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AliasedRelationContext/AliasedRelationContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$RelationPrimaryContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RelationContext/RelationContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/relation()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TablePropertyKeyContext/TablePropertyKeyContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyKey()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SingleStatementContext/SingleStatementContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleStatement()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QualifiedNameContext/QualifiedNameContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/qualifiedName()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryContext/QueryContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/query()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$HintStatementContext/HintStatementContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#java/util/List/add(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hintStatement()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NamedWindowContext/NamedWindowContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedWindow()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ColPositionContext/ColPositionContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colPosition()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CtesContext/CtesContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/ctes()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SingleExpressionContext/SingleExpressionContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleExpression()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FunctionIdentifierContext/FunctionIdentifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/functionIdentifier()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$BooleanDefaultContext/BooleanDefaultContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$BooleanExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ExistsContext/ExistsContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$BooleanExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/precpred(org.antlr.v4.runtime.RuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LogicalBinaryContext/LogicalBinaryContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$BooleanExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/pushNewRecursionContext(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/antlr/v4/runtime/FailedPredicateException/FailedPredicateException(org.antlr.v4.runtime.Parser,java.lang.String)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$BooleanExpressionContext/BooleanExpressionContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LogicalNotContext/LogicalNotContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$BooleanExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRecursionRule(org.antlr.v4.runtime.ParserRuleContext,int,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/triggerExitRuleEvent()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/unrollRecursionContexts(org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntervalValueContext/IntervalValueContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalValue()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ConstantListContext/ConstantListContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constantList()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinTypeContext/JoinTypeContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinType()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ComplexDataTypeContext/ComplexDataTypeContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$DataTypeContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PrimitiveDataTypeContext/PrimitiveDataTypeContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$DataTypeContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DataTypeContext/DataTypeContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/dataType()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NumericLiteralContext/NumericLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ConstantContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$StringLiteralContext/StringLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ConstantContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ConstantContext/ConstantContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NullLiteralContext/NullLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ConstantContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntervalLiteralContext/IntervalLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ConstantContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TypeConstructorContext/TypeConstructorContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ConstantContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$BooleanLiteralContext/BooleanLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$ConstantContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/constant()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SingleTableIdentifierContext/SingleTableIdentifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleTableIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetTablePropertiesContext/SetTablePropertiesContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$UnsetTablePropertiesContext/UnsetTablePropertiesContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AlterViewQueryContext/AlterViewQueryContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/matchWildcard()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LoadDataContext/LoadDataContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AnalyzeContext/AnalyzeContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetDatabasePropertiesContext/SetDatabasePropertiesContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ShowDatabasesContext/ShowDatabasesContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RenameTableContext/RenameTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateTempViewUsingContext/CreateTempViewUsingContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateTableContext/CreateTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DropTablePartitionsContext/DropTablePartitionsContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ShowTblPropertiesContext/ShowTblPropertiesContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AddTablePartitionContext/AddTablePartitionContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateHiveTableContext/CreateHiveTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ShowTableContext/ShowTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ExplainContext/ExplainContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RecoverPartitionsContext/RecoverPartitionsContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$UseContext/UseContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FailNativeCommandContext/FailNativeCommandContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ShowFunctionsContext/ShowFunctionsContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetTableSerDeContext/SetTableSerDeContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RepairTableContext/RepairTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ShowCreateTableContext/ShowCreateTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DropTableContext/DropTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DescribeTableContext/DescribeTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RefreshResourceContext/RefreshResourceContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateTableLikeContext/CreateTableLikeContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AddTableColumnsContext/AddTableColumnsContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TruncateTableContext/TruncateTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ShowColumnsContext/ShowColumnsContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateViewContext/CreateViewContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetTableLocationContext/SetTableLocationContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$StatementDefaultContext/StatementDefaultContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ShowTablesContext/ShowTablesContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$StatementContext/StatementContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DescribeFunctionContext/DescribeFunctionContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RefreshTableContext/RefreshTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ManageResourceContext/ManageResourceContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetConfigurationContext/SetConfigurationContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateFunctionContext/CreateFunctionContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$UncacheTableContext/UncacheTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ClearCacheContext/ClearCacheContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ShowPartitionsContext/ShowPartitionsContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DescribeDatabaseContext/DescribeDatabaseContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ChangeColumnContext/ChangeColumnContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateDatabaseContext/CreateDatabaseContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ResetConfigurationContext/ResetConfigurationContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DropFunctionContext/DropFunctionContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RenameTablePartitionContext/RenameTablePartitionContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DropDatabaseContext/DropDatabaseContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/statement()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CacheTableContext/CacheTableContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$StatementContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$BucketSpecContext/BucketSpecContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/bucketSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntervalContext/IntervalContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/interval()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SingleInsertQueryContext/SingleInsertQueryContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryNoWithContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$MultiInsertQueryContext/MultiInsertQueryContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryNoWithContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryNoWithContext/QueryNoWithContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryNoWith()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SkewSpecContext/SkewSpecContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/skewSpec()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinRelationContext/JoinRelationContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinRelation()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierListContext/IdentifierListContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierList()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RowFormatSerdeContext/RowFormatSerdeContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$RowFormatContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RowFormatContext/RowFormatContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RowFormatDelimitedContext/RowFormatDelimitedContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$RowFormatContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/rowFormat()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NamedExpressionContext/NamedExpressionContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpression()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#java/util/List/add(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$HintContext/HintContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/hint()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CastContext/CastContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/precpred(org.antlr.v4.runtime.RuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/pushNewRecursionContext(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SearchedCaseContext/SearchedCaseContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PrimaryExpressionContext/PrimaryExpressionContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ColumnReferenceContext/ColumnReferenceContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ParenthesizedExpressionContext/ParenthesizedExpressionContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DereferenceContext/DereferenceContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SubscriptContext/SubscriptContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FirstContext/FirstContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$RowConstructorContext/RowConstructorContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ConstantDefaultContext/ConstantDefaultContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SubqueryExpressionContext/SubqueryExpressionContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRecursionRule(org.antlr.v4.runtime.ParserRuleContext,int,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$StarContext/StarContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SimpleCaseContext/SimpleCaseContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#java/util/List/add(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TimeFunctionCallContext/TimeFunctionCallContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/triggerExitRuleEvent()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$StructContext/StructContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$FunctionCallContext/FunctionCallContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/unrollRecursionContexts(org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LastContext/LastContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimaryExpressionContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/primaryExpression(int)#org/antlr/v4/runtime/FailedPredicateException/FailedPredicateException(org.antlr.v4.runtime.Parser,java.lang.String)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ComplexColTypeListContext/ComplexColTypeListContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColTypeList()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/atn/ATN/getNumberOfDecisions()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/atn/PredictionContextCache/PredictionContextCache()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/atn/ATNDeserializer/deserialize(char[])
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/VocabularyImpl/VocabularyImpl(java.lang.String[],java.lang.String[])
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/Vocabulary/getSymbolicName(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#java/lang/String/toCharArray()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/atn/ATN/getDecisionState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/dfa/DFA/DFA(org.antlr.v4.runtime.atn.DecisionState,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/atn/ATNDeserializer/ATNDeserializer()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/RuntimeMetaData/checkVersion(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/<clinit>()#org/antlr/v4/runtime/Vocabulary/getLiteralName(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SingleFunctionIdentifierContext/SingleFunctionIdentifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleFunctionIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$BooleanValueContext/BooleanValueContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/booleanValue()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$JoinCriteriaContext/JoinCriteriaContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/joinCriteria()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/IdentifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WhenClauseContext/WhenClauseContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/whenClause()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntegerLiteralContext/IntegerLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$NumberContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NumberContext/NumberContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TinyIntLiteralContext/TinyIntLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$NumberContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$BigIntLiteralContext/BigIntLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$NumberContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$BigDecimalLiteralContext/BigDecimalLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$NumberContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SmallIntLiteralContext/SmallIntLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$NumberContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DoubleLiteralContext/DoubleLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$NumberContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$DecimalLiteralContext/DecimalLiteralContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$NumberContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/number()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$OrderedIdentifierListContext/OrderedIdentifierListContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifierList()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierCommentListContext/IdentifierCommentListContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierCommentList()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ComplexColTypeContext/ComplexColTypeContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/complexColType()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SampleContext/SampleContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/sample()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InlineTableContext/InlineTableContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/inlineTable()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NonReservedContext/NonReservedContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/nonReserved()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntervalFieldContext/IntervalFieldContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/intervalField()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#java/util/List/add(java.lang.Object)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WindowDefContext/WindowDefContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowSpecContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WindowRefContext/WindowRefContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$WindowSpecContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WindowSpecContext/WindowSpecContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/windowSpec()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierSeqContext/IdentifierSeqContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierSeq()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierCommentContext/IdentifierCommentContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/identifierComment()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SingleDataTypeContext/SingleDataTypeContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/singleDataType()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$OrderedIdentifierContext/OrderedIdentifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/orderedIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableIdentifierContext/TableIdentifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tableIdentifier()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PredicatedContext/PredicatedContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicated()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryTermDefaultContext/QueryTermDefaultContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryTermContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/precpred(org.antlr.v4.runtime.RuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/pushNewRecursionContext(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QueryTermContext/QueryTermContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRecursionRule(org.antlr.v4.runtime.ParserRuleContext,int,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetOperationContext/SetOperationContext(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryTermContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/triggerExitRuleEvent()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/apache/spark/sql/catalyst/parser/SqlBaseParser/unrollRecursionContexts(org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/queryTerm(int)#org/antlr/v4/runtime/FailedPredicateException/FailedPredicateException(org.antlr.v4.runtime.Parser,java.lang.String)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ComparisonOperatorContext/ComparisonOperatorContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/comparisonOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/antlr/v4/runtime/TokenStream/LT(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$PredicateContext/PredicateContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/predicate()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ResourceContext/ResourceContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/resource()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NamedExpressionSeqContext/NamedExpressionSeqContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedExpressionSeq()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$SetQuantifierContext/SetQuantifierContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/setQuantifier()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/antlr/v4/runtime/NoViableAltException/NoViableAltException(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TablePropertyValueContext/TablePropertyValueContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/tablePropertyValue()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/consume()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ArithmeticOperatorContext/ArithmeticOperatorContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/recoverInline(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/arithmeticOperator()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ColTypeListContext/ColTypeListContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/colTypeList()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$NamedQueryContext/NamedQueryContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/antlr/v4/runtime/TokenStream/LA(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/namedQuery()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$StorageHandlerContext/StorageHandlerContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/storageHandler()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/exitRule()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/match(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$CreateFileFormatContext/CreateFileFormatContext(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterOuterAlt(org.antlr.v4.runtime.ParserRuleContext,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/sync(org.antlr.v4.runtime.Parser)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getInterpreter()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/setState(int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/getState()
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/recover(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/apache/spark/sql/catalyst/parser/SqlBaseParser/enterRule(org.antlr.v4.runtime.ParserRuleContext,int,int)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/antlr/v4/runtime/ANTLRErrorStrategy/reportError(org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException)
org/apache/spark/sql/catalyst/parser/SqlBaseParser/createFileFormat()#org/antlr/v4/runtime/atn/ParserATNSimulator/adaptivePredict(org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/math/BigDecimal/toString()
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/Option/isDefined()
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/math/BigDecimal$/apply(scala.math.BigInt,java.math.MathContext)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/collection/TraversableLike/filter(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#java/math/MathContext/MathContext(int,java.math.RoundingMode)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#org/apache/spark/sql/catalyst/plans/logical/Statistics$$anonfun$simpleString$1/1(org.apache.spark.sql.catalyst.plans.logical.Statistics)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/Statistics/simpleString()#org/apache/spark/util/Utils$/bytesToString(scala.math.BigInt)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/BinaryArithmetic/left()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/types/DecimalType$Expression$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_1$mcI$sp()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/BinaryComparison$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryComparison)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/isDefinedAt(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryArithmetic/left()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/DecimalPrecision$/widerDecimalType(int,int,int,int)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryComparison/makeCopy(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/DecimalType$/bounded(int,int)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/DecimalType$/MAX_SCALE()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/math/package$/min(int,int)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/DecimalType$Expression$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_1$mcI$sp()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/math/package$/max(int,int)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/DecimalPrecision$/org$apache$spark$sql$catalyst$analysis$DecimalPrecision$$promotePrecision(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryComparison$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryComparison)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InlineTableContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#scala/collection/Seq$/tabulate(int,scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#scala/collection/mutable/Buffer/head()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitInlineTable$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitInlineTable$1$$anonfun$apply$22/22(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitInlineTable$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InlineTableContext/identifierList()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/EnhancedLogicalPlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$EnhancedLogicalPlan$/optionalMap$extension(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitInlineTable$1$$anonfun$34/34(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitInlineTable$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitInlineTable$1$$anonfun$33/33(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitInlineTable$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$InlineTableContext/expression()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitInlineTable/1/apply()#scala/collection/SeqLike/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$/org$apache$spark$sql$catalyst$analysis$Analyzer$ExtractWindowExpressions$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/Seq/distinct()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#org/apache/spark/sql/catalyst/analysis/Analyzer$ExtractWindowExpressions$$anonfun$72$$anonfun$7/7(org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions$$anonfun$72)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ExtractWindowExpressions/anonfun/72/apply(org.apache.spark.sql.catalyst.expressions.NamedExpression)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$$anonfun$9/9(org.apache.spark.sql.catalyst.expressions.objects.NewInstance)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$$anonfun$8/8(org.apache.spark.sql.catalyst.expressions.objects.NewInstance)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.objects.NewInstance,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$$anonfun$7/7(org.apache.spark.sql.catalyst.expressions.objects.NewInstance,java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/NewInstance/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.objects.NewInstance,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$1/1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$2/2()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/genComparisons(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/newCodeGenContext()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/compile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering$$anonfun$create$2/2(scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateOrdering/create(scala.collection.Seq)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#org/apache/spark/sql/catalyst/expressions/UnsafeProjection$/create(org.apache.spark.sql.types.DataType[])
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#org/apache/spark/sql/catalyst/expressions/UnsafeProjection$/create(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/UnsafeProjection/create(org.apache.spark.sql.types.DataType[])#org/apache/spark/sql/catalyst/expressions/UnsafeProjection$$anonfun$create$2/2()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/apply(scala.Option,scala.Option,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/math/BigInt/min(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/isIntersected(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.Range,org.apache.spark.sql.catalyst.plans.logical.statsEstimation.Range)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/intersect(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.Range,org.apache.spark.sql.catalyst.plans.logical.statsEstimation.Range,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/InnerOuterEstimation/anonfun/getIntersectedStats/1/apply(scala.Tuple2)#scala/math/package$/min(long,long)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#org/apache/spark/sql/catalyst/plans/JoinType$/apply(java.lang.String)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/Seq/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/plans/JoinType/apply(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#org/apache/spark/sql/catalyst/catalog/CatalogUtils$/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#org/apache/spark/sql/catalyst/catalog/CatalogUtils$$anonfun$8/8(java.lang.String,scala.collection.Seq,scala.Function2)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#org/apache/spark/sql/catalyst/catalog/CatalogUtils$$anonfun$7/7(java.lang.String,scala.collection.Seq,scala.Function2)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogUtils/normalizeBucketSpec(java.lang.String,scala.collection.Seq,org.apache.spark.sql.catalyst.catalog.BucketSpec,scala.Function2)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveWindowFrame$$anonfun$apply$30/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveWindowFrame$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveWindowFrame$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveWindowFrame$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowFrame/anonfun/apply/30/anonfun/applyOrElse/11/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/SpecifiedWindowFrame$/defaultWindowFrame(boolean,boolean)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$3$$anonfun$35/35(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$3)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/findAliases(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/newAliases(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeSet$/apply(scala.collection.Iterable)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$3$$anonfun$applyOrElse$32/32(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$3)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$3$$anonfun$applyOrElse$33/33(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$3)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/SerializeFromObject/outputSet()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/TruncDate/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/TruncDate$$anonfun$doGenCode$24/24(org.apache.spark.sql.catalyst.expressions.TruncDate,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,java.lang.String)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TruncDate/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/Some/x()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/unsafe/types/CalendarInterval/fromSingleUnitString(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#java/lang/String/substring(int,int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$48/48(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitIntervalField$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/validate(scala.Function0,java.lang.String,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntervalValueContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$apply$3/3(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitIntervalField$1,org.apache.spark.unsafe.types.CalendarInterval)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/unsafe/types/CalendarInterval/fromYearMonthString(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#java/lang/String/toLowerCase(java.util.Locale)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#java/lang/String/length()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#java/lang/IllegalArgumentException/getMessage()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/sql/catalyst/parser/ParseException/setStackTrace(java.lang.StackTraceElement[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#java/lang/IllegalArgumentException/getStackTrace()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/unsafe/types/CalendarInterval/fromDayTimeString(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#java/lang/String/endsWith(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitIntervalField/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitWindowDef$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitWindowDef$1$$anonfun$apply$36/36(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitWindowDef$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WindowDefContext/windowFrame()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitWindowDef$1$$anonfun$42/42(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitWindowDef$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitWindowDef$1$$anonfun$41/41(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitWindowDef$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WindowDefContext/sortItem()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitWindowDef/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitWindowDef$1$$anonfun$43/43(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitWindowDef$1)
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/PreciseTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/anonfun/2/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/anonfun/3/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/collection/Seq/tail()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/collection/TraversableOnce/toList()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Predef$/Boolean2boolean(java.lang.Boolean)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Function2/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/org$apache$spark$sql$catalyst$plans$logical$LogicalPlan$$resolveAsColumn(scala.collection.Seq,scala.Function2,org.apache.spark.sql.catalyst.expressions.Attribute)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/Seq$/empty()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/immutable/List/last()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$2/2(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq,scala.Function2)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$resolve$3/3(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq,scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$resolve$2/2(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq,scala.Function2)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/immutable/List/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$3/3(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function2)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/Seq/distinct()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/Some/get()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/resolve(scala.collection.Seq,scala.collection.Seq,scala.Function2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/children()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$2()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan$$anonfun$computeStats$1/1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.internal.SQLConf)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/Statistics$/apply$default$4()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/TraversableOnce/product(scala.math.Numeric)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/nodeName()
org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/computeStats(org.apache.spark.sql.internal.SQLConf)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InputFileBlockStart/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap$$anonfun$10$$anonfun$11/11(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.ColumnStatsMap$$anonfun$10)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap$$anonfun$10$$anonfun$12/12(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.ColumnStatsMap$$anonfun$10,org.apache.spark.sql.catalyst.plans.logical.ColumnStat)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#scala/collection/mutable/Map/get(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/exprId()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/ColumnStatsMap/anonfun/10/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/updateNdv(scala.math.BigInt,scala.math.BigInt,scala.math.BigInt)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$addToPath$1(java.lang.String,scala.Option)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#org/spark_project/guava/reflect/Invokable/getReturnType()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType$default$2()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#java/lang/reflect/Method/getName()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#java/beans/PropertyDescriptor/getReadMethod()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#java/beans/PropertyDescriptor/getName()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#org/spark_project/guava/reflect/TypeToken/method(java.lang.reflect.Method)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#java/beans/PropertyDescriptor/getWriteMethod()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/5/apply(java.beans.PropertyDescriptor)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/simpleString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveMissingReferences$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr$1$$anonfun$apply$55/55(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveMissingReferences$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveMissingReferences$$addMissingAttr$1,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveMissingReferences/addMissingAttr/1/apply(org.apache.spark.sql.catalyst.expressions.Attribute)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$6(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$7(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$any2stringadd$/$plus$extension(java.lang.Object,java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$3()
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$4()
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/any2stringadd(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/plans/logical/Pivot/anonfun/output/13/anonfun/apply/10/apply(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/AttributeReference$/apply$default$5(java.lang.String,org.apache.spark.sql.types.DataType,boolean,org.apache.spark.sql.types.Metadata)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$7/7(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$6/6(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$5/5(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$5/5(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$3/3(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$1/1(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$14/14(org.apache.spark.sql.catalyst.json.JacksonGenerator,scala.collection.Seq,org.apache.spark.sql.types.StructType)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$16/16(org.apache.spark.sql.catalyst.json.JacksonGenerator,scala.Function2,org.apache.spark.sql.types.MapType)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$9/9(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$17/17(org.apache.spark.sql.catalyst.json.JacksonGenerator,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$13/13(org.apache.spark.sql.catalyst.json.JacksonGenerator,org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$8/8(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$4/4(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$4/4(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$15/15(org.apache.spark.sql.catalyst.json.JacksonGenerator,scala.Function2)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$2/2(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$12/12(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$11/11(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/json/JacksonGenerator/org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/json/JacksonGenerator$$anonfun$org$apache$spark$sql$catalyst$json$JacksonGenerator$$makeWriter$10/10(org.apache.spark.sql.catalyst.json.JacksonGenerator)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/FalseLiteral()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/IntegralType$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/DecimalLiteral$/smallerThanSmallestLong(org.apache.spark.sql.types.Decimal)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/DecimalLiteral$/unapply(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/DecimalLiteral$/largerThanLargestLong(org.apache.spark.sql.types.Decimal)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Literal$/TrueLiteral()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection$/genericMutableRowType()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection$$anonfun$create$1/1(scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/compile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection$/newCodeGenContext()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/mutable/ArrayBuffer/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/TraversableLike/filter(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection$$anonfun$1/1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/generic/GenericTraversableTemplate/unzip(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection$$anonfun$2/2(scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateMutableProjection/create(scala.collection.Seq,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/JsonExprUtils$/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/JsonExprUtils$$anonfun$convertToMapData$1/1()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/CreateMap/eval$default$1()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/immutable/Map$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/toScalaMap(org.apache.spark.sql.catalyst.util.ArrayBasedMapData)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/convertToMapData(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/parser/CatalystSqlParser$/parseTableSchema(java.lang.String)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/JsonExprUtils$/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/JsonExprUtils/validateSchemaLiteral(org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[],int,int)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/arrayOffset()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#com/fasterxml/jackson/core/JsonFactory/createParser(java.io.Reader)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/io/InputStreamReader/InputStreamReader(java.io.InputStream,java.lang.String)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/remaining()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/array()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/hasArray()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/json/CreateJacksonParser$/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/unsafe/types/UTF8String/getByteBuffer()
org/apache/spark/sql/catalyst/json/CreateJacksonParser/utf8String(com.fasterxml.jackson.core.JsonFactory,org.apache.spark.unsafe.types.UTF8String)#java/nio/ByteBuffer/position()
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/OffsetWindowFunction/frame$lzycompute()#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveWindowOrder$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveWindowOrder$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveWindowOrder$$anonfun$apply$31$$anonfun$applyOrElse$12$$anonfun$80/80(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowOrder$$anonfun$apply$31$$anonfun$applyOrElse$12)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveWindowOrder$$anonfun$apply$31/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveWindowOrder$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveWindowOrder/anonfun/apply/31/anonfun/applyOrElse/12/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateNamedStruct/anonfun/doGenCode/1/apply(scala.Tuple2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#scala/Some/x()
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/expressions/aggregate/AggregateExpression$/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateFunction,org.apache.spark.sql.catalyst.expressions.aggregate.AggregateMode,boolean)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$/org$apache$spark$sql$catalyst$optimizer$RewriteDistinctAggregates$$patchAggregateFunctionChildren$1(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateFunction,scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$$anonfun$17$$anonfun$18/18(org.apache.spark.sql.catalyst.optimizer.RewriteDistinctAggregates$$anonfun$17)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates$/org$apache$spark$sql$catalyst$optimizer$RewriteDistinctAggregates$$evalWithinGroup$1(org.apache.spark.sql.catalyst.expressions.Literal,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.AttributeReference)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewriteDistinctAggregates/anonfun/17/apply(org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduceLeftOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$50/50(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$39/39(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$54/54(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$47/47(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$51/51(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$40/40(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$41/41(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$52/52(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$/org$apache$spark$sql$catalyst$optimizer$PushPredicateThroughJoin$$split(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$42/42(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$53/53(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$55/55(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$44/44(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$45/45(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$56/56(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$46/46(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$57/57(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/LeftExistence$/unapply(org.apache.spark.sql.catalyst.plans.JoinType)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableOnce/reduceLeftOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$applyOrElse$19/19(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$applyOrElse$18/18(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$applyOrElse$17/17(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$applyOrElse$16/16(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18,org.apache.spark.sql.catalyst.plans.logical.Join)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduceLeft(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$48/48(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$49/49(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin$$anonfun$apply$18$$anonfun$43/43(org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin$$anonfun$apply$18)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushPredicateThroughJoin/anonfun/apply/18/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat$$anonfun$toLinkedHashMap$1/1(org.apache.spark.sql.catalyst.catalog.CatalogStorageFormat,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#scala/collection/immutable/Map/isEmpty()
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat$$anonfun$toLinkedHashMap$4/4(org.apache.spark.sql.catalyst.catalog.CatalogStorageFormat,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#scala/Option/foreach(scala.Function1)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap/LinkedHashMap()
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat$$anonfun$toLinkedHashMap$5/5(org.apache.spark.sql.catalyst.catalog.CatalogStorageFormat)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat$$anonfun$toLinkedHashMap$3/3(org.apache.spark.sql.catalyst.catalog.CatalogStorageFormat,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#scala/collection/mutable/LinkedHashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogUtils$/maskCredentials(scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/toLinkedHashMap()#org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat$$anonfun$toLinkedHashMap$2/2(org.apache.spark.sql.catalyst.catalog.CatalogStorageFormat,scala.collection.mutable.LinkedHashMap)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#scala/collection/TraversableOnce/mkString()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#org/apache/spark/sql/catalyst/expressions/CaseWhenBase$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.CaseWhenBase)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#org/apache/spark/sql/catalyst/expressions/CaseWhenBase$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.CaseWhenBase)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/sql()#org/apache/spark/sql/catalyst/expressions/CaseWhenBase$$anonfun$7/7(org.apache.spark.sql.catalyst.expressions.CaseWhenBase)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#org/apache/spark/sql/catalyst/expressions/CaseWhenBase$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.CaseWhenBase)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#org/apache/spark/sql/catalyst/expressions/CaseWhenBase$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.CaseWhenBase)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#org/apache/spark/sql/catalyst/expressions/CaseWhenBase$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.CaseWhenBase)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#scala/collection/TraversableOnce/mkString()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/toString()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CaseWhenBase$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.CaseWhenBase)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CaseWhenBase$$anonfun$checkInputDataTypes$1/1(org.apache.spark.sql.catalyst.expressions.CaseWhenBase)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/collection/Seq/indexWhere(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CaseWhenBase/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp$$anonfun$doGenCode$18/18(org.apache.spark.sql.catalyst.expressions.FromUTCTimestamp,java.lang.String)
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/defineCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FromUTCTimestamp/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/SeqLike/reverseMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/math/Ordering$/ordered(scala.Function1)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$/timeMap()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$1/1()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/mutable/Map/keys()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/TraversableOnce/max(scala.math.Ordering)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$dumpTimeSpent$2/2(int)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/JavaConverters$/mapAsScalaMapConverter(java.util.Map)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$/dumpTimeSpent()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/spark_project/guava/util/concurrent/AtomicLongMap/asMap()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$dumpTimeSpent$1/1()
org/apache/spark/sql/catalyst/rules/RuleExecutor/dumpTimeSpent()#scala/collection/mutable/Map/toSeq()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$throwError(java.lang.String,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$2/2(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$1/1()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/foreachUp(scala.Function1)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$2/2()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$collectStreamingAggregates$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/collect(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$checkForStreaming$1/1()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker$$anonfun$3/3()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/head()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/UnsupportedOperationChecker/checkForStreaming(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.streaming.OutputMode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/spark_project/guava/reflect/Invokable/getReturnType()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#java/lang/reflect/Method/getName()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#java/beans/PropertyDescriptor/getReadMethod()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferExternalType(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/spark_project/guava/reflect/TypeToken/method(java.lang.reflect.Method)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#java/beans/PropertyDescriptor/getName()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/6/apply(java.beans.PropertyDescriptor)#org/spark_project/guava/reflect/TypeToken/getRawType()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/ResolveInlineTables/anonfun/validateInputDimension/1/apply(scala.Tuple2)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#org/apache/spark/sql/types/StructField$/apply$default$3()
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#org/apache/spark/sql/types/StructField$/apply$default$4()
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Stack/anonfun/elementSchema/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/contains(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$QUERY()
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$12/12(org.apache.spark.sql.catalyst.expressions.ParseUrl,org.apache.spark.sql.catalyst.InternalRow)
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ParseUrl/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$1/1(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$2/2(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$4/4(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$REF()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$5/5(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$6/6(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$7/7(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$8/8(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$9/9(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$PROTOCOL()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$USERINFO()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$AUTHORITY()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$FILE()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$QUERY()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$PATH()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$/org$apache$spark$sql$catalyst$expressions$ParseUrl$$HOST()
org/apache/spark/sql/catalyst/expressions/ParseUrl/getExtractPartFunc(org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/ParseUrl$$anonfun$getExtractPartFunc$3/3(org.apache.spark.sql.catalyst.expressions.ParseUrl)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryOperator/makeCopy(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/DecimalPrecision$/org$apache$spark$sql$catalyst$analysis$DecimalPrecision$$isFloat(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/BinaryOperator$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryOperator)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/types/DecimalType$/forType(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/DecimalPrecision/anonfun/3/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#org/apache/spark/sql/catalyst/plans/logical/SetOperation$$anonfun$rightConstraints$1/1(org.apache.spark.sql.catalyst.plans.logical.SetOperation,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#scala/Predef$/require(boolean)
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#scala/collection/immutable/Set$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/SetOperation/rightConstraints()#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/constraints()
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/GenArrayData$$anonfun$2/2(boolean,java.lang.String)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#org/apache/spark/unsafe/array/ByteArrayMethods/roundNumberOfBytesToNearestWord(int)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/GenArrayData$/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/GenArrayData/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)#org/apache/spark/sql/catalyst/expressions/GenArrayData$$anonfun$3/3(boolean,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#java/util/concurrent/atomic/AtomicInteger/getAndIncrement()
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(java.lang.String,java.lang.String,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Option)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/objects/MapObjects/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/curId()
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/apache/spark/sql/types/PythonUserDefinedType$$anonfun$jsonValue$5/5(org.apache.spark.sql.types.PythonUserDefinedType)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/apache/spark/sql/types/PythonUserDefinedType$$anonfun$jsonValue$6/6(org.apache.spark.sql.types.PythonUserDefinedType)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)
org/apache/spark/sql/types/PythonUserDefinedType/jsonValue()#org/apache/spark/sql/types/PythonUserDefinedType$$anonfun$jsonValue$4/4(org.apache.spark.sql.types.PythonUserDefinedType)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/1/apply(scala.Tuple2)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AggregationContext/groupingSet()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AggregationContext/CUBE()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AggregationContext/GROUPING()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withAggregation$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$AggregationContext/ROLLUP()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withAggregation/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withAggregation$1$$anonfun$30/30(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withAggregation$1)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/sql/catalyst/expressions/StringTranslate$/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#scala/Predef$/char2Character(char)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/lang/String/charAt(int)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/lang/String/length()
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/util/HashMap/HashMap()
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/util/HashMap/put(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#java/util/HashMap/get(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/StringTranslate/buildDict(org.apache.spark.unsafe.types.UTF8String,org.apache.spark.unsafe.types.UTF8String)#org/apache/spark/unsafe/types/UTF8String/toString()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat$/empty()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/TableIdentifier$/apply(java.lang.String)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/package$AttributeSeq/toStructType()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$15()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$16()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$10()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$6()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$11()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$7()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$12()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/package$/AttributeSeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$8()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$13()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$9()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$14()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/VIEW()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$17()
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/ExpectsInputTypes$class/checkInputDataTypes(org.apache.spark.sql.catalyst.expressions.ExpectsInputTypes)
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/TimeWindow/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/If/createAndAddFunction(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,org.apache.spark.sql.types.DataType,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/If/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_2()
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_1()
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/_3()
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/String/length()
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/If/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Union/withNewChildren(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$30/30(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$3/3(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$applyOrElse$15/15(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17,org.apache.spark.sql.catalyst.plans.logical.UnaryNode)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/UnaryNode/expressions()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$canPushThrough(org.apache.spark.sql.catalyst.plans.logical.UnaryNode)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$applyOrElse$14/14(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$applyOrElse$11/11(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$2/2(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduceLeft(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeSet$/apply(scala.collection.Iterable)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$28/28(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$26/26(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$31/31(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$29/29(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$27/27(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17,org.apache.spark.sql.catalyst.expressions.AttributeMap,org.apache.spark.sql.catalyst.plans.logical.Aggregate)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$32/32(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17,org.apache.spark.sql.catalyst.expressions.Expression,scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/span(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$/replaceAlias(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$applyOrElse$9/9(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$canPushThroughCondition(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$$anonfun$apply$17$$anonfun$applyOrElse$8/8(org.apache.spark.sql.catalyst.optimizer.PushDownPredicate$$anonfun$apply$17)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/PushDownPredicate/anonfun/apply/17/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/PushDownPredicate$/org$apache$spark$sql$catalyst$optimizer$PushDownPredicate$$pushDownPredicate(org.apache.spark.sql.catalyst.plans.logical.Filter,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQueries$1$$anonfun$46/46(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQueries$1,org.apache.spark.sql.catalyst.expressions.ExprId)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery$default$3()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQueries$1$$anonfun$applyOrElse$55/55(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQueries$1,org.apache.spark.sql.catalyst.expressions.ExprId)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQueries$1$$anonfun$applyOrElse$56/56(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQueries$1,org.apache.spark.sql.catalyst.expressions.ExprId)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/get()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/anonfun/org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/resolveSubQueries/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$4/4(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/headOption()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$3/3(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/x()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$5/5(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight$1/1(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/logDebug(scala.Function0)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/collect(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformUp(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/InSet/sql()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/InSet/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/InSet/sql()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InSet/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InSet/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InSet/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InSet/sql()#org/apache/spark/sql/catalyst/expressions/InSet$$anonfun$7/7(org.apache.spark.sql.catalyst.expressions.InSet)
org/apache/spark/sql/catalyst/expressions/InSet/sql()#scala/collection/immutable/Set/toSeq()
org/apache/spark/sql/catalyst/expressions/InSet/sql()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QualifiedNameContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$QualifiedNameContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$40/40(org.apache.spark.sql.catalyst.parser.AstBuilder)
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/Some/get()
org/apache/spark/sql/catalyst/parser/AstBuilder/visitFunctionName(org.apache.spark.sql.catalyst.parser.SqlBaseParser$QualifiedNameContext)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/util/Try/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/util/Try/orElse(scala.Function0)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/util/Try$/apply(scala.Function0)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$10$$anonfun$apply$12$$anonfun$applyOrElse$7/7(org.apache.spark.sql.catalyst.json.JacksonParser$$anonfun$makeConverter$10$$anonfun$apply$12,java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$10$$anonfun$apply$12$$anonfun$applyOrElse$3/3(org.apache.spark.sql.catalyst.json.JacksonParser$$anonfun$makeConverter$10$$anonfun$apply$12,java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#com/fasterxml/jackson/core/JsonParser/getText()
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#org/apache/spark/sql/catalyst/json/JacksonParser$$anonfun$makeConverter$10$$anonfun$apply$12$$anonfun$applyOrElse$4/4(org.apache.spark.sql.catalyst.json.JacksonParser$$anonfun$makeConverter$10$$anonfun$apply$12,java.lang.String)
org/apache/spark/sql/catalyst/json/JacksonParser/anonfun/makeConverter/10/anonfun/apply/12/applyOrElse(com.fasterxml.jackson.core.JsonToken,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/GetStructField$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/UnresolvedStar/anonfun/expand/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#org/apache/spark/util/Utils$/truncatedString$default$5()
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#org/apache/spark/sql/catalyst/plans/logical/With$$anonfun$15/15(org.apache.spark.sql.catalyst.plans.logical.With)
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#org/apache/spark/util/Utils$/truncatedString(scala.collection.Seq,java.lang.String,java.lang.String,java.lang.String,int)
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/With/simpleString()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#java/io/StringWriter/getBuffer()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#scala/collection/immutable/$colon$colon/tl$1()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonGenerator/writeStartArray()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#java/lang/IllegalStateException/IllegalStateException()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonGenerator/writeRaw(java.lang.String)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#java/lang/StringBuffer/length()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#org/apache/spark/sql/catalyst/expressions/GetJsonObject$$anonfun$org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath$1/1(org.apache.spark.sql.catalyst.expressions.GetJsonObject,com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,scala.collection.immutable.$colon$colon)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonGenerator/writeEndArray()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonGenerator/writeRaw(char[],int,int)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#org/apache/spark/sql/catalyst/expressions/GetJsonObject$$anonfun$org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath$3/3(org.apache.spark.sql.catalyst.expressions.GetJsonObject,java.io.StringWriter)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#java/lang/StringBuffer/toString()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#java/lang/StringBuffer/substring(int,int)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#org/apache/spark/sql/catalyst/expressions/PathInstruction$Index/index()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#org/apache/spark/sql/catalyst/expressions/PathInstruction$Named/name()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/skipChildren()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/getText()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#scala/collection/immutable/$colon$colon/head()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#org/apache/spark/sql/catalyst/expressions/GetJsonObject$$anonfun$org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath$2/2(org.apache.spark.sql.catalyst.expressions.GetJsonObject,com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/getTextLength()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonGenerator/copyCurrentStructure(com.fasterxml.jackson.core.JsonParser)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#scala/Function1/apply$mcZJ$sp(long)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/getTextCharacters()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/hasTextCharacters()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/getCurrentName()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/getCurrentToken()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/getTextOffset()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#org/apache/spark/sql/catalyst/expressions/GetJsonObject$$anonfun$org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath$4/4(org.apache.spark.sql.catalyst.expressions.GetJsonObject,com.fasterxml.jackson.core.JsonParser,scala.collection.immutable.List,scala.Product,scala.runtime.IntRef)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#scala/runtime/IntRef/create(int)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonGenerator/writeRawValue(java.lang.String)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#java/io/StringWriter/StringWriter()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#org/apache/spark/util/Utils$/tryWithResource(scala.Function0,scala.Function1)
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#com/fasterxml/jackson/core/JsonParser/nextToken()
org/apache/spark/sql/catalyst/expressions/GetJsonObject/org$apache$spark$sql$catalyst$expressions$GetJsonObject$$evaluatePath(com.fasterxml.jackson.core.JsonParser,com.fasterxml.jackson.core.JsonGenerator,org.apache.spark.sql.catalyst.expressions.WriteStyle,scala.collection.immutable.List)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/fastEquals(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/collection/Iterator/next()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$/checkAndGetOuterReferences(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/Function2/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/collection/Seq/iterator()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$/resolveOuterReferences(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#org/apache/spark/sql/catalyst/analysis/Analyzer/execute(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/collection/Iterator/hasNext()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#org/apache/spark/sql/catalyst/expressions/SubqueryExpression/plan()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$resolveSubQuery(org.apache.spark.sql.catalyst.expressions.SubqueryExpression,scala.collection.Seq,int,scala.Function2)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveSubquery$$anonfun$org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1$1/1(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery$)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveSubquery/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveSubquery$$failOnOuterReference$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/StringBuilder/append(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/Double/valueOf(double)
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/Long/valueOf(long)
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/Byte/valueOf(byte)
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/Short/valueOf(short)
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/Float/valueOf(float)
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/Boolean/valueOf(boolean)
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/UnsafeArrayData/get(int,org.apache.spark.sql.types.DataType)#java/lang/Integer/valueOf(int)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitMultiInsertQuery$1$$anonfun$3$$anonfun$apply$5/5(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitMultiInsertQuery$1$$anonfun$3)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/ParserUtils$/EnhancedLogicalPlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitMultiInsertQuery$1/org$apache$spark$sql$catalyst$parser$AstBuilder$$anonfun$$$outer()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitMultiInsertQuery$1$$anonfun$3$$anonfun$apply$1/1(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitMultiInsertQuery$1$$anonfun$3,org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$MultiInsertQueryBodyContext/insertInto()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/ParserUtils$EnhancedLogicalPlan$/optionalMap$extension(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitMultiInsertQuery$1$$anonfun$3$$anonfun$apply$6/6(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitMultiInsertQuery$1$$anonfun$3)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$MultiInsertQueryBodyContext/queryOrganization()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/ParserUtils$/validate(scala.Function0,java.lang.String,org.antlr.v4.runtime.ParserRuleContext)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitMultiInsertQuery/1/anonfun/3/apply(org.apache.spark.sql.catalyst.parser.SqlBaseParser$MultiInsertQueryBodyContext)#org/apache/spark/sql/catalyst/parser/SqlBaseParser$MultiInsertQueryBodyContext/querySpecification()
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/GenArrayData$/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/_4()
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/CreateArray$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.CreateArray,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/CreateArray/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#scala/Some/x()
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#scala/Tuple2/_2()
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#java/util/Arrays/equals(boolean[],boolean[])
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#scala/collection/immutable/Map/get(java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#java/util/Arrays/equals(long[],long[])
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#scala/Tuple2/_1()
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#java/util/Arrays/equals(java.lang.Object[],java.lang.Object[])
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#java/util/Arrays/equals(double[],double[])
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/Metadata/anonfun/equals/1/apply(java.lang.String)#scala/Option/get()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/math/BigDecimal/scale()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$DecimalConverter/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$DecimalConverter/DecimalConverter(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$/convertToCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/InternalRow$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$2/2()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/math/BigDecimal/precision()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$5/5()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#java/math/BigDecimal/scale()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$TimestampConverter$/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$StringConverter$/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$DateConverter$/toCatalyst(java.lang.Object)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#java/math/BigDecimal/precision()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/util/ArrayBasedMapData$/apply(scala.collection.Map,scala.Function1,scala.Function1)
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$1/1()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$3/3()
org/apache/spark/sql/catalyst/CatalystTypeConverters/convertToCatalyst(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$$anonfun$convertToCatalyst$4/4()
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashDecimal(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DecimalType,java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/collection/mutable/ArrayOps/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#org/apache/spark/sql/catalyst/expressions/HiveHash$$anonfun$genHashForStruct$2/2(org.apache.spark.sql.catalyst.expressions.HiveHash,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashForStruct(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String,org.apache.spark.sql.types.StructField[])#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashCalendarInterval(java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/HiveHash/genHashTimestamp(java.lang.String,java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Map/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$FixNullability$$anonfun$apply$24$$anonfun$applyOrElse$9/9(org.apache.spark.sql.catalyst.analysis.Analyzer$FixNullability$$anonfun$apply$24,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/children()
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/Iterable$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformExpressions(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$FixNullability$$anonfun$apply$24$$anonfun$60/60(org.apache.spark.sql.catalyst.analysis.Analyzer$FixNullability$$anonfun$apply$24)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$FixNullability$$anonfun$apply$24$$anonfun$61/61(org.apache.spark.sql.catalyst.analysis.Analyzer$FixNullability$$anonfun$apply$24)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$FixNullability$$anonfun$apply$24$$anonfun$62/62(org.apache.spark.sql.catalyst.analysis.Analyzer$FixNullability$$anonfun$apply$24)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$FixNullability$$anonfun$apply$24$$anonfun$64/64(org.apache.spark.sql.catalyst.analysis.Analyzer$FixNullability$$anonfun$apply$24)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableOnce/toSeq()
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/FixNullability/anonfun/apply/24/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableLike/groupBy(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#scala/Some/x()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableNameContext/sample()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableNameContext/strictIdentifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitTableName$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableNameContext/tableIdentifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitTableName$1$$anonfun$apply$20/20(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitTableName$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/EnhancedLogicalPlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$EnhancedLogicalPlan$/optionalMap$extension(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableName/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitTableName$1$$anonfun$32/32(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitTableName$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LateralViewContext/OUTER()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LateralViewContext/expression()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#java/lang/String/toLowerCase()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withGenerate$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withGenerate$1$$anonfun$apply$17/17(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withGenerate$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withGenerate$1$$anonfun$apply$18/18(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withGenerate$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withGenerate/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$LateralViewContext/qualifiedName()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Attribute/resolved()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2/cleanQuery$1(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Some/x()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/FrameBoundary$/unapply(org.apache.spark.sql.catalyst.expressions.FrameBoundary)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/inputSet()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/message()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2$$anonfun$1/1(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Traversable$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/SubqueryExpression/plan()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Attribute/sql()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Option/get()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/SubExprUtils$/getCorrelatedPredicates(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/Aggregate/expressions()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/expressions/AttributeSet$/apply(scala.collection.Iterable)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2$$anonfun$6/6(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2,scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1/org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$anonfun$$$outer()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/TraversableLike/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2$$anonfun$2/2(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2$$anonfun$3/3(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2$$anonfun$4/4(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/CheckAnalysis/anonfun/checkAnalysis/1/anonfun/apply/2/checkAggregate$1(org.apache.spark.sql.catalyst.plans.logical.Aggregate,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.Seq)#org/apache/spark/sql/catalyst/analysis/CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2$$anonfun$5/5(org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/ExternalMapToCatalyst$/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,scala.Function1,org.apache.spark.sql.types.DataType,scala.Function1,boolean)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$/listType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor$2/2(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/spark_project/guava/reflect/TypeToken/getComponentType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor$1/1(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$/elementType(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/collection/mutable/ArrayOps/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$/mapKeyValueType(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/types/DecimalType$/SYSTEM_DEFAULT()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Predef$DummyImplicit$/dummyImplicit()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke$/apply$default$5()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/spark_project/guava/reflect/TypeToken/isArray()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$/mapType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$/getJavaBeanReadableAndWritableProperties(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/spark_project/guava/reflect/TypeToken/getRawType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/spark_project/guava/reflect/TypeToken/isAssignableFrom(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$serializerFor(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/JavaTypeInference$/iterableType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#java/lang/Class/isAnnotationPresent(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/spark_project/guava/reflect/TypeToken/getComponentType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/JavaTypeInference$/elementType(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/JavaTypeInference$/getJavaBeanReadableProperties(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/JavaTypeInference$/mapKeyValueType(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/types/DecimalType$/SYSTEM_DEFAULT()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#java/lang/Class/newInstance()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/types/UDTRegistration$/getUDTFor(java.lang.String)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/types/DecimalType$/BigIntDecimal()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/collection/immutable/Set/contains(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#java/lang/Class/getAnnotation(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/spark_project/guava/reflect/TypeToken/isArray()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/JavaTypeInference$/mapType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/types/UDTRegistration$/exists(java.lang.String)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/spark_project/guava/reflect/TypeToken/getRawType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/spark_project/guava/reflect/TypeToken/isAssignableFrom(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$1/1(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set,java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)#scala/Option/get()
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/ScalaReflection$/isNativeType(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType$default$2()
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$5()
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/spark_project/guava/reflect/TypeToken/getRawType()
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$toCatalystArray$1$1/1(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)
org/apache/spark/sql/catalyst/JavaTypeInference/toCatalystArray$1(org.apache.spark.sql.catalyst.expressions.Expression,org.spark_project.guava.reflect.TypeToken)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#java/lang/Class/getComponentType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Option/nonEmpty()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$getPath$1(org.spark_project.guava.reflect.TypeToken,scala.Option)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/elementType(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$4/4(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$3/3(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#java/lang/Class/isArray()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor$1/1(org.spark_project.guava.reflect.TypeToken,scala.Option,java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$2/2(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/mapKeyValueType(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(org.spark_project.guava.reflect.TypeToken,scala.collection.immutable.Set)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor$2/2(org.spark_project.guava.reflect.TypeToken,scala.Option,java.lang.Class,java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/StaticInvoke$/apply$default$5()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType$default$2()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$5/5(org.spark_project.guava.reflect.TypeToken,scala.Option)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/listType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/NewInstance$/apply(java.lang.Class,scala.collection.Seq,org.apache.spark.sql.types.DataType,boolean)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/mapType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/collection/immutable/List/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$5()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/getJavaBeanReadableAndWritableProperties(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/types/ArrayType$/apply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/spark_project/guava/reflect/TypeToken/getRawType()
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/spark_project/guava/reflect/TypeToken/isAssignableFrom(org.spark_project.guava.reflect.TypeToken)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$inferExternalType(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/JavaTypeInference/org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor(org.spark_project.guava.reflect.TypeToken,scala.Option)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery$$anonfun$apply$1$$anonfun$6/6(org.apache.spark.sql.catalyst.optimizer.RewritePredicateSubquery$$anonfun$apply$1)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery$$anonfun$apply$1$$anonfun$applyOrElse$1/1(org.apache.spark.sql.catalyst.optimizer.RewritePredicateSubquery$$anonfun$apply$1)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/ConcatWs/anonfun/9/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParseException$$anonfun$getMessage$1$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.parser.ParseException$$anonfun$getMessage$1)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParseException$$anonfun$getMessage$1$$anonfun$apply$1/1(org.apache.spark.sql.catalyst.parser.ParseException$$anonfun$getMessage$1)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/collection/immutable/IndexedSeq$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/collection/mutable/ArrayOps/splitAt(int)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/collection/mutable/ArrayOps/foreach(scala.Function1)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/runtime/RichInt$/until$extension0(int,int)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/Predef$/intWrapper(int)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#java/lang/String/split(java.lang.String)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#org/apache/spark/sql/catalyst/parser/ParseException$$anonfun$getMessage$1$$anonfun$apply$3/3(org.apache.spark.sql.catalyst.parser.ParseException$$anonfun$getMessage$1)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/parser/ParseException/anonfun/getMessage/1/apply(java.lang.String)#scala/collection/mutable/StringBuilder/$plus$plus$eq(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$toString$1/1(org.apache.spark.sql.catalyst.expressions.ScalaUDF)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#org/apache/spark/sql/catalyst/expressions/ScalaUDF$$anonfun$toString$2/2(org.apache.spark.sql.catalyst.expressions.ScalaUDF)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/collection/Seq/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/toString()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableValuedFunctionContext/expression()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitTableValuedFunction$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$TableValuedFunctionContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitTableValuedFunction/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitTableValuedFunction$1$$anonfun$apply$21/21(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitTableValuedFunction$1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$search$1$$anonfun$apply$2/2(org.apache.spark.sql.catalyst.optimizer.JoinReorderDP$$anonfun$search$1)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/collection/TraversableOnce/sum(scala.math.Numeric)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$$anonfun$search$1/apply()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/search/1/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.WindowSpecDefinition)
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.WindowSpecDefinition)
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/collection/TraversableOnce/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/WindowSpecDefinition/sql()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$$anonfun$stripExtraNewLines$1/1(scala.collection.mutable.StringBuilder,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripExtraNewLines(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/mutable/StringBuilder/result()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/mutable/ArrayOps/foreach(scala.Function1)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/collection/immutable/StringOps/split(char)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripExtraNewLines(java.lang.String)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/mutable/StringBuilder/result()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/immutable/StringOps/split(char)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$$anonfun$stripOverlappingComments$1/1(scala.collection.mutable.StringBuilder,scala.collection.Map,scala.runtime.ObjectRef)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/runtime/ObjectRef/create(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)#scala/collection/mutable/ArrayOps/foreach(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/Expand$$anonfun$1/1(int)
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#scala/collection/Seq/reduce(scala.Function2)
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#scala/collection/SeqLike/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#org/apache/spark/sql/catalyst/plans/logical/Expand$$anonfun$org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask$1/1()
org/apache/spark/sql/catalyst/plans/logical/Expand/org$apache$spark$sql$catalyst$plans$logical$Expand$$buildBitmask(scala.collection.Seq,scala.collection.immutable.Map)#scala/collection/immutable/Map/size()
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/SeqLike/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Expand$$anonfun$21/21()
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/plans/logical/Expand/apply(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/Expand$$anonfun$20/20(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#org/apache/spark/sql/catalyst/analysis/package$AnalysisErrorAt/failAnalysis(java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer/execute(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#org/apache/spark/sql/catalyst/analysis/package$/AnalysisErrorAt(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveRelations$$anonfun$33/apply()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveRelations$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#org/apache/spark/sql/catalyst/analysis/AnalysisContext$/get()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveRelations/anonfun/33/apply()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/collection/mutable/Buffer$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/collection/immutable/Map/mapValues(scala.Function1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withWindows$1$$anonfun$29/29(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withWindows$1,scala.collection.immutable.Map)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$WindowsContext/namedWindow()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/collection/immutable/Map$/canBuildFrom()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withWindows$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withWindows$1$$anonfun$apply$13/13(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withWindows$1)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/org/apache/spark/sql/catalyst/parser/AstBuilder/withWindows/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withWindows$1$$anonfun$28/28(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$org$apache$spark$sql$catalyst$parser$AstBuilder$$withWindows$1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$calculateSingleCondition$1/1(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$6/6(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$calculateSingleCondition$2/2(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/expressions/Equality$/unapply(org.apache.spark.sql.catalyst.expressions.BinaryComparison)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/collection/SetLike/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/collection/immutable/HashSet$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/collection/Seq/forall(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateSingleCondition(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/math/BigDecimal$/double2bigDecimal(double)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/math/BigDecimal/$div(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/math/BigDecimal$/int2bigDecimal(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/math/BigDecimal/$minus(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateNullCheck(org.apache.spark.sql.catalyst.expressions.Attribute,boolean,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$evaluateNullCheck$1/1(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/math/BigDecimal$/double2bigDecimal(double)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/apply(scala.Option,scala.Option,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$evaluateBinaryForTwoColumns$3/3(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/math/BigDecimal$/apply(double)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/ceil(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/math/BigInt/$less(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/Tuple2/_1$mcZ$sp()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$evaluateBinaryForTwoColumns$1/1(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$evaluateBinaryForTwoColumns$2/2(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/Tuple2$mcZZ$sp/sp(boolean,boolean)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForTwoColumns(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Attribute,boolean)#scala/math/BigDecimal/$times(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal$/double2bigDecimal(double)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$evaluateEquality$1/1(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/apply(scala.Option,scala.Option,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal/$div(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateEquality(org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal/$greater(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal/$div(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal$/apply(double)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal/$less(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal$/double2bigDecimal(double)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal/$greater$eq(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/ceil(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigInt/$less(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal$/apply(java.lang.String)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/apply(scala.Option,scala.Option,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal$/apply(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal/$less$eq(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/Tuple2/_2$mcZ$sp()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/Tuple2/_1$mcZ$sp()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal/$minus(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/Tuple2$mcZZ$sp/sp(boolean,boolean)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateBinaryForNumeric(org.apache.spark.sql.catalyst.expressions.BinaryComparison,org.apache.spark.sql.catalyst.expressions.Attribute,org.apache.spark.sql.catalyst.expressions.Literal,boolean)#scala/math/BigDecimal/$times(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/ceil(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/Option/get()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#org/apache/spark/sql/catalyst/expressions/AttributeMap$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$1/1(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils$/getOutputSize(scala.collection.Seq,scala.math.BigInt,org.apache.spark.sql.catalyst.expressions.AttributeMap)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/runtime/BoxesRunTime/equalsNumObject(java.lang.Number,java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/math/BigDecimal/$times(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/estimate()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$9/9(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/math/BigInt$/apply(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/collection/immutable/Set/minBy(scala.Function1,scala.math.Ordering)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/math/BigDecimal/$div(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/package$/BigInt()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$evaluateInSet$1/1(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/collection/immutable/Set/isEmpty()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$7/7(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.plans.logical.statsEstimation.NumericRange)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$8/8(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/math/BigDecimal$/double2bigDecimal(double)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/math/BigDecimal/min(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/Range$/apply(scala.Option,scala.Option,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/math/BigDecimal$/apply(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/math/Ordering$/ordered(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/math/BigInt/min(scala.math.BigInt)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/collection/immutable/Set/maxBy(scala.Function1,scala.math.Ordering)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/collection/immutable/Set/size()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/evaluateInSet(org.apache.spark.sql.catalyst.expressions.Attribute,scala.collection.immutable.Set,boolean)#scala/collection/immutable/Set/filter(scala.Function1)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/math/BigDecimal$/double2bigDecimal(double)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$2/2(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$4/4(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$5/5(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/math/BigDecimal/$minus(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Some/x()
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation$$anonfun$3/3(org.apache.spark.sql.catalyst.plans.logical.statsEstimation.FilterEstimation)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/math/BigDecimal/$times(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation/calculateFilterSelectivity(org.apache.spark.sql.catalyst.expressions.Expression,boolean)#scala/math/BigDecimal/$plus(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat$/empty()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/package$AttributeSeq/toStructType()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$15()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$5()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$10()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$6()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$11()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$7()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$12()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/expressions/package$/AttributeSeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$8()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$13()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$9()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$14()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$16()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTableType$/VIEW()
org/apache/spark/sql/catalyst/catalog/SessionCatalog/anonfun/getTempViewOrPermanentTableMetadata/3/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)#org/apache/spark/sql/catalyst/catalog/CatalogTable$/apply$default$17()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#org/apache/spark/sql/catalyst/expressions/NonNullLiteral$/unapply(org.apache.spark.sql.catalyst.expressions.Literal)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#org/apache/spark/sql/catalyst/expressions/ExtractValue$/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#java/lang/Object/toString()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExtractValue/apply(org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Expression,scala.Function2)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/collection/mutable/ArrayOps/indexWhere(scala.Function1)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#org/apache/spark/sql/catalyst/expressions/ExtractValue$$anonfun$findField$1/1()
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#org/apache/spark/sql/catalyst/expressions/ExtractValue$$anonfun$1/1(java.lang.String,scala.Function2)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/collection/mutable/ArrayOps/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/collection/mutable/ArrayOps/filter(scala.Function1)
org/apache/spark/sql/catalyst/expressions/ExtractValue/findField(org.apache.spark.sql.types.StructField[],java.lang.String,scala.Function2)#scala/collection/mutable/ArrayOps/indexWhere(scala.Function1,int)
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#scala/collection/Seq/isEmpty()
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/expressions/aggregate/Count$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.aggregate.Count)
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#scala/collection/TraversableOnce/reduce(scala.Function2)
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#scala/collection/Seq/filter(scala.Function1)
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$ExpressionConversions$DslExpression/$plus(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$expressions$/longToLiteral(long)
org/apache/spark/sql/catalyst/expressions/aggregate/Count/updateExpressions$lzycompute()#org/apache/spark/sql/catalyst/dsl/package$expressions$/DslExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/optimizer/JoinReorderDP$JoinPlan/JoinPlan(scala.collection.immutable.Set,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.collection.immutable.Set,org.apache.spark.sql.catalyst.optimizer.Cost)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/Predef$/Set()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/Predef$/ArrowAssoc(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/Predef$/wrapIntArray(int[])
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/math/BigInt$/int2bigInt(int)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/JoinReorderDP/anonfun/3/apply(scala.Tuple2)#scala/collection/immutable/Set$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/anonfun/89/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#scala/Option$/option2Iterable(scala.Option)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$/findCommonTypeForBinaryComparison()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#scala/Option/orElse(scala.Function0)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#scala/Function2/apply(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/analysis/TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$7$$anonfun$apply$14/14(org.apache.spark.sql.catalyst.analysis.TypeCoercion$InConversion$$anonfun$apply$4$$anonfun$7,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.catalyst.expressions.Attribute)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/7/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#java/lang/Double/isNaN()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/Predef$/double2Double(double)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal$/apply(int)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal/toLong()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal$/apply(long)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/Predef$/$conforms()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/Predef$/float2Float(float)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#java/lang/Double/isInfinite()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#java/lang/Float/isNaN()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal/toDouble()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal/toInt()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/Option/orNull(scala.Predef$$less$colon$less)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/package$/BigDecimal()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal/setScale(int,scala.Enumeration$Value)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal$/apply(double)
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal/toShort()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal/toFloat()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/math/BigDecimal/toByte()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#java/lang/Float/isInfinite()
org/apache/spark/sql/catalyst/expressions/RoundBase/nullSafeEval(java.lang.Object)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/RoundBase/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/FromUnixTime/nullSafeCodeGen(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,scala.Function2)
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/FromUnixTime$$anonfun$doGenCode$14/14(org.apache.spark.sql.catalyst.expressions.FromUnixTime,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/FromUnixTime/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#org/apache/spark/sql/types/HiveStringType$/replaceCharType(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ColTypeContext/dataType()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#org/apache/spark/sql/catalyst/parser/ParserUtils$/string(org.antlr.v4.runtime.tree.TerminalNode)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#org/apache/spark/sql/types/package$/HIVE_TYPE_STRING()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ColTypeContext/identifier()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitColType$1/apply()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()
org/apache/spark/sql/catalyst/parser/AstBuilder/anonfun/visitColType/1/apply()#org/apache/spark/sql/catalyst/parser/SqlBaseParser$ColTypeContext/STRING()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery$$anonfun$apply$1$$anonfun$applyOrElse$1$$anonfun$7/7(org.apache.spark.sql.catalyst.optimizer.RewritePredicateSubquery$$anonfun$apply$1$$anonfun$applyOrElse$1)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq$/unapplySeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery$/org$apache$spark$sql$catalyst$optimizer$RewritePredicateSubquery$$getValueExpression(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Some/get()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/TraversableOnce/reduceLeft(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Some/isEmpty()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery$/splitConjunctivePredicates(org.apache.spark.sql.catalyst.expressions.Expression)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/SeqLike/apply(int)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/EqualTo$/tupled()
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery$/org$apache$spark$sql$catalyst$optimizer$RewritePredicateSubquery$$rewriteExistentialExpr(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/SeqLike/lengthCompare(int)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/RewritePredicateSubquery/anonfun/apply/1/anonfun/applyOrElse/1/apply(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.expressions.Expression)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBooleanCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBooleanCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBooleanCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBooleanCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBooleanCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/Cast/castToBooleanCode(org.apache.spark.sql.types.DataType)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDoubleCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDoubleCode$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDoubleCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDoubleCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDoubleCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToDoubleCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDoubleCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/SparkException/SparkException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction$1/1(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$nullSafeCastFunction(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimal$5/5(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimal$4/4(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimal$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimal$7/7(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.types.FractionalType)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimal$2/2(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimal$6/6(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.types.IntegralType)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimal(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimal$1/1(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$org$apache$spark$sql$catalyst$expressions$Cast$$cast$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/SparkException/SparkException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$org$apache$spark$sql$catalyst$expressions$Cast$$cast$1/1(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$org$apache$spark$sql$catalyst$expressions$Cast$$cast$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/org$apache$spark$sql$catalyst$expressions$Cast$$cast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DataType$/equalsStructurally(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToIntCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToIntCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToIntCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToIntCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToIntCode$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/castToIntCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToIntCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToLongCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToLongCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToLongCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToLongCode$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToLongCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToLongCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToLongCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToFloatCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToFloatCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToFloatCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToFloatCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToFloatCode$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToFloatCode(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToFloatCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$10/10(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$1/1(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$7/7(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$8/8(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToBoolean(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToBoolean$9/9(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimalCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimalCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimalCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimalCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimalCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimalCode$6/6(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToDecimalCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DecimalType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToDecimalCode$7/7(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.DecimalType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestampCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestampCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestampCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestampCode$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestampCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestampCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestampCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestampCode$7/7(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castStructCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast,scala.Function3[],java.lang.String,java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.Cast,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/Cast/castStructCode(org.apache.spark.sql.types.StructType,org.apache.spark.sql.types.StructType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/collection/mutable/ArrayOps/mkString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToByteCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToByteCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToByteCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToByteCode$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToByteCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToByteCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToByteCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToShortCode$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToShortCode$1/1(org.apache.spark.sql.catalyst.expressions.Cast,java.lang.String)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToShortCode$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToShortCode$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToShortCode$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToShortCode(org.apache.spark.sql.types.DataType,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToShortCode$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/apply(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$/org$apache$spark$sql$catalyst$expressions$Cast$$resolvableNullability(boolean,boolean)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$canCast$1/1()
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/forall(scala.Function1)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Array$/canBuildFrom(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$/forceNullable(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/canCast(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$3/3(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$4/4(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$5/5(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$6/6(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$7/7(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$8/8(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DecimalType$/unapply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$9/9(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$10/10(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$1/1(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/Cast/castToTimestamp(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Cast$$anonfun$castToTimestamp$2/2(org.apache.spark.sql.catalyst.expressions.Cast)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/ScalaUDF/anonfun/27/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1$$anonfun$apply$3/3(org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1,java.lang.String)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1$$anonfun$apply$6/6(org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1,org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#scala/collection/Seq/foldLeft(java.lang.Object,scala.Function2)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/util/Utils$/isTesting()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$Strategy/maxIterations()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/errors/package$TreeNodeException/TreeNodeException(org.apache.spark.sql.catalyst.trees.TreeNode,java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1$$anonfun$apply$4/4(org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1,scala.runtime.IntRef,org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1$$anonfun$apply$5/5(org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1,org.apache.spark.sql.catalyst.trees.TreeNode,org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$$anonfun$execute$1$$anonfun$apply$1/1(org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$Batch/rules()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$Batch/name()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#scala/runtime/IntRef/create(int)
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#org/apache/spark/sql/catalyst/rules/RuleExecutor$Batch/strategy()
org/apache/spark/sql/catalyst/rules/RuleExecutor/anonfun/execute/1/apply(org.apache.spark.sql.catalyst.rules.RuleExecutor$Batch)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/Iterator/next()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/immutable/StringOps/toIterator()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#java/util/regex/Pattern/quote(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#org/apache/spark/sql/catalyst/util/StringUtils$/escapeLikeRegex(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#java/lang/Character/toString(char)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#org/apache/spark/sql/catalyst/util/StringUtils$/fail$1(java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/$plus$plus$eq(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/result()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/Iterator/hasNext()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/runtime/BoxesRunTime/boxToCharacter(char)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/runtime/BoxesRunTime/unboxToChar(java.lang.Object)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/util/StringUtils/escapeLikeRegex(java.lang.String)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/$colon$colon/tl$1()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/find(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/toList()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/nonEmpty()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/List/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/ReorderJoin$$anonfun$3/3(org.apache.spark.sql.catalyst.optimizer.ReorderJoin,scala.collection.immutable.List)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/outputSet()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/partition(scala.Function1)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/ReorderJoin$$anonfun$createOrderedJoin$1/1(org.apache.spark.sql.catalyst.optimizer.ReorderJoin,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Tuple4/_4()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/ReorderJoin$$anonfun$1/1(org.apache.spark.sql.catalyst.optimizer.ReorderJoin)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/reduceLeft(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/ReorderJoin$$anonfun$2/2(org.apache.spark.sql.catalyst.optimizer.ReorderJoin,scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#org/apache/spark/sql/catalyst/optimizer/ReorderJoin$$anonfun$4/4(org.apache.spark.sql.catalyst.optimizer.ReorderJoin,org.apache.spark.sql.catalyst.expressions.AttributeSet)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/immutable/$colon$colon/head()
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/collection/Seq/reduceLeftOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ReorderJoin/createOrderedJoin(scala.collection.Seq,scala.collection.Seq)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Iterator/flatMap(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/containsStar(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Iterator/toList()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$expandStarExpression$1$$anonfun$applyOrElse$39/39(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$expandStarExpression$1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$expandStarExpression$1$$anonfun$applyOrElse$38/38(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$expandStarExpression$1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Expression/children()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$expandStarExpression$1$$anonfun$39/39(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$expandStarExpression$1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$expandStarExpression$1$$anonfun$38/38(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$expandStarExpression$1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/expandStarExpression/1/applyOrElse(org.apache.spark.sql.catalyst.expressions.Expression,scala.Function1)#scala/collection/Seq/grouped(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeStructToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,scala.collection.Seq,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeArrayToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$$anonfun$4$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$$anonfun$4)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#java/lang/String/trim()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/types/Decimal$/MAX_LONG_DIGITS()
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection$/org$apache$spark$sql$catalyst$expressions$codegen$GenerateUnsafeProjection$$writeMapToBuffer(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,java.lang.String,org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType,java.lang.String)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection/anonfun/4/apply(scala.Tuple2)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#scala/Option/isDefined()
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#org/apache/spark/sql/catalyst/IdentifierWithDatabase$class/org$apache$spark$sql$catalyst$IdentifierWithDatabase$$quoteIdentifier(org.apache.spark.sql.catalyst.IdentifierWithDatabase,java.lang.String)
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#org/apache/spark/sql/catalyst/IdentifierWithDatabase$$anonfun$1/1(org.apache.spark.sql.catalyst.IdentifierWithDatabase)
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#scala/Option/get()
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/IdentifierWithDatabase/class/quotedString(org.apache.spark.sql.catalyst.IdentifierWithDatabase)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/expressions()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$buildExpandedProjectList(scala.collection.Seq,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$apply$9$$anonfun$36/36(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$apply$9$$anonfun$applyOrElse$35/35(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9,org.apache.spark.sql.catalyst.plans.logical.ScriptTransformation)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/exists(scala.Function1)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$dedupRight(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/expressions/Expression/fastEquals(org.apache.spark.sql.catalyst.trees.TreeNode)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$apply$9$$anonfun$applyOrElse$36/36(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Sort/resolved()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$$outer()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/logTrace(scala.Function0)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Intersect/duplicateResolved()
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$apply$9$$anonfun$applyOrElse$6/6(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$$anonfun$apply$9$$anonfun$applyOrElse$34/34(org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/transformExpressionsUp(scala.PartialFunction)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/analysis/Analyzer$ResolveReferences$/containsStar(scala.collection.Seq)
org/apache/spark/sql/catalyst/analysis/Analyzer/ResolveReferences/anonfun/apply/9/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/Except/duplicateResolved()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$6(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$4(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$3(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/name()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Cast$/apply$default$3()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Alias$/apply$default$5(org.apache.spark.sql.catalyst.expressions.Expression,java.lang.String)
org/apache/spark/sql/catalyst/analysis/TypeCoercion/InConversion/anonfun/apply/4/anonfun/8/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/Attribute/dataType()
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin$$anonfun$apply$25$$anonfun$62/62(org.apache.spark.sql.catalyst.optimizer.ReplaceIntersectWithSemiJoin$$anonfun$apply$25)
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/Seq/reduceLeftOption(scala.Function2)
org/apache/spark/sql/catalyst/optimizer/ReplaceIntersectWithSemiJoin/anonfun/apply/25/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/output()
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#scala/collection/immutable/StringOps/stripSuffix(java.lang.String)
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/WeekOfYear/anonfun/doGenCode/11/apply(java.lang.String)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor$2$$anonfun$apply$1/1(org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor$2)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/JavaTypeInference$/org$apache$spark$sql$catalyst$JavaTypeInference$$getPath$1(org.spark_project.guava.reflect.TypeToken,scala.Option)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/JavaTypeInference$/inferDataType(java.lang.Class)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply(scala.Function1,org.apache.spark.sql.catalyst.expressions.Expression,org.apache.spark.sql.types.DataType,boolean,scala.Option)
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$6()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/JavaTypeInference$$anonfun$org$apache$spark$sql$catalyst$JavaTypeInference$$deserializerFor$2/apply()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$4()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/expressions/objects/Invoke$/apply$default$5()
org/apache/spark/sql/catalyst/JavaTypeInference/anonfun/org/apache/spark/sql/catalyst/JavaTypeInference/deserializerFor/2/apply()#org/apache/spark/sql/catalyst/expressions/objects/MapObjects$/apply$default$5()
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#scala/math/Ordering/reverse()
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/apply(int)
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#scala/math/Ordering/compare(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/InterpretedOrdering/compare(org.apache.spark.sql.catalyst.InternalRow,org.apache.spark.sql.catalyst.InternalRow)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#scala/util/Try/getOrElse(scala.Function0)
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#scala/util/Try$/apply(scala.Function0)
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#org/apache/spark/sql/types/StructType$$anonfun$6/6(java.lang.String)
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#org/apache/spark/sql/types/StructType$$anonfun$7/7(java.lang.String)
org/apache/spark/sql/types/StructType/fromString(java.lang.String)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/StructType$$anonfun$merge$1/1(scala.collection.mutable.ArrayBuffer,scala.collection.immutable.Map)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1()
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Option/isEmpty()
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayBuffer$/empty()
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/StructType$/apply(scala.collection.Seq)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/SparkException/SparkException(java.lang.String)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/StructType$$anonfun$merge$2/2(scala.collection.immutable.Map)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/filterNot(scala.Function1)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/StructType$$anonfun$merge$3/3(scala.collection.mutable.ArrayBuffer)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2()
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/foreach(scala.Function1)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/StructType$/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/StructType$/fieldsMap(org.apache.spark.sql.types.StructField[])
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_2$mcI$sp()
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/_1$mcI$sp()
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/types/StructType/merge(org.apache.spark.sql.types.DataType,org.apache.spark.sql.types.DataType)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Array$/apply(scala.collection.Seq,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$$anonfun$default$1/1()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#java/lang/String/getBytes(java.nio.charset.Charset)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/collection/immutable/Map$/apply(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/reflect/ClassTag$/Nothing()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/unsafe/types/CalendarInterval/CalendarInterval(int,long)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$/Map()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$/default(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$DummyImplicit$/dummyImplicit()
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/types/Decimal$/apply(long,int,int)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#org/apache/spark/sql/catalyst/InternalRow$/fromSeq(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/default(org.apache.spark.sql.types.DataType)#scala/Predef$/refArrayOps(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toByte()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/unsafe/types/CalendarInterval/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/sql/catalyst/expressions/Literal$/create(java.lang.Object,org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/sql/catalyst/expressions/Literal$/fromJSON(org.json4s.JsonAST$JValue)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/json4s/JsonAST$JString/s()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/sys/package$/error(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toBoolean()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/Decimal$/apply(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/Predef$/assert(boolean)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toInt()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toDouble()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#java/sql/Date/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/apache/spark/sql/types/DataType$/parseDataType(org.json4s.JsonAST$JValue)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toLong()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#java/sql/Timestamp/valueOf(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toShort()
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#org/json4s/MonadicJValue/$bslash(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/fromJSON(org.json4s.JsonAST$JValue)#scala/collection/immutable/StringOps/toFloat()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#org/apache/spark/sql/types/Decimal$/apply(java.math.BigDecimal)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#java/lang/Math/max(int,int)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#org/apache/spark/sql/catalyst/expressions/Literal$/componentTypeToDataType(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/fromJavaDate(java.sql.Date)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#java/math/BigDecimal/scale()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/math/BigDecimal/scale()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#java/lang/Class/getComponentType()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/boxToShort(short)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/boxToFloat(float)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#org/apache/spark/sql/types/Decimal$/apply(scala.math.BigDecimal)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/boxToBoolean(boolean)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/boxToByte(byte)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#java/math/BigDecimal/precision()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#org/apache/spark/sql/catalyst/CatalystTypeConverters$/createToCatalystConverter(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/ScalaRunTime$/isArray(java.lang.Object,int)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/math/BigDecimal/precision()
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#org/apache/spark/sql/catalyst/util/DateTimeUtils$/fromJavaTimestamp(java.sql.Timestamp)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/apply(java.lang.Object)#org/apache/spark/sql/types/ArrayType$/apply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#java/lang/Class/isArray()
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#org/apache/spark/sql/types/DecimalType$/SYSTEM_DEFAULT()
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#java/lang/Class/getComponentType()
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#org/apache/spark/sql/types/ArrayType$/apply(org.apache.spark.sql.types.DataType)
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#org/apache/spark/sql/catalyst/expressions/Literal$/componentTypeToDataType(java.lang.Class)
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/expressions/Literal/componentTypeToDataType(java.lang.Class)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/augmentString(java.lang.String)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/String/trim()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/StringOps/StringOps(java.lang.String)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/collection/immutable/StringOps/stripMargin()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/treeString(boolean,boolean)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/treeString$default$2()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
org/apache/spark/sql/catalyst/optimizer/CheckCartesianProducts/anonfun/apply/20/applyOrElse(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,scala.Function1)#scala/Function1/apply(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#java/util/Arrays/hashCode(byte[])
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#java/lang/Double/doubleToLongBits(double)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#java/lang/Float/floatToIntBits(float)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#java/lang/Object/hashCode()
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/BaseGenericInternalRow/class/hashCode(org.apache.spark.sql.catalyst.expressions.BaseGenericInternalRow)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/lang/StringBuffer/delete(int,int)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/text/DecimalFormat/format(long)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/lang/StringBuffer/toString()
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/text/DecimalFormat/format(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/text/DecimalFormat/applyLocalizedPattern(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/Some/x()
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/lang/StringBuffer/length()
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/Some/Some(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/lang/StringBuffer/append(java.lang.String)
org/apache/spark/sql/catalyst/expressions/FormatNumber/nullSafeEval(java.lang.Object,java.lang.Object)#java/text/DecimalFormat/format(double)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/collection/immutable/List$/canBuildFrom()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/JsonAST$JString$/apply(java.lang.String)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/JsonAST$JInt$/apply(scala.math.BigInt)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/JsonAST$JBool$/apply(boolean)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/JsonAST$JArray$/apply(scala.collection.immutable.List)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/package$/JObject()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/package$/JInt()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/package$/JBool()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/package$/JDouble()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/package$/JString()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/math/BigInt$/long2bigInt(long)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/apache/spark/sql/types/Metadata$$anonfun$1/1()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/JsonAST$JObject$/apply(scala.collection.immutable.List)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/apache/spark/sql/types/Metadata$$anonfun$2/2()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/collection/mutable/ArrayOps/toList()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/runtime/ScalaRunTime$/isArray(java.lang.Object,int)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#java/lang/Object/getClass()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/JsonAST$JDouble$/apply(double)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/collection/immutable/Map/toList()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#org/json4s/package$/JArray()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$toJsonValue(java.lang.Object)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/collection/immutable/Map/mapValues(scala.Function1)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#org/apache/spark/sql/types/Metadata$$anonfun$org$apache$spark$sql$types$Metadata$$hash$1/1()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#org/apache/spark/sql/types/Metadata$$anonfun$org$apache$spark$sql$types$Metadata$$hash$2/2()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/runtime/ScalaRunTime$/hash(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/runtime/ScalaRunTime$/isArray(java.lang.Object,int)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#java/lang/Object/getClass()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/collection/mutable/ArrayOps/toSeq()
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/runtime/BoxesRunTime/boxToLong(long)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/runtime/BoxesRunTime/boxToDouble(double)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)
org/apache/spark/sql/types/Metadata/org$apache$spark$sql$types$Metadata$$hash(java.lang.Object)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#scala/collection/immutable/Set/$plus$plus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#scala/collection/immutable/Set/$minus$minus(scala.collection.GenTraversableOnce)
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/plans/QueryPlan$$anonfun$2/2(org.apache.spark.sql.catalyst.plans.QueryPlan)
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#org/apache/spark/sql/catalyst/plans/QueryPlan$$anonfun$1/1(org.apache.spark.sql.catalyst.plans.QueryPlan)
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#scala/collection/immutable/Set$/canBuildFrom()
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#scala/collection/immutable/Set/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#scala/collection/TraversableOnce/toSet()
org/apache/spark/sql/catalyst/plans/QueryPlan/constructIsNotNullConstraints(scala.collection.immutable.Set)#scala/collection/Seq/filterNot(scala.Function1)
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/IterableLike/forall(scala.Function1)
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/SubqueryExpression$$anonfun$semanticEquals$1/1(org.apache.spark.sql.catalyst.expressions.SubqueryExpression)
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/SubqueryExpression/children()
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/expressions/SubqueryExpression/plan()
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#org/apache/spark/sql/catalyst/plans/logical/LogicalPlan/sameResult(org.apache.spark.sql.catalyst.plans.QueryPlan)
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/String/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#java/lang/Object/getClass()
org/apache/spark/sql/catalyst/expressions/SubqueryExpression/semanticEquals(org.apache.spark.sql.catalyst.expressions.Expression)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#java/lang/String/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#java/lang/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#javax/xml/xpath/XPath/compile(java.lang.String)
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#java/lang/StringBuilder/append(java.lang.String)
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#javax/xml/xpath/XPathExpression/evaluate(org.xml.sax.InputSource,javax.xml.namespace.QName)
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#java/lang/String/length()
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil$ReusableStringReader/set(java.lang.String)
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#java/lang/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/xml/UDFXPathUtil/eval(java.lang.String,java.lang.String,javax.xml.namespace.QName)#javax/xml/xpath/XPathExpressionException/getMessage()
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/Predef$/genericArrayOps(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.CreateMap,org.apache.spark.sql.catalyst.InternalRow)
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$4/4(org.apache.spark.sql.catalyst.expressions.CreateMap,org.apache.spark.sql.catalyst.InternalRow)
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/mutable/ArrayOps/contains(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/CreateMap/values()
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/immutable/IndexedSeq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/immutable/IndexedSeq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/CreateMap/eval(org.apache.spark.sql.catalyst.InternalRow)#java/lang/RuntimeException/RuntimeException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$checkInputDataTypes$5/5(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$checkInputDataTypes$4/4(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/SeqLike/length()
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$checkInputDataTypes$3/3(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$checkInputDataTypes$2/2(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/immutable/IndexedSeq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/immutable/IndexedSeq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/analysis/TypeCheckResult$TypeCheckFailure/TypeCheckFailure(java.lang.String)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#org/apache/spark/sql/catalyst/expressions/CreateMap/values()
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/Seq/size()
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/mutable/StringBuilder/append(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/SeqLike/distinct()
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateMap/checkInputDataTypes()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/_1()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/_2()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.CreateMap,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_1()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/_3()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/GenArrayData$/genCodeToCreateArrayData(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.types.DataType,scala.collection.Seq,boolean)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$7/7(org.apache.spark.sql.catalyst.expressions.CreateMap,org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/_4()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#org/apache/spark/sql/catalyst/expressions/CreateMap/values()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/IndexedSeq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/collection/immutable/IndexedSeq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#java/lang/Class/getName()
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateMap/doGenCode(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)#scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$dataType$8/8(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$dataType$7/7(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$dataType$5/5(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$dataType$4/4(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#org/apache/spark/sql/catalyst/expressions/CreateMap/values()
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#scala/Option/map(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#scala/collection/immutable/IndexedSeq/exists(scala.Function1)
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#org/apache/spark/sql/catalyst/expressions/CreateMap$$anonfun$dataType$6/6(org.apache.spark.sql.catalyst.expressions.CreateMap)
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#scala/collection/immutable/IndexedSeq/headOption()
org/apache/spark/sql/catalyst/expressions/CreateMap/dataType()#scala/Option/getOrElse(scala.Function0)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$recordCompilationStats$1$$anonfun$apply$4/4(org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#scala/util/control/NonFatal$/unapply(java.lang.Throwable)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#org/apache/spark/metrics/source/CodegenMetrics$/METRIC_GENERATED_CLASS_BYTECODE_SIZE()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#scala/Tuple2/_2()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#com/codahale/metrics/Histogram/update(int)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#scala/MatchError/MatchError(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$recordCompilationStats$1$$anonfun$apply$6/6(org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#org/codehaus/janino/util/ClassFile/ClassFile(java.io.InputStream)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/logWarning(scala.Function0,java.lang.Throwable)
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#scala/Option/get()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#java/io/ByteArrayInputStream/ByteArrayInputStream(byte[])
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#scala/Option/isEmpty()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#scala/collection/convert/Decorators$AsScala/asScala()
org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator/anonfun/recordCompilationStats/1/apply(scala.Tuple2)#scala/collection/IterableLike/foreach(scala.Function1)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/Some/x()
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/Option/foreach(scala.Function1)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#org/apache/spark/sql/catalyst/parser/ParseException$$anonfun$getMessage$1/1(org.apache.spark.sql.catalyst.parser.ParseException,scala.collection.mutable.StringBuilder,int,int)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/Predef$/wrapRefArray(java.lang.Object[])
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#org/apache/spark/sql/catalyst/parser/ParseException$$anonfun$getMessage$2/2(org.apache.spark.sql.catalyst.parser.ParseException,scala.collection.mutable.StringBuilder)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/collection/mutable/StringBuilder/$plus$plus$eq(java.lang.String)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/StringContext/StringContext(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/runtime/BoxesRunTime/boxToInteger(int)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/collection/mutable/StringBuilder/StringBuilder()
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/Predef$/genericWrapArray(java.lang.Object)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/StringContext/s(scala.collection.Seq)
org/apache/spark/sql/catalyst/parser/ParseException/getMessage()#scala/collection/mutable/StringBuilder/toString()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonParser/getTextLength()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#java/lang/IllegalStateException/IllegalStateException(java.lang.String)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonParser/getTextCharacters()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonGenerator/writeRaw(java.lang.String)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonParser/hasTextCharacters()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonGenerator/writeRaw(char[],int,int)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonParser/getText()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonGenerator/copyCurrentStructure(com.fasterxml.jackson.core.JsonParser)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonParser/getCurrentToken()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$copyCurrentStructure(com.fasterxml.jackson.core.JsonGenerator,com.fasterxml.jackson.core.JsonParser)#com/fasterxml/jackson/core/JsonParser/getTextOffset()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/reflect/ClassTag$/Any()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/JsonTuple$$anonfun$5/5(org.apache.spark.sql.catalyst.expressions.JsonTuple,org.apache.spark.sql.catalyst.InternalRow)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#java/io/ByteArrayOutputStream/toByteArray()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/length()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/JsonTuple$$anonfun$6/6(org.apache.spark.sql.catalyst.expressions.JsonTuple,org.apache.spark.sql.catalyst.InternalRow)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#java/lang/Object/equals(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/immutable/Nil$/$colon$colon(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/IndexedSeq$/canBuildFrom()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/JsonTuple$$anonfun$org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow$1/1(org.apache.spark.sql.catalyst.expressions.JsonTuple,java.io.ByteArrayOutputStream)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/sql/catalyst/expressions/JsonTuple$$anonfun$org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow$2/2(org.apache.spark.sql.catalyst.expressions.JsonTuple,com.fasterxml.jackson.core.JsonParser)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#com/fasterxml/jackson/core/JsonParser/getCurrentName()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/IndexedSeq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#com/fasterxml/jackson/core/JsonParser/getCurrentToken()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/Array$/ofDim(int,scala.reflect.ClassTag)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/indexOf(java.lang.Object)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/unsafe/types/UTF8String/fromBytes(byte[])
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#com/fasterxml/jackson/core/JsonParser/skipChildren()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#java/io/ByteArrayOutputStream/ByteArrayOutputStream()
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#org/apache/spark/util/Utils$/tryWithResource(scala.Function0,scala.Function1)
org/apache/spark/sql/catalyst/expressions/JsonTuple/org$apache$spark$sql$catalyst$expressions$JsonTuple$$parseRow(com.fasterxml.jackson.core.JsonParser,org.apache.spark.sql.catalyst.InternalRow)#com/fasterxml/jackson/core/JsonParser/nextToken()
